{
  "shortest_processing_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    return min(feasible_operations, key=lambda x: x[2])\n",
  "longest_processing_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    return max(feasible_operations, key=lambda x: x[2])\n",
  "earliest_idle_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    return min(feasible_operations, key=lambda x: machine_status[x[1]])\n",
  "latest_idle_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    return max(feasible_operations, key=lambda x: machine_status[x[1]])\n",
  "earliest_available_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    job_status = current_status['job_status']\n    return min(feasible_operations, key=lambda x: job_status[x[0]])\n",
  "balanced_machine_load": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    return min(feasible_operations, key=lambda x: (machine_status[x[1]], x[2]))\n",
  "weighted_spt_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    \n    proc_norm = proc_times / (np.mean(proc_times) + 1e-9)\n    mach_norm = mach_times / (np.mean(mach_times) + 1e-9)\n    \n    scores = 0.6 * proc_norm + 0.4 * mach_norm\n    return feasible_operations[int(np.argmin(scores))]\n",
  "job_machine_balance": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    scores = [machine_status[op[1]] + job_status[op[0]] + op[2] for op in feasible_operations]\n    return feasible_operations[int(np.argmin(scores))]\n",
  "minimal_start_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    start_times = [max(machine_status[op[1]], job_status[op[0]]) for op in feasible_operations]\n    return feasible_operations[int(np.argmin(start_times))]\n",
  "minimal_completion_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    completion_times = [max(machine_status[op[1]], job_status[op[0]]) + op[2] for op in feasible_operations]\n    return feasible_operations[int(np.argmin(completion_times))]\n",
  "machine_utilization_max": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    # Negative processing time for machines with low status (more idle)\n    scores = [machine_status[op[1]] - 2.0 * op[2] for op in feasible_operations]\n    return feasible_operations[int(np.argmin(scores))]\n",
  "random_choice": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    seed = int(sum(machine_status) + sum(job_status)) % (2**31)\n    rng = np.random.default_rng(seed)\n    idx = int(rng.integers(0, len(feasible_operations)))\n    return feasible_operations[idx]\n",
  "alternating_spt_lpt": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    job_status = current_status['job_status']\n    \n    mode = int(sum(job_status)) % 2\n    if mode == 0:\n        return min(feasible_operations, key=lambda x: x[2])\n    else:\n        return max(feasible_operations, key=lambda x: x[2])\n",
  "processing_time_percentile": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    \n    proc_times = np.array([op[2] for op in feasible_operations])\n    target = float(np.percentile(proc_times, 40))\n    \n    deviations = np.abs(proc_times - target)\n    return feasible_operations[int(np.argmin(deviations))]\n",
  "machine_variance_min": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    best_op = None\n    best_var = float('inf')\n    \n    for op in feasible_operations:\n        new_status = machine_status.copy()\n        new_status[op[1]] = max(machine_status[op[1]], job_status[op[0]]) + op[2]\n        var = float(np.var(new_status))\n        if var < best_var:\n            best_var = var\n            best_op = op\n    \n    return best_op\n",
  "slack_time_priority": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    slacks = [abs(machine_status[op[1]] - job_status[op[0]]) for op in feasible_operations]\n    return feasible_operations[int(np.argmin(slacks))]\n",
  "bottleneck_machine_avoid": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    # Find operations NOT on the busiest machine\n    max_status = max(machine_status)\n    non_bottleneck = [op for op in feasible_operations if machine_status[op[1]] < max_status]\n    \n    candidates = non_bottleneck if non_bottleneck else feasible_operations\n    return min(candidates, key=lambda x: x[2])\n",
  "job_id_priority": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    return min(feasible_operations, key=lambda x: (x[0], x[2]))\n",
  "machine_id_priority": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    return min(feasible_operations, key=lambda x: (x[1], x[2]))\n",
  "weighted_job_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    job_times = np.array([job_status[op[0]] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    \n    job_norm = job_times / (np.mean(job_times) + 1e-9)\n    mach_norm = mach_times / (np.mean(mach_times) + 1e-9)\n    \n    scores = 0.5 * job_norm + 0.5 * mach_norm\n    return feasible_operations[int(np.argmin(scores))]\n",
  "adaptive_spt_lpt": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    progress = np.mean(machine_status) / (max(machine_status) + 1e-9)\n    \n    if progress < 0.4:\n        return max(feasible_operations, key=lambda x: x[2])\n    else:\n        return min(feasible_operations, key=lambda x: x[2])\n",
  "max_machine_min_processing": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    mach_times = [machine_status[op[1]] for op in feasible_operations]\n    max_time = max(mach_times)\n    \n    candidates = [op for op, mt in zip(feasible_operations, mach_times) if mt == max_time]\n    return min(candidates, key=lambda x: x[2])\n",
  "composite_three_factor": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times = np.array([job_status[op[0]] for op in feasible_operations], dtype=float)\n    \n    proc_norm = proc_times / (np.mean(proc_times) + 1e-9)\n    mach_norm = mach_times / (np.mean(mach_times) + 1e-9)\n    job_norm = job_times / (np.mean(job_times) + 1e-9)\n    \n    scores = 0.4 * proc_norm + 0.3 * mach_norm + 0.3 * job_norm\n    return feasible_operations[int(np.argmin(scores))]\n",
  "exponential_processing_weight": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    weights = np.exp(-proc_times / (np.mean(proc_times) + 1e-9))\n    \n    machine_status = current_status['machine_status']\n    seed = int(sum(machine_status)) % (2**31)\n    rng = np.random.default_rng(seed)\n    \n    probs = weights / (np.sum(weights) + 1e-9)\n    idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n",
  "round_robin_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    # Group by job_id\n    jobs = {}\n    for op in feasible_operations:\n        if op[0] not in jobs:\n            jobs[op[0]] = []\n        jobs[op[0]].append(op)\n    \n    # Pick job with lowest total machine time, then shortest operation\n    best_job = min(jobs.keys(), key=lambda j: sum([machine_status[o[1]] for o in jobs[j]]))\n    return min(jobs[best_job], key=lambda x: x[2])\n",
  "ratio_processing_availability": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    ratios = [op[2] / (machine_status[op[1]] + 1.0) for op in feasible_operations]\n    return feasible_operations[int(np.argmin(ratios))]\n",
  "stochastic_greedy": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    \n    # Lower processing time = higher probability\n    inv_times = 1.0 / (proc_times + 1e-9)\n    probs = inv_times / (np.sum(inv_times) + 1e-9)\n    \n    seed = int(sum(machine_status) + sum(job_status)) % (2**31)\n    rng = np.random.default_rng(seed)\n    \n    idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n",
  "hybrid_makespan_estimator": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    best_op = None\n    best_makespan = float('inf')\n    \n    for op in feasible_operations:\n        new_mach_status = machine_status.copy()\n        new_job_status = job_status.copy()\n        \n        start = max(machine_status[op[1]], job_status[op[0]])\n        new_mach_status[op[1]] = start + op[2]\n        new_job_status[op[0]] = start + op[2]\n        \n        makespan = max(max(new_mach_status), max(new_job_status))\n        if makespan < best_makespan:\n            best_makespan = makespan\n            best_op = op\n    \n    return best_op\n",
  "normalized_multi_objective": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times = np.array([job_status[op[0]] for op in feasible_operations], dtype=float)\n    \n    def minmax_norm(x):\n        mn, mx = x.min(), x.max()\n        if mx - mn < 1e-9:\n            return np.zeros_like(x)\n        return (x - mn) / (mx - mn + 1e-9)\n    \n    proc_norm = minmax_norm(proc_times)\n    mach_norm = minmax_norm(mach_times)\n    job_norm = minmax_norm(job_times)\n    \n    scores = proc_norm + mach_norm + job_norm\n    return feasible_operations[int(np.argmin(scores))]\n",
  "idle_time_minimizer": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n    \n    idle_times = [max(0, job_status[op[0]] - machine_status[op[1]]) for op in feasible_operations]\n    return feasible_operations[int(np.argmin(idle_times))]\n",
  "priority_score_blend": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    \n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_loads = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    \n    inv_proc = 1.0 / (proc_times + 1e-9)\n    inv_mach = 1.0 / (mach_loads + 1.0)\n    \n    scores = inv_proc + inv_mach\n    return feasible_operations[int(np.argmax(scores))]\n",
  "earliest_start_longest_processing": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    def key(op):\n        start = max(ms[op[1]], js[op[0]])\n        return (start, -op[2], ms[op[1]])\n    return min(feasible_operations, key=key)\n",
  "latest_start_shortest_processing": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    def key(op):\n        start = max(ms[op[1]], js[op[0]])\n        return (-start, op[2], js[op[0]])\n    return min(feasible_operations, key=key)\n",
  "job_waiting_pressure": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    # waiting = machine_time - job_time (positive means job is blocked by the machine)\n    pressures = [max(0.0, float(ms[op[1]] - js[op[0]])) for op in feasible_operations]\n    # Break ties by shorter processing to release the machine quickly\n    best = int(np.argmax(pressures))\n    best_pressure = pressures[best]\n    candidates = [op for op, p in zip(feasible_operations, pressures) if abs(p - best_pressure) < 1e-12]\n    return min(candidates, key=lambda op: op[2])\n",
  "machine_waiting_pressure": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    # waiting = job_time - machine_time (positive means machine is blocked by the job)\n    pressures = [max(0.0, float(js[op[0]] - ms[op[1]])) for op in feasible_operations]\n    # Break ties by longest processing to avoid future fragmentation\n    best = int(np.argmax(pressures))\n    best_pressure = pressures[best]\n    candidates = [op for op, p in zip(feasible_operations, pressures) if abs(p - best_pressure) < 1e-12]\n    return max(candidates, key=lambda op: op[2])\n",
  "gini_machine_load_reducer": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = current_status['job_status']\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        return float((n + 1 - 2 * np.sum(cum) / (cum[-1] + 1e-12)) / n)\n\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        val = gini(ms)\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n    return best_op\n",
  "gini_job_completion_reducer": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        return float((n + 1 - 2 * np.sum(cum) / (cum[-1] + 1e-12)) / n)\n\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(float(ms[op[1]]), js[op[0]])\n        js[op[0]] = start + float(op[2])\n        val = gini(js)\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n    return best_op\n",
  "minimize_max_machine_time_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = current_status['job_status']\n\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        val = float(ms.max())\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12:\n            # tie-break: earlier start\n            s_best = max(ms0[best_op[1]], float(js[best_op[0]]))\n            s_now = max(ms0[op[1]], float(js[op[0]]))\n            if s_now < s_best - 1e-12:\n                best_op = op\n    return best_op\n",
  "minimize_max_job_time_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(float(ms[op[1]]), js[op[0]])\n        js[op[0]] = start + float(op[2])\n        val = float(js.max())\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n    return best_op\n",
  "variance_adaptive_weighting": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    v = float(np.var(ms))\n    # High variance -> emphasize balancing (availability); low variance -> emphasize processing time\n    w_avail = v / (v + 1.0)\n    w_proc = 1.0 - w_avail\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    start = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n\n    proc_n = proc / (np.mean(proc) + 1e-12)\n    start_n = start / (np.mean(start) + 1e-12)\n\n    score = w_proc * proc_n + w_avail * start_n\n    return feasible_operations[int(np.argmin(score))]\n",
  "dynamic_percentile_target": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    imbalance = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    # More imbalance -> target longer ops (higher percentile) to stabilize busy machines; else shorter ops\n    pct = 30.0 + 50.0 * min(1.0, imbalance)\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    target = float(np.percentile(proc, pct))\n    idx = int(np.argmin(np.abs(proc - target)))\n    return feasible_operations[idx]\n",
  "least_loaded_machine_then_lpt": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    loads = [ms[op[1]] for op in feasible_operations]\n    min_load = min(loads)\n    candidates = [op for op, ld in zip(feasible_operations, loads) if ld == min_load]\n    return max(candidates, key=lambda op: op[2])\n",
  "most_loaded_machine_then_earliest_start": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    loads = [ms[op[1]] for op in feasible_operations]\n    max_load = max(loads)\n    candidates = [op for op, ld in zip(feasible_operations, loads) if ld == max_load]\n\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]), op[2]))\n",
  "regret_min_completion_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    by_m = {}\n    for op in feasible_operations:\n        m = op[1]\n        start = max(ms[m], js[op[0]])\n        comp = start + op[2]\n        by_m.setdefault(m, []).append((comp, op))\n\n    best_op, best_regret = None, -float('inf')\n    for m, lst in by_m.items():\n        lst.sort(key=lambda x: x[0])\n        if len(lst) == 1:\n            regret = float('inf')\n            chosen = lst[0][1]\n        else:\n            regret = float(lst[1][0] - lst[0][0])\n            chosen = lst[0][1]\n        # Maximize regret (protect scarce good choices)\n        if regret > best_regret:\n            best_regret = regret\n            best_op = chosen\n        elif abs(regret - best_regret) < 1e-12:\n            # tie-break: shorter completion\n            s1 = max(ms[best_op[1]], js[best_op[0]]) + best_op[2]\n            s2 = max(ms[chosen[1]], js[chosen[0]]) + chosen[2]\n            if s2 < s1:\n                best_op = chosen\n    return best_op\n",
  "epsilon_greedy_completion": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    comp = np.array([max(ms[op[1]], js[op[0]]) + op[2] for op in feasible_operations], dtype=float)\n    greedy_idx = int(np.argmin(comp))\n\n    # Exploration rate increases when schedule is very imbalanced\n    imbalance = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    eps = min(0.35, 0.05 + 0.30 * min(1.0, imbalance))\n\n    seed = int(np.sum(ms) + 7 * np.sum(js)) % (2**31)\n    rng = np.random.default_rng(seed)\n    if float(rng.random()) < eps:\n        # Explore among top-k by completion time\n        k = min(3, len(feasible_operations))\n        topk = np.argsort(comp)[:k]\n        return feasible_operations[int(topk[int(rng.integers(0, k))])]\n    return feasible_operations[greedy_idx]\n",
  "softmax_makespan_delta": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    cur_ms = float(max(ms0.max(), js0.max()))\n    deltas = []\n    for op in feasible_operations:\n        ms = ms0.copy(); js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        finish = start + float(op[2])\n        ms[op[1]] = finish\n        js[op[0]] = finish\n        new_ms = float(max(ms.max(), js.max()))\n        deltas.append(new_ms - cur_ms)\n\n    deltas = np.array(deltas, dtype=float)\n    # Lower delta -> higher probability\n    scale = np.std(deltas) + 1e-9\n    logits = -deltas / scale\n    logits = logits - np.max(logits)\n    probs = np.exp(logits)\n    probs = probs / (np.sum(probs) + 1e-12)\n\n    seed = int(np.sum(ms0) + 13 * np.sum(js0)) % (2**31)\n    rng = np.random.default_rng(seed)\n    idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n",
  "avoid_last_machine_if_possible": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    last_m = current_status.get('last_machine', None)\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    if last_m is None:\n        # fallback: earliest completion\n        return min(feasible_operations, key=lambda op: max(ms[op[1]], js[op[0]]) + op[2])\n\n    non_last = [op for op in feasible_operations if op[1] != last_m]\n    candidates = non_last if non_last else feasible_operations\n\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]) + op[2], op[2]))\n",
  "avoid_last_job_if_possible": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    last_j = current_status.get('last_job', None)\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    if last_j is None:\n        return min(feasible_operations, key=lambda op: max(ms[op[1]], js[op[0]]) + op[2])\n\n    non_last = [op for op in feasible_operations if op[0] != last_j]\n    candidates = non_last if non_last else feasible_operations\n\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]), op[2]))\n",
  "wait_then_process_tradeoff": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    waits = np.array([abs(ms[op[1]] - js[op[0]]) for op in feasible_operations], dtype=float)\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    alpha = float(np.mean(waits) / (np.mean(proc) + 1e-12))\n    score = waits + alpha * proc\n    return feasible_operations[int(np.argmin(score))]\n",
  "min_idle_then_min_gini": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        return float((n + 1 - 2 * np.sum(cum) / (cum[-1] + 1e-12)) / n)\n\n    best_op = None\n    best_key = None\n    for op in feasible_operations:\n        idle = max(0.0, js[op[0]] - ms0[op[1]])\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        key = (idle, gini(ms), op[2])\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n    return best_op\n",
  "criticality_ratio_focus": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    med = float(np.median(ms))\n    def score(op):\n        m = op[1]\n        start = max(ms[m], js[op[0]])\n        critical = max(0.0, ms[m] - med)\n        return (-critical / (start + 1.0), start, op[2])\n\n    return min(feasible_operations, key=score)\n",
  "harmonic_blend_score": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_val = None, -float('inf')\n    for op in feasible_operations:\n        start = max(ms[op[1]], js[op[0]])\n        proc = float(op[2])\n        load = float(ms[op[1]])\n        a = 1.0 / (proc + 1e-12)\n        b = 1.0 / (start + 1.0)\n        c = 1.0 / (load + 1.0)\n        hm = 3.0 / (1.0/(a+1e-12) + 1.0/(b+1e-12) + 1.0/(c+1e-12))\n        if hm > best_val + 1e-12:\n            best_val, best_op = hm, op\n        elif abs(hm - best_val) < 1e-12:\n            # tie-break: earlier completion\n            if start + proc < max(ms[best_op[1]], js[best_op[0]]) + best_op[2]:\n                best_op = op\n    return best_op\n",
  "two_stage_filter_then_score": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms0[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    min_s = float(starts.min())\n    q = float(np.percentile(starts, 25) - min_s)\n    threshold = min_s + max(0.0, q)\n\n    filtered = [op for op, s in zip(feasible_operations, starts) if s <= threshold + 1e-12]\n    candidates = filtered if filtered else feasible_operations\n\n    best_op, best_val = None, float('inf')\n    for op in candidates:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        # dispersion proxy: mean absolute deviation\n        mad = float(np.mean(np.abs(ms - np.mean(ms))))\n        key = (mad, start + float(op[2]), op[2])\n        if best_op is None or key < best_val:\n            best_val = key\n            best_op = op\n    return best_op\n",
  "earliest_completion_shortest_processing": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (max(ms[op[1]], js[op[0]]) + op[2], op[2], max(ms[op[1]], js[op[0]])))\n",
  "earliest_completion_longest_processing": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (max(ms[op[1]], js[op[0]]) + op[2], -op[2], max(ms[op[1]], js[op[0]])))\n",
  "min_slack_to_mean_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mu = float(np.mean(ms))\n    def key(op):\n        start = max(ms[op[1]], js[op[0]])\n        slack = start - mu\n        return (slack, op[2], start)\n    return min(feasible_operations, key=key)\n",
  "max_slack_to_mean_time": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mu = float(np.mean(ms))\n    def key(op):\n        start = max(ms[op[1]], js[op[0]])\n        slack = start - mu\n        return (-slack, op[2], start)\n    return min(feasible_operations, key=key)\n",
  "zscore_machine_priority": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mu = float(np.mean(ms))\n    sd = float(np.std(ms) + 1e-12)\n    def key(op):\n        m = op[1]\n        z = (ms[m] - mu) / sd\n        start = max(ms[m], js[op[0]])\n        return (-z, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "zscore_job_priority": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mu = float(np.mean(js))\n    sd = float(np.std(js) + 1e-12)\n    def key(op):\n        j = op[0]\n        z = (js[j] - mu) / sd\n        start = max(ms[op[1]], js[j])\n        return (-z, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "min_pairwise_makespan_gap": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy(); js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        fin = start + float(op[2])\n        ms[op[1]] = fin\n        js[op[0]] = fin\n        val = abs(float(ms.max()) - float(js.max()))\n        key = (val, fin, op[2])\n        if best_op is None or key < best_val:\n            best_val = key\n            best_op = op\n    return best_op\n",
  "min_mean_absolute_deviation_machines": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        mu = float(np.mean(ms))\n        mad = float(np.mean(np.abs(ms - mu)))\n        key = (mad, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n    return best_op\n",
  "min_mean_absolute_deviation_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        mu = float(np.mean(js))\n        mad = float(np.mean(np.abs(js - mu)))\n        key = (mad, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n    return best_op\n",
  "entropy_balanced_machines": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def entropy(x):\n        x = np.asarray(x, dtype=float)\n        s = float(np.sum(x))\n        if s <= 1e-12:\n            return 0.0\n        p = x / s\n        p = np.clip(p, 1e-12, 1.0)\n        return float(-np.sum(p * np.log(p)))\n\n    best_op, best_val = None, -float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        val = entropy(ms)\n        key = (val, -(start + float(op[2])))\n        if best_op is None or key > (best_val, float('-inf')):\n            best_val = val\n            best_op = op\n    return best_op\n",
  "entropy_balanced_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def entropy(x):\n        x = np.asarray(x, dtype=float)\n        s = float(np.sum(x))\n        if s <= 1e-12:\n            return 0.0\n        p = x / s\n        p = np.clip(p, 1e-12, 1.0)\n        return float(-np.sum(p * np.log(p)))\n\n    best_op, best_val = None, -float('inf')\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        val = entropy(js)\n        if val > best_val + 1e-12:\n            best_val = val\n            best_op = op\n        elif abs(val - best_val) < 1e-12:\n            # tie-break: earlier completion\n            if start + op[2] < max(ms[best_op[1]], js0[best_op[0]]) + best_op[2]:\n                best_op = op\n    return best_op\n",
  "median_machine_pull": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    med = float(np.median(ms))\n    def key(op):\n        m = op[1]\n        dist = abs(ms[m] - med)\n        start = max(ms[m], js[op[0]])\n        return (dist, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "quantile_machine_pull_25": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    q = float(np.percentile(ms, 25))\n    def key(op):\n        m = op[1]\n        dist = abs(ms[m] - q)\n        start = max(ms[m], js[op[0]])\n        return (dist, start, -op[2])\n    return min(feasible_operations, key=key)\n",
  "quantile_machine_pull_75": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    q = float(np.percentile(ms, 75))\n    def key(op):\n        m = op[1]\n        dist = abs(ms[m] - q)\n        start = max(ms[m], js[op[0]])\n        return (dist, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "min_idle_ratio": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    def key(op):\n        idle = max(0.0, js[op[0]] - ms[op[1]])\n        ratio = idle / (float(op[2]) + 1.0)\n        start = max(ms[op[1]], js[op[0]])\n        return (ratio, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "max_idle_ratio": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    def key(op):\n        idle = max(0.0, js[op[0]] - ms[op[1]])\n        ratio = idle / (float(op[2]) + 1.0)\n        start = max(ms[op[1]], js[op[0]])\n        return (-ratio, op[2], start)\n    return min(feasible_operations, key=key)\n",
  "local_best_in_machine_competition": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    by_m = {}\n    for op in feasible_operations:\n        m = op[1]\n        start = max(ms[m], js[op[0]])\n        comp = start + op[2]\n        by_m.setdefault(m, []).append((comp, op))\n\n    reps = []\n    for m, lst in by_m.items():\n        lst.sort(key=lambda x: x[0])\n        best_comp, best_op = lst[0]\n        second = lst[1][0] if len(lst) > 1 else best_comp + 1e9\n        regret = float(second - best_comp)\n        reps.append((regret, best_comp, best_op))\n\n    # pick machine whose best option is most \"fragile\" (largest regret)\n    reps.sort(key=lambda t: (-t[0], t[1]))\n    return reps[0][2]\n",
  "completion_time_gap_to_best": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    comps = [max(ms[op[1]], js[op[0]]) + op[2] for op in feasible_operations]\n    best = min(comps)\n    gaps = [c - best for c in comps]\n    mx = max(gaps)\n    candidates = [op for op, g in zip(feasible_operations, gaps) if abs(g - mx) < 1e-12]\n    # tie-break: earliest start among the worst-gap set\n    return min(candidates, key=lambda op: max(ms[op[1]], js[op[0]]))\n",
  "min_completion_time_gap_to_best": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    comps = [max(ms[op[1]], js[op[0]]) + op[2] for op in feasible_operations]\n    best = min(comps)\n    gaps = [c - best for c in comps]\n    mn = min(gaps)\n    candidates = [op for op, g in zip(feasible_operations, gaps) if abs(g - mn) < 1e-12]\n    # tie-break: prefer ops on less-loaded machines\n    return min(candidates, key=lambda op: (ms[op[1]], op[2]))\n",
  "min_squared_load_after_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = current_status['job_status']\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        val = float(np.sum(ms * ms))\n        key = (val, start + float(op[2]), op[2])\n        if best_op is None or key < best_val:\n            best_val = key\n            best_op = op\n    return best_op\n",
  "min_squared_load_after_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        val = float(np.sum(js * js))\n        key = (val, start + float(op[2]), op[2])\n        if best_op is None or key < best_val:\n            best_val = key\n            best_op = op\n    return best_op\n",
  "inverse_temperature_rank_blend": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    procs = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # ranks: 0 best\n    r_start = np.argsort(np.argsort(starts))\n    r_proc = np.argsort(np.argsort(procs))\n\n    imb = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    temp = 1.0 / (1.0 + 3.0 * min(1.0, imb))\n\n    score = temp * r_proc + (1.0 - temp) * r_start\n    return feasible_operations[int(np.argmin(score))]\n",
  "deterministic_hash_round_robin_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int(np.sum(ms) + 31 * np.sum(js)) & 0x7fffffff\n\n    # group by job\n    by_j = {}\n    for op in feasible_operations:\n        by_j.setdefault(op[0], []).append(op)\n\n    jobs = sorted(by_j.keys())\n    if not jobs:\n        return feasible_operations[0]\n\n    start_idx = seed % len(jobs)\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    for k in range(len(jobs)):\n        j = jobs[(start_idx + k) % len(jobs)]\n        # pick job's best op by earliest completion\n        ops = by_j[j]\n        best = min(ops, key=lambda op: max(ms_f[op[1]], js_f[op[0]]) + op[2])\n        return best\n    return feasible_operations[0]\n",
  "deterministic_hash_round_robin_machines": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int(17 * np.sum(ms) + 7 * np.sum(js)) & 0x7fffffff\n\n    by_m = {}\n    for op in feasible_operations:\n        by_m.setdefault(op[1], []).append(op)\n\n    machines = sorted(by_m.keys())\n    if not machines:\n        return feasible_operations[0]\n\n    start_idx = seed % len(machines)\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    for k in range(len(machines)):\n        m = machines[(start_idx + k) % len(machines)]\n        ops = by_m[m]\n        # best by earliest start, then longest processing\n        best = min(ops, key=lambda op: (max(ms_f[op[1]], js_f[op[0]]), -op[2]))\n        return best\n    return feasible_operations[0]\n",
  "anti_starvation_oldest_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    js = current_status['job_status']\n    ms = current_status['machine_status']\n\n    min_jtime = min(js[op[0]] for op in feasible_operations)\n    candidates = [op for op in feasible_operations if js[op[0]] == min_jtime]\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]), op[2]))\n",
  "anti_starvation_oldest_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    min_mtime = min(ms[op[1]] for op in feasible_operations)\n    candidates = [op for op in feasible_operations if ms[op[1]] == min_mtime]\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]) + op[2], op[2]))\n",
  "min_changeover_proxy": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    last_m = current_status.get('last_machine', None)\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    def key(op):\n        penalty = 0 if (last_m is not None and op[1] == last_m) else 1\n        start = max(ms[op[1]], js[op[0]])\n        comp = start + op[2]\n        return (penalty, comp, op[2])\n    return min(feasible_operations, key=key)\n",
  "max_ready_queue_machine": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    counts = {}\n    for op in feasible_operations:\n        counts[op[1]] = counts.get(op[1], 0) + 1\n\n    max_c = max(counts.values())\n    candidates = [op for op in feasible_operations if counts[op[1]] == max_c]\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]) + op[2], op[2]))\n",
  "max_ready_queue_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    counts = {}\n    for op in feasible_operations:\n        counts[op[0]] = counts.get(op[0], 0) + 1\n\n    max_c = max(counts.values())\n    candidates = [op for op in feasible_operations if counts[op[0]] == max_c]\n    return min(candidates, key=lambda op: (max(ms[op[1]], js[op[0]]), op[2]))\n",
  "min_start_time_spread_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        spread = float(ms.max() - ms.min())\n        key = (spread, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_cv_machines_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        mu = float(np.mean(ms))\n        sd = float(np.std(ms))\n        cv = sd / (mu + 1e-12)\n        key = (cv, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_cv_jobs_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        mu = float(np.mean(js))\n        sd = float(np.std(js))\n        cv = sd / (mu + 1e-12)\n        key = (cv, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "max_machine_release_rate": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_val = None, -float('inf')\n    for op in feasible_operations:\n        idle = max(0.0, js[op[0]] - ms[op[1]])\n        val = float(op[2]) / (idle + 1.0)\n        if val > best_val + 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12:\n            start = max(ms[op[1]], js[op[0]])\n            bstart = max(ms[best_op[1]], js[best_op[0]])\n            if start < bstart:\n                best_op = op\n    return best_op\n",
  "min_machine_release_rate": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def key(op):\n        idle = max(0.0, js[op[0]] - ms[op[1]])\n        r = float(op[2]) / (idle + 1.0)\n        start = max(ms[op[1]], js[op[0]])\n        return (r, start, op[2])\n    return min(feasible_operations, key=key)\n",
  "lookahead_two_step_makespan_proxy": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def greedy_next(ms, js, ops):\n        if not ops:\n            return None\n        comps = [max(ms[op[1]], js[op[0]]) + op[2] for op in ops]\n        return ops[int(np.argmin(comps))]\n\n    best_op, best_val = None, float('inf')\n    for op in feasible_operations:\n        ms = ms0.copy(); js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        fin = start + float(op[2])\n        ms[op[1]] = fin\n        js[op[0]] = fin\n\n        # crude next-step set: all ops except the chosen one\n        remaining = [x for x in feasible_operations if x is not op]\n        nxt = greedy_next(ms, js, remaining)\n        if nxt is not None:\n            s2 = max(ms[nxt[1]], js[nxt[0]])\n            f2 = s2 + float(nxt[2])\n            ms2 = ms.copy(); js2 = js.copy()\n            ms2[nxt[1]] = f2\n            js2[nxt[0]] = f2\n            val = float(max(ms2.max(), js2.max()))\n        else:\n            val = float(max(ms.max(), js.max()))\n\n        key = (val, fin, op[2])\n        if key < (best_val, float('inf'), float('inf')):\n            best_val, best_op = val, op\n    return best_op\n",
  "min_kurtosis_machines_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(x):\n        x = np.asarray(x, dtype=float)\n        mu = float(np.mean(x))\n        sd = float(np.std(x) + 1e-12)\n        z = (x - mu) / sd\n        return float(np.mean(z**4))\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        k = kurtosis(ms)\n        key = (k, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_kurtosis_jobs_after": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(x):\n        x = np.asarray(x, dtype=float)\n        mu = float(np.mean(x))\n        sd = float(np.std(x) + 1e-12)\n        z = (x - mu) / sd\n        return float(np.mean(z**4))\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        k = kurtosis(js)\n        key = (k, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_l1_to_uniform_machines": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        mu = float(np.mean(ms))\n        l1 = float(np.sum(np.abs(ms - mu)))\n        key = (l1, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_l1_to_uniform_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        mu = float(np.mean(js))\n        l1 = float(np.sum(np.abs(js - mu)))\n        key = (l1, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_l2_to_uniform_machines": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        mu = float(np.mean(ms))\n        l2 = float(np.sum((ms - mu) ** 2))\n        key = (l2, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "min_l2_to_uniform_jobs": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        js[op[0]] = start + float(op[2])\n        mu = float(np.mean(js))\n        l2 = float(np.sum((js - mu) ** 2))\n        key = (l2, start + float(op[2]), op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "max_parallelism_proxy": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (max(ms[op[1]], js[op[0]]), ms[op[1]] + js[op[0]], op[2]))\n",
  "min_parallelism_proxy": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (-max(ms[op[1]], js[op[0]]), op[2], ms[op[1]]))\n",
  "balanced_start_and_completion": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    comps = np.array([starts[i] + feasible_operations[i][2] for i in range(len(feasible_operations))], dtype=float)\n\n    def mm(x):\n        mn, mx = float(np.min(x)), float(np.max(x))\n        if mx - mn < 1e-12:\n            return np.zeros_like(x)\n        return (x - mn) / (mx - mn)\n\n    sN = mm(starts)\n    cN = mm(comps)\n    score = sN + cN\n    return feasible_operations[int(np.argmin(score))]\n",
  "min_rank_of_sum_availability": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    vals = np.array([ms[op[1]] + js[op[0]] for op in feasible_operations], dtype=float)\n    ranks = np.argsort(np.argsort(vals))\n    idx = int(np.argmin(ranks + 0.01 * np.array([op[2] for op in feasible_operations], dtype=float)))\n    return feasible_operations[idx]\n",
  "max_rank_of_sum_availability": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    vals = np.array([ms[op[1]] + js[op[0]] for op in feasible_operations], dtype=float)\n    ranks = np.argsort(np.argsort(vals))\n    best_rank = int(np.max(ranks))\n    candidates = [op for op, r in zip(feasible_operations, ranks) if int(r) == best_rank]\n    return min(candidates, key=lambda op: max(ms[op[1]], js[op[0]]) + op[2])\n",
  "min_start_gap_machine_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (abs(ms[op[1]] - js[op[0]]), -op[2], max(ms[op[1]], js[op[0]])))\n",
  "max_start_gap_machine_job": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    return min(feasible_operations, key=lambda op: (-abs(ms[op[1]] - js[op[0]]), op[2], max(ms[op[1]], js[op[0]])))\n",
  "min_estimated_blocking_risk": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mmin = float(np.min(ms))\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        start = max(ms[op[1]], js[op[0]])\n        comp = start + float(op[2])\n        risk = comp - mmin\n        key = (risk, comp, op[2])\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n",
  "shortest_processing_time_aug_0": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times, clip to avoid negative values\n    proc_times = np.clip(\n        np.array([op[2] for op in feasible_operations]), 0, None\n    )\n\n    # Find index of the operation with the smallest processing time\n    best_idx = int(np.argmin(proc_times))\n    return feasible_operations[best_idx]\n\n",
  "shortest_processing_time_aug_1": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Hyperparameters\n    weight_time = 0.7          # weight for processing time\n    weight_job  = 0.3          # weight for job identifier\n    noise_scale = 1e-6         # deterministic noise\n\n    # Compute weighted score for each operation\n    scores = [\n        weight_time * op[2] + weight_job * op[0] + noise_scale * i\n        for i, op in enumerate(feasible_operations)\n    ]\n\n    best_idx = int(np.argmin(scores))\n    return feasible_operations[best_idx]\n\n",
  "shortest_processing_time_aug_2": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Temperature (\u03c4) with epsilon to prevent zero denominator\n    tau = 0.1 + 1e-12\n\n    # Compute softmin probabilities\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n    logits = -proc_times / tau\n    max_logit = np.max(logits)\n    exp_logits = np.exp(logits - max_logit)          # for numerical stability\n    probs = exp_logits / (np.sum(exp_logits) + 1e-12)\n\n    # Clip probabilities to a safe range\n    probs = np.clip(probs, 1e-12, 1 - 1e-12)\n\n    # Randomly select an operation according to the probabilities\n    chosen_idx = int(np.random.choice(len(feasible_operations), p=probs))\n    return feasible_operations[chosen_idx]\n\n",
  "shortest_processing_time_aug_3": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Compute median processing time\n    median_time = np.median(proc_times)\n\n    # Compute absolute distance to median, add epsilon to avoid zero division\n    distances = np.abs(proc_times - median_time) + 1e-12\n\n    # Clip distances to a reasonable upper bound\n    distances = np.clip(distances, 0, 1e6)\n\n    # Add deterministic noise for tie\u2011breaking\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    scores = distances + noise\n\n    best_idx = int(np.argmin(scores))\n    return feasible_operations[best_idx]\n\n",
  "longest_processing_time_aug_4": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Small deterministic noise to break ties (increasing sequence)\n    noise = np.arange(len(proc_times), dtype=np.float64) * 1e-9\n\n    # Choose operation with maximum (time + noise)\n    idx = np.argmax(proc_times + noise)\n    return feasible_operations[idx]\n\n",
  "longest_processing_time_aug_5": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Separate components\n    jobs = np.array([op[0] for op in feasible_operations], dtype=np.float64)\n    times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Weighted score: 60% time, 40% job id\n    score = 0.6 * times + 0.4 * jobs\n\n    # Deterministic tie\u2011breaking noise\n    noise = np.arange(len(score), dtype=np.float64) * 1e-9\n    score += noise\n\n    idx = np.argmax(score)\n    return feasible_operations[idx]\n\n",
  "longest_processing_time_aug_6": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times\n    times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Determine top\u2011k (k=3 or less if not enough operations)\n    k = min(3, len(times))\n    # Indices of the k largest times\n    top_idx = np.argpartition(-times, k - 1)[:k]\n    # Randomly pick among them\n    rng = np.random.default_rng(seed=42)\n    chosen_idx = rng.choice(top_idx)\n\n    return feasible_operations[chosen_idx]\n\n",
  "longest_processing_time_aug_7": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times\n    times = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Clip to avoid division by zero and add epsilon to denominator\n    clipped = np.clip(times, 1e-12, None)\n    inverse = 1.0 / (clipped + 1e-12)\n\n    # Choose the operation with the smallest inverse (i.e., largest time)\n    idx = np.argmin(inverse)\n    return feasible_operations[idx]\n\n",
  "earliest_idle_machine_aug_8": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Gather idle times for all feasible operations\n    idle_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    # Prevent extreme values that could break comparisons\n    idle_times = np.clip(idle_times, 0, 1e9)\n    # Pick the operation with the smallest idle time\n    idx = np.argmin(idle_times)\n    return feasible_operations[idx]\n\n",
  "earliest_idle_machine_aug_9": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    idle = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    idle = np.clip(idle, 0, 1e6)                     # bound values\n    temp = 1.0                                       # temperature for soft\u2011min\n    weights = np.exp(-idle / temp)                   # soft\u2011min weights\n    noise = 1e-6 * np.arange(len(idle))              # deterministic tie\u2011breaker\n    weights += noise\n    weights /= (np.sum(weights) + 1e-12)              # normalize, avoid div\u2011by\u2011zero\n    idx = np.argmax(weights)                         # choose operation with highest weight\n    return feasible_operations[idx]\n\n",
  "earliest_idle_machine_aug_10": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    idle = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    idle = np.clip(idle, 0, 1e6)                     # prevent outliers\n    median_val = np.median(idle)\n    diff = np.abs(idle - median_val)                 # distance from median\n    idx = np.argmin(diff)                            # minimal distance\n    return feasible_operations[idx]\n\n",
  "earliest_idle_machine_aug_11": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    idle = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    idle = np.clip(idle, 1e-12, 1e9)                  # avoid zero division\n    inv = 1.0 / (idle + 1e-12)                       # add epsilon to denominator\n    idx = np.argmax(inv)                             # largest inverse => smallest idle\n    return feasible_operations[idx]\n\n",
  "latest_idle_machine_aug_12": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Vectorized extraction of machine load values\n    statuses = np.array([machine_status[op[1]] for op in feasible_operations], dtype=np.float64)\n    # Deterministic noise to break ties\n    noise = np.linspace(0, 1e-6, len(feasible_operations), dtype=np.float64)\n    scores = statuses + noise\n    idx = np.argmax(scores)\n    return feasible_operations[idx]\n\n",
  "latest_idle_machine_aug_13": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Gather machine load values\n    statuses = np.array([machine_status[op[1]] for op in feasible_operations], dtype=np.float64)\n    # Softmax scoring with temperature (parameter tuning)\n    beta = 10.0\n    exp_vals = np.exp(beta * statuses - np.max(beta * statuses))  # numerical stability\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)  # epsilon to avoid division by zero\n    idx = np.argmax(probs)\n    return feasible_operations[idx]\n\n",
  "latest_idle_machine_aug_14": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Compute load values for each candidate operation\n    statuses = np.array([machine_status[op[1]] for op in feasible_operations], dtype=np.float64)\n    # Select the top\u2011k busiest machines and pick one at random (semantic diversity)\n    k = min(5, len(feasible_operations))\n    top_k_idx = np.argpartition(-statuses, k-1)[:k]\n    rng = np.random.default_rng()\n    chosen_idx = rng.choice(top_k_idx)\n    return feasible_operations[chosen_idx]\n\n",
  "latest_idle_machine_aug_15": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    epsilon = 1e-12\n    # Ratio of load to load plus epsilon (parameter tuning)\n    statuses = np.array([machine_status[op[1]] for op in feasible_operations], dtype=np.float64)\n    ratios = statuses / (statuses + epsilon)\n    # Deterministic noise clipped to avoid extreme values (semantic diversity)\n    noise = np.random.uniform(-0.05, 0.05, size=ratios.shape)\n    noise = np.clip(noise, -0.05, 0.05)\n    scores = ratios + noise\n    idx = np.argmax(scores)\n    return feasible_operations[idx]\n\n",
  "earliest_available_job_aug_16": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    job_status = current_status['job_status']\n    # Convert to numpy for vectorised min calculation\n    jobs = np.array([op[0] for op in feasible_operations], dtype=np.int64)\n    values = np.array([job_status[j] for j in jobs], dtype=np.float64)\n\n    # Clip to avoid any accidental division\u2011by\u2011zero in downstream code\n    values = np.clip(values, 1e-12, np.inf)\n    idx = np.argmin(values)\n    return feasible_operations[idx]\n\n",
  "earliest_available_job_aug_17": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    rng = np.random.default_rng()\n    job_status = current_status['job_status']\n    jobs = np.array([op[0] for op in feasible_operations], dtype=np.int64)\n    values = np.array([job_status[j] for j in jobs], dtype=np.float64)\n\n    # Add tiny Gaussian noise to break ties deterministically\n    noise = rng.normal(scale=1e-4, size=values.shape)\n    scores = np.exp(-(values + noise))          # soft\u2011min scores\n\n    # Normalise with epsilon to avoid division by zero\n    denom = np.sum(scores) + 1e-12\n    probs = scores / denom\n\n    idx = rng.choice(len(feasible_operations), p=probs)\n    return feasible_operations[idx]\n\n",
  "earliest_available_job_aug_18": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    rng = np.random.default_rng()\n    job_status = current_status['job_status']\n    jobs = np.array([op[0] for op in feasible_operations], dtype=np.int64)\n    values = np.array([job_status[j] for j in jobs], dtype=np.float64)\n\n    # Sort indices by availability time\n    sorted_idx = np.argsort(values)\n\n    # Choose a random element among the top\u2011k earliest\n    top_k = min(5, len(values))\n    chosen = rng.choice(sorted_idx[:top_k])\n    return feasible_operations[chosen]\n\n",
  "earliest_available_job_aug_19": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    rng = np.random.default_rng()\n    job_status = current_status['job_status']\n    jobs = np.array([op[0] for op in feasible_operations], dtype=np.int64)\n    values = np.array([job_status[j] for j in jobs], dtype=np.float64)\n\n    # Median as a robust centre point\n    median_val = np.median(values)\n\n    # Absolute deviation from the median\n    dev = np.abs(values - median_val)\n\n    # Small uniform noise for deterministic tie\u2011breaking\n    noise = rng.uniform(-1e-5, 1e-5, size=dev.shape)\n    dev += noise\n\n    idx = np.argmin(dev)\n    # Clip index to stay within bounds\n    idx = int(np.clip(idx, 0, len(feasible_operations) - 1))\n    return feasible_operations[idx]\n\n",
  "balanced_machine_load_aug_20": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Rename for clarity and convert to numpy arrays\n    loads = np.array([current_status['machine_status'][op[1]] for op in feasible_operations], dtype=float)\n    ops   = np.array(feasible_operations)\n\n    # Clip loads to avoid extreme values and add a tiny epsilon\n    loads = np.clip(loads, 0, 1e9) + 1e-12\n\n    # Find the index of the minimum load\n    idx = np.argmin(loads)\n\n    return tuple(ops[idx])\n\n",
  "balanced_machine_load_aug_21": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Weights for load and operation index (priority)\n    w_load = 0.6\n    w_prio = 0.4\n\n    # Extract machine loads and operation indices\n    loads = np.array([current_status['machine_status'][op[1]] for op in feasible_operations], dtype=float)\n    prio  = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Compute composite score\n    score = w_load * loads + w_prio * prio\n\n    # Keep only the top\u2011k (k=3) candidates\n    top_k = 3\n    top_indices = np.argpartition(score, top_k)[:top_k]\n    best_idx = top_indices[np.argmin(score[top_indices])]\n\n    return tuple(feasible_operations[best_idx])\n\n",
  "balanced_machine_load_aug_22": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Base score: machine load\n    loads = np.array([current_status['machine_status'][op[1]] for op in feasible_operations], dtype=float)\n\n    # Add deterministic noise to break ties\n    noise = 1e-6 * np.arange(len(feasible_operations))\n    scores = loads + noise\n\n    # Softmin probabilities (temperature = 1.0)\n    temp = 1.0\n    probs = np.exp(-scores / temp)\n    probs /= np.sum(probs) + 1e-12\n\n    # Randomly pick one operation according to the distribution\n    chosen_idx = np.random.choice(len(feasible_operations), p=probs)\n\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "balanced_machine_load_aug_23": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract loads and priorities\n    loads = np.array([current_status['machine_status'][op[1]] for op in feasible_operations], dtype=float)\n    prio  = np.array([op[2] for op in feasible_operations], dtype=float) + 1e-12  # avoid zero division\n\n    # Normalise load by priority, clip to [0, 1] and add epsilon\n    eps = 1e-12\n    norm = loads / (prio + eps)\n    norm = np.clip(norm, 0, 1) + eps\n\n    # Choose operation with minimal normalised load\n    best_idx = np.argmin(norm)\n\n    return tuple(feasible_operations[best_idx])\n\n",
  "weighted_spt_machine_aug_24": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Extract processing times and machine availability with list comprehensions\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    # Scale by median to dampen outliers\n    proc_scale = np.median(proc_times) + 1e-12\n    mach_scale = np.median(mach_times) + 1e-12\n    proc_norm = proc_times / proc_scale\n    mach_norm = mach_times / mach_scale\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    # Weighted combination (60% processing time, 40% machine availability)\n    scores = 0.7 * proc_norm + 0.3 * mach_norm + noise\n    # Clip to avoid extreme values\n    scores = np.clip(scores, 0, np.inf)\n    return feasible_operations[int(np.argmin(scores))]\n\n",
  "weighted_spt_machine_aug_25": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Vectorized extraction using fromiter\n    proc_times = np.fromiter((op[2] for op in feasible_operations), dtype=float)\n    mach_times = np.fromiter((machine_status[op[1]] for op in feasible_operations), dtype=float)\n    # Scale by sum to normalise\n    proc_scale = np.sum(proc_times) + 1e-12\n    mach_scale = np.sum(mach_times) + 1e-12\n    proc_norm = proc_times / proc_scale\n    mach_norm = mach_times / mach_scale\n    # Compute scores\n    scores = 0.6 * proc_norm + 0.4 * mach_norm\n    # Clip to a reasonable range\n    scores = np.clip(scores, 0, 1e6)\n    # Top\u2011k selection to reduce search space\n    k = min(5, len(feasible_operations))\n    top_k_idx = np.argpartition(scores, k-1)[:k]\n    chosen = top_k_idx[np.argmin(scores[top_k_idx])]\n    return feasible_operations[chosen]\n\n",
  "weighted_spt_machine_aug_26": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    # Extract values with list comprehensions\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine_status[op[1]] for op in feasible_operations], dtype=float)\n    # Scale by mean\n    proc_scale = np.mean(proc_times) + 1e-12\n    mach_scale = np.mean(mach_times) + 1e-12\n    proc_norm = proc_times / proc_scale\n    mach_norm = mach_times / mach_scale\n    # Weighted combination that prefers larger values (maximisation)\n    scores = 0.4 * proc_norm + 0.6 * mach_norm\n    scores = np.clip(scores, 0, np.inf)\n    # Resolve ties by random selection among the best\n    max_score = np.max(scores)\n    candidates = np.where(scores == max_score)[0]\n    chosen_idx = np.random.choice(candidates)\n    return feasible_operations[chosen_idx]\n\n",
  "job_machine_balance_aug_27": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Local copies with clearer names\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    # Convert list of operations to a NumPy array for vectorised processing\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Extract machine times, job times and durations\n    machine_times = np.array([m_status[op[1]] for op in ops], dtype=float)\n    job_times    = np.array([j_status[op[0]] for op in ops], dtype=float)\n    durations    = np.array([op[2] for op in ops], dtype=float)\n\n    # Compute a simple linear score\n    scores = machine_times + job_times + durations\n\n    # Add deterministic noise to break ties consistently\n    noise = 1e-6 * np.arange(len(scores))\n    scores += noise\n\n    # Keep scores bounded to avoid overflow\n    scores = np.clip(scores, 0, 1e6)\n\n    # Pick the operation with the minimal score\n    idx = np.argmin(scores)\n    return feasible_operations[idx]\n\n",
  "job_machine_balance_aug_28": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_times = np.array([m_status[op[1]] for op in ops], dtype=float)\n    job_times    = np.array([j_status[op[0]] for op in ops], dtype=float)\n    durations    = np.array([op[2] for op in ops], dtype=float)\n\n    # Weighted score with adjusted coefficients\n    scores = 0.6 * machine_times + 0.4 * job_times + durations\n\n    # Soft\u2011min probability distribution\n    temperature = 0.1\n    exp_vals = np.exp(-(scores + 1e-12) / temperature)   # +1e-12 avoids huge exponents\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)          # +1e-12 prevents division by zero\n    probs = np.clip(probs, 0, 1)                           # bound probabilities\n\n    # Randomly select an operation according to the soft\u2011min distribution\n    idx = np.random.choice(len(ops), p=probs)\n    return feasible_operations[idx]\n\n",
  "job_machine_balance_aug_29": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_times = np.array([m_status[op[1]] for op in ops], dtype=float)\n    job_times    = np.array([j_status[op[0]] for op in ops], dtype=float)\n    durations    = np.array([op[2] for op in ops], dtype=float)\n\n    # Balanced score with new weight ratios\n    scores = 0.5 * machine_times + 0.5 * job_times + durations\n\n    # Deterministic noise to resolve ties\n    noise = 1e-7 * np.arange(len(scores))\n    scores += noise\n\n    # Clip to keep values reasonable\n    scores = np.clip(scores, 0, 1e6)\n\n    # Randomly choose among the top\u2011k smallest scores\n    k = min(5, len(scores))\n    top_k_idx = np.argpartition(scores, k - 1)[:k]\n    chosen_idx = top_k_idx[np.random.randint(0, len(top_k_idx))]\n\n    return feasible_operations[chosen_idx]\n\n",
  "job_machine_balance_aug_30": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_times = np.array([m_status[op[1]] for op in ops], dtype=float)\n    job_times    = np.array([j_status[op[0]] for op in ops], dtype=float)\n    durations    = np.array([op[2] for op in ops], dtype=float)\n\n    # Use median values as a robust central tendency\n    median_machine = np.clip(np.median(machine_times), 0, 1e6)\n    median_job     = np.clip(np.median(job_times), 0, 1e6)\n\n    # Score based on deviation from the median plus duration\n    scores = np.abs(machine_times - median_machine) + \\\n             np.abs(job_times - median_job) + durations\n\n    # Small deterministic noise for tie breaking\n    noise = 1e-6 * np.arange(len(scores))\n    scores += noise\n\n    idx = np.argmin(scores)\n    return feasible_operations[idx]\n\n",
  "minimal_start_time_aug_31": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    job_state = current_status['job_status']\n    idx = 0\n    best_start = np.inf\n    best_op = None\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        est = machine_state[op[1]] if machine_state[op[1]] > job_state[op[0]] else job_state[op[0]]\n        est = np.clip(est, 0, 1e9) + 1e-12\n        if est < best_start:\n            best_start = est\n            best_op = op\n        idx += 1\n    return best_op\n\n",
  "minimal_start_time_aug_32": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    job_state = current_status['job_status']\n    w_machine = 0.6\n    w_job = 0.4\n    ests = np.array([\n        w_machine * machine_state[op[1]] + w_job * job_state[op[0]]\n        for op in feasible_operations\n    ])\n    ests = np.clip(ests, 0, 1e9) + 1e-12\n    temp = 1.0\n    probs = np.exp(-ests / (temp + 1e-12))\n    probs = probs / (np.sum(probs) + 1e-12)\n    chosen_idx = np.argmax(probs)\n    return feasible_operations[chosen_idx]\n\n",
  "minimal_start_time_aug_33": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    job_state = current_status['job_status']\n    start_times = np.array([\n        max(machine_state[op[1]], job_state[op[0]])\n        for op in feasible_operations\n    ])\n    start_times = np.clip(start_times, 0, 1e9) + 1e-12\n    k = min(7, len(feasible_operations))\n    top_indices = np.argsort(start_times)[:k]\n    chosen_idx = np.random.choice(top_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "minimal_start_time_aug_34": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    job_state = current_status['job_status']\n    start_times = np.array([\n        np.median([machine_state[op[1]], job_state[op[0]]])\n        for op in feasible_operations\n    ])\n    start_times = np.clip(start_times, 0, 1e9) + 1e-12\n    noise = np.arange(len(start_times)) * 1e-6\n    start_times += noise\n    chosen_idx = np.argmin(start_times)\n    return feasible_operations[chosen_idx]\n\n",
  "minimal_completion_time_aug_35": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract machine and job status as numpy arrays\n    machine_status = np.asarray(current_status['machine_status'])\n    job_status     = np.asarray(current_status['job_status'])\n\n    # Convert list of tuples to a structured numpy array\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Retrieve machine and job indices for all operations\n    machine_idx = ops[:, 1].astype(int)\n    job_idx     = ops[:, 0].astype(int)\n\n    # Compute earliest start times and completion times\n    machine_avail = machine_status[machine_idx]\n    job_avail     = job_status[job_idx]\n    start_time    = np.maximum(machine_avail, job_avail)\n    comp_time     = start_time + ops[:, 2]\n\n    # Select the operation with minimal completion time\n    chosen_index = np.argmin(comp_time)\n    return feasible_operations[chosen_index]\n\n",
  "minimal_completion_time_aug_36": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.asarray(current_status['machine_status'])\n    job_status     = np.asarray(current_status['job_status'])\n    ops            = np.array(feasible_operations, dtype=object)\n\n    machine_avail = machine_status[ops[:, 1].astype(int)]\n    job_avail     = job_status[ops[:, 0].astype(int)]\n    start_time    = np.maximum(machine_avail, job_avail)\n    comp_time     = start_time + ops[:, 2]\n\n    # Soft\u2011minimum probabilities\n    temperature = 0.5\n    exp_vals    = np.exp(-comp_time / (temperature + 1e-12))\n    probs       = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Randomly pick one of the top\u2011k fastest operations\n    top_k = 3\n    top_indices = np.argpartition(comp_time, top_k)[:top_k]\n    top_probs   = probs[top_indices]\n    top_probs   = top_probs / (np.sum(top_probs) + 1e-12)\n\n    chosen = np.random.choice(top_indices, p=top_probs)\n    return feasible_operations[chosen]\n\n",
  "minimal_completion_time_aug_37": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.asarray(current_status['machine_status'])\n    job_status     = np.asarray(current_status['job_status'])\n    ops            = np.array(feasible_operations, dtype=object)\n\n    machine_avail = machine_status[ops[:, 1].astype(int)]\n    job_avail     = job_status[ops[:, 0].astype(int)]\n    start_time    = np.maximum(machine_avail, job_avail)\n    comp_time     = start_time + ops[:, 2]\n\n    # Median adjustment to keep relative ordering but add a subtle shift\n    median_comp   = np.median(comp_time)\n    comp_adj      = comp_time + 0.1 * (comp_time - median_comp)\n\n    # Small deterministic Gaussian noise for tie\u2011breaking\n    rng   = np.random.default_rng()\n    noise = rng.normal(scale=1e-6, size=comp_adj.shape)\n    comp_noisy = comp_adj + noise\n\n    chosen_index = np.argmin(comp_noisy)\n    return feasible_operations[chosen_index]\n\n",
  "minimal_completion_time_aug_38": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.asarray(current_status['machine_status'])\n    job_status     = np.asarray(current_status['job_status'])\n    ops            = np.array(feasible_operations, dtype=object)\n\n    machine_avail = machine_status[ops[:, 1].astype(int)]\n    job_avail     = job_status[ops[:, 0].astype(int)]\n\n    # Weighted average of machine and job availability\n    w_m = 0.6\n    w_j = 0.4\n    weighted_start = (w_m * machine_avail + w_j * job_avail) / (w_m + w_j + 1e-12)\n    weighted_start = np.clip(weighted_start, 0, 1e9)\n\n    comp_time = weighted_start + ops[:, 2]\n    chosen_index = np.argmin(comp_time)\n    return feasible_operations[chosen_index]\n\n",
  "machine_utilization_max_aug_39": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Normalise machine status (avoid division by zero with epsilon)\n    ms = np.clip(current_status['machine_status'], 0, 1)\n    ms_norm = ms / (1.0 + 1e-12)\n\n    # Vectorised score: idle machines (higher status) minus twice the duration\n    scores = np.array([ms_norm[op[1]] - 2.0 * op[2] for op in feasible_operations])\n\n    # Choose operation with minimal score\n    idx = int(np.argmin(scores))\n    return feasible_operations[idx]\n\n",
  "machine_utilization_max_aug_40": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    rng = np.random.default_rng(seed=42)\n\n    ms = np.clip(current_status['machine_status'], 0, 1)\n\n    # Heavier weight on operation duration\n    scores = np.array([ms[op[1]] - 2.5 * op[2] for op in feasible_operations])\n\n    # Take the top 7 lowest scores (or fewer if not enough candidates)\n    top_k = min(7, len(scores))\n    top_indices = np.argpartition(scores, top_k - 1)[:top_k]\n    chosen_idx = rng.choice(top_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "machine_utilization_max_aug_41": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    rng = np.random.default_rng(seed=123)\n\n    ms = np.clip(current_status['machine_status'], 0, 1)\n\n    # Base scores with a stronger duration penalty\n    base_scores = np.array([ms[op[1]] - 2.0 * op[2] for op in feasible_operations])\n\n    # Deterministic noise to break ties (scaled by 1e-6)\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    scores = base_scores + noise\n\n    # Softmin with temperature alpha\n    alpha = 5.0\n    exp_vals = np.exp(-alpha * scores)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)  # epsilon in denominator\n    probs = np.clip(probs, 0, 1)  # safeguard\n\n    chosen_idx = rng.choice(len(feasible_operations), p=probs)\n    return feasible_operations[chosen_idx]\n\n",
  "machine_utilization_max_aug_42": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.clip(current_status['machine_status'], 0, 1)\n\n    # Slightly different weight on duration\n    scores = np.array([ms[op[1]] - 1.8 * op[2] for op in feasible_operations])\n\n    median_score = np.median(scores)\n\n    # Compute absolute distance to median, normalised to avoid division by zero\n    distances = np.abs(scores - median_score) / (1.0 + 1e-12)\n\n    idx = int(np.argmin(distances))\n    return feasible_operations[idx]\n\n",
  "random_choice_aug_43": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_status = current_status['machine_status']\n        job_status = current_status['job_status']\n\n        # Deterministic seed derived from status sums, scaled to avoid overflow\n        seed_val = int((np.sum(machine_status) + np.sum(job_status)) * 1e-3) % (2**31)\n        rng = np.random.default_rng(seed=seed_val)\n\n        # Pick an index uniformly\n        idx = rng.integers(low=0, high=len(feasible_operations))\n        return feasible_operations[idx]\n    return None\n\n",
  "random_choice_aug_44": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_status = current_status['machine_status']\n        job_status = current_status['job_status']\n\n        # Weighted sum with epsilon to avoid division by zero\n        weighted_sum = (2 * np.sum(machine_status) +\n                        3 * np.sum(job_status) + 1e-12)\n        seed_val = int(weighted_sum) % (2**31)\n        seed_val = np.clip(seed_val, 0, 2**31 - 1)\n\n        rng = np.random.default_rng(seed=seed_val)\n\n        # Generate random scores for each feasible operation\n        scores = rng.random(len(feasible_operations))\n\n        # Choose the top_k candidates (k=3) deterministically\n        top_k = 3\n        if len(feasible_operations) <= top_k:\n            top_indices = np.arange(len(feasible_operations))\n        else:\n            top_indices = np.argpartition(scores, -top_k)[-top_k:]\n\n        # Randomly pick one of the top candidates\n        chosen_idx = rng.choice(top_indices)\n        return feasible_operations[chosen_idx]\n    return None\n\n",
  "random_choice_aug_45": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_status = current_status['machine_status']\n        job_status = current_status['job_status']\n\n        # Deterministic seed\n        seed_val = int((np.sum(machine_status) + np.sum(job_status)) % (2**31))\n        rng = np.random.default_rng(seed=seed_val)\n\n        # Random scores for each operation\n        scores = rng.random(len(feasible_operations))\n\n        # Compute soft\u2011min probabilities\n        exp_scores = np.exp(-scores)\n        denom = np.sum(exp_scores) + 1e-12  # epsilon to avoid division by zero\n        probs = exp_scores / denom\n\n        # Sample according to the soft\u2011min distribution\n        chosen_idx = rng.choice(len(feasible_operations), p=probs)\n        return feasible_operations[chosen_idx]\n    return None\n\n",
  "random_choice_aug_46": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_status = current_status['machine_status']\n        job_status = current_status['job_status']\n\n        # Deterministic seed\n        seed_val = int((np.sum(machine_status) + np.sum(job_status)) % (2**31))\n        rng = np.random.default_rng(seed=seed_val)\n\n        # Random scores for each operation\n        scores = rng.random(len(feasible_operations))\n\n        # Deterministic noise based on operation index\n        indices = np.arange(len(feasible_operations))\n        noise = np.sin(indices * 123.456) * 1e-4  # small amplitude\n\n        # Combine scores with noise and pick the minimum\n        combined = scores + noise\n        chosen_idx = int(np.argmin(combined))\n        chosen_idx = int(np.clip(chosen_idx, 0, len(feasible_operations) - 1))\n        return feasible_operations[chosen_idx]\n    return None\n\n",
  "alternating_spt_lpt_aug_47": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract durations and clip to a sane range\n    durations = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n    durations = np.clip(durations, 0.0, 1e6)\n\n    # Compute mode with a tiny epsilon to avoid exact zero issues\n    mode = int((np.sum(current_status['job_status']) + 1e-12) % 2)\n\n    # Invert the original parity logic: mode 1 -> min, else -> max\n    if mode == 1:\n        idx = np.argmin(durations)\n    else:\n        idx = np.argmax(durations)\n\n    return feasible_operations[idx]\n\n",
  "alternating_spt_lpt_aug_48": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Parameters\n    top_k = 3\n    weight = 0.7          # emphasis on duration\n    noise_eps = 1e-6\n\n    # Prepare durations and clip them\n    durations = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n    durations = np.clip(durations, 0.0, 1e6)\n\n    # Compute weighted scores (lower is better)\n    scores = weight * durations + (1 - weight) * 0.0\n    # Add tiny deterministic noise to break ties\n    scores += noise_eps * np.arange(len(scores))\n\n    # Soft\u2011min probabilities\n    exp_neg = np.exp(-scores / (np.max(scores) + 1e-12))\n    probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n\n    # Select top\u2011k indices\n    top_indices = np.argsort(probs)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs /= np.sum(top_probs)  # re\u2011normalize\n\n    # Randomly pick one among top\u2011k\n    chosen_idx = np.random.choice(top_indices, p=top_probs)\n    return feasible_operations[chosen_idx]\n\n",
  "alternating_spt_lpt_aug_49": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract and clip durations\n    durations = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n    durations = np.clip(durations, 0.0, 1e6)\n\n    # Median duration\n    med = np.median(durations)\n\n    # Find indices within a small window around the median\n    window = 1e-5  # tolerance\n    close_indices = np.where(np.abs(durations - med) <= window)[0]\n\n    if close_indices.size == 0:\n        # Fallback: use the closest duration overall\n        close_indices = [np.argmin(np.abs(durations - med))]\n\n    # Randomly pick one of the candidates\n    chosen_idx = np.random.choice(close_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "alternating_spt_lpt_aug_50": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Prepare durations and clip to avoid extreme values\n    durations = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n    durations = np.clip(durations, 1e-12, 1e6)  # avoid zero\n\n    # Compute negative durations for soft\u2011max (shorter -> higher prob)\n    neg_dur = -durations\n    exp_vals = np.exp(neg_dur - np.max(neg_dur))  # stability trick\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Clip probabilities to a reasonable range to avoid zero probabilities\n    probs = np.clip(probs, 1e-6, 1.0)\n    probs /= np.sum(probs)\n\n    # Sample one operation according to the distribution\n    chosen_idx = np.random.choice(len(feasible_operations), p=probs)\n    return feasible_operations[chosen_idx]\n\n",
  "processing_time_percentile_aug_51": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times with a list comprehension\n    times = [op[2] for op in feasible_operations]\n\n    # Target percentile with a tiny epsilon to avoid exact 0/0 cases\n    target = float(np.percentile(times, 40) + 1e-12)\n\n    # Clip target to a reasonable range (non\u2011negative)\n    target = np.clip(target, 0, np.max(times) + 1e-12)\n\n    # Deterministic noise to break ties\n    noise = np.arange(len(times)) * 1e-9\n\n    # Deviation from target plus noise\n    deviations = np.abs(np.array(times) - target) + noise\n\n    # Index of minimal deviation\n    idx = int(np.argmin(deviations))\n\n    return feasible_operations[idx]\n\n",
  "processing_time_percentile_aug_52": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = feasible_operations\n    times = []\n    i = 0\n    # While loop to gather processing times\n    while i < len(ops):\n        times.append(ops[i][2])\n        i += 1\n\n    times_arr = np.array(times)\n\n    # Weighted target: 60% min, 40% max\n    target = 0.6 * np.min(times_arr) + 0.4 * np.max(times_arr)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(times_arr)) * 1e-9\n    deviations = np.abs(times_arr - target) + noise\n\n    # Soft\u2011min weights (inverse exponential)\n    denom = np.max(deviations) + 1e-12   # epsilon to avoid div\u2011by\u2011zero\n    weights = np.exp(-deviations / denom)\n\n    # Clip weights to keep them in [0,1]\n    weights = np.clip(weights, 0, 1)\n\n    # Choose the operation with the largest weight\n    idx = int(np.argmax(weights))\n\n    return ops[idx]\n\n",
  "processing_time_percentile_aug_53": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = feasible_operations\n    times = np.array([op[2] for op in ops])\n\n    # Target at the 35th percentile with epsilon\n    target = float(np.percentile(times, 35) + 1e-12)\n    target = np.clip(target, 0, np.max(times) + 1e-12)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(times)) * 1e-9\n    deviations = np.abs(times - target) + noise\n\n    # Select the k smallest deviations\n    k = 5\n    if k > len(deviations):\n        k = len(deviations)\n    top_k_idx = np.argpartition(deviations, k)[:k]\n\n    # Deterministic seed derived from current_status\n    seed = hash(str(current_status)) % (2**32 - 1) if current_status else 0\n    rng = np.random.default_rng(seed)\n\n    chosen_idx = int(rng.choice(top_k_idx))\n    return ops[chosen_idx]\n\n",
  "processing_time_percentile_aug_54": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = feasible_operations\n    times = np.array([op[2] for op in ops])\n\n    # Median target\n    target = np.median(times)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(times)) * 1e-9\n    deviations = np.abs(times - target) + noise\n\n    # Soft\u2011max probabilities (negative deviations)\n    denom = np.max(deviations) + 1e-12   # epsilon\n    probs = np.exp(-deviations / denom)\n\n    # Clip probabilities to [0, 1]\n    probs = np.clip(probs, 0, 1)\n\n    # Select the operation with the highest probability\n    idx = int(np.argmax(probs))\n\n    return ops[idx]\n\n",
  "machine_variance_min_aug_55": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Convert status lists to NumPy arrays for vectorised arithmetic\n    mach_status = np.array(current_status['machine_status'], dtype=float)\n    job_status  = np.array(current_status['job_status'],  dtype=float)\n\n    eps        = 1e-12\n    max_time   = 1e12\n    best_var   = np.inf\n    best_op    = None\n\n    for op in feasible_operations:\n        # Compute completion time for this operation\n        new_mach = mach_status.copy()\n        new_mach[op[1]] = max(mach_status[op[1]], job_status[op[0]]) + op[2]\n        new_mach = np.clip(new_mach, 0, max_time)\n\n        # Variance of the updated machine schedule\n        var = np.var(new_mach)\n\n        # Small deterministic noise for deterministic tie\u2011breaking\n        noise = 1e-6 * np.random.randint(1, 1_000)\n\n        if var + noise < best_var:\n            best_var = var + noise\n            best_op  = op\n\n    return best_op\n\n",
  "machine_variance_min_aug_56": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_status = np.array(current_status['machine_status'], dtype=float)\n    job_status  = np.array(current_status['job_status'],  dtype=float)\n\n    eps        = 1e-12\n    max_time   = 1e12\n    best_op    = None\n    best_weight = -np.inf\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        new_mach = mach_status.copy()\n        new_mach[op[1]] = max(mach_status[op[1]], job_status[op[0]]) + op[2]\n        new_mach = np.clip(new_mach, 0, max_time)\n\n        # Use median as a proxy for balance instead of variance\n        median_val = np.median(new_mach)\n        var_val    = np.var(new_mach)\n        score      = 0.5 * var_val + 0.5 * median_val\n\n        # Soft\u2011min weighting (higher weight for lower score)\n        weight = np.exp(-score / (1.0 + eps))\n\n        if weight > best_weight:\n            best_weight = weight\n            best_op     = op\n\n        idx += 1\n\n    return best_op\n\n",
  "machine_variance_min_aug_57": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_status = np.array(current_status['machine_status'], dtype=float)\n    job_status  = np.array(current_status['job_status'],  dtype=float)\n\n    eps        = 1e-12\n    max_time   = 1e12\n    best_op    = None\n    best_max   = np.inf\n\n    for op in feasible_operations:\n        new_mach = mach_status.copy()\n        new_mach[op[1]] = max(mach_status[op[1]], job_status[op[0]]) + op[2]\n        new_mach = np.clip(new_mach, 0, max_time)\n\n        # Max imbalance instead of variance\n        cur_max = np.max(new_mach)\n\n        # Deterministic noise using the operation index\n        noise = 1e-6 * (op[0] * 1000 + op[1])\n\n        if cur_max + noise < best_max:\n            best_max = cur_max + noise\n            best_op  = op\n\n    return best_op\n\n",
  "slack_time_priority_aug_58": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    eps = 1e-12\n    machine_times = current_status['machine_status']\n    job_times = current_status['job_status']\n\n    # Vectorise the list of operations for fast array operations\n    ops = np.array(feasible_operations, dtype=object)\n    machine_idxs = ops[:, 1]\n    job_idxs = ops[:, 0]\n\n    machine_vals = machine_times[machine_idxs]\n    job_vals = job_times[job_idxs]\n\n    # Compute absolute slack and clip to avoid negative values\n    slacks = np.abs(machine_vals - job_vals)\n    slacks = np.clip(slacks, 0, None)\n\n    # Inverse slack gives higher weight to smaller slack\n    weights = 1.0 / (slacks + eps)\n    chosen_idx = int(np.argmax(weights))\n\n    return feasible_operations[chosen_idx]\n\n",
  "slack_time_priority_aug_59": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = current_status['machine_status']\n    job_times = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_vals = machine_times[ops[:, 1]]\n    job_vals = job_times[ops[:, 0]]\n\n    slacks = np.abs(machine_vals - job_vals)\n    slacks = np.clip(slacks, 0, None)\n\n    median_slack = np.median(slacks)\n    diff_to_median = np.abs(slacks - median_slack)\n\n    chosen_idx = int(np.argmin(diff_to_median))\n    return feasible_operations[chosen_idx]\n\n",
  "slack_time_priority_aug_60": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    eps = 1e-12\n    machine_times = current_status['machine_status']\n    job_times = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_vals = machine_times[ops[:, 1]]\n    job_vals = job_times[ops[:, 0]]\n\n    slacks = np.abs(machine_vals - job_vals)\n    slacks = np.clip(slacks, 0, None)\n\n    # Add a tiny deterministic noise to break ties\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    noisy_slacks = slacks + noise\n\n    top_k = 5\n    top_indices = np.argpartition(noisy_slacks, top_k - 1)[:top_k]\n\n    rng = np.random.default_rng()\n    chosen_idx = rng.choice(top_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "bottleneck_machine_avoid_aug_61": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'])\n    max_status = np.max(machine_status)\n\n    # Build non\u2011bottleneck list using a while loop\n    idx = 0\n    non_bottleneck = []\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        if machine_status[op[1]] < max_status:\n            non_bottleneck.append(op)\n        idx += 1\n\n    candidates = non_bottleneck if non_bottleneck else feasible_operations\n\n    # Add tiny deterministic noise based on the operation id to break ties\n    proc_times = np.array([op[2] + 1e-12 * op[0] for op in candidates])\n    min_idx = np.argmin(proc_times)\n    return candidates[min_idx]\n\n",
  "bottleneck_machine_avoid_aug_62": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'])\n    max_status = np.max(machine_status)\n\n    # Prefer operations on the bottleneck machine\n    bottleneck_ops = [op for op in feasible_operations if machine_status[op[1]] == max_status]\n    candidates = bottleneck_ops if bottleneck_ops else feasible_operations\n\n    # Softmin over processing times with a temperature parameter\n    temperature = 1.0\n    proc_times = np.array([op[2] for op in candidates])\n    weights = np.exp(-proc_times / (temperature + 1e-12))\n    weights = np.clip(weights, 1e-12, None)  # avoid zero weights\n    probs = weights / (np.sum(weights) + 1e-12)\n\n    idx = np.random.choice(len(candidates), p=probs)\n    return candidates[idx]\n\n",
  "bottleneck_machine_avoid_aug_63": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.clip(np.array(current_status['machine_status']), 0, np.inf)\n    max_status = np.max(machine_status)\n\n    # Keep non\u2011bottleneck operations\n    non_bottleneck = [op for op in feasible_operations if machine_status[op[1]] < max_status]\n    candidates = non_bottleneck if non_bottleneck else feasible_operations\n\n    proc = np.array([op[2] for op in candidates])\n    median = np.median(proc)\n\n    # Absolute difference from median, with deterministic offset to break ties\n    diff = np.abs(proc - median) + 1e-12 * np.arange(len(candidates))\n    min_idx = np.argmin(diff)\n    return candidates[min_idx]\n\n",
  "bottleneck_machine_avoid_aug_64": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.clip(np.array(current_status['machine_status']), 0, np.inf)\n    max_status = np.max(machine_status)\n\n    # Prefer non\u2011bottleneck operations\n    non_bottleneck = [op for op in feasible_operations if machine_status[op[1]] < max_status]\n    candidates = non_bottleneck if non_bottleneck else feasible_operations\n\n    # Compute a weighted score: 0.6 * (proc_time / machine_status) + 0.4 * machine_status\n    scores = []\n    for op in candidates:\n        denom = machine_status[op[1]] + 1e-12  # epsilon to avoid division by zero\n        score = 0.6 * (op[2] / denom) + 0.4 * machine_status[op[1]]\n        scores.append(score)\n\n    scores = np.array(scores)\n    # Deterministic noise based on operation id\n    noise = 1e-12 * np.arange(len(candidates))\n    scores += noise\n\n    min_idx = np.argmin(scores)\n    return candidates[min_idx]\n\n",
  "job_id_priority_aug_65": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=np.float64)\n    job_ids     = ops[:, 0]\n    machine_ids = ops[:, 2]\n\n    # Parameter tuning: heavier weight on job ID\n    w_job, w_machine = 0.7, 0.3\n    priority = w_job * job_ids + w_machine * machine_ids\n\n    # Deterministic tie\u2011breaker\n    noise = 1e-6 * np.arange(len(priority))\n    priority += noise\n\n    idx = np.argmin(priority)\n    return tuple(ops[idx].astype(int))\n\n",
  "job_id_priority_aug_66": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=np.float64)\n    job_ids     = ops[:, 0]\n    machine_ids = ops[:, 2]\n\n    # Parameter tuning: equal weighting of job and machine IDs\n    w_job, w_machine = 0.5, 0.5\n    priority = w_job * job_ids + w_machine * machine_ids\n\n    # Hyper\u2011parameter: number of top candidates to consider\n    top_k = min(7, len(priority))\n    top_idx = np.argpartition(priority, top_k - 1)[:top_k]\n    top_priority = priority[top_idx]\n\n    # Softmin weighting (adds epsilon to avoid division by zero)\n    weights = np.exp(-top_priority)\n    weights /= np.sum(weights) + 1e-12\n\n    chosen = np.random.choice(top_idx, p=weights)\n    return tuple(ops[chosen].astype(int))\n\n",
  "job_id_priority_aug_67": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=np.float64)\n    job_ids     = ops[:, 0]\n    machine_ids = ops[:, 2]\n\n    # Median aggregation (semantic\u2011preserving alternative)\n    median_job     = np.median(job_ids)\n    median_machine = np.median(machine_ids)\n\n    # Distance from median\n    distance = np.abs(job_ids - median_job) + np.abs(machine_ids - median_machine)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-6 * np.arange(len(distance))\n    distance += noise\n\n    idx = np.argmin(distance)\n    return tuple(ops[idx].astype(int))\n\n",
  "job_id_priority_aug_68": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        ops = np.array(feasible_operations, dtype=np.int64)\n        job_ids     = ops[:, 0]\n        machine_ids = ops[:, 2]\n\n        # Parameter tuning: slightly more emphasis on machine ID\n        priority = 0.6 * job_ids + 0.4 * machine_ids\n\n        # Clip to avoid any potential overflow\n        priority = np.clip(priority, 0, 1e6)\n\n        idx = np.argmin(priority)\n        return tuple(ops[idx])\n    return None\n\n",
  "machine_id_priority_aug_69": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Convert to a NumPy array for vectorised handling\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1].astype(np.float64)\n    op_ids = ops[:, 2].astype(np.float64)\n\n    # Ensure machine IDs are non\u2011negative (clip) and add a tiny epsilon\n    machine_ids = np.clip(machine_ids, 0, None)\n    op_ids = np.clip(op_ids, 0, None)\n\n    # Lexicographic sorting: first by machine_id, then by op_id\n    order = np.lexsort((op_ids, machine_ids))\n    best_idx = order[0]\n\n    # Return as a plain tuple to preserve the original API\n    return tuple(ops[best_idx])\n\n",
  "machine_id_priority_aug_70": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1].astype(np.float64)\n    op_ids = ops[:, 2].astype(np.float64)\n\n    # Clip to avoid negative values and add epsilon to denominators\n    machine_ids = np.clip(machine_ids, 0, None)\n    op_ids = np.clip(op_ids, 0, None)\n\n    # Compute weighted score\n    scores = 0.7 * machine_ids + 0.3 * op_ids\n\n    # Add a tiny deterministic noise to break exact ties\n    noise = np.arange(len(scores), dtype=np.float64) * 1e-12\n    scores += noise\n\n    best_idx = np.argmin(scores)\n    return tuple(ops[best_idx])\n\n",
  "machine_id_priority_aug_71": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1].astype(np.float64)\n\n    # Clip to avoid negative values\n    machine_ids = np.clip(machine_ids, 0, None)\n\n    min_machine = np.min(machine_ids)\n    candidates = ops[machine_ids == min_machine]\n\n    # If only one candidate, return it; otherwise choose randomly\n    if len(candidates) == 1:\n        return tuple(candidates[0])\n    else:\n        idx = np.random.choice(len(candidates))\n        return tuple(candidates[idx])\n\n",
  "machine_id_priority_aug_72": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1].astype(np.float64)\n\n    # Clip to keep values non\u2011negative and add epsilon\n    machine_ids = np.clip(machine_ids, 0, None)\n    eps = 1e-12\n\n    # Temperature controls the softness of the selection\n    temperature = 1.0\n    weights = np.exp(-machine_ids / (temperature + eps))\n\n    # Normalise weights (denominator never zero due to eps)\n    probs = weights / (np.sum(weights) + eps)\n\n    # Choose the operation with the highest probability (argmax)\n    best_idx = np.argmax(probs)\n    return tuple(ops[best_idx])\n\n",
  "weighted_job_machine_aug_73": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Gather machine and job times for all feasible operations\n    mach_times = np.array(\n        [current_status['machine_status'][op[1]] for op in feasible_operations],\n        dtype=float\n    )\n    job_times = np.array(\n        [current_status['job_status'][op[0]] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Normalise by mean (with epsilon) and compute weighted score\n    job_norm = job_times / (np.mean(job_times) + 1e-12)\n    mach_norm = mach_times / (np.mean(mach_times) + 1e-12)\n    scores = 0.6 * job_norm + 0.4 * mach_norm\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.arange(len(scores)) * 1e-6\n    scores += noise\n\n    # Choose the operation with the minimal score\n    return feasible_operations[np.argmin(scores)]\n\n",
  "weighted_job_machine_aug_74": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract times using list comprehensions\n    m_times = np.array(\n        [current_status['machine_status'][op[1]] for op in feasible_operations],\n        dtype=float\n    )\n    j_times = np.array(\n        [current_status['job_status'][op[0]] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Normalise by median (with epsilon) and clip scores\n    j_norm = j_times / (np.median(j_times) + 1e-12)\n    m_norm = m_times / (np.median(m_times) + 1e-12)\n    scores = 0.8 * j_norm + 0.2 * m_norm\n    scores = np.clip(scores, 0, 1)\n\n    # Add tiny deterministic noise for deterministic tie\u2011breaking\n    scores += np.arange(len(scores)) * 1e-8\n\n    return feasible_operations[np.argmin(scores)]\n\n",
  "weighted_job_machine_aug_75": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Retrieve times\n    m_t = np.array(\n        [current_status['machine_status'][op[1]] for op in feasible_operations],\n        dtype=float\n    )\n    j_t = np.array(\n        [current_status['job_status'][op[0]] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Normalise and compute scores\n    j_norm = j_t / (np.mean(j_t) + 1e-12)\n    m_norm = m_t / (np.mean(m_t) + 1e-12)\n    scores = 0.5 * j_norm + 0.5 * m_norm\n\n    # Soft\u2011min selection\n    scores = np.clip(scores, 1e-12, None)          # avoid division by zero\n    probs = np.exp(-5 * scores)                    # alpha = 5\n    probs /= np.sum(probs)\n\n    # Randomly pick according to soft\u2011min probabilities\n    idx = np.random.choice(len(probs), p=probs)\n    return feasible_operations[idx]\n\n",
  "weighted_job_machine_aug_76": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Times for all feasible operations\n    m_t = np.array(\n        [current_status['machine_status'][op[1]] for op in feasible_operations],\n        dtype=float\n    )\n    j_t = np.array(\n        [current_status['job_status'][op[0]] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Normalise by maximum (with epsilon) and compute weighted score\n    j_norm = j_t / (np.max(j_t) + 1e-12)\n    m_norm = m_t / (np.max(m_t) + 1e-12)\n    scores = 0.7 * j_norm + 0.3 * m_norm\n\n    # Choose a random operation among the top\u2011k lowest scores\n    top_k = min(7, len(scores))\n    idxs = np.argpartition(scores, top_k - 1)[:top_k]\n    rng = np.random.default_rng(0)                # deterministic RNG\n    chosen = rng.choice(idxs)\n\n    return feasible_operations[chosen]\n\n",
  "adaptive_spt_lpt_aug_77": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Clip machine status to avoid negative values and compute progress\n    machine_status = np.clip(current_status['machine_status'], 0, None)\n    progress = np.max(machine_status) / (np.sum(machine_status) + 1e-12)\n\n    # Invert the usual threshold: choose LPT when progress is high\n    if progress >= 0.4:\n        # Add tiny deterministic noise to each operation's processing time\n        noisy_ops = [\n            (op[0], op[1], op[2] + (hash(op) % 1000) * 1e-6)\n            for op in feasible_operations\n        ]\n        return max(noisy_ops, key=lambda x: x[2])  # LPT\n    else:\n        noisy_ops = [\n            (op[0], op[1], op[2] + (hash(op) % 1000) * 1e-6)\n            for op in feasible_operations\n        ]\n        return min(noisy_ops, key=lambda x: x[2])  # SPT\n\n",
  "adaptive_spt_lpt_aug_78": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    progress = np.sum(machine_status) / (len(machine_status) * np.max(machine_status) + 1e-12)\n\n    times = np.array([op[2] for op in feasible_operations])\n\n    if progress < 0.5:\n        # Randomly pick among the 3 longest operations\n        topk = np.argpartition(-times, 3)[:3]\n        idx = np.random.choice(topk)\n        return feasible_operations[idx]\n    else:\n        # Randomly pick among the 3 shortest operations\n        topk = np.argpartition(times, 3)[:3]\n        idx = np.random.choice(topk)\n        return feasible_operations[idx]\n\n",
  "max_machine_min_processing_aug_79": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Rename for clarity\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1]\n    proc_times = ops[:, 2].astype(float)\n\n    # Gather machine completion times in a vectorised way\n    machine_status = current_status['machine_status']\n    machine_times = np.array([machine_status[mid] for mid in machine_ids], dtype=float)\n\n    # Add a tiny epsilon to avoid zero\u2011division issues in downstream calculations\n    machine_times = np.clip(machine_times, a_min=1e-12, a_max=None)\n\n    # Determine the busiest machine(s) with a deterministic noise term\n    noise = np.arange(len(machine_times)) * 1e-6\n    noisy_times = machine_times + noise\n    max_time = np.max(noisy_times)\n\n    # Select all operations that belong to the busiest machine(s)\n    candidate_mask = noisy_times == max_time\n    candidates = ops[candidate_mask]\n\n    # Among candidates, pick the one with the shortest processing time\n    # (deterministic tie\u2011break using the original processing time)\n    best_idx = np.argmin(candidates[:, 2].astype(float))\n    return tuple(candidates[best_idx])\n\n",
  "max_machine_min_processing_aug_80": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1]\n    proc_times = ops[:, 2].astype(float)\n\n    machine_status = current_status['machine_status']\n    machine_times = np.array([machine_status[mid] for mid in machine_ids], dtype=float)\n\n    # Avoid division by zero by adding a tiny epsilon\n    machine_times = np.clip(machine_times, a_min=1e-12, a_max=None)\n\n    # Invert the selection: pick machine with smallest completion time\n    min_time = np.min(machine_times)\n    mask = machine_times == min_time\n    candidates = ops[mask]\n\n    # Weighted score: 0.7 * machine_time + 0.3 * processing_time\n    # Normalise scores to [0, 1] using clipping\n    scores = 0.7 * machine_times[mask] + 0.3 * proc_times[mask]\n    scores = np.clip(scores, 0, np.max(scores) + 1e-12)\n\n    # Pick operation with minimal score\n    best_idx = np.argmin(scores)\n    return tuple(candidates[best_idx])\n\n",
  "max_machine_min_processing_aug_81": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1]\n    proc_times = ops[:, 2].astype(float)\n\n    machine_status = current_status['machine_status']\n    machine_times = np.array([machine_status[mid] for mid in machine_ids], dtype=float)\n\n    # Ensure machine times are non\u2011zero\n    machine_times = np.clip(machine_times, a_min=1e-12, a_max=None)\n\n    # Determine top_k (here 5) operations with the largest machine times\n    top_k = 5\n    if len(machine_times) <= top_k:\n        top_indices = np.arange(len(machine_times))\n    else:\n        top_indices = np.argpartition(-machine_times, top_k)[:top_k]\n\n    top_ops = ops[top_indices]\n    top_proc_times = proc_times[top_indices]\n\n    # Among top\u2011k, find the minimal processing time(s)\n    min_proc = np.min(top_proc_times)\n    min_mask = top_proc_times == min_proc\n    best_candidates = top_ops[min_mask]\n\n    # If multiple, pick one at random\n    if len(best_candidates) > 1:\n        chosen_idx = np.random.choice(len(best_candidates))\n        return tuple(best_candidates[chosen_idx])\n    else:\n        return tuple(best_candidates[0])\n\n",
  "max_machine_min_processing_aug_82": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1]\n    proc_times = ops[:, 2].astype(float)\n\n    machine_status = current_status['machine_status']\n    machine_times = np.array([machine_status[mid] for mid in machine_ids], dtype=float)\n\n    # Add epsilon to avoid zero\u2011division in exponential calculations\n    machine_times = np.clip(machine_times, a_min=1e-12, a_max=None)\n\n    # Compute a soft\u2011score: lower scores are better\n    # weight controls influence of machine time vs processing time\n    weight = 0.8\n    scores = weight * machine_times + (1 - weight) * proc_times\n    # Add tiny random noise to break ties deterministically\n    noise = np.random.uniform(-1e-6, 1e-6, size=scores.shape)\n    scores += noise\n\n    # Convert to probabilities via softmax (negative scores)\n    exp_vals = np.exp(-scores - np.max(-scores))  # stability\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)  # clip epsilon\n\n    # Choose operation with highest probability (argmax)\n    chosen_idx = np.argmax(probs)\n    return tuple(ops[chosen_idx])\n\n",
  "composite_three_factor_aug_83": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = current_status['machine_status']\n    job = current_status['job_status']\n\n    # Extract the relevant values using list comprehensions\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([machine[op[1]] for op in feasible_operations], dtype=float)\n    job_times = np.array([job[op[0]] for op in feasible_operations], dtype=float)\n\n    # Normalise by the mean plus a tiny epsilon\n    proc_norm = proc_times / (np.mean(proc_times) + 1e-12)\n    mach_norm = mach_times / (np.mean(mach_times) + 1e-12)\n    job_norm = job_times  / (np.mean(job_times)  + 1e-12)\n\n    # Clip the normalised values to keep them in a reasonable range\n    proc_norm = np.clip(proc_norm, 0, 10)\n    mach_norm = np.clip(mach_norm, 0, 10)\n    job_norm = np.clip(job_norm, 0, 10)\n\n    # Composite score (weights unchanged from the original)\n    scores = 0.4 * proc_norm + 0.3 * mach_norm + 0.3 * job_norm\n\n    # Pick the operation with the minimum score by taking the argmax of the negative\n    idx = np.argmax(-scores)\n    return feasible_operations[idx]\n\n",
  "composite_three_factor_aug_84": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = current_status['machine_status']\n    j_stat = current_status['job_status']\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach = np.array([m_stat[op[1]] for op in feasible_operations], dtype=float)\n    jobt = np.array([j_stat[op[0]] for op in feasible_operations], dtype=float)\n\n    # Use the median for normalisation instead of the mean\n    proc_norm = proc / (np.median(proc) + 1e-12)\n    mach_norm = mach / (np.median(mach) + 1e-12)\n    job_norm = jobt / (np.median(jobt) + 1e-12)\n\n    # Add a tiny deterministic noise to break ties\n    noise = 1e-6 * np.arange(len(feasible_operations))\n    scores = 0.5 * proc_norm + 0.25 * mach_norm + 0.25 * job_norm + noise\n\n    # Clip scores to a sensible range before selecting the minimum\n    scores = np.clip(scores, 0, 1)\n\n    idx = np.argmin(scores)\n    return feasible_operations[idx]\n\n",
  "composite_three_factor_aug_85": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m = current_status['machine_status']\n    j = current_status['job_status']\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach = np.array([m[op[1]] for op in feasible_operations], dtype=float)\n    jobt = np.array([j[op[0]] for op in feasible_operations], dtype=float)\n\n    proc_norm = proc / (np.mean(proc) + 1e-12)\n    mach_norm = mach / (np.mean(mach) + 1e-12)\n    job_norm = jobt / (np.mean(jobt) + 1e-12)\n\n    scores = 0.4 * proc_norm + 0.3 * mach_norm + 0.3 * job_norm\n\n    # Soft\u2011min probability distribution\n    alpha = 5.0\n    probs = np.exp(-alpha * scores)\n    probs /= probs.sum() + 1e-12\n\n    # Randomly pick among the top\u2011k most probable operations\n    top_k = min(3, len(feasible_operations))\n    top_idx = np.argsort(probs)[:top_k]\n    top_probs = probs[top_idx]\n    top_probs /= top_probs.sum() + 1e-12\n\n    chosen = np.random.choice(top_idx, p=top_probs)\n    return feasible_operations[chosen]\n\n",
  "composite_three_factor_aug_86": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = current_status['machine_status']\n    job = current_status['job_status']\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach = np.array([machine[op[1]] for op in feasible_operations], dtype=float)\n    jobt = np.array([job[op[0]] for op in feasible_operations], dtype=float)\n\n    # Normalise by the maximum value (proxy approximation)\n    proc_norm = proc / (np.max(proc) + 1e-12)\n    mach_norm = mach / (np.max(mach) + 1e-12)\n    job_norm = jobt / (np.max(jobt) + 1e-12)\n\n    # Different weight distribution\n    scores = 0.6 * proc_norm + 0.2 * mach_norm + 0.2 * job_norm\n\n    # Deterministic tie\u2011breaking by adding a tiny epsilon times the index\n    scores += 1e-9 * np.arange(len(feasible_operations))\n\n    # Ensure scores stay within a bounded range\n    scores = np.clip(scores, 0, 1)\n\n    idx = np.argmin(scores)\n    return feasible_operations[idx]\n\n",
  "exponential_processing_weight_aug_87": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract processing times\n    times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Use median to reduce influence of outliers\n    denom = np.median(times) + 1e-12\n    wts = np.exp(-times / denom)\n\n    # Deterministic noise to break ties\n    noise = 1e-8 * np.arange(len(feasible_operations))\n    wts += noise\n\n    ms = current_status['machine_status']\n    seed = int(sum(ms)) % (2**31)\n    rng_gen = np.random.default_rng(seed)\n\n    probs = wts / (np.sum(wts) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1 - 1e-12)\n\n    idx = int(rng_gen.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n\n",
  "exponential_processing_weight_aug_88": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Inverse weighting: shorter times get larger weights\n    wts = 1.0 / (times + 1e-12)\n\n    # Softmax to keep values in a reasonable range\n    wts = np.exp(np.log(wts) - np.log(np.sum(wts) + 1e-12))\n\n    ms = current_status['machine_status']\n    seed = (int(sum(ms)) + len(feasible_operations)) % (2**31)\n    rng_gen = np.random.default_rng(seed)\n\n    # Select top\u2011k by weight\n    top_k = 3\n    idxs = np.argpartition(-wts, top_k - 1)[:top_k]\n    probs = wts[idxs]\n    probs = probs / (np.sum(probs) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1 - 1e-12)\n\n    chosen = rng_gen.choice(idxs, p=probs)\n    return feasible_operations[chosen]\n\n",
  "exponential_processing_weight_aug_89": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Inverse weighting\n    wts = 1.0 / (times + 1e-12)\n    wts = np.clip(wts, 1e-12, 1e12)\n\n    # Deterministic noise based on index\n    noise = 1e-9 * np.arange(len(feasible_operations))\n    wts += noise\n\n    idx = int(np.argmax(wts))\n    return feasible_operations[idx]\n\n",
  "exponential_processing_weight_aug_90": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Softmin: smaller times get higher probability\n    wts = np.exp(-times / (np.mean(times) + 1e-12))\n    wts = np.clip(wts, 1e-12, 1e12)\n\n    ms = current_status['machine_status']\n    seed = int(np.sum(ms) * 1000) % (2**31)\n    rng_gen = np.random.default_rng(seed)\n\n    probs = wts / (np.sum(wts) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1 - 1e-12)\n\n    idx = int(rng_gen.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n\n",
  "round_robin_jobs_aug_91": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n\n    # Build a dictionary of operations grouped by job id\n    jobs = {}\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        job = op[0]\n        jobs.setdefault(job, []).append(op)\n        idx += 1\n\n    # Compute the total machine time for each job\n    job_keys = np.array(list(jobs.keys()), dtype=int)\n    total_times = np.array(\n        [sum(m_status[op[1]] for op in jobs[j]) for j in job_keys],\n        dtype=np.float64,\n    )\n\n    # Add a small random perturbation to avoid exact ties\n    noise = np.random.uniform(0, 1e-6, size=total_times.shape)\n    # Soft\u2011min: larger weight for smaller times\n    weights = np.exp(-(total_times + noise) / (1.0 + 1e-12))\n    best_job = job_keys[np.argmax(weights)]\n\n    # Pick the operation with the shortest duration within the best job\n    ops = jobs[best_job]\n    durations = np.array([op[2] for op in ops], dtype=np.float64)\n    durations = np.clip(durations, 0, 1e9)  # prevent overflow\n    # Add noise for deterministic tie\u2011breaking\n    durations += 1e-12 * np.random.rand(len(durations))\n    best_idx = np.argmin(durations)\n    return ops[best_idx]\n\n",
  "round_robin_jobs_aug_92": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n\n    # Group operations by job id\n    jobs = {}\n    for op in feasible_operations:\n        jobs.setdefault(op[0], []).append(op)\n\n    # Compute the maximum machine time for each job\n    job_keys = np.array(list(jobs.keys()), dtype=int)\n    max_times = np.array(\n        [max(m_status[op[1]] for op in jobs[j]) for j in job_keys],\n        dtype=np.float64,\n    )\n\n    # Clip to avoid extreme values\n    max_times = np.clip(max_times, 0, 1e9)\n\n    # Invert the times to use as weights (smaller times \u2192 larger weight)\n    weights = 1.0 / (max_times + 1e-12)\n    top_k = min(7, len(weights))\n    top_indices = np.argpartition(weights, -top_k)[-top_k:]\n    chosen_idx = np.random.choice(top_indices)\n    best_job = job_keys[chosen_idx]\n\n    # Choose the shortest operation of the selected job\n    ops = jobs[best_job]\n    durations = np.array([op[2] for op in ops], dtype=np.float64)\n    durations = np.clip(durations, 0, 1e9)\n    durations += 1e-12 * np.random.rand(len(durations))\n    best_idx = np.argmin(durations)\n    return ops[best_idx]\n\n",
  "round_robin_jobs_aug_93": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n\n    # Build a list of jobs and their operations\n    jobs = {}\n    for op in feasible_operations:\n        jobs.setdefault(op[0], []).append(op)\n\n    # Compute mean machine time for each job (vectorised)\n    job_keys = np.array(list(jobs.keys()), dtype=int)\n    mean_times = np.array(\n        [np.mean([m_status[op[1]] for op in jobs[j]]) for j in job_keys],\n        dtype=np.float64,\n    )\n    mean_times = np.clip(mean_times, 0, 1e9)\n\n    # Randomly pick one of the three jobs with the lowest mean times\n    top_k = min(3, len(mean_times))\n    top_indices = np.argpartition(mean_times, top_k - 1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    best_job = job_keys[chosen_idx]\n\n    # Select the operation with the minimal duration\n    ops = jobs[best_job]\n    durations = np.array([op[2] for op in ops], dtype=np.float64)\n    durations = np.clip(durations, 0, 1e9)\n    durations += 1e-12 * np.random.rand(len(durations))\n    best_idx = np.argmin(durations)\n    return ops[best_idx]\n\n",
  "round_robin_jobs_aug_94": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n\n    # Group operations by job id\n    jobs = {}\n    for op in feasible_operations:\n        jobs.setdefault(op[0], []).append(op)\n\n    # Compute aggregated metrics\n    job_keys = np.array(list(jobs.keys()), dtype=int)\n    sums = np.array(\n        [sum(m_status[op[1]] for op in jobs[j]) for j in job_keys],\n        dtype=np.float64,\n    )\n    maxs = np.array(\n        [max(m_status[op[1]] for op in jobs[j]) for j in job_keys],\n        dtype=np.float64,\n    )\n\n    # Weighted score: 0.6 * sum + 0.4 * max\n    scores = 0.6 * sums + 0.4 * maxs\n    scores = np.clip(scores, 0, 1e9)\n\n    # Pick the job with the minimal score\n    best_idx = np.argmin(scores)\n    best_job = job_keys[best_idx]\n\n    # Select the operation with the shortest duration\n    ops = jobs[best_job]\n    durations = np.array([op[2] for op in ops], dtype=np.float64)\n    durations = np.clip(durations, 0, 1e9)\n    durations += 1e-12 * np.random.rand(len(durations))\n    best_op_idx = np.argmin(durations)\n    return ops[best_op_idx]\n\n",
  "ratio_processing_availability_aug_95": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    eps = 1e-12\n    # Compute ratios with a small deterministic noise to break ties\n    ratios = [\n        np.clip(\n            op[2] / (machine_state[op[1]] + 1.0 + eps),\n            0,\n            1e6\n        ) + idx * 1e-8\n        for idx, op in enumerate(feasible_operations)\n    ]\n    best_index = int(np.argmin(ratios))\n    return feasible_operations[best_index]\n\n",
  "ratio_processing_availability_aug_96": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    eps = 1e-12\n    best_idx = None\n    best_val = np.inf\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        ratio = np.clip(\n            op[2] / (machine_state[op[1]] + 1.0 + eps),\n            0,\n            1e6\n        ) + idx * 1e-9  # deterministic tie\u2011breaker\n        if ratio < best_val:\n            best_val = ratio\n            best_idx = idx\n        idx += 1\n    return feasible_operations[best_idx]\n\n",
  "ratio_processing_availability_aug_97": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_state = current_status['machine_status']\n    eps = 1e-12\n    times = np.array([op[2] for op in feasible_operations], dtype=float)\n    avail = np.array([machine_state[op[1]] for op in feasible_operations], dtype=float)\n\n    # Weighted ratio: 60\u202f% processing time ratio + 40\u202f% raw time\n    ratios = 0.6 * (times / (avail + 1.0 + eps)) + 0.4 * times\n    ratios = np.clip(ratios, 0, 1e6)\n\n    # Argmin via argmax of the negative values\n    idx = int(np.argmax(-ratios))\n\n    # If the chosen index is not among the top\u20115, pick randomly from them\n    top_k = 5\n    sorted_indices = np.argsort(ratios)\n    top_indices = sorted_indices[:top_k]\n    if idx not in top_indices:\n        idx = np.random.choice(top_indices)\n\n    return feasible_operations[idx]\n\n",
  "stochastic_greedy_aug_98": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    # Extract processing times with a list comprehension\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Inverse processing times with a safety epsilon\n    inv_times = 1.0 / (proc_times + 1e-12)\n\n    # Deterministic noise to break ties\n    noise = np.linspace(0, 1e-6, len(feasible_operations))\n    inv_times += noise\n\n    # Compute probabilities and clip to avoid numerical issues\n    probs = inv_times / (inv_times.sum() + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # Seed from the sum of the status arrays\n    seed = int(sum(machine_status) + sum(job_status)) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n\n",
  "stochastic_greedy_aug_99": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Soft\u2011min weighting (exponential decay)\n    alpha = 0.5\n    weights = np.exp(-alpha * proc_times)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = 1e-8 * np.arange(len(feasible_operations))\n    weights += noise\n\n    # Keep only the top\u2011k shortest operations\n    top_k = 3\n    top_indices = np.argsort(proc_times)[:top_k]\n    top_weights = weights[top_indices]\n\n    probs = top_weights / (top_weights.sum() + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # Seed from the product of the status sums\n    seed = int(sum(machine_status) * sum(job_status)) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    chosen = rng.choice(top_indices, p=probs)\n    return feasible_operations[chosen]\n\n",
  "stochastic_greedy_aug_100": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Inverse times with epsilon\n    inv_times = 1.0 / (proc_times + 1e-12)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-8 * np.arange(len(feasible_operations))\n    inv_times += noise\n\n    # Normalise to probabilities and clip\n    probs = inv_times / (inv_times.sum() + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # Manual cumulative distribution for selection\n    cum_probs = np.cumsum(probs)\n\n    # Seed derived from the mean of the status arrays\n    seed = int(np.clip(np.mean(machine_status) * np.mean(job_status), 0, 2**31 - 1))\n    rng = np.random.default_rng(seed)\n\n    rand_val = rng.random()\n    idx = np.searchsorted(cum_probs, rand_val)\n    return feasible_operations[idx]\n\n",
  "stochastic_greedy_aug_101": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Proxy weighting: inverse square to heavily favour short times\n    inv_sq = 1.0 / (proc_times**2 + 1e-12)\n\n    # Deterministic noise to break ties\n    noise = 1e-9 * np.arange(len(feasible_operations))\n    inv_sq += noise\n\n    probs = inv_sq / (inv_sq.sum() + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # Seed with a simple multiplier on the status sums\n    seed = int((sum(machine_status) + sum(job_status)) * 7) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n\n",
  "hybrid_makespan_estimator_aug_102": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'],     dtype=float)\n\n    best_op       = None\n    best_makespan = np.inf\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        # start time is the later of machine and job availability\n        start = max(machine_status[op[1]], job_status[op[0]]) + 1e-12\n\n        # simulate new status after performing this operation\n        new_mach = machine_status.copy()\n        new_job  = job_status.copy()\n        new_mach[op[1]] = start + op[2]\n        new_job[op[0]]  = start + op[2]\n\n        # makespan for this candidate\n        makespan = max(np.max(new_mach), np.max(new_job))\n\n        # deterministic noise to break ties\n        noise = 1e-9 * (idx + 1)\n        if makespan + noise < best_makespan:\n            best_makespan = makespan + noise\n            best_op = op\n\n        idx += 1\n\n    return best_op\n\n",
  "hybrid_makespan_estimator_aug_103": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'],     dtype=float)\n    ops            = np.array(feasible_operations, dtype=object)\n\n    n_ops = ops.shape[0]\n    makespans = np.empty(n_ops, dtype=float)\n\n    # compute makespan for each candidate\n    for i, op in enumerate(ops):\n        start = max(machine_status[op[1]], job_status[op[0]]) + 1e-12\n        new_mach = machine_status.copy()\n        new_job  = job_status.copy()\n        new_mach[op[1]] = start + op[2]\n        new_job[op[0]]  = start + op[2]\n        makespans[i] = max(np.max(new_mach), np.max(new_job))\n\n    # keep only the best top_k candidates\n    top_k = 7\n    if n_ops > top_k:\n        idx_sorted = np.argsort(makespans)\n        top_idx    = idx_sorted[:top_k]\n        ops        = ops[top_idx]\n        makespans  = makespans[top_idx]\n\n    # soft\u2011min weighting\n    beta   = 1.0\n    weights = np.exp(-beta * makespans)\n    weights = weights / (np.sum(weights) + 1e-12)          # epsilon in denominator\n    weights = np.clip(weights, 0, 1)                       # bound probabilities\n\n    chosen = np.random.choice(len(ops), p=weights)\n    return tuple(ops[chosen])\n\n",
  "hybrid_makespan_estimator_aug_104": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'],     dtype=float)\n\n    best_op   = None\n    best_score = np.inf\n\n    for op in feasible_operations:\n        start = max(machine_status[op[1]], job_status[op[0]]) + 1e-12\n        new_mach = machine_status.copy()\n        new_job  = job_status.copy()\n        new_mach[op[1]] = start + op[2]\n        new_job[op[0]]  = start + op[2]\n\n        # median of all completion times\n        all_times = np.concatenate([new_mach, new_job])\n        score = np.median(all_times)\n\n        # deterministic noise based on the hash of the operation\n        noise = 1e-6 * (hash(op) % 100000)\n        if score + noise < best_score:\n            best_score = score + noise\n            best_op = op\n\n    return best_op\n\n",
  "hybrid_makespan_estimator_aug_105": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'],     dtype=float)\n\n    best_op       = None\n    best_makespan = np.inf\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        start = max(machine_status[op[1]], job_status[op[0]]) + 1e-12\n\n        new_mach = machine_status.copy()\n        new_job  = job_status.copy()\n        new_mach[op[1]] = start + op[2]\n        new_job[op[0]]  = start + op[2]\n\n        # clip to avoid overflow in pathological cases\n        new_mach = np.clip(new_mach, None, 1e9)\n        new_job  = np.clip(new_job,  None, 1e9)\n\n        makespan = np.max([np.max(new_mach), np.max(new_job)])\n        if makespan < best_makespan:\n            best_makespan = makespan\n            best_op = op\n\n        idx += 1\n\n    return best_op\n\n",
  "normalized_multi_objective_aug_106": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # renamed variables for clarity\n    status = current_status\n    mach_state = status['machine_status']\n    job_state  = status['job_status']\n\n    # build arrays with a list comprehension\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_times = np.array([mach_state[op[1]] for op in feasible_operations], dtype=float)\n    job_times  = np.array([job_state[op[0]]  for op in feasible_operations], dtype=float)\n\n    def minmax_norm(x):\n        mn, mx = x.min(), x.max()\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    # weighted sum with different weights\n    proc_norm = minmax_norm(proc_times)\n    mach_norm = minmax_norm(mach_times)\n    job_norm  = minmax_norm(job_times)\n\n    scores = 0.4 * proc_norm + 0.3 * mach_norm + 0.3 * job_norm\n\n    # deterministic tie\u2011breaking with a tiny noise term\n    noise = np.arange(len(scores), dtype=float) * 1e-6\n    return feasible_operations[int(np.argmin(scores + noise))]\n\n",
  "normalized_multi_objective_aug_107": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # local aliases\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # gather data with a while\u2011loop\n    n = len(feasible_operations)\n    proc = np.empty(n, dtype=float)\n    mach = np.empty(n, dtype=float)\n    job  = np.empty(n, dtype=float)\n    i = 0\n    while i < n:\n        op = feasible_operations[i]\n        proc[i] = op[2]\n        mach[i] = ms[op[1]]\n        job[i]  = js[op[0]]\n        i += 1\n\n    def minmax_norm(x):\n        mn, mx = x.min(), x.max()\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    proc_norm = minmax_norm(proc)\n    mach_norm = minmax_norm(mach)\n    job_norm  = minmax_norm(job)\n\n    # aggregate with median\n    scores = np.median([proc_norm, mach_norm, job_norm], axis=0)\n\n    # soft\u2011min probabilities\n    alpha = 1.0\n    probs = np.exp(-alpha * scores)\n    probs /= probs.sum() + 1e-12\n\n    # sample random top\u20113\n    top_k = 3\n    top_indices = np.argsort(probs)[-top_k:][::-1]\n    rng = np.random.default_rng()\n    chosen = rng.choice(top_indices)\n    return feasible_operations[int(chosen)]\n\n",
  "normalized_multi_objective_aug_108": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # build arrays using a for\u2011loop\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    job  = np.array([js[op[0]]  for op in feasible_operations], dtype=float)\n\n    def simple_norm(x):\n        max_val = x.max() + 1e-12\n        return np.clip(x / max_val, 0.0, 1.0)\n\n    proc_norm = simple_norm(proc)\n    mach_norm = simple_norm(mach)\n    job_norm  = simple_norm(job)\n\n    # use sum aggregation\n    scores = proc_norm + mach_norm + job_norm\n\n    # random choice among the 5 lowest scores\n    top_k = 5\n    sorted_idx = np.argsort(scores)\n    candidates = sorted_idx[:top_k]\n    rng = np.random.default_rng()\n    chosen = rng.choice(candidates)\n    return feasible_operations[int(chosen)]\n\n",
  "normalized_multi_objective_aug_109": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # collect data with a list comprehension\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    job  = np.array([js[op[0]] for op in feasible_operations], dtype=float)\n\n    def inverted_norm(x):\n        mx = x.max() + 1e-12\n        return np.clip((mx - x) / (mx + 1e-12), 0.0, 1.0)\n\n    proc_inv = inverted_norm(proc)\n    mach_inv = inverted_norm(mach)\n    job_inv  = inverted_norm(job)\n\n    # weighted sum with different weights\n    scores = 0.5 * proc_inv + 0.25 * mach_inv + 0.25 * job_inv\n\n    # add deterministic noise for tie\u2011breaking\n    noise = np.linspace(0, 1e-6, len(scores))\n    return feasible_operations[int(np.argmin(scores + noise))]\n\n",
  "idle_time_minimizer_aug_110": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    # Build idle\u2011time array with a while\u2011loop (syntactic rewrite)\n    idle = np.empty(len(feasible_operations), dtype=np.float64)\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        # Compute idle time and clip to non\u2011negative values\n        idle_val = job_status[op[0]] - machine_status[op[1]]\n        idle_val = max(0.0, idle_val)\n        idle[i] = idle_val\n        i += 1\n\n    # Add a deterministic noise term to break ties\n    noise = np.arange(len(feasible_operations)) * 1e-9\n    idle += noise\n\n    # Choose the operation with the smallest (noisy) idle time\n    chosen_index = int(np.argmin(idle))\n    return feasible_operations[chosen_index]\n\n",
  "idle_time_minimizer_aug_111": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    # Vectorised idle\u2011time calculation\n    idle = np.array(\n        [max(0.0, job_status[op[0]] - machine_status[op[1]]) for op in feasible_operations],\n        dtype=np.float64\n    )\n\n    # Hyper\u2011parameter: weight for the idle time component (0.0\u20131.0)\n    weight = 0.6\n    # The second component is a placeholder (zero) \u2013 this keeps the semantics\n    weighted_idle = weight * idle + (1.0 - weight) * 0.0\n\n    # Clip to avoid any negative values caused by numerical errors\n    weighted_idle = np.clip(weighted_idle, 0, None)\n\n    # Return the operation with the minimal weighted idle time\n    chosen_index = int(np.argmin(weighted_idle))\n    return feasible_operations[chosen_index]\n\n",
  "idle_time_minimizer_aug_112": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    # Compute idle times and clip to non\u2011negative\n    idle = np.array(\n        [max(0.0, job_status[op[0]] - machine_status[op[1]]) for op in feasible_operations],\n        dtype=np.float64\n    )\n    idle = np.clip(idle, 0, None)\n\n    # Soft\u2011min parameters\n    beta = 5.0  # temperature; higher beta \u2192 more greedy\n    # Compute Boltzmann weights (add epsilon to avoid division by zero)\n    exp_vals = np.exp(-beta * idle + 1e-12)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Randomly choose an operation according to the soft\u2011min probabilities\n    chosen_index = int(np.random.choice(len(feasible_operations), p=probs))\n    return feasible_operations[chosen_index]\n\n",
  "idle_time_minimizer_aug_113": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    job_status = current_status['job_status']\n\n    # Compute idle times\n    idle = np.array(\n        [max(0.0, job_status[op[0]] - machine_status[op[1]]) for op in feasible_operations],\n        dtype=np.float64\n    )\n    idle = np.clip(idle, 0, None)\n\n    # Median threshold with a tiny epsilon to keep it strictly positive\n    median_val = np.median(idle) + 1e-12\n\n    # Find all operations below the median threshold\n    candidates = np.where(idle <= median_val)[0]\n\n    if candidates.size > 0:\n        # If there are candidates, pick the one with the smallest idle among them\n        chosen_index = int(np.argmin(idle[candidates]))\n        chosen_index = candidates[chosen_index]\n    else:\n        # Fallback: choose the overall minimal idle time\n        chosen_index = int(np.argmin(idle))\n\n    return feasible_operations[chosen_index]\n\n",
  "priority_score_blend_aug_114": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n\n    # Gather processing times and current machine loads\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_loads = np.array([machine_status.get(op[1], 0.0) for op in feasible_operations], dtype=float)\n\n    # Avoid division by zero and keep loads non\u2011negative\n    mach_loads = np.clip(mach_loads, 1e-12, None)\n\n    # Inverse values (add tiny epsilon for safety)\n    inv_proc = 1.0 / (proc_times + 1e-12)\n    inv_mach = 1.0 / (mach_loads + 1.0)\n\n    # Combine scores and add deterministic tie\u2011breaking noise\n    scores = inv_proc + inv_mach\n    scores += 1e-6 * np.arange(len(feasible_operations))\n\n    # Pick the operation with the highest score\n    idx = int(np.argmax(scores))\n    return feasible_operations[idx]\n\n",
  "priority_score_blend_aug_115": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    rng = np.random.default_rng()\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_loads = np.array([machine_status.get(op[1], 0.0) for op in feasible_operations], dtype=float)\n\n    inv_proc = 1.0 / (proc_times + 1e-12)\n    inv_mach = 1.0 / (mach_loads + 1.0)\n\n    # Weighted combination with a bias toward processing time\n    scores = 0.7 * inv_proc + 0.3 * inv_mach\n\n    # Small deterministic noise to break ties\n    noise = 1e-7 * rng.integers(0, 100, size=len(feasible_operations))\n    scores += noise\n\n    # Randomly pick from the top\u2011k scoring operations\n    top_k = min(3, len(feasible_operations))\n    top_indices = np.argpartition(-scores, top_k - 1)[:top_k]\n    chosen_idx = int(rng.choice(top_indices))\n\n    return feasible_operations[chosen_idx]\n\n",
  "priority_score_blend_aug_116": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_loads = np.array([machine_status.get(op[1], 0.0) for op in feasible_operations], dtype=float)\n\n    inv_proc = 1.0 / (proc_times + 1e-12)\n    inv_mach = 1.0 / (mach_loads + 1.0)\n\n    # Median of the two inverse values per operation\n    scores = np.median([inv_proc, inv_mach], axis=0)\n    scores = np.clip(scores, 0, None)  # ensure non\u2011negative\n\n    # Deterministic tie\u2011breaking with a small decreasing noise\n    scores -= 1e-8 * np.arange(len(feasible_operations))\n\n    idx = int(np.argmax(scores))\n    return feasible_operations[idx]\n\n",
  "priority_score_blend_aug_117": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = current_status['machine_status']\n    rng = np.random.default_rng()\n\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    mach_loads = np.array([machine_status.get(op[1], 0.0) for op in feasible_operations], dtype=float)\n\n    inv_proc = 1.0 / (proc_times + 1e-12)\n    inv_mach = 1.0 / (mach_loads + 1.0)\n\n    scores = inv_proc + inv_mach\n\n    # Convert scores to a softmin probability distribution\n    exp_neg = np.exp(-scores)\n    probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    chosen_idx = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[chosen_idx]\n\n",
  "earliest_start_longest_processing_aug_118": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Compute earliest start times\n    starts = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    starts = np.clip(starts, 0, None)                     # keep non\u2011negative\n\n    # Weighted score: earlier start + moderate processing time\n    scores = starts + 0.5 * ops[:, 2]\n\n    # Small deterministic noise to break ties\n    noise = np.random.uniform(0, 1e-6, size=scores.shape)\n    scores += noise\n\n    idx = np.argmin(scores)\n    return tuple(ops[idx])\n\n",
  "earliest_start_longest_processing_aug_119": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Extract arrays for vectorised operations\n    job_ids   = np.array([op[0] for op in feasible_operations])\n    machine_ids = np.array([op[1] for op in feasible_operations])\n    proc_times = np.array([op[2] for op in feasible_operations])\n\n    starts = np.maximum(ms[machine_ids], js[job_ids])\n    starts = np.clip(starts, 0, None)\n\n    # Tuned weighted sum (more emphasis on start time)\n    scores = 0.7 * starts + 0.3 * proc_times\n\n    # Soft\u2011min probabilities\n    min_score = np.min(scores)\n    exp_vals = np.exp(- (scores - min_score) / (0.1 + 1e-12))\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Randomly pick from the best three candidates\n    top_k = 3\n    top_idx = np.argpartition(-scores, top_k-1)[:top_k]\n    chosen = np.random.choice(top_idx, p=probs[top_idx] / (np.sum(probs[top_idx]) + 1e-12))\n\n    return feasible_operations[chosen]\n\n",
  "earliest_start_longest_processing_aug_120": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    starts = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    starts = np.clip(starts, 0, None)\n\n    # Use median of starts to normalise\n    median_start = np.median(starts)\n\n    # Load proxy: maximum machine utilisation among candidates\n    load = np.max(ms[ops[:, 1]])\n\n    scores = (starts - median_start) + 0.5 * ops[:, 2] + 0.1 * load\n    scores = np.clip(scores, -1e12, 1e12)            # bound to avoid overflow\n\n    # Deterministic noise for reproducible tie\u2011breaking\n    noise = 1e-6 * np.arange(len(scores))\n    scores += noise\n\n    idx = np.argmin(scores)\n    return tuple(ops[idx])\n\n",
  "earliest_start_longest_processing_aug_121": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        ms = current_status['machine_status']\n        js = current_status['job_status']\n        best_op = None\n        best_key = (np.inf, np.inf, np.inf)\n\n        i = 0\n        while i < len(feasible_operations):\n            op = feasible_operations[i]\n            start = max(ms[op[1]], js[op[0]])\n            start = np.clip(start, 0, None)           # ensure non\u2011negative\n\n            key = (start, -op[2], ms[op[1]])\n            if key < best_key:\n                best_key = key\n                best_op = op\n            i += 1\n\n        return best_op\n    else:\n        return None\n\n",
  "latest_start_shortest_processing_aug_122": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = current_status['machine_status']\n    job_stat = current_status['job_status']\n    eps = 1e-12\n\n    # Pre\u2011compute clipped start times\n    starts = [\n        np.clip(max(mach_stat[op[1]], job_stat[op[0]]), 0, 1e6)\n        for op in feasible_operations\n    ]\n\n    # Compute a score: negative ratio of start to processing time, plus small noise\n    scores = [\n        - (s / (op[2] + eps)) + (op[0] * 1e-6)  # deterministic tie\u2011breaker\n        for s, op in zip(starts, feasible_operations)\n    ]\n\n    # Find the operation with the minimal score using a while loop\n    min_idx = 0\n    min_score = scores[0]\n    i = 1\n    while i < len(scores):\n        if scores[i] < min_score:\n            min_score = scores[i]\n            min_idx = i\n        i += 1\n\n    return feasible_operations[min_idx]\n\n",
  "latest_start_shortest_processing_aug_123": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = current_status['machine_status']\n    job_stat = current_status['job_status']\n    eps = 1e-12\n\n    # Compute start times and ratio scores\n    starts = np.array([max(mach_stat[op[1]], job_stat[op[0]]) for op in feasible_operations])\n    ratios = starts / (np.array([op[2] for op in feasible_operations]) + eps)\n\n    # Weighted score: 0.6*ratio + 0.4*processing_time\n    weights = np.array([0.6, 0.4])\n    scores = weights[0] * ratios + weights[1] * np.array([op[2] for op in feasible_operations])\n\n    # Soft\u2011min probability distribution\n    exp_neg = np.exp(-scores)\n    probs = exp_neg / (np.sum(exp_neg) + eps)\n    probs = np.clip(probs, 0, 1)  # safeguard against numerical errors\n\n    # Select the operation with the highest probability\n    chosen_idx = int(np.argmax(probs))\n    return feasible_operations[chosen_idx]\n\n",
  "latest_start_shortest_processing_aug_124": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = current_status['machine_status']\n    job_stat = current_status['job_status']\n    eps = 1e-12\n\n    # Compute start times and median\u2011adjusted scores\n    starts = np.array([max(mach_stat[op[1]], job_stat[op[0]]) for op in feasible_operations])\n    median_start = np.median(starts)\n    adj_start = starts - median_start  # center around median\n\n    # Compute a composite score: adjusted start + processing time\n    scores = adj_start + np.array([op[2] for op in feasible_operations])\n\n    # Select top\u2011k (k=3) candidates\n    k = 3\n    if len(scores) <= k:\n        top_k_idx = np.arange(len(scores))\n    else:\n        top_k_idx = np.argpartition(scores, k)[:k]\n\n    # Among top\u2011k, choose the one with the smallest score (deterministic)\n    best_idx_in_top = top_k_idx[np.argmin(scores[top_k_idx])]\n    return feasible_operations[best_idx_in_top]\n\n",
  "latest_start_shortest_processing_aug_125": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = current_status['machine_status']\n    job_stat = current_status['job_status']\n    eps = 1e-12\n\n    # Vectorised start time computation with clipping\n    starts = np.array([\n        np.clip(max(mach_stat[op[1]], job_stat[op[0]]), 0, 1e6)\n        for op in feasible_operations\n    ])\n\n    # Vectorised processing times\n    proc_times = np.array([op[2] for op in feasible_operations])\n\n    # Compute a score: start / (proc_time + eps) + eps to avoid division by zero\n    scores = starts / (proc_times + eps) + eps\n\n    # Select operation with the minimal score\n    chosen_idx = int(np.argmin(scores))\n    return feasible_operations[chosen_idx]\n\n",
  "job_waiting_pressure_aug_126": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n    # Vectorised pressure calculation\n    machine_times = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n    pressures = np.maximum(0.0, machine_times - job_times)\n    # Highest pressure first\n    max_idx = int(np.argmax(pressures))\n    best_pressure = pressures[max_idx]\n    # All ops with the same maximal pressure\n    candidates_idx = np.where(np.abs(pressures - best_pressure) < 1e-12)[0]\n    if len(candidates_idx) == 1:\n        return feasible_operations[candidates_idx[0]]\n    # Tie\u2011break by the smallest processing time\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    min_proc_idx = candidates_idx[np.argmin(proc_times[candidates_idx])]\n    return feasible_operations[min_proc_idx]\n\n",
  "job_waiting_pressure_aug_127": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n    eps = 1e-12\n    machine_times = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n    # Pressure with a safe denominator\n    pressures = (machine_times - job_times) / (1.0 + eps)\n    pressures = np.maximum(0.0, pressures)\n    # Deterministic noise to break ties\n    noise = np.arange(len(pressures), dtype=float) * 1e-6\n    pressures_noisy = pressures + noise\n    max_idx = int(np.argmax(pressures_noisy))\n    best_pressure = pressures[max_idx]\n    # Candidates with equal true pressure\n    candidates_idx = np.where(np.abs(pressures - best_pressure) < eps)[0]\n    if len(candidates_idx) == 1:\n        return feasible_operations[candidates_idx[0]]\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    proc_times_clipped = np.clip(proc_times, a_min=0.0, a_max=None)\n    min_proc_idx = candidates_idx[np.argmin(proc_times_clipped[candidates_idx])]\n    return feasible_operations[min_proc_idx]\n\n",
  "job_waiting_pressure_aug_128": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n    eps = 1e-12\n    machine_times = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n    pressures = np.maximum(0.0, machine_times - job_times)\n    # Randomly pick among the top\u2011k highest pressures\n    top_k = min(3, len(pressures))\n    if top_k == 0:\n        return None\n    top_indices = np.argpartition(-pressures, top_k-1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "job_waiting_pressure_aug_129": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n    eps = 1e-12\n    machine_times = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n    pressures = np.maximum(0.0, machine_times - job_times)\n    # Use the median pressure as a threshold\n    median_pressure = np.median(pressures)\n    candidates_idx = np.where(pressures >= median_pressure)[0]\n    if len(candidates_idx) == 0:\n        candidates_idx = np.arange(len(pressures))\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    proc_norm = np.clip(proc_times / (proc_times.max() + eps), 0.0, 1.0)\n    # Weighted score: pressure + inverse processing time\n    scores = 0.6 * pressures[candidates_idx] + 0.4 * (1.0 - proc_norm[candidates_idx])\n    best_local = int(np.argmax(scores))\n    chosen_idx = candidates_idx[best_local]\n    return feasible_operations[chosen_idx]\n\n",
  "machine_waiting_pressure_aug_130": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Vectorised pressure calculation\n    job_times = np.array([js[op[0]] for op in feasible_operations], dtype=float)\n    machine_times = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    pressures = np.maximum(0.0, job_times - machine_times)\n\n    # Deterministic noise for stable tie\u2011breaking\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-6\n    pressures += noise\n\n    # Clip to avoid extreme values\n    pressures = np.clip(pressures, 0.0, np.inf)\n\n    best_idx = int(np.argmax(pressures))\n    best_pressure = pressures[best_idx]\n\n    # Gather all ops with the same best pressure (within tolerance)\n    mask = np.abs(pressures - best_pressure) < 1e-12\n    candidates = [op for op, m in zip(feasible_operations, mask) if m]\n\n    # Final tie\u2011break by longest processing time\n    return max(candidates, key=lambda op: op[2])\n\n",
  "machine_waiting_pressure_aug_131": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    best_score = -np.inf\n    best_op = None\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        job_time = js[op[0]]\n        machine_time = ms[op[1]]\n        pressure = max(0.0, job_time - machine_time)\n\n        # Weighted score: 70\u202f% pressure + 30\u202f% processing time\n        score = 0.7 * pressure + 0.3 * op[2]\n\n        if score > best_score + 1e-12:\n            best_score = score\n            best_op = op\n        elif abs(score - best_score) < 1e-12:\n            # Tie\u2011break by longer processing time\n            if op[2] > best_op[2]:\n                best_op = op\n        idx += 1\n\n    return best_op\n\n",
  "machine_waiting_pressure_aug_132": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Compute pressures\n    pressures = np.array(\n        [max(0.0, js[op[0]] - ms[op[1]]) for op in feasible_operations], dtype=float\n    )\n\n    # Softmin probabilities (stable exponentiation)\n    eps = 1e-12\n    scores = -pressures\n    probs = np.exp(scores - np.max(scores))\n    probs = probs / (np.sum(probs) + eps)\n\n    # Random choice among the top\u2011k (k\u202f=\u202f3 or fewer)\n    top_k = min(3, len(feasible_operations))\n    top_indices = np.argpartition(-pressures, top_k - 1)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (np.sum(top_probs) + eps)\n\n    chosen_idx = np.random.choice(top_indices, p=top_probs)\n    return feasible_operations[chosen_idx]\n\n",
  "machine_waiting_pressure_aug_133": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Calculate pressures\n    pressures = np.array(\n        [max(0.0, js[op[0]] - ms[op[1]]) for op in feasible_operations], dtype=float\n    )\n\n    # Use median to bound extreme values\n    median_pressure = np.median(pressures)\n    pressures_clipped = np.clip(pressures, 0.0, median_pressure)\n\n    # Weighted score: pressure + 0.5 \u00d7 processing time\n    scores = pressures_clipped + 0.5 * np.array([op[2] for op in feasible_operations], dtype=float)\n\n    best_idx = int(np.argmax(scores))\n    return feasible_operations[best_idx]\n\n",
  "gini_machine_load_reducer_aug_134": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times = current_status['job_status']\n\n    def gini(values):\n        vals = np.asarray(values, dtype=float)\n        if np.allclose(vals, 0.0):\n            return 0.0\n        sorted_vals = np.sort(vals)\n        cum_vals = np.cumsum(sorted_vals)\n        denom = cum_vals[-1] + 1e-12\n        numerator = (len(sorted_vals) + 1 - 2 * np.mean(cum_vals) / denom)\n        g = float(numerator / len(sorted_vals))\n        return np.clip(g, 0.0, 1.0)\n\n    best_op = None\n    best_score = float('inf')\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        ms = machine_times.copy()\n        earliest_start = max(ms[op[1]], float(job_times[op[0]]))\n        ms[op[1]] = earliest_start + float(op[2])\n        score = gini(ms)\n        # deterministic tie\u2011breaking noise\n        score += 1e-13 * op[0]\n        if score < best_score - 1e-12:\n            best_score, best_op = score, op\n        elif abs(score - best_score) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n        idx += 1\n    return best_op\n\n",
  "gini_machine_load_reducer_aug_135": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js = current_status['job_status']\n\n    def gini(x):\n        vals = np.asarray(x, dtype=float)\n        if np.allclose(vals, 0.0):\n            return 0.0\n        xs = np.sort(vals)\n        n = xs.size\n        cum = np.cumsum(xs)\n        denom = cum[-1] + 1e-12\n        val = (n + 1 - 2 * np.sum(cum) / denom) * 0.95\n        return np.clip(float(val) / n, 0.0, 1.0)\n\n    rng = np.random.default_rng(seed=42)\n    scores = []\n    for op in feasible_operations:\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        scores.append(gini(ms))\n    if not scores:\n        return None\n    k = min(5, len(scores))\n    top_indices = np.argsort(scores)[:k]\n    top_scores = np.array([scores[i] for i in top_indices])\n    probs = np.exp(-top_scores / 0.5)\n    probs /= np.sum(probs)\n    chosen_idx = rng.choice(top_indices, p=probs)\n    return feasible_operations[chosen_idx]\n\n",
  "gini_machine_load_reducer_aug_136": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status = current_status['job_status']\n\n    def gini(vals):\n        v = np.asarray(vals, dtype=float)\n        if np.allclose(v, 0.0):\n            return 0.0\n        sorted_v = np.sort(v)\n        cum = np.cumsum(sorted_v)\n        denom = cum[-1] + 1e-10\n        val = (len(sorted_v) + 1 - 2 * np.median(cum) / denom)\n        return np.clip(float(val) / len(sorted_v), 0.0, 1.0)\n\n    best_op = None\n    best_val = float('inf')\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        ms = machine_status.copy()\n        start = max(ms[op[1]], float(job_status[op[0]]))\n        ms[op[1]] = start + float(op[2])\n        val = gini(ms)\n        # deterministic noise for tie\u2011breaking\n        val += 1e-14 * (op[1] * 7 + op[2])\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n        i += 1\n    return best_op\n\n",
  "gini_machine_load_reducer_aug_137": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    m_times = np.array(current_status['machine_status'], dtype=float)\n    j_times = current_status['job_status']\n\n    def heuristic(ms):\n        total = np.sum(ms)\n        peak = np.max(ms)\n        return 0.7 * total + 0.3 * peak\n\n    best_op = None\n    best_score = float('inf')\n    for op in feasible_operations:\n        ms = m_times.copy()\n        earliest = max(ms[op[1]], float(j_times[op[0]]))\n        ms[op[1]] = np.clip(earliest + float(op[2]), 0.0, np.inf)\n        score = heuristic(ms)\n        # deterministic noise\n        score += 1e-13 * op[1]\n        if score < best_score - 1e-12:\n            best_score, best_op = score, op\n        elif abs(score - best_score) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n    return best_op\n\n",
  "gini_job_completion_reducer_aug_138": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        denom = cum[-1] + 1e-12\n        return float((n + 1 - 2 * np.sum(cum) / denom) / n)\n\n    best_op = None\n    best_val = np.inf\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        js = js0.copy()\n        start = np.clip(max(float(ms[op[1]]), js[op[0]]), 0, np.inf)\n        js[op[0]] = start + float(op[2])\n        val = gini(js) + 1e-6 * op[2]          # deterministic noise for tie\u2011breaking\n        if val < best_val - 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n        idx += 1\n    return best_op\n\n",
  "gini_job_completion_reducer_aug_139": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        denom = cum[-1] + 1e-12\n        # use mean instead of sum for aggregation\n        return float((n + 1 - 2 * np.mean(cum) / denom) / n)\n\n    candidates = []\n    for op in feasible_operations:\n        js = js0.copy()\n        start = np.clip(max(float(ms[op[1]]), js[op[0]]), 0, np.inf)\n        js[op[0]] = start + float(op[2])\n        candidates.append((gini(js), op[2], op))\n    # sort by Gini value then by duration\n    candidates.sort(key=lambda t: (t[0], t[1]))\n    return candidates[0][2]\n\n",
  "gini_job_completion_reducer_aug_140": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = current_status['machine_status']\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        denom = cum[-1] + 1e-12\n        # use max instead of sum for a different aggregation\n        return float((n + 1 - 2 * np.max(cum) / denom) / n)\n\n    values = []\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(float(ms[op[1]]), js[op[0]])\n        js[op[0]] = start + float(op[2])\n        values.append((gini(js), op))\n\n    min_val = min(v[0] for v in values)\n    top_ops = [v[1] for v in values if abs(v[0] - min_val) < 1e-12]\n\n    if len(top_ops) > 1:\n        chosen = np.random.choice(top_ops)  # random tie\u2011breaking among top\u2011k\n    else:\n        chosen = top_ops[0]\n    return chosen\n\n",
  "gini_job_completion_reducer_aug_141": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n = xs.size\n        cum = np.cumsum(xs)\n        denom = cum[-1] + 1e-12\n        return float((n + 1 - 2 * np.sum(cum) / denom) / n)\n\n    n_ops = len(feasible_operations)\n    machine_indices = np.array([op[1] for op in feasible_operations], dtype=int)\n    job_indices = np.array([op[0] for op in feasible_operations], dtype=int)\n    durations = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    js = np.tile(js0, (n_ops, 1))\n    start = np.maximum(ms[machine_indices], js[np.arange(n_ops), job_indices])\n    start = np.clip(start, 0, np.inf)\n    js[np.arange(n_ops), job_indices] = start + durations\n\n    vals = np.array([gini(js[i]) + 1e-6 * durations[i] for i in range(n_ops)])\n    # lexsort: first key vals, second key durations for deterministic tie\u2011breaking\n    idx = np.lexsort((durations, vals))\n    return feasible_operations[idx[0]]\n\n",
  "minimize_max_machine_time_after_aug_142": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    eps = 1e-12\n    ms0 = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    ops_arr = np.array(feasible_operations, dtype=object)\n    n = ops_arr.shape[0]\n    start = np.maximum(ms0[ops_arr[:, 1]], js[ops_arr[:, 0]])\n    start = np.clip(start, 0, None)\n    ms_temp = np.tile(ms0, (n, 1))\n    ms_temp[np.arange(n), ops_arr[:, 1]] = start + ops_arr[:, 2]\n    val = ms_temp.max(axis=1)\n\n    min_val = val.min()\n    idx_candidates = np.where(val <= min_val + eps)[0]\n    start_candidates = start[idx_candidates]\n    best_idx = idx_candidates[np.argmin(start_candidates)]\n    return tuple(ops_arr[best_idx])\n\n",
  "minimize_max_machine_time_after_aug_143": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    eps = 1e-12\n    ms0 = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    ops_arr = np.array(feasible_operations, dtype=object)\n    n = ops_arr.shape[0]\n    start = np.maximum(ms0[ops_arr[:, 1]], js[ops_arr[:, 0]])\n    start = np.clip(start, 0, None)\n    ms_temp = np.tile(ms0, (n, 1))\n    ms_temp[np.arange(n), ops_arr[:, 1]] = start + ops_arr[:, 2]\n    val = ms_temp.max(axis=1)\n\n    temperature = 1.0\n    weights = np.exp(-val / (temperature + eps))\n    noise = 1e-6 * np.arange(n)\n    weights += noise\n    best_idx = np.argmax(weights)\n    return tuple(ops_arr[best_idx])\n\n",
  "minimize_max_machine_time_after_aug_144": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    eps = 1e-12\n    ms0 = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    ops_list = list(feasible_operations)\n    best_op = None\n    best_val = float('inf')\n    while ops_list:\n        op = ops_list.pop(0)\n        ms = ms0.copy()\n        start = max(ms[op[1]], float(js[op[0]]))\n        start = max(start, 0.0)\n        ms[op[1]] = start + float(op[2])\n        val = float(np.clip(ms.mean(), 0, None))\n        if val < best_val - eps:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < eps:\n            s_best = max(ms0[best_op[1]], float(js[best_op[0]]))\n            s_now = max(ms0[op[1]], float(js[op[0]]))\n            if s_now < s_best - eps:\n                best_op = op\n    return best_op\n\n",
  "minimize_max_machine_time_after_aug_145": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    eps = 1e-12\n    ms0 = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    ops_arr = np.array(feasible_operations, dtype=object)\n    n = ops_arr.shape[0]\n    start = np.maximum(ms0[ops_arr[:, 1]], js[ops_arr[:, 0]])\n    start = np.clip(start, 0, None)\n    ms_temp = np.tile(ms0, (n, 1))\n    ms_temp[np.arange(n), ops_arr[:, 1]] = start + ops_arr[:, 2]\n    val = ms_temp.max(axis=1)\n\n    top_k = 3\n    idx_sorted = np.argsort(val)\n    k = min(top_k, n)\n    top_indices = idx_sorted[:k]\n    min_val = val[top_indices].max()\n    candidates = top_indices[np.where(val[top_indices] <= min_val + eps)[0]]\n    chosen_idx = np.random.choice(candidates)\n    return tuple(ops_arr[chosen_idx])\n\n",
  "minimize_max_job_time_after_aug_146": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    best_op = None\n    best_val = float('inf')\n    ops_list = list(feasible_operations)\n    idx = 0\n    while idx < len(ops_list):\n        op = ops_list[idx]\n        start_time = max(float(m_status[op[1]]), j_status[op[0]])\n        new_job = j_status.copy()\n        new_job[op[0]] = start_time + float(op[2])\n        current_val = float(np.max(new_job))\n        if current_val < best_val - 1e-12:\n            best_val, best_op = current_val, op\n        elif abs(current_val - best_val) < 1e-12 and op[2] < best_op[2]:\n            best_op = op\n        idx += 1\n\n    return best_op\n\n",
  "minimize_max_job_time_after_aug_147": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Compute candidate start times and resulting max job times\n    candidates = []\n    for op in feasible_operations:\n        start = max(ms[op[1]], js[op[0]])\n        updated = js.copy()\n        updated[op[0]] = start + op[2]\n        max_time = float(np.clip(np.max(updated), 0, 1e12))\n        candidates.append((max_time, op))\n\n    # Select best with deterministic noise for tie\u2011breaking\n    best_val, best_op = min(\n        candidates,\n        key=lambda x: (x[0], -0.001 * hash(x[1]))  # deterministic perturbation\n    )\n    return best_op\n\n",
  "minimize_max_job_time_after_aug_148": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Compute median\u2011based proxy times for each candidate\n    max_times = []\n    for op in feasible_operations:\n        start = max(ms[op[1]], js[op[0]])\n        new_js = js.copy()\n        new_js[op[0]] = start + op[2]\n        max_times.append(float(np.median(new_js)))\n\n    # Randomly pick among the top\u2011k smallest times (k=3)\n    top_k = 3\n    idx_sorted = np.argsort(max_times)\n    top_indices = idx_sorted[:top_k]\n\n    # Deterministic noise to break ties\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    adjusted = np.array(max_times) + noise\n    best_index = top_indices[np.argmin(adjusted[top_indices])]\n    return feasible_operations[best_index]\n\n",
  "minimize_max_job_time_after_aug_149": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Proxy: weighted sum of squared job completion times\n    weight = 1.5\n    scores = []\n    for op in feasible_operations:\n        start = max(ms[op[1]], js[op[0]])\n        tmp = js.copy()\n        tmp[op[0]] = start + op[2]\n        score = float(np.clip(np.sum(np.square(tmp)) * weight, 0, 1e12))\n        scores.append(score)\n\n    # Choose operation with minimal proxy score\n    best_idx = np.argmin(scores)\n    return feasible_operations[best_idx]\n\n",
  "variance_adaptive_weighting_aug_150": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    v = float(np.var(ms))\n    w_avail = v / (v + 1.0)\n    w_proc = 1.0 - w_avail\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    start = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n\n    median_proc = np.median(proc) + 1e-12\n    median_start = np.median(start) + 1e-12\n    proc_n = proc / median_proc\n    start_n = start / median_start\n\n    score = w_proc * proc_n + w_avail * start_n\n    noise = np.random.uniform(-1e-6, 1e-6, size=score.shape)\n    score += noise\n\n    exp_neg = np.exp(-score)\n    probs = exp_neg / np.clip(np.sum(exp_neg), 1e-12, None)\n    idx = int(np.argmax(probs))\n    return feasible_operations[idx]\n\n",
  "variance_adaptive_weighting_aug_151": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    v = float(np.var(ms))\n    w_avail = (v + 0.5) / (v + 1.5)\n    w_proc = 1.0 - w_avail\n\n    proc = []\n    start = []\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        proc.append(float(op[2]))\n        start.append(float(max(ms[op[1]], js[op[0]])))\n        i += 1\n    proc = np.array(proc, dtype=float)\n    start = np.array(start, dtype=float)\n\n    mean_proc = np.sum(proc) / (len(proc) + 1e-12)\n    mean_start = np.sum(start) / (len(start) + 1e-12)\n\n    proc_n = proc / mean_proc\n    start_n = start / mean_start\n\n    score = w_proc * proc_n + w_avail * start_n\n\n    top_k = min(3, len(score))\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices)\n    return feasible_operations[chosen]\n\n",
  "variance_adaptive_weighting_aug_152": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    v = float(np.var(ms))\n    w_avail = v / (v + 1.0)\n    w_proc = 1.0 - w_avail\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    machine_indices = np.array([op[1] for op in feasible_operations], dtype=int)\n    job_indices = np.array([op[0] for op in feasible_operations], dtype=int)\n    start = np.maximum(ms[machine_indices], js[job_indices])\n\n    mean_proc = np.sum(proc) / (len(proc) + 1e-12)\n    mean_start = np.sum(start) / (len(start) + 1e-12)\n\n    proc_n = proc / mean_proc\n    start_n = start / mean_start\n\n    score = w_proc * proc_n + w_avail * start_n\n\n    noise = np.sin(np.arange(len(score))) * 1e-9\n    score += noise\n\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "variance_adaptive_weighting_aug_153": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    mad = np.mean(np.abs(ms - np.mean(ms))) + 1e-12\n    w_avail = np.clip(mad / (mad + 0.5), 0.0, 1.0)\n    w_proc = 1.0 - w_avail\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    start = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n\n    mean_proc = np.mean(proc) + 1e-12\n    mean_start = np.mean(start) + 1e-12\n\n    proc_n = proc / mean_proc\n    start_n = start / mean_start\n\n    score = w_proc * proc_n + w_avail * start_n\n\n    exp_neg = np.exp(-score)\n    probs = exp_neg / np.clip(np.sum(exp_neg), 1e-12, None)\n    idx = int(np.argmax(probs))\n    return feasible_operations[idx]\n\n",
  "dynamic_percentile_target_aug_154": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # machine load imbalance using mean\n    ms = np.array(current_status['machine_status'], dtype=float)\n    imbalance = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    pct = 30.0 + 50.0 * min(1.0, imbalance)\n    pct = np.clip(pct, 0.0, 100.0)\n\n    # target processing time\n    proc_times = np.array([op[2] for op in feasible_operations], dtype=float)\n    target = float(np.percentile(proc_times, pct))\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.arange(len(feasible_operations)) * 1e-6\n\n    # find operation with minimal absolute difference to target\n    min_diff = float('inf')\n    chosen = None\n    for idx, op in enumerate(feasible_operations):\n        diff = abs(op[2] - target) + noise[idx]\n        if diff < min_diff:\n            min_diff = diff\n            chosen = op\n    return chosen\n\n",
  "dynamic_percentile_target_aug_155": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    imbalance = float((ms.max() - ms.min()) / (np.median(ms) + 1e-12))\n    pct = np.clip(20.0 + 60.0 * min(1.0, imbalance), 0.0, 100.0)\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    target = float(np.percentile(proc, pct))\n\n    # compute soft\u2011min weights (inverse distance)\n    diff = np.abs(proc - target) + 1e-12\n    weights = 1.0 / diff\n    probs = weights / weights.sum()\n\n    # sample one operation according to soft\u2011min probabilities\n    idx = np.random.choice(len(feasible_operations), p=probs)\n    return feasible_operations[idx]\n\n",
  "dynamic_percentile_target_aug_156": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    imbalance = float((ms.max() - ms.min()) / (ms.sum() + 1e-12))\n    pct = np.clip(25.0 + 55.0 * min(1.0, imbalance), 0.0, 100.0)\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n    target = float(np.percentile(proc, pct))\n\n    # distance to target\n    dist = np.abs(proc - target)\n\n    # choose among top\u2011k closest operations\n    k = min(5, len(feasible_operations))\n    idxs = np.argpartition(dist, k-1)[:k]\n    chosen = feasible_operations[idxs[0]]\n    return chosen\n\n",
  "dynamic_percentile_target_aug_157": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    imbalance = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    pct = np.clip(28.0 + 48.0 * min(1.0, imbalance), 0.0, 100.0)\n\n    proc = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # approximate percentile using partition (fast selection)\n    k = int(round(pct / 100.0 * len(proc)))\n    k = np.clip(k, 1, len(proc)-1)\n    target = float(np.partition(proc, k-1)[k-1])\n\n    # random choice among operations within a small window around target\n    window = 0.05 * (proc.max() - proc.min() + 1e-12)\n    mask = np.abs(proc - target) <= window\n    candidates = [op for op, m in zip(feasible_operations, mask) if m]\n    if not candidates:\n        candidates = feasible_operations\n    return np.random.choice(candidates)\n\n",
  "least_loaded_machine_then_lpt_aug_158": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if len(feasible_operations) == 0:\n        return None\n\n    ms = current_status['machine_status']\n    # Vectorise the load extraction and clip to avoid overflow\n    loads = np.clip(np.array([ms[op[1]] for op in feasible_operations], dtype=np.float64),\n                    0, 1e9)\n\n    # Small epsilon added to the min calculation\n    min_load = np.min(loads) + 1e-12\n\n    # Find all operations that match the minimum load (within a tiny tolerance)\n    min_indices = np.where(np.isclose(loads, min_load, atol=1e-12))[0]\n    candidates = [feasible_operations[i] for i in min_indices]\n\n    # Deterministic noise for tie\u2011breaking (hash\u2011based)\n    def noise(op):\n        return (hash(op) % 1000) * 1e-6\n\n    best = max(candidates, key=lambda op: op[2] + noise(op))\n    return best\n\n",
  "least_loaded_machine_then_lpt_aug_159": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    loads = np.clip(np.array([ms[op[1]] for op in feasible_operations], dtype=np.float64),\n                    0, 1e9)\n\n    # Soft\u2011min weighting with a temperature hyper\u2011parameter\n    temp = 0.5\n    inv = np.exp(-loads / (temp + 1e-12))\n    probs = inv / (np.sum(inv) + 1e-12)\n\n    # Randomly pick among the top\u2011k longest operations\n    top_k = 3\n    idx_sorted = np.argsort(-loads)          # longest first\n    top_indices = idx_sorted[:top_k]\n    chosen = np.random.choice(top_indices, p=probs[top_indices])\n\n    return feasible_operations[chosen]\n\n",
  "least_loaded_machine_then_lpt_aug_160": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if len(feasible_operations) == 0:\n        return None\n\n    ms = current_status['machine_status']\n    loads = np.clip(np.array([ms[op[1]] for op in feasible_operations], dtype=np.float64),\n                    0, 1e9)\n\n    median_load = np.median(loads) + 1e-12\n    mask = loads <= median_load + 1e-8\n    candidates = [feasible_operations[i] for i, m in enumerate(mask) if m]\n\n    # Deterministic noise for tie\u2011breaking\n    def noise(op):\n        return (hash(op) % 1000) * 1e-7\n\n    best = max(candidates, key=lambda op: op[2] + noise(op))\n    return best\n\n",
  "least_loaded_machine_then_lpt_aug_161": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    loads = np.clip(np.array([ms[op[1]] for op in feasible_operations], dtype=np.float64),\n                    0, 1e9)\n    durations = np.array([op[2] for op in feasible_operations], dtype=np.float64)\n\n    # Proxy load: machine load + half the operation duration\n    proxy_load = loads + 0.5 * durations\n    proxy_load = np.clip(proxy_load, 0, 1e9)\n\n    avg_proxy = np.mean(proxy_load) + 1e-12\n    mask = proxy_load <= avg_proxy + 1e-8\n    candidates = [feasible_operations[i] for i, m in enumerate(mask) if m]\n\n    if not candidates:\n        return None\n\n    # Randomly choose among the longest operations in the candidate set\n    top_k = 4\n    durations_cand = np.array([op[2] for op in candidates], dtype=np.float64)\n    idx_sorted = np.argsort(-durations_cand)          # longest first\n    top_indices = idx_sorted[:top_k]\n    chosen = np.random.choice(top_indices)\n\n    return candidates[chosen]\n\n",
  "most_loaded_machine_then_earliest_start_aug_162": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = current_status['machine_status']\n    job_times     = current_status['job_status']\n\n    # Load of the machine that would process each operation\n    loads = np.array([machine_times[op[1]] for op in feasible_operations], dtype=float)\n\n    # Identify operations belonging to the most\u2011loaded machine(s)\n    max_load = np.max(loads)\n    candidates = [op for op, ld in zip(feasible_operations, loads) if ld == max_load]\n\n    # Earliest feasible start time for each candidate\n    starts = np.array([max(machine_times[op[1]], job_times[op[0]]) for op in candidates], dtype=float)\n\n    # Clip to avoid zero and add tiny noise for deterministic tie\u2011breaking\n    starts = np.clip(starts, 1e-12, None)\n    noise  = np.random.uniform(0, 1e-6, size=starts.shape)\n    scores = starts + noise\n\n    idx = np.argmin(scores)\n    return candidates[idx]\n\n",
  "most_loaded_machine_then_earliest_start_aug_163": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    loads  = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n\n    # Composite score and soft\u2011min probabilities\n    scores = 0.6 * loads + 0.4 * starts\n    tau    = 1.0\n    exp_vals = np.exp(-scores / tau)\n\n    denom = np.sum(exp_vals) + 1e-12  # avoid division by zero\n    probs = exp_vals / denom\n\n    idx = np.argmax(probs)  # soft\u2011minimum \u2192 highest probability\n    return feasible_operations[idx]\n\n",
  "most_loaded_machine_then_earliest_start_aug_164": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    loads = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    min_load = np.min(loads)\n\n    # Candidates on the least\u2011loaded machine(s)\n    candidates = [op for op, ld in zip(feasible_operations, loads) if ld <= min_load + 1e-12]\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in candidates], dtype=float)\n    median_start = np.median(starts)\n\n    # Choose candidate whose start is closest to the median\n    diff = np.abs(starts - median_start) + 1e-12\n    idx = np.argmin(diff)\n    return candidates[idx]\n\n",
  "most_loaded_machine_then_earliest_start_aug_165": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n\n    loads = np.array([ms[op[1]] for op in feasible_operations], dtype=float)\n    sorted_idx = np.argsort(-loads)  # descending order\n\n    top_k = min(3, len(feasible_operations))\n    top_idx = sorted_idx[:top_k]\n    top_idx = np.clip(top_idx, 0, len(feasible_operations) - 1)  # safety\n\n    chosen = np.random.choice(top_idx)\n    return feasible_operations[chosen]\n\n",
  "regret_min_completion_time_aug_166": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n\n    best_op = None\n    best_regret = -np.inf\n    best_completion = np.inf\n\n    # Group operations by machine index\n    for m in range(len(ms)):\n        ops_m = [op for op in feasible_operations if op[1] == m]\n        if not ops_m:\n            continue\n\n        jobs = np.array([op[0] for op in ops_m], dtype=int)\n        durations = np.array([op[2] for op in ops_m])\n\n        starts = np.maximum(ms[m], js[jobs])\n        completions = starts + durations\n\n        order = np.argsort(completions)\n        sorted_ops = [ops_m[i] for i in order]\n        sorted_comps = completions[order]\n\n        if len(sorted_ops) == 1:\n            regret = np.inf\n            chosen = sorted_ops[0]\n            chosen_comp = sorted_comps[0]\n        else:\n            regret = sorted_comps[1] - sorted_comps[0]\n            chosen = sorted_ops[0]\n            chosen_comp = sorted_comps[0]\n\n        if (\n            regret > best_regret\n            or (abs(regret - best_regret) < 1e-12 and chosen_comp < best_completion)\n        ):\n            best_regret = regret\n            best_op = chosen\n            best_completion = chosen_comp\n\n    return best_op\n\n",
  "regret_min_completion_time_aug_167": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    top_k = 3  # hyper\u2011parameter tuning\n\n    best_op = None\n    best_regret = -np.inf\n    best_completion = np.inf\n\n    # Build a dictionary of completions per machine\n    by_m = {}\n    for op in feasible_operations:\n        m = op[1]\n        start = max(ms[m], js[op[0]])\n        comp = start + op[2]\n        by_m.setdefault(m, []).append((comp, op))\n\n    for m, lst in by_m.items():\n        lst.sort(key=lambda x: x[0])\n        top_ops = lst[:top_k]\n        if not top_ops:\n            continue\n\n        if len(top_ops) == 1:\n            regret = np.inf\n            chosen, chosen_comp = top_ops[0][1], top_ops[0][0]\n        else:\n            regret = top_ops[1][0] - top_ops[0][0]\n            chosen, chosen_comp = top_ops[0][1], top_ops[0][0]\n\n        if (\n            regret > best_regret\n            or (abs(regret - best_regret) < 1e-12 and chosen_comp < best_completion)\n        ):\n            best_regret = regret\n            best_op = chosen\n            best_completion = chosen_comp\n\n    return best_op\n\n",
  "regret_min_completion_time_aug_168": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    if not feasible_operations:\n        return None\n\n    # Deterministic noise derived from the operation hash\n    noise_scale = 1e-6\n    completions = []\n    for op in feasible_operations:\n        job, machine, dur = op\n        start = max(ms[machine], js[job])\n        comp = start + dur\n        noise = noise_scale * (hash(op) & 0xFFFF)\n        completions.append(comp + noise)\n\n    completions = np.array(completions)\n    ops = np.array(feasible_operations, dtype=object)\n\n    best_op = None\n    best_regret = -np.inf\n\n    for m in set(op[1] for op in ops):\n        idx = np.where([op[1] == m for op in ops])[0]\n        comp_m = completions[idx]\n        op_m = ops[idx]\n        sorted_idx = np.argsort(comp_m)\n        sorted_ops = op_m[sorted_idx]\n        sorted_comps = comp_m[sorted_idx]\n\n        if len(sorted_ops) == 1:\n            regret = np.inf\n            chosen = sorted_ops[0]\n        else:\n            regret = sorted_comps[1] - sorted_comps[0]\n            chosen = sorted_ops[0]\n\n        if regret > best_regret:\n            best_regret = regret\n            best_op = chosen\n        elif abs(regret - best_regret) < 1e-12:\n            # Soft\u2011min tie\u2011break: probability proportional to exp(-completion/temperature)\n            temperature = 1e-3\n            best_idx = np.where(ops == best_op)[0][0]\n            prob_best = np.exp(-completions[best_idx] / temperature)\n            prob_chosen = np.exp(-completions[idx[0]] / temperature)\n            if prob_chosen > prob_best:\n                best_op = chosen\n\n    return best_op\n\n",
  "regret_min_completion_time_aug_169": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    if not feasible_operations:\n        return None\n\n    best_op = None\n    best_regret = -np.inf\n    best_completion = np.inf\n\n    by_m = {}\n    for op in feasible_operations:\n        job, machine, dur = op\n        start = np.maximum(ms[machine], js[job])\n        comp = start + dur + 1e-12  # small epsilon added to completion\n        by_m.setdefault(machine, []).append((comp, op))\n\n    for m, lst in by_m.items():\n        lst.sort(key=lambda x: x[0])\n        if len(lst) == 0:\n            continue\n\n        if len(lst) == 1:\n            regret = np.inf\n            chosen, chosen_comp = lst[0][1], lst[0][0]\n        else:\n            # Clip to avoid negative values and add epsilon to denominator\n            diff = lst[1][0] - lst[0][0]\n            regret = np.clip(diff / (1.0 + 1e-12), 0, np.inf)\n            chosen, chosen_comp = lst[0][1], lst[0][0]\n\n        if (\n            regret > best_regret\n            or (abs(regret - best_regret) < 1e-12 and chosen_comp < best_completion)\n        ):\n            best_regret = regret\n            best_op = chosen\n            best_completion = chosen_comp\n\n    return best_op\n\n",
  "epsilon_greedy_completion_aug_170": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.array(current_status['machine_status'], dtype=float)\n    j_stat = np.array(current_status['job_status'], dtype=float)\n\n    # Compute completion times for all feasible operations\n    comp = np.array(\n        [max(m_stat[op[1]], j_stat[op[0]]) + op[2] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Add deterministic noise to break ties\n    comp += np.arange(len(comp)) * 1e-9\n\n    # Soft\u2011min selection\n    alpha = 10.0\n    weights = np.exp(-alpha * comp)\n    weights /= np.sum(weights) + 1e-12\n    greedy_idx = int(np.argmax(weights))\n\n    # Imbalance\u2011based exploration probability\n    imbalance = (m_stat.max() - m_stat.min()) / (m_stat.mean() + 1e-12)\n    eps = np.clip(0.05 + 0.30 * min(1.0, imbalance), 0.0, 1.0)\n\n    seed = int(np.sum(m_stat) + 7 * np.sum(j_stat)) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    if rng.random() < eps:\n        # Explore among the top\u20113 by completion time\n        k = min(3, len(feasible_operations))\n        topk = np.argsort(comp)[:k]\n        idx = rng.integers(0, k)\n        return feasible_operations[int(topk[idx])]\n\n    return feasible_operations[greedy_idx]\n\n",
  "epsilon_greedy_completion_aug_171": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times = np.array(current_status['job_status'], dtype=float)\n\n    comp = np.array(\n        [max(machine_times[op[1]], job_times[op[0]]) + op[2] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Imbalance based on median machine time\n    imbalance = (np.max(machine_times) - np.min(machine_times)) / (\n        np.median(machine_times) + 1e-12\n    )\n    eps = np.clip(0.1 + 0.3 * min(1.0, imbalance), 0.0, 1.0)\n\n    seed = int(np.sum(machine_times) + 13 * np.sum(job_times)) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    if rng.random() < eps:\n        top_k = min(5, len(feasible_operations))\n        top_indices = np.argsort(comp)[:top_k]\n        return feasible_operations[int(rng.choice(top_indices))]\n\n    return feasible_operations[int(np.argmin(comp))]\n\n",
  "epsilon_greedy_completion_aug_172": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    comp = np.array(\n        [max(m_status[op[1]], j_status[op[0]]) + op[2] for op in feasible_operations],\n        dtype=float\n    )\n\n    # Weighted score that also accounts for current machine load\n    w = 0.7\n    score = w * comp + (1 - w) * np.max(m_status)\n\n    # Small deterministic noise for tie\u2011breaking\n    rng_noise = np.random.default_rng(\n        int(np.sum(m_status) + 11 * np.sum(j_status)) % (2**31)\n    )\n    score += rng_noise.random(len(score)) * 1e-6\n\n    # Softmax selection\n    beta = 5.0\n    probs = np.exp(-beta * score)\n    probs /= np.sum(probs) + 1e-12\n    greedy_idx = int(np.argmax(probs))\n\n    imbalance = (np.max(m_status) - np.min(m_status)) / (\n        np.mean(m_status) + 1e-12\n    )\n    eps = np.clip(0.25 + 0.2 * min(1.0, imbalance), 0.0, 0.5)\n\n    seed = int(np.sum(m_status) + 11 * np.sum(j_status)) % (2**31)\n    rng_explore = np.random.default_rng(seed)\n\n    if rng_explore.random() < eps:\n        top_k = min(3, len(feasible_operations))\n        top_indices = np.argsort(score)[:top_k]\n        return feasible_operations[int(rng_explore.choice(top_indices))]\n\n    return feasible_operations[greedy_idx]\n\n",
  "epsilon_greedy_completion_aug_173": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_times = np.array(current_status['machine_status'], dtype=float)\n    j_times = np.array(current_status['job_status'], dtype=float)\n\n    comp = np.array(\n        [max(m_times[op[1]], j_times[op[0]]) + op[2] for op in feasible_operations],\n        dtype=float\n    )\n\n    imbalance = (np.max(m_times) - np.min(m_times)) / (\n        np.mean(m_times) + 1e-12\n    )\n    eps = np.clip(0.05 + 0.35 * min(1.0, imbalance), 0.0, 1.0)\n\n    seed = int(np.sum(m_times) + 17 * np.sum(j_times)) % (2**31)\n    rng = np.random.default_rng(seed)\n\n    if rng.random() < eps:\n        # Deterministic exploration: rotate among the top\u20113 operations\n        k = min(3, len(feasible_operations))\n        topk = np.argsort(comp)[:k]\n        idx = (seed // 7) % k\n        return feasible_operations[int(topk[idx])]\n\n    return feasible_operations[int(np.argmin(comp))]\n\n",
  "softmax_makespan_delta_aug_174": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # renamed variables for clarity\n    m_stat = np.array(current_status['machine_status'], dtype=float)\n    j_stat = np.array(current_status['job_status'], dtype=float)\n\n    # current makespan (max of machine and job times)\n    cur_ms = float(max(m_stat.max(), j_stat.max()))\n\n    # compute deltas using a while loop\n    deltas = np.empty(len(feasible_operations), dtype=float)\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        start = max(m_stat[op[1]], j_stat[op[0]])\n        finish = start + float(op[2])\n        deltas[idx] = max(finish, cur_ms) - cur_ms\n        idx += 1\n\n    # scale factor with a small epsilon to avoid division by zero\n    scale = np.clip(np.std(deltas) + 1e-6, a_min=1e-12, a_max=None)\n\n    # softmin logits with deterministic noise for tie\u2011breaking\n    logits = -deltas / scale\n    noise = np.linspace(0, 1e-5, len(deltas))\n    logits += noise\n    logits -= np.max(logits)\n\n    probs = np.exp(logits)\n    probs /= (np.sum(probs) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # deterministic seed based on current status\n    seed = int(np.sum(m_stat) + 13 * np.sum(j_stat)) % (2**31)\n    rng = np.random.default_rng(seed)\n    chosen = int(rng.choice(len(feasible_operations), p=probs))\n    return feasible_operations[chosen]\n\n",
  "softmax_makespan_delta_aug_175": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n    cur_ms = float(max(ms0.max(), js0.max()))\n\n    # compute deltas\n    deltas = []\n    for op in feasible_operations:\n        start = max(ms0[op[1]], js0[op[0]])\n        finish = start + float(op[2])\n        deltas.append(max(finish, cur_ms) - cur_ms)\n    deltas = np.array(deltas, dtype=float)\n\n    # scaling with a tighter epsilon\n    scale = np.clip(np.std(deltas) + 1e-8, a_min=1e-12, a_max=None)\n    logits = -deltas / scale\n    logits -= np.max(logits)\n\n    probs = np.exp(logits)\n    probs /= (np.sum(probs) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # add small deterministic noise for tie\u2011breaking\n    rng_noise = np.random.default_rng(42)\n    probs += rng_noise.uniform(0, 1e-6, size=probs.shape)\n    probs /= (np.sum(probs) + 1e-12)\n\n    # top\u2011k selection (k = 7)\n    top_k = min(7, len(feasible_operations))\n    top_indices = np.argpartition(-probs, top_k-1)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs /= (np.sum(top_probs) + 1e-12)\n\n    seed = int(np.sum(ms0) + 13 * np.sum(js0)) % (2**31)\n    rng = np.random.default_rng(seed)\n    chosen = int(rng.choice(top_indices, p=top_probs))\n    return feasible_operations[chosen]\n\n",
  "softmax_makespan_delta_aug_176": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.array(current_status['machine_status'], dtype=float)\n    j_stat = np.array(current_status['job_status'], dtype=float)\n\n    # use median of the two max values for a slightly different makespan estimate\n    cur_ms = float(np.median([m_stat.max(), j_stat.max()]))\n\n    deltas = []\n    for op in feasible_operations:\n        start = max(m_stat[op[1]], j_stat[op[0]])\n        finish = start + float(op[2])\n        new_ms = float(np.max([finish, cur_ms]))\n        deltas.append(new_ms - cur_ms)\n    deltas = np.array(deltas, dtype=float)\n\n    # scaling with a moderate epsilon\n    scale = np.clip(np.std(deltas) + 1e-7, a_min=1e-12, a_max=None)\n    logits = -deltas / scale\n    logits -= np.max(logits)\n\n    probs = np.exp(logits)\n    probs /= (np.sum(probs) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # pick randomly among the top\u20113 probabilities\n    top_k = min(3, len(feasible_operations))\n    top_indices = np.argpartition(-probs, top_k-1)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs /= (np.sum(top_probs) + 1e-12)\n\n    seed = int(np.sum(m_stat) + 13 * np.sum(j_stat)) % (2**31)\n    rng = np.random.default_rng(seed)\n    chosen = int(rng.choice(top_indices, p=top_probs))\n    return feasible_operations[chosen]\n\n",
  "softmax_makespan_delta_aug_177": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n    cur_ms = float(max(ms0.max(), js0.max()))\n\n    # vectorised computation of start times and finishes\n    machine_indices = [op[1] for op in feasible_operations]\n    job_indices     = [op[0] for op in feasible_operations]\n    durations       = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    starts   = np.maximum(ms0[machine_indices], js0[job_indices])\n    finishes = starts + durations\n\n    # deltas are the increase in makespan (if any)\n    deltas = np.maximum(0.0, finishes - cur_ms)\n\n    # scaling with a very small epsilon\n    scale = np.clip(np.std(deltas) + 1e-9, a_min=1e-12, a_max=None)\n    logits = -deltas / scale\n    logits -= np.max(logits)\n\n    probs = np.exp(logits)\n    probs /= (np.sum(probs) + 1e-12)\n    probs = np.clip(probs, 1e-12, 1.0)\n\n    # choose among the top\u20115 probabilities\n    top_k = min(5, len(feasible_operations))\n    top_indices = np.argpartition(-probs, top_k-1)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs /= (np.sum(top_probs) + 1e-12)\n\n    seed = int(np.sum(ms0) + 13 * np.sum(js0)) % (2**31)\n    rng = np.random.default_rng(seed)\n    chosen = int(rng.choice(top_indices, p=top_probs))\n    return feasible_operations[chosen]\n\n",
  "avoid_last_machine_if_possible_aug_178": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    last_m = current_status.get('last_machine', None)\n\n    scores = []\n    for op in feasible_operations:\n        j, m, d = op\n        ready = max(ms[m], js[j])\n        denom = ready + 1e-12                     # epsilon to avoid div\u2011zero\n        score = (ready + d) / (1.0 + denom)        # weighted completion time\n        score = np.clip(score, 0, 1e6)             # bound the score\n        # deterministic tie\u2011breaking noise\n        noise = 1e-6 * (j + m + d)\n        scores.append(score + noise)\n\n    # Prefer operations that do not use the last machine if possible\n    if last_m is not None:\n        filtered_ops = [op for op in feasible_operations if op[1] != last_m]\n        if filtered_ops:\n            filtered_scores = [s for op, s in zip(feasible_operations, scores)\n                               if op[1] != last_m]\n            feasible_operations = filtered_ops\n            scores = filtered_scores\n\n    idx = np.argmin(scores)\n    return feasible_operations[idx]\n\n",
  "avoid_last_machine_if_possible_aug_179": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    last_m = current_status.get('last_machine', None)\n\n    # Separate the components of each operation\n    ops_arr = np.array(feasible_operations, dtype=object)\n    jobs = np.array([op[0] for op in ops_arr], dtype=int)\n    machines = np.array([op[1] for op in ops_arr], dtype=int)\n    durations = np.array([op[2] for op in ops_arr], dtype=float)\n\n    ready = np.maximum(ms[machines], js[jobs])\n    # Use the median of ready times as a baseline\n    baseline = np.median(ready) + 1e-12\n    scores = (ready - baseline) + durations\n    scores = np.clip(scores, 0, 1e6)\n\n    # Deterministic noise\n    noise = 1e-8 * (jobs + machines + durations)\n    scores += noise\n\n    # Exclude the last machine if possible\n    if last_m is not None:\n        mask = machines != last_m\n        if mask.any():\n            scores = scores[mask]\n            ops_arr = ops_arr[mask]\n\n    # Random choice among the top\u20115 operations\n    top_k = 5\n    top_indices = np.argsort(scores)[:top_k]\n    rng = np.random.default_rng(seed=int(np.sum(scores) * 1e5) % (2**32 - 1))\n    chosen_idx = rng.choice(top_indices)\n    return ops_arr[chosen_idx]\n\n",
  "avoid_last_machine_if_possible_aug_180": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n    last_m = current_status.get('last_machine', None)\n\n    ops = feasible_operations\n    scores = []\n\n    i = 0\n    while i < len(ops):\n        j, m, d = ops[i]\n        ready = max(ms[m], js[j])\n        denom = ready + 1e-12\n        # Use the maximum of ready time and duration as score\n        score = np.max([ready, d]) / (1.0 + denom)\n        score = np.clip(score, 0, 1e6)\n        # Deterministic tie\u2011breaking noise\n        score += 1e-5 * (j - m + d)\n        scores.append(score)\n        i += 1\n\n    # If a last machine is recorded, prefer other machines\n    if last_m is not None:\n        filtered_ops = []\n        filtered_scores = []\n        for op, s in zip(ops, scores):\n            if op[1] != last_m:\n                filtered_ops.append(op)\n                filtered_scores.append(s)\n        if filtered_ops:\n            ops = filtered_ops\n            scores = filtered_scores\n\n    # Find the index of the minimal score using a while loop\n    min_idx = 0\n    min_score = scores[0]\n    j = 1\n    while j < len(scores):\n        if scores[j] < min_score:\n            min_score = scores[j]\n            min_idx = j\n        j += 1\n\n    return ops[min_idx]\n\n",
  "avoid_last_job_if_possible_aug_181": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_job = current_status.get('last_job')\n    machine = np.array(current_status['machine_status'])\n    job = np.array(current_status['job_status'])\n\n    ops = np.array(feasible_operations, dtype=np.int64)\n    job_idx = ops[:, 0]\n    machine_idx = ops[:, 1]\n    duration = ops[:, 2]\n\n    machine = np.clip(machine, 0, None)\n    job = np.clip(job, 0, None)\n\n    # Compute earliest start times\n    start_ready = np.maximum(machine[machine_idx], job[job_idx]) + duration\n\n    # Ratio that involves a division \u2013 guard with epsilon\n    ratio = machine[machine_idx] / (job[job_idx] + 1e-12)\n    ratio = np.clip(ratio, 0, 10)\n\n    # Weighted score with a small deterministic noise\n    score = 0.6 * start_ready + 0.4 * ratio\n    noise = 1e-6 * np.arange(len(ops))\n    score += noise\n\n    if last_job is None:\n        idx = np.argmin(score)\n        return tuple(ops[idx])\n\n    mask = job_idx != last_job\n    if not np.any(mask):\n        mask = np.ones_like(mask, dtype=bool)\n\n    idx = np.argmin(score[mask])\n    idx = np.where(mask)[0][idx]\n    return tuple(ops[idx])\n\n",
  "avoid_last_job_if_possible_aug_182": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_job = current_status.get('last_job')\n    machine = np.array(current_status['machine_status'])\n    job = np.array(current_status['job_status'])\n\n    ops = feasible_operations[:]\n    if last_job is not None:\n        ops = [op for op in ops if op[0] != last_job]\n        if not ops:\n            ops = feasible_operations[:]\n\n    scores = []\n    i = 0\n    while i < len(ops):\n        op = ops[i]\n        m = machine[op[1]]\n        j = job[op[0]]\n        dur = op[2]\n        # weighted sum with hyperparameters\n        w = 0.7 * m + 0.3 * j + dur\n        # deterministic noise to break ties\n        noise = 1e-6 * (op[0] * 31 + op[1] * 17 + op[2])\n        scores.append(w + noise)\n        i += 1\n\n    scores = np.array(scores, dtype=np.float64)\n    temp = 0.5  # temperature hyper\u2011parameter\n    exp_vals = np.exp(-scores / (temp + 1e-12))\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n    probs = np.clip(probs, 0, 1)\n\n    idx = np.argmax(probs)\n    return ops[idx]\n\n",
  "avoid_last_job_if_possible_aug_183": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_job = current_status.get('last_job')\n    machine = np.array(current_status['machine_status'])\n    job = np.array(current_status['job_status'])\n\n    ops = np.array(feasible_operations, dtype=np.int64)\n    job_idx = ops[:, 0]\n    machine_idx = ops[:, 1]\n    duration = ops[:, 2]\n\n    # Earliest start times\n    start = np.maximum(machine[machine_idx], job[job_idx]) + duration\n\n    # Ratio with division \u2013 guard with epsilon\n    ratio = machine[machine_idx] / (duration + 1e-12)\n    ratio = np.clip(ratio, 0, 5)\n\n    # Median aggregation plus deterministic noise\n    base = np.median(start) + 0.3 * ratio\n    noise = 1e-6 * (job_idx * 13 + machine_idx * 7 + duration)\n    score = base + noise\n\n    if last_job is not None:\n        mask = job_idx != last_job\n        if not np.any(mask):\n            mask = np.ones_like(mask, dtype=bool)\n        ops = ops[mask]\n        score = score[mask]\n\n    top_k = 5\n    top_k = min(top_k, len(score))\n    idx_sorted = np.argsort(score)[:top_k]\n\n    rng = np.random.default_rng(seed=42)  # deterministic random choice\n    chosen = rng.choice(idx_sorted)\n    return tuple(ops[chosen])\n\n",
  "wait_then_process_tradeoff_aug_184": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    eps = 1e-12\n    machine = np.array(current_status['machine_status'], dtype=float)\n    job = np.array(current_status['job_status'], dtype=float)\n\n    # Vectorised wait times and processing times\n    waits = np.array([abs(machine[op[1]] - job[op[0]]) for op in feasible_operations],\n                     dtype=float)\n    procs = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Median\u2011based alpha with clipping\n    alpha = np.mean(waits) / (np.mean(procs) + eps)\n    alpha = np.clip(alpha, 0.0, 10.0)\n\n    # Deterministic tie\u2011breaker: small incremental noise\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    score = waits + alpha * procs + noise\n\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "wait_then_process_tradeoff_aug_185": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    eps = 1e-12\n    machine = np.array(current_status['machine_status'], dtype=float)\n    job = np.array(current_status['job_status'], dtype=float)\n\n    waits = np.array([abs(machine[op[1]] - job[op[0]]) for op in feasible_operations],\n                     dtype=float)\n    procs = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Adjusted alpha using square\u2011root mean wait\n    alpha = np.sqrt(np.mean(waits)) / (np.mean(procs) + eps)\n    alpha = np.clip(alpha, 0.0, 5.0)\n\n    # Weighted score with different coefficients\n    score = 0.7 * waits + 0.3 * alpha * procs\n\n    # Add small random noise for tie\u2011breaking\n    noise = np.random.rand(len(feasible_operations)) * 1e-5\n    score += noise\n\n    # Softmin probability over the top\u2011k operations\n    top_k = 5\n    idxs = np.argpartition(score, top_k)[:top_k]\n    probs = np.exp(-score[idxs])\n    probs /= np.sum(probs)\n\n    chosen = idxs[np.argmax(probs)]\n    return feasible_operations[chosen]\n\n",
  "wait_then_process_tradeoff_aug_186": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    eps = 1e-12\n    machine = np.array(current_status['machine_status'], dtype=float)\n    job = np.array(current_status['job_status'], dtype=float)\n\n    waits = []\n    procs = []\n    for op in feasible_operations:\n        wait = abs(machine[op[1]] - job[op[0]])\n        waits.append(wait)\n        procs.append(op[2])\n    waits = np.array(waits, dtype=float)\n    procs = np.array(procs, dtype=float)\n\n    alpha = np.mean(waits) / (np.median(procs) + eps)\n    alpha = np.clip(alpha, 0.0, 8.0)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    score = waits + alpha * procs + noise\n    score = np.clip(score, 0.0, 1e6)\n\n    # Choose the operation with the maximum of the negative score\n    idx = int(np.argmax(-score))\n    return feasible_operations[idx]\n\n",
  "min_idle_then_min_gini_aug_187": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'],    dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n  = xs.size\n        cum = np.cumsum(xs)\n        return float((n + 1 - 2 * np.sum(cum) / (cum[-1] + 1e-12)) / n)\n\n    # Vectorised idle calculation\n    jobs     = np.array([op[0] for op in feasible_operations], dtype=int)\n    machines = np.array([op[1] for op in feasible_operations], dtype=int)\n    durations= np.array([op[2] for op in feasible_operations], dtype=float)\n\n    idle_vals = np.maximum(0.0, js[jobs] - ms0[machines])\n\n    # Build a key for each operation and add a tiny deterministic noise\n    keys = []\n    for idx, op in enumerate(feasible_operations):\n        ms = ms0.copy()\n        start = np.maximum(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        key = (idle_vals[idx], gini(ms), op[2], 1e-6 * idx)   # deterministic noise\n        keys.append(key)\n\n    # Pick the operation with the minimal key\n    best_op = min(zip(feasible_operations, keys), key=lambda x: x[1])[0]\n    return best_op\n\n",
  "min_idle_then_min_gini_aug_188": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'],    dtype=float)\n\n    def gini(x):\n        x = np.asarray(x, dtype=float)\n        if np.allclose(x, 0.0):\n            return 0.0\n        xs = np.sort(x)\n        n  = xs.size\n        cum = np.cumsum(xs)\n        return float((n + 1 - 2 * np.sum(cum) / (cum[-1] + 1e-12)) / n)\n\n    # --- First pass: find the best weighted key with a while loop ---\n    idx      = 0\n    best_op  = None\n    best_key = None\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        idle = max(0.0, js[op[0]] - ms0[op[1]])\n        ms   = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        # Weighted key: idle (0.7) + Gini (0.25) + duration (0.05)\n        key = idle * 0.7 + gini(ms) * 0.25 + op[2] * 0.05\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op  = op\n        idx += 1\n\n    # --- Second pass: random choice among the top\u20113 keys ---\n    all_keys = []\n    for op in feasible_operations:\n        idle = max(0.0, js[op[0]] - ms0[op[1]])\n        ms   = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n        key = idle * 0.7 + gini(ms) * 0.25 + op[2] * 0.05\n        all_keys.append((key, op))\n\n    all_keys.sort(key=lambda x: x[0])\n    top_k = min(3, len(all_keys))\n    rng = np.random.default_rng(0)\n    chosen = rng.choice([op for _, op in all_keys[:top_k]])\n    return chosen\n\n",
  "min_idle_then_min_gini_aug_189": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'],    dtype=float)\n\n    def proxy_load_variance(ms):\n        ms = np.asarray(ms, dtype=float)\n        if np.allclose(ms, 0.0):\n            return 0.0\n        # Approximate load imbalance by peak\u2011to\u2011peak over total load\n        return float((np.ptp(ms) + 1e-12) / (np.sum(ms) + 1e-12))\n\n    # Compute scores for all operations\n    scores = []\n    for op in feasible_operations:\n        idle = max(0.0, js[op[0]] - ms0[op[1]])\n        ms   = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        # Inverted logic: larger idle is worse, so use negative idle\n        score = -idle * 0.5 + proxy_load_variance(ms) * 0.4 + op[2] * 0.1\n        scores.append(score)\n\n    scores = np.array(scores)\n    best_val = np.min(scores)\n    best_indices = np.where(np.isclose(scores, best_val, atol=1e-12))[0]\n\n    rng = np.random.default_rng(42)\n    chosen_idx = rng.choice(best_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "criticality_ratio_focus_aug_190": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    med = float(np.median(ms))\n\n    # Add a tiny noise for deterministic tie\u2011breaking\n    noise = 1e-9\n\n    def _score(op):\n        m, j, t = op\n        start = max(ms[m], js[j])\n        critical = max(0.0, ms[m] - med)\n        denom = start + 1e-12\n        return (-critical / denom + noise, start, t)\n\n    return min(feasible_operations, key=_score)\n\n",
  "criticality_ratio_focus_aug_191": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    med = float(np.median(ms))\n\n    best_op = None\n    best_weight = -np.inf\n\n    for op in feasible_operations:\n        m, j, t = op\n        start = max(ms[m], js[j])\n        critical = max(0.0, ms[m] - med)\n        denom = start + 1e-12\n        score = -critical / denom\n        # softmin weight: exp(-score)\n        weight = np.exp(-score)\n        # add deterministic noise to break ties\n        weight += 1e-9\n        if weight > best_weight:\n            best_weight = weight\n            best_op = op\n\n    return best_op\n\n",
  "criticality_ratio_focus_aug_192": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    med = float(np.median(ms))\n\n    # Unpack operations into separate arrays\n    ops_arr = np.array(feasible_operations, dtype=object)\n    machine_idx = ops_arr[:, 1].astype(int)\n    job_idx = ops_arr[:, 0].astype(int)\n    duration = ops_arr[:, 2].astype(float)\n\n    start = np.maximum(ms[machine_idx], js[job_idx])\n    start = np.clip(start, 1e-12, None)          # avoid division by zero\n    critical = np.maximum(0.0, ms[machine_idx] - med)\n\n    # Weighted score: more weight on criticality, less on start time\n    score = -critical / start + 0.5 * duration\n\n    # Add deterministic noise for tie\u2011breaking\n    noise = np.arange(len(score)) * 1e-9\n    score += noise\n\n    idx = np.argmin(score)\n    return tuple(ops_arr[idx])\n\n",
  "criticality_ratio_focus_aug_193": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    med = float(np.median(ms))\n\n    ops_arr = np.array(feasible_operations, dtype=object)\n    machine_idx = ops_arr[:, 1].astype(int)\n    job_idx = ops_arr[:, 0].astype(int)\n    duration = ops_arr[:, 2].astype(float)\n\n    start = np.maximum(ms[machine_idx], js[job_idx])\n    start = np.clip(start, 1e-12, None)          # prevent division by zero\n    critical = np.maximum(0.0, ms[machine_idx] - med)\n\n    # Simple linear score: lower criticality and start time preferred\n    score = critical + start\n\n    # Pick top\u2011k (k=3) operations with the smallest scores\n    k = 3\n    idx_sorted = np.argsort(score)\n    top_k_idx = idx_sorted[:min(k, len(feasible_operations))]\n\n    # Randomly choose one among the top\u2011k\n    chosen_idx = np.random.choice(top_k_idx)\n    return tuple(ops_arr[chosen_idx])\n\n",
  "harmonic_blend_score_aug_194": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = np.asarray(current_status['machine_status'], dtype=np.float64)\n    job = np.asarray(current_status['job_status'], dtype=np.float64)\n\n    ops = np.array(feasible_operations, dtype=object)\n    job_ids = np.array([op[0] for op in ops], dtype=int)\n    machine_ids = np.array([op[1] for op in ops], dtype=int)\n    proc_times = np.array([op[2] for op in ops], dtype=np.float64)\n\n    start_times = np.maximum(machine[machine_ids], job[job_ids])\n    loads = machine[machine_ids]\n\n    eps = 1e-12\n    a = 1.0 / (proc_times + eps)\n    b = 1.0 / (start_times + 1.0 + eps)\n    c = 1.0 / (loads + 1.0 + eps)\n\n    hm_scores = 3.0 / (1.0/(a + eps) + 1.0/(b + eps) + 1.0/(c + eps))\n\n    best_idx = np.argmax(hm_scores)\n    best_op = tuple(ops[best_idx])\n\n    mask = np.abs(hm_scores - hm_scores[best_idx]) < 1e-12\n    if np.any(mask):\n        completion = start_times + proc_times\n        min_completion = np.min(completion[mask])\n        tie_idx = np.where(mask & (completion == min_completion))[0]\n        best_op = tuple(ops[tie_idx[0]])\n\n    return best_op\n\n",
  "harmonic_blend_score_aug_195": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = np.asarray(current_status['machine_status'], dtype=np.float64)\n    job = np.asarray(current_status['job_status'], dtype=np.float64)\n\n    eps = 1e-12\n    weights = np.array([0.4, 0.3, 0.3], dtype=np.float64)\n\n    best_op = None\n    best_score = -np.inf\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        start = max(machine[op[1]], job[op[0]])\n        proc = float(op[2])\n        load = float(machine[op[1]])\n\n        inv_proc = 1.0 / (proc + eps)\n        inv_start = 1.0 / (start + 1.0 + eps)\n        inv_load = 1.0 / (load + 1.0 + eps)\n\n        score = np.dot(weights, np.array([inv_proc, inv_start, inv_load]))\n\n        if score > best_score + eps:\n            best_score, best_op = score, op\n        elif abs(score - best_score) < eps:\n            noise = ((hash(op) % 1000) / 1e6)\n            if noise > 0.5:\n                best_op = op\n        idx += 1\n\n    top_k = 5\n    scores = []\n    for op in feasible_operations:\n        start = max(machine[op[1]], job[op[0]])\n        proc = float(op[2])\n        load = float(machine[op[1]])\n        inv_proc = 1.0 / (proc + eps)\n        inv_start = 1.0 / (start + 1.0 + eps)\n        inv_load = 1.0 / (load + 1.0 + eps)\n        scores.append(np.dot(weights, np.array([inv_proc, inv_start, inv_load])))\n    scores = np.array(scores)\n    max_score = np.max(scores)\n    candidates = [op for op, s in zip(feasible_operations, scores) if abs(s - max_score) < eps]\n    if len(candidates) > 1:\n        chosen = np.random.choice(np.array(candidates), size=1)[0]\n        best_op = chosen\n\n    return best_op\n\n",
  "two_stage_filter_then_score_aug_196": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # --- Stage 1: compute earliest feasible start times (while loop) ---\n    starts = np.empty(len(feasible_operations), dtype=float)\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        starts[i] = max(ms0[op[1]], js[op[0]])\n        i += 1\n\n    min_s = float(starts.min())\n    q     = float(np.percentile(starts, 25) - min_s)\n    threshold = min_s + max(0.0, q)\n    threshold = np.clip(threshold, None, None)   # no effect, but keeps the rule\n\n    # --- Stage 2: keep operations whose start is within the threshold ---\n    filtered = []\n    i = 0\n    while i < len(feasible_operations):\n        if starts[i] <= threshold + 1e-12:\n            filtered.append(feasible_operations[i])\n        i += 1\n    candidates = filtered if filtered else feasible_operations\n\n    # --- Stage 3: evaluate candidates ---\n    best_op   = None\n    best_key  = (float('inf'), float('inf'), float('inf'))\n\n    i = 0\n    while i < len(candidates):\n        op = candidates[i]\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        # dispersion proxy: mean absolute deviation with epsilon safety\n        mean_ms = np.sum(ms) / (ms.size + 1e-12)\n        mad     = np.mean(np.abs(ms - mean_ms))\n\n        # deterministic noise for tie\u2011breaking\n        noise = 1e-9 * (op[0] + op[1])\n        key   = (mad + noise, start + float(op[2]), op[2])\n\n        if key < best_key:\n            best_key = key\n            best_op  = op\n        i += 1\n\n    return best_op\n\n",
  "two_stage_filter_then_score_aug_197": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # compute earliest start times\n    starts = np.array([max(ms0[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n\n    min_s = float(starts.min())\n    q     = float(np.percentile(starts, 50) - min_s)          # 50th percentile instead of 25th\n    threshold = min_s + max(0.0, 0.5 * q)                    # scaling factor 0.5\n    threshold = np.clip(threshold, None, None)\n\n    # keep operations within the threshold\n    filtered = [op for op, s in zip(feasible_operations, starts) if s <= threshold + 1e-12]\n    candidates = filtered if filtered else feasible_operations\n\n    # compute soft\u2011min scores\n    scores = []\n    i = 0\n    while i < len(candidates):\n        op = candidates[i]\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        mean_ms = np.sum(ms) / (ms.size + 1e-12)\n        mad     = np.mean(np.abs(ms - mean_ms))\n        comp    = start + float(op[2])\n\n        # weighted sum: lower is better\n        score = 0.6 * mad + 0.4 * comp\n        scores.append(score)\n        i += 1\n\n    scores = np.array(scores)\n\n    # soft\u2011min probabilities\n    alpha = 20.0\n    exp_vals = np.exp(-alpha * scores)\n    probs    = exp_vals / (exp_vals.sum() + 1e-12)\n\n    # deterministic choice: pick the operation with highest probability\n    idx = int(np.argmax(probs))\n    return candidates[idx]\n\n",
  "two_stage_filter_then_score_aug_198": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # earliest start times (while loop)\n    starts = np.empty(len(feasible_operations), dtype=float)\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        starts[i] = max(ms0[op[1]], js[op[0]])\n        i += 1\n\n    min_s = float(starts.min())\n    q     = float(np.percentile(starts, 25) - min_s)\n    threshold = min_s + max(0.0, 1.2 * q)                    # scaling factor 1.2\n    threshold = np.clip(threshold, None, None)\n\n    # filter operations\n    filtered = []\n    i = 0\n    while i < len(feasible_operations):\n        if starts[i] <= threshold + 1e-12:\n            filtered.append(feasible_operations[i])\n        i += 1\n    candidates = filtered if filtered else feasible_operations\n\n    # evaluate candidates\n    scores = []\n    i = 0\n    while i < len(candidates):\n        op = candidates[i]\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        mean_ms = np.sum(ms) / (ms.size + 1e-12)\n        disp    = np.sum(np.abs(ms - mean_ms))                 # sum of absolute deviations\n        comp    = start + float(op[2])\n\n        # weighted score\n        score = 0.5 * disp + 0.3 * comp + 0.2 * op[2]\n        scores.append(score)\n        i += 1\n\n    scores = np.array(scores)\n\n    # deterministic top\u20115 selection\n    top_k = min(5, len(candidates))\n    top_indices = np.argpartition(scores, top_k - 1)[:top_k]\n    best_idx = int(np.min(top_indices))\n    return candidates[best_idx]\n\n",
  "two_stage_filter_then_score_aug_199": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # compute earliest start times (while loop)\n    starts = np.empty(len(feasible_operations), dtype=float)\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        starts[i] = max(ms0[op[1]], js[op[0]])\n        i += 1\n\n    min_s = float(starts.min())\n    q     = float(np.percentile(starts, 75) - min_s)          # 75th percentile\n    threshold = min_s + max(0.0, 0.8 * q)                    # scaling factor 0.8\n    threshold = np.clip(threshold, None, None)\n\n    # filter operations\n    filtered = []\n    i = 0\n    while i < len(feasible_operations):\n        if starts[i] <= threshold + 1e-12:\n            filtered.append(feasible_operations[i])\n        i += 1\n    candidates = filtered if filtered else feasible_operations\n\n    # evaluate candidates\n    scores = []\n    i = 0\n    while i < len(candidates):\n        op = candidates[i]\n        ms = ms0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        ms[op[1]] = start + float(op[2])\n\n        mean_ms = np.sum(ms) / (ms.size + 1e-12)\n        disp    = np.max(np.abs(ms - mean_ms))                 # max absolute deviation\n        comp    = start + float(op[2])\n\n        # weighted score (lower is better)\n        score = -(0.6 * disp + 0.4 * comp)                     # negative for softmax\n        scores.append(score)\n        i += 1\n\n    scores = np.array(scores)\n\n    # softmax probabilities\n    exp_vals = np.exp(scores - np.max(scores))\n    probs    = exp_vals / (exp_vals.sum() + 1e-12)\n\n    # deterministic choice: argmax of probabilities\n    idx = int(np.argmax(probs))\n    return candidates[idx]\n\n",
  "earliest_completion_shortest_processing_aug_200": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Vectorised start and completion times\n    start = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    completion = start + ops[:, 2]\n\n    # Weighted score: 60% completion, 40% duration\n    score = 0.6 * completion + 0.4 * ops[:, 2]\n\n    # Small noise to avoid perfect ties\n    noise = np.random.uniform(0, 1e-6, size=score.shape)\n    score += noise\n\n    # Soft\u2011min probability\n    temp = 0.1\n    exp_neg = np.exp(-score / (temp + 1e-12))\n    probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n    chosen_idx = np.argmax(probs)\n\n    return tuple(ops[chosen_idx])\n\n",
  "earliest_completion_shortest_processing_aug_201": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    start = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    completion = start + ops[:, 2]\n    score = completion + ops[:, 2]\n\n    # Add tiny noise to ensure strict ordering\n    score += np.random.uniform(0, 1e-6, size=score.shape)\n\n    top_k = 5\n    sorted_idx = np.argsort(score)\n    candidates = sorted_idx[:min(top_k, len(score))]\n    chosen_idx = np.random.choice(candidates)\n\n    return tuple(ops[chosen_idx])\n\n",
  "earliest_completion_shortest_processing_aug_202": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    start = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    completion = start + ops[:, 2]\n    score = completion\n\n    # Add deterministic noise to break ties\n    score += np.arange(len(score)) * 1e-9\n\n    median_score = np.median(score)\n    diff = np.abs(score - median_score)\n    min_idx = np.argmin(diff)\n\n    # If several ops are equally close, choose the one with smallest duration\n    same_diff = np.isclose(diff, diff[min_idx], atol=1e-12)\n    if np.sum(same_diff) > 1:\n        durations = ops[same_diff, 2]\n        min_dur_idx = np.argmin(durations)\n        chosen_idx = np.where(same_diff)[0][min_dur_idx]\n    else:\n        chosen_idx = min_idx\n\n    return tuple(ops[chosen_idx])\n\n",
  "earliest_completion_shortest_processing_aug_203": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Clip start times to avoid negative or excessively large values\n    start = np.maximum(ms[ops[:, 1]], js[ops[:, 0]])\n    start = np.clip(start, 0, 1e6)\n\n    completion = start + ops[:, 2]\n    # Weighted score: 80% completion, 20% duration\n    score = 0.8 * completion + 0.2 * ops[:, 2]\n\n    # Clip scores to keep them within a reasonable range\n    score = np.clip(score, 0, 1e6)\n\n    # Add a fixed small noise term for deterministic tie breaking\n    score += np.arange(len(score)) * 1e-9\n\n    chosen_idx = np.argmin(score)\n    return tuple(ops[chosen_idx])\n\n",
  "earliest_completion_longest_processing_aug_204": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Convert status lists to numpy arrays for vectorised ops\n    machine_avail = np.array(current_status['machine_status'])\n    job_avail     = np.array(current_status['job_status'])\n\n    # Keep the operations as an object array to preserve tuple structure\n    ops = np.array(feasible_operations, dtype=object)\n\n    # Start times are the later of machine and job availability\n    start_time = np.maximum(machine_avail[ops[:, 1]], job_avail[ops[:, 0]])\n\n    # Completion times\n    completion = start_time + ops[:, 2]\n\n    # Ratio of duration to start time (adds fragmentation penalty)\n    ratio = ops[:, 2] / (start_time + 1e-12)          # epsilon to avoid div\u2011by\u2011zero\n    ratio = np.clip(ratio, 0, 1)                      # bound to avoid extreme values\n\n    # Composite score: lower completion, higher ratio is better\n    score = completion - 10 * ratio\n\n    best_idx = np.argmin(score)\n    return tuple(ops[best_idx])\n\n",
  "earliest_completion_longest_processing_aug_205": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_avail = np.array(current_status['machine_status'])\n    job_avail     = np.array(current_status['job_status'])\n\n    best_idx   = None\n    best_score = np.inf\n    i          = 0\n\n    while i < len(feasible_operations):\n        job, machine, dur = feasible_operations[i]\n        start = max(machine_avail[machine], job_avail[job])\n        comp  = start + dur\n\n        # Ratio penalty with epsilon in denominator\n        ratio = dur / (start + 1e-12)\n        score = comp - 5 * ratio\n\n        if score < best_score:\n            best_score = score\n            best_idx   = i\n        i += 1\n\n    return feasible_operations[best_idx]\n\n",
  "earliest_completion_longest_processing_aug_206": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_avail = np.array(current_status['machine_status'])\n    job_avail     = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    start_time = np.maximum(machine_avail[ops[:, 1]], job_avail[ops[:, 0]])\n    completion = start_time + ops[:, 2]\n\n    # Clip completion times to avoid overflow (bounded operation)\n    completion = np.clip(completion, 0, 1e9)\n\n    median_comp = np.median(completion)\n\n    # Define a window around the median (\u00b110\u202f%)\n    lower = median_comp * 0.9\n    upper = median_comp * 1.1\n\n    mask = (completion >= lower) & (completion <= upper)\n    candidates = ops[mask]\n    if len(candidates) == 0:\n        candidates = ops\n\n    # Sort candidates by completion and pick a random one among the top\u2011k\n    sorted_idx = np.argsort(completion[mask])\n    top_k = min(3, len(sorted_idx))\n    chosen_idx = np.random.choice(sorted_idx[:top_k])\n\n    return tuple(candidates[chosen_idx])\n\n",
  "min_slack_to_mean_time_aug_207": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # rename for clarity\n    m_stat = np.asarray(current_status['machine_status'], dtype=float)\n    j_stat = np.asarray(current_status['job_status'], dtype=float)\n\n    # compute average machine status\n    avg_m = float(np.mean(m_stat))\n\n    # build candidate keys\n    keys = []\n    for op in feasible_operations:\n        start_time = max(m_stat[op[1]], j_stat[op[0]])\n        slack_val = start_time - avg_m\n        keys.append((slack_val, op[2], start_time, op))\n\n    # choose the operation with the smallest key\n    best = min(keys, key=lambda x: (x[0], x[1], x[2]))\n    return best[3]\n\n",
  "min_slack_to_mean_time_aug_208": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.asarray(current_status['machine_status'], dtype=float)\n    j_stat = np.asarray(current_status['job_status'], dtype=float)\n\n    # safe mean: add epsilon to denominator\n    n = len(m_stat)\n    avg_m = float(np.sum(m_stat) / (n + 1e-12))\n\n    # weight factor for balancing slack and priority\n    w = 0.6\n    best = None\n    best_score = np.inf\n\n    for op in feasible_operations:\n        start_time = max(m_stat[op[1]], j_stat[op[0]])\n        slack_val = np.clip(start_time - avg_m, -1e6, 1e6)\n        score = w * slack_val + (1 - w) * op[2]  # op[2] treated as priority\n        if score < best_score:\n            best_score = score\n            best = op\n\n    return best\n\n",
  "min_slack_to_mean_time_aug_209": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.asarray(current_status['machine_status'], dtype=float)\n    j_stat = np.asarray(current_status['job_status'], dtype=float)\n\n    # use maximum machine status\n    max_m = float(np.max(m_stat))\n\n    machine_indices = [op[1] for op in feasible_operations]\n    job_indices     = [op[0] for op in feasible_operations]\n    starts = np.maximum(m_stat[machine_indices], j_stat[job_indices])\n\n    # compute slacks with clipping\n    slacks = np.clip(starts - max_m, -1e6, 1e6)\n\n    # choose operation with smallest slack\n    idx = np.argmin(slacks)\n    return feasible_operations[idx]\n\n",
  "max_slack_to_mean_time_aug_210": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_arr = np.asarray(current_status['machine_status'], dtype=float)\n    job_arr      = np.asarray(current_status['job_status'], dtype=float)\n\n    # Use the median of machine status as the reference point\n    mean_machine = float(np.median(machine_arr))\n\n    # Compute start times for all feasible operations\n    starts = np.array([max(machine_arr[op[1]], job_arr[op[0]]) for op in feasible_operations],\n                      dtype=float)\n\n    # Slack is the difference between start time and the reference machine status\n    slacks = starts - mean_machine\n    # Clip negative slack to zero \u2013 we only care about positive slack\n    slacks = np.clip(slacks, 0, None)\n\n    # Add a tiny deterministic noise to break ties\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-9\n    # We want the operation with the largest slack, so use negative slack as a key\n    scores = -slacks + noise\n\n    chosen_index = int(np.argmin(scores))\n    return feasible_operations[chosen_index]\n\n",
  "max_slack_to_mean_time_aug_211": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    mu = float(np.mean(ms))\n\n    # Compute start times and slack values using a while loop\n    start_list, slack_list = [], []\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        start = max(ms[op[1]], js[op[0]])\n        start_list.append(start)\n        slack_list.append(start - mu)\n        i += 1\n\n    slack_arr = np.array(slack_list, dtype=float)\n\n    # Soft\u2011min weighting with a small temperature (avoid division by zero)\n    temp = 1.0 + 1e-12\n    weights = np.exp(-slack_arr / temp)\n    probs = weights / np.clip(np.sum(weights), 1e-12, None)\n\n    # Pick randomly from the top\u20113 slack operations\n    top_k = min(3, len(feasible_operations))\n    top_indices = np.argsort(-slack_arr)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / np.clip(np.sum(top_probs), 1e-12, None)\n\n    chosen_idx = int(np.random.choice(top_indices, p=top_probs))\n    return feasible_operations[chosen_idx]\n\n",
  "max_slack_to_mean_time_aug_212": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        ms = np.asarray(current_status['machine_status'], dtype=float)\n        js = np.asarray(current_status['job_status'], dtype=float)\n        # Reference point is the maximum machine status\n        mu = float(np.max(ms))\n\n        # Compute start times and clip them to the reference point\n        starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations],\n                          dtype=float)\n        starts = np.clip(starts, None, mu)\n\n        slacks = starts - mu\n        # Deterministic noise for tie\u2011breaking\n        noise = np.arange(len(feasible_operations), dtype=float) * 1e-8\n        scores = -slacks + noise\n\n        chosen_index = int(np.argmin(scores))\n        return feasible_operations[chosen_index]\n    else:\n        return None\n\n",
  "max_slack_to_mean_time_aug_213": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_arr = np.asarray(current_status['machine_status'], dtype=float)\n    job_arr     = np.asarray(current_status['job_status'], dtype=float)\n    mu = float(np.mean(machine_arr))\n\n    begin_list, slack_list = [], []\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        begin = max(machine_arr[op[1]], job_arr[op[0]])\n        begin_list.append(begin)\n        # Use squared slack to emphasize larger differences\n        slack_list.append(np.square(begin - mu))\n        idx += 1\n\n    slack_arr = np.array(slack_list, dtype=float)\n    # Clip negative slack to zero\n    slack_arr = np.clip(slack_arr, 0, None)\n\n    # Deterministic noise for stable tie\u2011breaking\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-7\n    scores = -slack_arr + noise\n\n    chosen = int(np.argmin(scores))\n    return feasible_operations[chosen]\n\n",
  "zscore_machine_priority_aug_214": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    mu = np.mean(ms)\n    sd = np.std(ms) + 1e-12          # epsilon to avoid division by zero\n\n    # Convert the list of tuples into a NumPy array for vectorised indexing\n    ops_arr = np.array(feasible_operations, dtype=object)\n    m_idx = np.array([op[1] for op in ops_arr])\n    j_idx = np.array([op[0] for op in ops_arr])\n\n    # z\u2011score for each machine referenced by the operation\n    z = (ms[m_idx] - mu) / sd\n    z = np.clip(z, -10.0, 10.0)      # keep values bounded\n\n    # earliest start time respecting both machine and job availability\n    start = np.maximum(ms[m_idx], js[j_idx])\n\n    # deterministic noise to break ties (operation index * 1e\u20116)\n    noise = np.arange(len(ops_arr)) * 1e-6\n\n    # Combined score: prefer lower z\u2011score (more loaded machine) and earlier start\n    score = -z + start + noise\n\n    idx = np.argmin(score)\n    return tuple(ops_arr[idx])\n\n",
  "zscore_machine_priority_aug_215": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    mu = np.mean(ms)\n    sd = np.std(ms) + 1e-12          # epsilon\n\n    scores = []\n    idx = 0\n    rng = np.random.default_rng(0)   # deterministic RNG\n\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        m, j = op[1], op[0]\n        z = (ms[m] - mu) / sd\n        z = np.clip(z, -5.0, 5.0)\n        start = max(ms[m], js[j])\n        # weighted combination: 0.4 * z (negative) + 0.6 * start\n        scores.append(-0.4 * z + 0.6 * start)\n        idx += 1\n\n    scores = np.array(scores)\n\n    # softmin: probability proportional to exp(-score)\n    exp_neg = np.exp(-scores)\n    probs = exp_neg / exp_neg.sum()\n\n    # choose randomly among the three best (lowest score) operations\n    top_k = 3\n    top_indices = np.argsort(scores)[:top_k]\n    chosen = rng.choice(top_indices, p=probs[top_indices]/probs[top_indices].sum())\n\n    return feasible_operations[chosen]\n\n",
  "zscore_machine_priority_aug_216": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    mu = np.median(ms)\n    sd = np.max(np.abs(ms - mu)) + 1e-12  # surrogate for std\n\n    z_vals = []\n    start_vals = []\n\n    for op in feasible_operations:\n        m, j = op[1], op[0]\n        z = (ms[m] - mu) / sd\n        z = np.clip(z, -4.0, 4.0)\n        z_vals.append(z)\n        start_vals.append(max(ms[m], js[j]))\n\n    # deterministic noise: sum of tuple elements scaled\n    noise = np.array([sum(op) * 1e-7 for op in feasible_operations])\n\n    score = np.array(z_vals) * -1 + np.array(start_vals) + noise\n    idx = np.argmin(score)\n    return feasible_operations[idx]\n\n",
  "zscore_machine_priority_aug_217": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    mu = np.mean(ms)\n    sd = np.std(ms) + 1e-12\n\n    scores = []\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        m, j = op[1], op[0]\n        z = (ms[m] - mu) / sd\n        z = np.clip(z, -3.0, 3.0)\n        start = max(ms[m], js[j])\n        scores.append(-z + start)\n        idx += 1\n\n    scores = np.array(scores)\n\n    # softmax probabilities (higher score -> lower probability)\n    exp_scores = np.exp(-scores)\n    probs = exp_scores / exp_scores.sum()\n\n    top_k = 5\n    top_indices = np.argsort(scores)[:top_k]\n\n    rng = np.random.default_rng(42)\n    chosen = rng.choice(top_indices, p=probs[top_indices]/probs[top_indices].sum())\n\n    return feasible_operations[chosen]\n\n",
  "zscore_job_priority_aug_218": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    mu = float(np.mean(js))\n    sd = float(np.std(js) + 1e-12)\n\n    # Clip z\u2011scores to avoid extreme values\n    z_vals = np.clip((js - mu) / sd, -5.0, 5.0)\n\n    # Build candidate list with deterministic noise for start times\n    candidates = []\n    for op in feasible_operations:\n        j, m, op_id = op\n        start = max(ms[m], js[j]) + 1e-6 * op_id  # deterministic noise\n        key = (-z_vals[j], start, op_id)\n        candidates.append((key, op))\n\n    # Return operation with minimal key\n    return min(candidates, key=lambda x: x[0])[1]\n\n",
  "zscore_job_priority_aug_219": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    mu = float(np.mean(js))\n    sd = float(np.std(js) + 1e-12)\n\n    # Clip z\u2011scores to a reasonable range\n    z_vals = np.clip((js - mu) / sd, -10.0, 10.0)\n\n    # Weights for the components of the score\n    w_z = 0.6\n    w_start = 0.4\n\n    scores = []\n    for op in feasible_operations:\n        j, m, op_id = op\n        start = max(ms[m], js[j])\n        score = w_z * (-z_vals[j]) + w_start * start\n        scores.append(score)\n\n    min_score = min(scores)\n    eps = 1e-6\n    candidates = [op for op, sc in zip(feasible_operations, scores)\n                  if abs(sc - min_score) < eps]\n\n    if len(candidates) > 1:\n        rng = np.random.default_rng()\n        return rng.choice(candidates)\n    return candidates[0]\n\n",
  "zscore_job_priority_aug_220": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    mu = float(np.median(js))\n    range_js = float(np.max(js) - np.min(js) + 1e-12)\n    sd = range_js\n\n    z_vals = np.clip((js - mu) / sd, -3.0, 3.0)\n\n    best_op = None\n    best_key = (np.inf, np.inf, np.inf)\n\n    for op in feasible_operations:\n        j, m, op_id = op\n        start = np.max([ms[m], js[j]]) + 1e-7 * (j + m)  # deterministic noise\n        key = (-z_vals[j], start, op_id)\n        if key < best_key:\n            best_key = key\n            best_op = op\n\n    return best_op\n\n",
  "zscore_job_priority_aug_221": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    mu = float(np.mean(js))\n    sd = float(np.std(js) + 1e-12)\n\n    z_vals = np.clip((js - mu) / sd, -4.0, 4.0)\n\n    best_op = None\n    best_score = -np.inf\n\n    for op in feasible_operations:\n        j, m, op_id = op\n        start = max(ms[m], js[j])\n        score = z_vals[j] - 0.5 * (start ** 2)  # quadratic penalty\n        score += 1e-8 * op_id  # deterministic noise\n        if score > best_score:\n            best_score = score\n            best_op = op\n\n    return best_op\n\n",
  "min_pairwise_makespan_gap_aug_222": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Clip status arrays to non\u2011negative values\n    ms = np.clip(np.array(current_status['machine_status'], dtype=float), 0.0, None)\n    js = np.clip(np.array(current_status['job_status'], dtype=float), 0.0, None)\n\n    # Prepare arrays for vectorised computation\n    ops = np.array(feasible_operations, dtype=object)\n    job_ids    = np.array([op[0] for op in ops], dtype=int)\n    machine_ids= np.array([op[1] for op in ops], dtype=int)\n    durations  = np.array([float(op[2]) for op in ops], dtype=float)\n\n    # Compute start and finish times for each operation\n    start = np.maximum(ms[machine_ids], js[job_ids])\n    fin   = start + durations\n\n    # Create per\u2011operation copies of status arrays\n    ms_new = ms[np.newaxis, :].repeat(len(ops), axis=0)\n    js_new = js[np.newaxis, :].repeat(len(ops), axis=0)\n    ms_new[np.arange(len(ops)), machine_ids] = fin\n    js_new[np.arange(len(ops)), job_ids]    = fin\n\n    # Gap between the maximum machine and job times\n    max_ms = np.max(ms_new, axis=1)\n    max_js = np.max(js_new, axis=1)\n    gaps   = np.abs(max_ms - max_js)\n\n    # Soft score with deterministic noise for tie\u2011breaking\n    noise = np.arange(len(ops)) * 1e-6\n    score = gaps / (fin + 1e-12) + noise\n\n    # Choose the operation with the minimum score\n    best_idx = np.argmin(score)\n    return tuple(ops[best_idx])\n\n",
  "min_pairwise_makespan_gap_aug_223": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.clip(np.array(current_status['machine_status'], dtype=float), 0.0, None)\n    js = np.clip(np.array(current_status['job_status'], dtype=float), 0.0, None)\n\n    ops_list = list(feasible_operations)\n    best_score = float('inf')\n    best_ops = []\n\n    while ops_list:\n        op = ops_list.pop()  # pop from the end\n        start = max(ms[op[1]], js[op[0]])\n        fin   = start + float(op[2])\n\n        ms_new = ms.copy()\n        js_new = js.copy()\n        ms_new[op[1]] = fin\n        js_new[op[0]] = fin\n\n        gap   = abs(float(ms_new.max()) - float(js_new.max()))\n        score = 0.6 * gap + 0.4 * fin  # weighted score\n\n        if score < best_score:\n            best_score = score\n            best_ops = [op]\n        elif score == best_score:\n            best_ops.append(op)\n\n    # Randomly choose among the top 3 best operations\n    top_k = min(3, len(best_ops))\n    chosen = np.random.choice(best_ops, size=top_k, replace=False)\n    return tuple(chosen[0])\n\n",
  "min_pairwise_makespan_gap_aug_224": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.clip(np.array(current_status['machine_status'], dtype=float), 0.0, None)\n    js = np.clip(np.array(current_status['job_status'], dtype=float), 0.0, None)\n\n    best_val = float('inf')\n    best_op  = None\n    noise_factor = 1e-6\n\n    for idx, op in enumerate(feasible_operations):\n        start = max(ms[op[1]], js[op[0]])\n        fin   = start + float(op[2])\n\n        ms_new = ms.copy()\n        js_new = js.copy()\n        ms_new[op[1]] = fin\n        js_new[op[0]] = fin\n\n        median_ms = np.median(ms_new)\n        median_js = np.median(js_new)\n        val = abs(median_ms - median_js)\n\n        # Weighted score: give more importance to the gap\n        score = 0.7 * val + 0.3 * fin + noise_factor * idx\n\n        if score < best_val:\n            best_val = score\n            best_op  = op\n\n    return tuple(best_op)\n\n",
  "min_mean_absolute_deviation_machines_aug_225": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_base = np.clip(np.array(current_status['machine_status'], dtype=float), 0, None)\n    job_base     = np.clip(np.array(current_status['job_status'], dtype=float), 0, None)\n\n    scores = []\n    for op in feasible_operations:\n        ms = machine_base.copy()\n        start = max(ms[op[1]], job_base[op[0]])\n        start = np.clip(start, 0, None)\n        end = start + float(op[2])\n        ms[op[1]] = end\n\n        mu  = np.sum(ms) / (len(ms) + 1e-12)          # epsilon added to denominator\n        mad = np.mean(np.abs(ms - mu))\n\n        # deterministic tie\u2011breaker\n        noise = 1e-9 * (op[0] + op[1])\n        scores.append(mad + noise)\n\n    best_idx = int(np.argmin(scores))\n    return tuple(feasible_operations[best_idx])\n\n",
  "min_mean_absolute_deviation_machines_aug_226": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_base = np.clip(np.array(current_status['machine_status'], dtype=float), 0, None)\n    job_base     = np.clip(np.array(current_status['job_status'], dtype=float), 0, None)\n\n    scores = []\n    for op in feasible_operations:\n        ms = machine_base.copy()\n        start = max(ms[op[1]], job_base[op[0]])\n        start = np.clip(start, 0, None)\n        end = start + float(op[2])\n        ms[op[1]] = end\n\n        mu  = np.sum(ms) / (len(ms) + 1e-12)\n        mad = np.mean(np.abs(ms - mu))\n\n        # weighted score with tuned parameters\n        score = 0.6 * mad + 0.4 * end\n        scores.append(score)\n\n    # softmin selection\n    temp   = 0.1\n    exp_vals = np.exp(-np.array(scores) / temp)\n    probs    = exp_vals / (np.sum(exp_vals) + 1e-12)   # epsilon for denominator\n\n    idx = np.random.choice(len(feasible_operations), p=probs)\n    return tuple(feasible_operations[idx])\n\n",
  "min_mean_absolute_deviation_machines_aug_227": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_base = np.clip(np.array(current_status['machine_status'], dtype=float), 0, None)\n    job_base     = np.clip(np.array(current_status['job_status'], dtype=float), 0, None)\n\n    scores = []\n    for op in feasible_operations:\n        ms = machine_base.copy()\n        start = max(ms[op[1]], job_base[op[0]])\n        start = np.clip(start, 0, None)\n        end = start + float(op[2])\n        ms[op[1]] = end\n\n        mu  = np.sum(ms) / (len(ms) + 1e-12)\n        mad = np.mean(np.abs(ms - mu))\n\n        # deterministic noise for tie\u2011breaking\n        noise = 1e-8 * (op[0] ** 2 + op[1] ** 2)\n        scores.append(mad + noise)\n\n    scores = np.array(scores)\n    top_k = 3\n    if len(scores) <= top_k:\n        candidates = np.arange(len(scores))\n    else:\n        candidates = np.argpartition(scores, top_k)[:top_k]\n\n    chosen = np.random.choice(candidates)\n    return tuple(feasible_operations[chosen])\n\n",
  "min_mean_absolute_deviation_machines_aug_228": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_base = np.clip(np.array(current_status['machine_status'], dtype=float), 0, None)\n        job_base     = np.clip(np.array(current_status['job_status'], dtype=float), 0, None)\n\n        candidates = []\n        for op in feasible_operations:\n            ms = machine_base.copy()\n            start = max(ms[op[1]], job_base[op[0]])\n            start = np.clip(start, 0, None)\n            end = start + float(op[2])\n            ms[op[1]] = end\n\n            mu  = np.sum(ms) / (len(ms) + 1e-12)\n            mad = np.sum(np.abs(ms - mu)) / (len(ms) + 1e-12)   # sum instead of mean\n\n            key = (mad, end, op[2])\n            candidates.append((key, op))\n\n        best_op = min(candidates, key=lambda x: x[0])[1]\n        return tuple(best_op)\n\n    return None\n\n",
  "min_mean_absolute_deviation_jobs_aug_229": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    eps = 1e-12\n\n    for op in feasible_operations:\n        # Start time: maximum of machine availability and job ready time\n        start = np.maximum(ms[op[1]], js0[op[0]])\n        # End time, clipped to be non\u2011negative\n        end = np.clip(start + float(op[2]), 0.0, np.inf)\n\n        # Updated completion times for this job\n        js = js0.copy()\n        js[op[0]] = end\n\n        # Mean and MAD with safe division\n        mu = np.sum(js) / (len(js) + eps)\n        mad = np.sum(np.abs(js - mu)) / (len(js) + eps)\n\n        key = (mad, end, op[2])\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n\n    return best_op\n\n",
  "min_mean_absolute_deviation_jobs_aug_230": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    eps = 1e-12\n\n    for op in feasible_operations:\n        start = np.maximum(ms[op[1]], js0[op[0]])\n        end   = np.clip(start + float(op[2]), 0.0, np.inf)\n\n        js = js0.copy()\n        js[op[0]] = end\n\n        # Median and MAD with safe division\n        mu  = np.median(js)\n        mad = np.sum(np.abs(js - mu)) / (len(js) + eps)\n\n        key = (mad, np.max(js), end)\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n\n    return best_op\n\n",
  "min_mean_absolute_deviation_jobs_aug_231": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    eps = 1e-12\n    scores = []\n    ops = []\n\n    for op in feasible_operations:\n        start = np.maximum(ms[op[1]], js0[op[0]])\n        end   = np.clip(start + float(op[2]), 0.0, np.inf)\n\n        js = js0.copy()\n        js[op[0]] = end\n\n        mu  = np.sum(js) / (len(js) + eps)\n        mad = np.sum(np.abs(js - mu)) / (len(js) + eps)\n\n        # Hyper\u2011parameterised weighted score\n        score = 0.6 * mad + 0.4 * end\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores)\n\n    # Randomly pick from the best top\u2011k (k=7)\n    top_k = min(7, len(ops))\n    top_indices = np.argpartition(scores, top_k - 1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n\n    return ops[chosen_idx]\n\n",
  "entropy_balanced_machines_aug_232": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'], dtype=float)\n\n    def entropy_vector(x):\n        total = np.sum(x) + 1e-12\n        probs = x / total\n        probs = np.clip(probs, 1e-12, 1.0)\n        return float(-np.sum(probs * np.log(probs)))\n\n    best_op     = None\n    best_tuple  = (-np.inf, np.inf)\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        temp_machine = machine_times.copy()\n        start_time = max(temp_machine[op[1]], float(job_times[op[0]]))\n        temp_machine[op[1]] = start_time + float(op[2])\n        ent_val = entropy_vector(temp_machine)\n        score_tuple = (ent_val, -0.7 * (start_time + float(op[2])))\n        if score_tuple > best_tuple:\n            best_tuple = score_tuple\n            best_op    = op\n        idx += 1\n    return best_op\n\n",
  "entropy_balanced_machines_aug_233": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    ops    = []\n    rng    = np.random.default_rng(42)\n\n    for idx, op in enumerate(feasible_operations):\n        temp_machine = machine_status.copy()\n        start_time = max(temp_machine[op[1]], float(job_status[op[0]]))\n        temp_machine[op[1]] = start_time + float(op[2])\n\n        total = np.sum(temp_machine) + 1e-12\n        probs = temp_machine / total\n        probs = np.clip(probs, 1e-12, 1.0)\n\n        entropy_val = -np.mean(probs * np.log(probs))\n        noise = 1e-6 * idx\n        score = 0.8 * entropy_val - 0.2 * (start_time + float(op[2])) + noise\n\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores)\n    top_k = 3\n    if len(feasible_operations) <= top_k:\n        best_idx = np.argmax(scores)\n    else:\n        top_indices = np.argpartition(-scores, top_k)[:top_k]\n        best_idx = rng.choice(top_indices)\n\n    return ops[best_idx]\n\n",
  "entropy_balanced_machines_aug_234": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'], dtype=float)\n\n    best_op     = None\n    best_weight = -np.inf\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        temp_machine = machine_times.copy()\n        start_time = max(temp_machine[op[1]], float(job_times[op[0]]))\n        temp_machine[op[1]] = start_time + float(op[2])\n\n        total = np.sum(temp_machine) + 1e-12\n        probs = temp_machine / total\n        probs = np.clip(probs, 1e-12, 1.0)\n\n        entropy_val = -np.sum(probs * np.log(probs))\n        cost = start_time + float(op[2]) + 1e-6 * idx\n        weight = np.exp(entropy_val - 0.5 * cost)\n\n        if weight > best_weight:\n            best_weight = weight\n            best_op     = op\n        idx += 1\n\n    return best_op\n\n",
  "entropy_balanced_machines_aug_235": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status     = np.array(current_status['job_status'], dtype=float)\n    rng            = np.random.default_rng(123)\n\n    scores = []\n    ops    = []\n\n    for idx, op in enumerate(feasible_operations):\n        temp_machine = machine_status.copy()\n        start_time = max(temp_machine[op[1]], float(job_status[op[0]]))\n        temp_machine[op[1]] = start_time + float(op[2])\n\n        total = np.sum(temp_machine) + 1e-12\n        probs = temp_machine / total\n        probs = np.clip(probs, 1e-12, 1.0)\n\n        entropy_val = -np.mean(probs * np.log(probs))\n        cost = start_time + float(op[2])\n        noise = 1e-7 * idx\n        score = 0.6 * entropy_val - 0.4 * cost + noise\n\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores)\n    top_k = 5\n    if len(feasible_operations) <= top_k:\n        best_idx = np.argmax(scores)\n    else:\n        top_indices = np.argpartition(-scores, top_k)[:top_k]\n        best_idx = rng.choice(top_indices)\n\n    return ops[best_idx]\n\n",
  "entropy_balanced_jobs_aug_236": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'],   dtype=float)\n\n    def _entropy(t):\n        total = np.sum(t) + 1e-12          # avoid division by zero\n        probs = np.clip(t / total, 1e-12, 1.0)  # keep probabilities valid\n        return -np.sum(probs * np.log(probs))\n\n    best_op, best_val = None, -np.inf\n    for op in feasible_operations:\n        job, machine, dur = op\n        start = max(machine_times[machine], job_times[job])\n        new_job_times = job_times.copy()\n        new_job_times[job] = start + float(dur)\n\n        val = _entropy(new_job_times)\n        if val > best_val + 1e-12:\n            best_val, best_op = val, op\n        elif abs(val - best_val) < 1e-12:\n            # tie\u2011break: earlier completion time\n            new_finish = start + dur\n            best_start = max(machine_times[best_op[1]], job_times[best_op[0]])\n            best_finish = best_start + best_op[2]\n            if new_finish < best_finish:\n                best_op = op\n    return best_op\n\n",
  "entropy_balanced_jobs_aug_237": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'],   dtype=float)\n    eps = 1e-12\n\n    entropies = []\n    for op in feasible_operations:\n        job, machine, dur = op\n        start = max(machine_times[machine], job_times[job])\n        new_job_times = job_times.copy()\n        new_job_times[job] = start + float(dur)\n\n        total = np.sum(new_job_times) + eps\n        probs = np.clip(new_job_times / total, eps, 1.0)\n        entropies.append(-np.sum(probs * np.log(probs)))\n\n    entropies = np.array(entropies, dtype=float)\n\n    # Softmax weighting\n    max_e = np.max(entropies)\n    exp_vals = np.exp(entropies - max_e)\n    probs = exp_vals / (np.sum(exp_vals) + eps)\n\n    # Add deterministic noise to break ties\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    probs += noise\n    probs /= np.sum(probs) + eps\n\n    idx = np.argmax(probs)\n    return feasible_operations[idx]\n\n",
  "entropy_balanced_jobs_aug_238": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'],   dtype=float)\n    eps = 1e-12\n\n    def _entropy(t):\n        total = np.sum(t) + eps\n        probs = np.clip(t / total, eps, 1.0)\n        return -np.sum(probs * np.log(probs))\n\n    best_op, best_val = None, -np.inf\n    best_med = None\n    for op in feasible_operations:\n        job, machine, dur = op\n        start = max(machine_times[machine], job_times[job])\n        new_job_times = job_times.copy()\n        new_job_times[job] = start + float(dur)\n\n        val = _entropy(new_job_times)\n        med = np.median(new_job_times)\n\n        if val > best_val + 1e-12:\n            best_val, best_op, best_med = val, op, med\n        elif abs(val - best_val) < 1e-12:\n            # tie\u2011break using median of completion times\n            if med < best_med:\n                best_op, best_med = op, med\n    return best_op\n\n",
  "entropy_balanced_jobs_aug_239": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'],   dtype=float)\n    eps = 1e-12\n\n    def _max_prob(t):\n        total = np.sum(t) + eps\n        probs = np.clip(t / total, eps, 1.0)\n        return np.max(probs)\n\n    best_op, best_score = None, -np.inf\n    for idx, op in enumerate(feasible_operations):\n        job, machine, dur = op\n        start = max(machine_times[machine], job_times[job])\n        new_job_times = job_times.copy()\n        new_job_times[job] = start + float(dur)\n\n        score = _max_prob(new_job_times)\n        score += idx * 1e-6          # deterministic noise\n\n        if score > best_score + 1e-12:\n            best_score, best_op = score, op\n        elif abs(score - best_score) < 1e-12:\n            # tie\u2011break by earlier completion\n            new_finish = start + dur\n            best_start = max(machine_times[best_op[1]], job_times[best_op[0]])\n            best_finish = best_start + best_op[2]\n            if new_finish < best_finish:\n                best_op = op\n    return best_op\n\n",
  "median_machine_pull_aug_240": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Use the mean of machine loads as a reference point\n    ref = np.mean(ms)\n    eps = 1e-12\n\n    # Vectorise the operations list\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n\n    # Distance of each machine from the reference load\n    dist = np.abs(ms[m_idx] - ref)\n    dist = np.clip(dist, 0, np.inf)          # safeguard against negative values\n\n    # Earliest possible start time on each machine\n    start = np.maximum(ms[m_idx], js[j_idx])\n\n    # Weighted score with an epsilon\u2011protected denominator\n    score = (dist / (1.0 + eps)) + 0.5 * (start / (1.0 + eps))\n\n    # Choose the operation with the smallest score\n    min_idx = np.argmin(score)\n    return tuple(ops[min_idx])\n\n",
  "median_machine_pull_aug_241": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    eps = 1e-12\n    ref = np.mean(ms)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n\n    dist = np.abs(ms[m_idx] - ref)\n    start = np.maximum(ms[m_idx], js[j_idx])\n\n    # Deterministic tie\u2011breaking noise\n    noise = np.arange(len(ops)) * 1e-9\n    score = dist + start + noise\n\n    # Select the top\u2011k smallest scores and pick one at random\n    top_k = 7\n    if len(score) > top_k:\n        idxs = np.argpartition(score, top_k)[:top_k]\n    else:\n        idxs = np.arange(len(score))\n    chosen = np.random.choice(idxs)\n    return tuple(ops[chosen])\n\n",
  "median_machine_pull_aug_242": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    eps = 1e-12\n    ref = np.median(ms)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n\n    dist = np.abs(ms[m_idx] - ref)\n\n    # Use sum of machine and job times as the start metric\n    start = ms[m_idx] + js[j_idx]\n    start = np.clip(start, 0, 1e6)          # bound to avoid overflow\n\n    # Weighted aggregation with different coefficients\n    score = 0.6 * dist + 0.4 * (start / (1.0 + eps))\n\n    min_idx = np.argmin(score)\n    return tuple(ops[min_idx])\n\n",
  "median_machine_pull_aug_243": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:                     # inverted conditional\n        ms = np.array(current_status['machine_status'], dtype=float)\n        js = np.array(current_status['job_status'], dtype=float)\n\n        eps = 1e-12\n        ref = np.median(ms)\n\n        best_op = None\n        best_score = np.inf\n        noise = 0.0\n\n        for op in feasible_operations:\n            m = op[1]\n            dist = abs(ms[m] - ref)\n            start = np.maximum(ms[m], js[op[0]])  # use maximum start\n            score = dist + start + noise          # deterministic tie\u2011breaker\n\n            if score < best_score:\n                best_score = score\n                best_op = op\n\n            noise += 1e-9\n\n        return best_op\n    else:\n        return None\n\n",
  "quantile_machine_pull_25_aug_244": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q = np.percentile(ms, 25)\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = ops[:, 1].astype(int)\n\n    # Distances to the lower quartile load\n    dists = np.abs(ms[machine_ids] - q)\n\n    # Earliest feasible start times\n    starts = np.maximum(np.maximum(ms[machine_ids], js[ops[:, 0].astype(int)]), 1e-12)\n    starts = np.clip(starts, 0, np.inf)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.arange(len(ops)) * 1e-9\n\n    # Weighted score with a protected division\n    eps = 1e-12\n    scores = 0.6 * dists + 0.4 * starts + eps / (starts + eps) + noise\n\n    best_idx = np.argmin(scores)\n    return tuple(ops[best_idx])\n\n",
  "quantile_machine_pull_25_aug_245": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q = np.quantile(ms, 0.25)\n\n    ops = []\n    scores = []\n\n    for op in feasible_operations:\n        m = op[1]\n        dist = abs(ms[m] - q)\n        start = max(ms[m], js[op[0]])\n        start = max(start, 1e-12)\n        start = np.clip(start, 0, np.inf)\n        score = 0.5 * dist + 0.5 * start\n        ops.append(op)\n        scores.append(score)\n\n    scores = np.array(scores, dtype=float)\n    top_k = min(7, len(scores))\n    top_indices = np.argpartition(scores, top_k)[:top_k]\n\n    # Soft\u2011min probabilities with a tiny epsilon in the denominator\n    eps = 1e-12\n    temp = 1.0\n    probs = np.exp(-scores[top_indices] / (temp + eps))\n    probs /= probs.sum()\n\n    rng = np.random.default_rng()\n    chosen_idx = rng.choice(top_indices, p=probs)\n    return ops[chosen_idx]\n\n",
  "quantile_machine_pull_25_aug_246": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q = np.percentile(ms, 25)\n\n    best_score = np.inf\n    best_op = None\n    idx = 0\n    ops = list(feasible_operations)\n\n    eps = 1e-12\n    while idx < len(ops):\n        op = ops[idx]\n        m = op[1]\n        dist = abs(ms[m] - q)\n        start = max(ms[m], js[op[0]])\n        start = max(start, 1e-12)\n        start = np.clip(start, 0, np.inf)\n\n        # Aggregation with np.sum and a protected division\n        score = np.sum([dist, start]) + (dist / (start + eps))\n\n        if score < best_score:\n            best_score = score\n            best_op = op\n\n        idx += 1\n\n    return best_op\n\n",
  "quantile_machine_pull_25_aug_247": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    mean_load = np.mean(ms)\n\n    ops = []\n    scores = []\n\n    eps = 1e-12\n    for op in feasible_operations:\n        m = op[1]\n        dist = abs(ms[m] - mean_load)\n        start = max(ms[m], js[op[0]])\n        start = max(start, 1e-12)\n        start = np.clip(start, 0, np.inf)\n\n        # Weighted score with a protected division\n        score = 0.8 * dist + 0.2 * ((start + eps) / (mean_load + eps))\n        ops.append(op)\n        scores.append(score)\n\n    scores = np.array(scores, dtype=float)\n    top_k = min(3, len(scores))\n    top_indices = np.argpartition(scores, top_k)[:top_k]\n\n    rng = np.random.default_rng()\n    chosen = rng.choice(top_indices)\n    return ops[chosen]\n\n",
  "quantile_machine_pull_75_aug_248": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q = np.percentile(ms, 75)\n\n    # Convert the list of tuples to a structured NumPy array for vectorised ops\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n    o_idx = ops[:, 2].astype(int)\n\n    # Compute the distance to the 75th\u2011percentile load and earliest start time\n    dist   = np.abs(ms[m_idx] - q)\n    start  = np.maximum(ms[m_idx], js[j_idx])\n\n    # Small deterministic noise to break ties\n    rng    = np.random.default_rng(42)\n    noise  = rng.normal(scale=1e-8, size=dist.shape)\n\n    # Stack the criteria: dist, start, operation id, noise\n    key = np.stack((dist, start, o_idx, noise), axis=1)\n\n    # lexsort sorts by the last key first \u2192 use reverse order\n    idx = np.lexsort((key[:, 3], key[:, 2], key[:, 1], key[:, 0]))[0]\n    return feasible_operations[idx]\n\n",
  "quantile_machine_pull_75_aug_249": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q  = np.percentile(ms, 75)\n\n    rng = np.random.default_rng(123)\n\n    def score(op):\n        m = op[1]\n        dist  = abs(ms[m] - q)\n        start = max(ms[m], js[op[0]])\n        # Weighted sum with a tiny random perturbation for deterministic tie\u2011breaking\n        return 0.6 * dist + 0.4 * start + rng.uniform(-1e-8, 1e-8)\n\n    return min(feasible_operations, key=score)\n\n",
  "quantile_machine_pull_75_aug_250": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q  = np.percentile(ms, 75)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n    o_idx = ops[:, 2].astype(int)\n\n    dist  = np.abs(ms[m_idx] - q)\n    start = np.maximum(ms[m_idx], js[j_idx])\n\n    # Soft\u2011min scoring (negative exponential of weighted sum)\n    score = 0.6 * dist + 0.4 * start\n    rng   = np.random.default_rng(2024)\n    temp  = 0.05\n\n    exp_neg = np.exp(-score / (temp + 1e-12))\n    probs   = exp_neg / (np.sum(exp_neg) + 1e-12)   # epsilon to avoid div\u2011by\u2011zero\n\n    # Sample one operation according to the soft\u2011min distribution\n    chosen = rng.choice(len(ops), p=probs)\n    return feasible_operations[chosen]\n\n",
  "quantile_machine_pull_75_aug_251": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n    q  = np.median(ms)                     # use median instead of 75th percentile\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = ops[:, 1].astype(int)\n    j_idx = ops[:, 0].astype(int)\n    o_idx = ops[:, 2].astype(int)\n\n    dist  = np.abs(ms[m_idx] - q)\n    start = np.maximum(ms[m_idx], js[j_idx])\n\n    # Aggregate by simple sum of distance and start time\n    score = dist + start\n\n    rng   = np.random.default_rng(987)\n    top_k = 7\n    # Pick a random operation among the top_k lowest scores\n    top_idxs = np.argsort(score)[:top_k]\n    chosen = rng.choice(top_idxs)\n    return feasible_operations[chosen]\n\n",
  "min_idle_ratio_aug_252": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    # Extract columns for vectorised calculations\n    jobs     = np.fromiter((op[0] for op in feasible_operations), dtype=int)\n    machines = np.fromiter((op[1] for op in feasible_operations), dtype=int)\n    durations = np.fromiter((op[2] for op in feasible_operations), dtype=float)\n\n    # Compute idle time and ratio (with epsilon to avoid division by zero)\n    idle   = np.maximum(0.0, js[jobs] - ms[machines])\n    denom  = durations + 1.0 + 1e-12\n    ratio  = idle / denom\n    start  = np.maximum(ms[machines], js[jobs])\n\n    # Clip ratio to keep it within a reasonable range\n    ratio = np.clip(ratio, 0.0, 1.0)\n\n    # Deterministic tie\u2011breaking noise\n    noise  = np.arange(len(feasible_operations), dtype=float) * 1e-6\n    score  = ratio + noise\n\n    idx = np.argmin(score)\n    return feasible_operations[idx]\n\n",
  "min_idle_ratio_aug_253": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    jobs     = np.fromiter((op[0] for op in feasible_operations), dtype=int)\n    machines = np.fromiter((op[1] for op in feasible_operations), dtype=int)\n    durations = np.fromiter((op[2] for op in feasible_operations), dtype=float)\n\n    idle  = np.maximum(0.0, js[jobs] - ms[machines])\n    denom = durations + 1.0 + 1e-12\n    ratio = idle / denom\n    start = np.maximum(ms[machines], js[jobs])\n\n    # Weighted combination of ratio and start\n    score = 0.6 * ratio + 0.4 * start\n\n    # Top\u2011k deterministic choice (k = 3)\n    top_k = 3\n    if len(feasible_operations) <= top_k:\n        selected_idx = np.argmin(score)\n    else:\n        # Get indices of the k smallest scores\n        top_indices = np.argpartition(score, top_k - 1)[:top_k]\n        # Choose the median score among the top\u2011k\n        median_idx = sorted(top_indices, key=lambda i: score[i])[len(top_indices) // 2]\n        selected_idx = median_idx\n\n    return feasible_operations[selected_idx]\n\n",
  "min_idle_ratio_aug_254": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    jobs     = np.fromiter((op[0] for op in feasible_operations), dtype=int)\n    machines = np.fromiter((op[1] for op in feasible_operations), dtype=int)\n    durations = np.fromiter((op[2] for op in feasible_operations), dtype=float)\n\n    idle   = np.maximum(0.0, js[jobs] - ms[machines])\n    denom  = durations + 1.0 + 1e-12\n    ratio  = idle / denom\n    start  = np.maximum(ms[machines], js[jobs])\n\n    # Simple composite score\n    score = ratio + start / 10.0\n    # Softmin with temperature\n    temp   = 0.5\n    probs  = np.exp(-score / temp)\n    probs  = probs / probs.sum()\n\n    selected_idx = int(np.argmax(probs))\n    return feasible_operations[selected_idx]\n\n",
  "min_idle_ratio_aug_255": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    jobs     = np.fromiter((op[0] for op in feasible_operations), dtype=int)\n    machines = np.fromiter((op[1] for op in feasible_operations), dtype=int)\n    durations = np.fromiter((op[2] for op in feasible_operations), dtype=float)\n\n    idle   = np.maximum(0.0, js[jobs] - ms[machines])\n    denom  = durations + 1.0 + 1e-12\n    ratio  = idle / denom\n    start  = np.maximum(ms[machines], js[jobs])\n\n    # Composite metric that prefers higher ratio but lower start\n    composite = ratio - 0.01 * start\n    composite = np.clip(composite, 0.0, 1.0)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-7\n    composite += noise\n\n    idx = np.argmax(composite)\n    return feasible_operations[idx]\n\n",
  "max_idle_ratio_aug_256": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if len(feasible_operations) == 0:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times     = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    for op in feasible_operations:\n        idle  = np.clip(job_times[op[0]] - machine_times[op[1]], 0, None)\n        ratio = idle / (float(op[2]) + 1.0 + 1e-12)          # epsilon added\n        start = max(machine_times[op[1]], job_times[op[0]])\n        scores.append((-ratio, op[2], start))\n\n    # lexicographic minimum using numpy\n    scores_arr = np.array(scores, dtype=object)\n    idx = np.lexsort((scores_arr[:, 2], scores_arr[:, 1], scores_arr[:, 0]))[0]\n    return feasible_operations[idx]\n\n",
  "max_idle_ratio_aug_257": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = np.array(current_status['machine_status'], dtype=float)\n    job     = np.array(current_status['job_status'], dtype=float)\n\n    scored_ops = []\n    for op in feasible_operations:\n        idle  = np.clip(job[op[0]] - machine[op[1]], 0, None)\n        # Tuned denominator (0.5 instead of 1.0) and small noise for tie\u2011breaking\n        ratio = idle / (float(op[2]) + 0.5 + 1e-12)\n        noise = np.random.uniform(0, 1e-6)\n        scored_ops.append(( -ratio + noise, op))\n\n    # Pick one of the top\u20113 best candidates\n    top_k = min(3, len(scored_ops))\n    top_idx = np.argsort([s[0] for s in scored_ops])[:top_k]\n    chosen = np.random.choice(top_idx)\n    return scored_ops[chosen][1]\n\n",
  "max_idle_ratio_aug_258": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine = np.array(current_status['machine_status'], dtype=float)\n    job     = np.array(current_status['job_status'], dtype=float)\n\n    # List\u2011comprehension to build the score tuples\n    scores = np.array(\n        [\n            (\n                -np.clip(job[op[0]] - machine[op[1]], 0, None) /\n                (float(op[2]) + 1.0 + 1e-12),\n                op[2],\n                np.max([machine[op[1]], job[op[0]]])          # np.max used\n            )\n            for op in feasible_operations\n        ],\n        dtype=object\n    )\n\n    # Choose the lexicographically smallest tuple\n    idx = np.lexsort((scores[:, 2], scores[:, 1], scores[:, 0]))[0]\n    return feasible_operations[idx]\n\n",
  "local_best_in_machine_competition_aug_259": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_state = current_status['machine_status']\n    job_state   = current_status['job_status']\n\n    # Vectorised completion time calculation\n    comp_times = np.array([max(machine_state[op[1]], job_state[op[0]]) + op[2]\n                           for op in feasible_operations])\n\n    # Group operations by machine\n    by_machine = {}\n    for idx, op in enumerate(feasible_operations):\n        m = op[1]\n        by_machine.setdefault(m, []).append((comp_times[idx], op, idx))\n\n    # Build regret list\n    reps = []\n    for m, lst in by_machine.items():\n        lst.sort(key=lambda x: x[0])                     # best first\n        best_comp, best_op, best_idx = lst[0]\n        second_comp = lst[1][0] if len(lst) > 1 else best_comp + 1e9\n        regret = float(second_comp - best_comp)\n        regret = np.clip(regret, 0, 1e9)                 # bound the value\n        # deterministic noise for tie\u2011breaking\n        noise = 1e-6 * best_idx\n        reps.append((regret + noise, best_comp, best_op))\n\n    reps.sort(key=lambda t: (-t[0], t[1]))               # max regret, then earliest completion\n    return reps[0][2]\n\n",
  "local_best_in_machine_competition_aug_260": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_state = current_status['machine_status']\n    job_state     = current_status['job_status']\n\n    # Completion times\n    comp_times = np.array([max(machine_state[op[1]], job_state[op[0]]) + op[2]\n                           for op in feasible_operations])\n\n    by_machine = {}\n    for idx, op in enumerate(feasible_operations):\n        m = op[1]\n        by_machine.setdefault(m, []).append((comp_times[idx], op))\n\n    # Regret per machine\n    reps = []\n    for m, lst in by_machine.items():\n        lst.sort(key=lambda x: x[0])\n        best_comp, best_op = lst[0]\n        second_comp = lst[1][0] if len(lst) > 1 else best_comp + 1e9\n        regret = float(second_comp - best_comp)\n        reps.append((regret, best_op))\n\n    # Keep only the top\u2011k machines\n    top_k = 3\n    reps = sorted(reps, key=lambda t: -t[0])[:top_k]\n\n    # Soft\u2011min weighting\n    exp_vals = np.exp(np.clip(-np.array([t[0] for t in reps]), -700, 0))\n    exp_vals = np.clip(exp_vals, 1e-12, None)           # avoid division by zero\n    weights   = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Deterministic selection: weighted index rounded\n    idx = int(np.round(np.sum(weights * np.arange(len(reps))))) % len(reps)\n    return reps[idx][1]\n\n",
  "local_best_in_machine_competition_aug_261": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_state = current_status['machine_status']\n    j_state = current_status['job_status']\n\n    # Compute completion times\n    comps = np.array([max(m_state[op[1]], j_state[op[0]]) + op[2]\n                      for op in feasible_operations])\n\n    # Group by machine\n    by_m = {}\n    for idx, op in enumerate(feasible_operations):\n        by_m.setdefault(op[1], []).append((comps[idx], op, idx))\n\n    reps = []\n    for m, lst in by_m.items():\n        times = np.array([t[0] for t in lst])\n        if len(times) == 1:\n            best_idx = 0\n            second = times[0] + 1e9\n        else:\n            best_idx = np.argmin(times)\n            second = np.partition(times, 1)[1]\n        best_comp, best_op, best_idx = lst[best_idx]\n        regret = float(second - best_comp)\n        regret = np.clip(regret, 0, 1e9)\n\n        # Deterministic \u201crandom\u201d choice among top\u2011k\n        reps.append((regret, best_op, best_idx))\n\n    # Take the top\u2011k regrets\n    top_k = 5\n    reps.sort(key=lambda t: -t[0])\n    top = reps[:top_k]\n\n    # Deterministic selector: sum of indices modulo length\n    selector = sum([t[2] for t in top]) % len(top)\n    return top[selector][1]\n\n",
  "local_best_in_machine_competition_aug_262": "import numpy as np\nfrom collections import defaultdict\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        machine_status = current_status['machine_status']\n        job_status     = current_status['job_status']\n\n        by_machine = defaultdict(list)\n        idx = 0\n        while idx < len(feasible_operations):\n            op = feasible_operations[idx]\n            m = op[1]\n            start = machine_status[m] if machine_status[m] > job_status[op[0]] else job_status[op[0]]\n            comp  = start + op[2]\n            by_machine[m].append((comp, op, idx))\n            idx += 1\n\n        reps = []\n        for m, lst in by_machine.items():\n            comps = np.array([t[0] for t in lst])\n            sorted_idx = np.argsort(comps)\n            best = lst[sorted_idx[0]]\n            second = comps[sorted_idx[1]] if len(lst) > 1 else best[0] + 1e9\n            regret = float(second - best[0])\n            regret = np.clip(regret, 0, 1e9)\n            reps.append((regret, best[1]))\n\n        # Probability proportional to regret\n        total_regret = np.sum([r[0] for r in reps]) + 1e-12\n        probs = np.array([r[0] for r in reps]) / total_regret\n        probs = np.clip(probs, 1e-12, None)\n\n        # Deterministic weighted index\n        weighted = np.sum(probs * np.arange(len(reps))) % len(reps)\n        return reps[int(weighted)][1]\n    else:\n        return None\n\n",
  "completion_time_gap_to_best_aug_263": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # rename status dictionaries for clarity\n    machine_times = current_status['machine_status']\n    job_times    = current_status['job_status']\n\n    # convert operation list to structured numpy arrays for vectorised ops\n    jobs   = np.array([op[0] for op in feasible_operations], dtype=int)\n    machines = np.array([op[1] for op in feasible_operations], dtype=int)\n    durations = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # fetch current completion times for each operation\n    m_t = np.take(machine_times, machines)\n    j_t = np.take(job_times, jobs)\n\n    # completion time for each feasible operation\n    comp_times = np.maximum(m_t, j_t) + durations\n\n    # best (minimal) completion time\n    best_comp = np.min(comp_times)\n\n    # gaps relative to the best completion time\n    gaps = comp_times - best_comp\n\n    # identify the largest gap (within a tiny tolerance)\n    max_gap = np.max(gaps)\n    eps = 1e-12\n    candidate_mask = np.abs(gaps - max_gap) < eps\n\n    # candidate operations\n    candidates = [feasible_operations[i] for i, ok in enumerate(candidate_mask) if ok]\n\n    # tie\u2011break: earliest possible start time among the worst\u2011gap set\n    start_times = np.maximum(m_t, j_t)\n    earliest_start = np.min(start_times[candidate_mask])\n    chosen = min(\n        candidates,\n        key=lambda op: np.maximum(\n            machine_times[op[1]],\n            job_times[op[0]]\n        )\n    )\n    return chosen\n\n",
  "completion_time_gap_to_best_aug_264": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = current_status['machine_status']\n    j_stat = current_status['job_status']\n\n    # vectorised extraction of operation data\n    ops = np.array(feasible_operations, dtype=object)\n    jobs   = ops[:, 0].astype(int)\n    machines = ops[:, 1].astype(int)\n    durations = ops[:, 2].astype(float)\n\n    m_times = np.take(m_stat, machines)\n    j_times = np.take(j_stat, jobs)\n\n    # compute completion times\n    comp_times = np.maximum(m_times, j_times) + durations\n\n    # weighted score: completion time + 0.4 * (gap from best)\n    best_comp = np.min(comp_times)\n    gaps = comp_times - best_comp\n    scores = comp_times + 0.4 * gaps\n\n    # pick top\u2011k operations (k = 3) and deterministically choose the one with the smallest index\n    k = 3\n    top_k_idx = np.argsort(scores)[:k]\n    top_k_ops = ops[top_k_idx]\n\n    # deterministic tie\u2011breaker: smallest job index, then machine index\n    chosen = sorted(\n        top_k_ops.tolist(),\n        key=lambda op: (op[0], op[1])\n    )[0]\n    return chosen\n\n",
  "completion_time_gap_to_best_aug_265": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n    j_ids = ops[:, 0].astype(int)\n    m_ids = ops[:, 1].astype(int)\n    durs   = ops[:, 2].astype(float)\n\n    m_t = np.take(ms, m_ids)\n    j_t = np.take(js, j_ids)\n\n    comp = np.maximum(m_t, j_t) + durs\n\n    # use median instead of minimum for the reference completion time\n    ref = np.median(comp)\n\n    gaps = comp - ref\n\n    # add tiny deterministic noise to break ties\n    noise = 1e-6 * np.arange(len(gaps))\n    noisy_gaps = gaps + noise\n\n    # choose operation with the maximum noisy gap\n    best_idx = np.argmax(noisy_gaps)\n\n    # tie\u2011break by earliest start time if multiple candidates share the same noisy gap\n    start_times = np.maximum(m_t, j_t)\n    best_start = np.min(start_times[best_idx:best_idx+1])\n\n    return tuple(ops[best_idx])\n\n",
  "min_completion_time_gap_to_best_aug_266": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)          # keep tuples\n\n    machine_idx = ops[:, 1]\n    job_idx     = ops[:, 0]\n    durations   = ops[:, 2]\n\n    start_times = np.maximum(ms[machine_idx], js[job_idx])\n    comps       = start_times + durations\n\n    best   = np.min(comps)\n    gaps   = comps - best\n    min_gap = np.min(gaps)\n\n    # Find all operations whose gap is within a tiny tolerance of the minimum\n    tol    = 1e-12\n    mask   = np.abs(gaps - min_gap) <= tol\n    cand_ops = ops[mask]\n\n    # Deterministic noise to break ties: order\u2011dependent tiny offset\n    noise = np.arange(cand_ops.shape[0]) * 1e-15\n    machine_loads = ms[cand_ops[:, 1]]\n    scores = machine_loads + cand_ops[:, 2] + noise\n\n    idx = np.argmin(scores)\n    return tuple(cand_ops[idx].item())\n\n",
  "min_completion_time_gap_to_best_aug_267": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_idx = ops[:, 1]\n    job_idx     = ops[:, 0]\n    durations   = ops[:, 2]\n\n    start_times = np.maximum(ms[machine_idx], js[job_idx])\n    comps       = start_times + durations\n\n    # Softmin: lower completion times receive higher weight\n    temp   = 0.5\n    weights = np.exp(-comps / (temp + 1e-12))\n    weights /= np.sum(weights) + 1e-12\n\n    idx = np.argmax(weights)\n    return tuple(ops[idx].item())\n\n",
  "min_completion_time_gap_to_best_aug_268": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_idx = ops[:, 1]\n    job_idx     = ops[:, 0]\n    durations   = ops[:, 2]\n\n    start_times = np.maximum(ms[machine_idx], js[job_idx])\n    comps       = start_times + durations\n\n    gaps = comps - np.min(comps)\n\n    top_k = 3\n    sorted_idx = np.argsort(gaps)\n    top_indices = sorted_idx[:top_k]\n\n    # Deterministic tie\u2011break: smallest machine load among the top\u2011k\n    selected_idx = top_indices[0]\n    min_load = ms[ops[top_indices[0], 1]]\n    for idx in top_indices:\n        if ms[ops[idx, 1]] < min_load:\n            selected_idx = idx\n            min_load = ms[ops[idx, 1]]\n\n    return tuple(ops[selected_idx].item())\n\n",
  "min_completion_time_gap_to_best_aug_269": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n    ops = np.array(feasible_operations, dtype=object)\n\n    machine_idx = ops[:, 1]\n    job_idx     = ops[:, 0]\n    durations   = ops[:, 2]\n\n    # Weighted estimate of the start time\n    w_machine = 0.6\n    w_job     = 0.4\n    est_start = w_machine * ms[machine_idx] + w_job * js[job_idx]\n    est_comp  = est_start + durations\n\n    idx = np.argmin(est_comp)\n    return tuple(ops[idx].item())\n\n",
  "min_squared_load_after_machine_aug_270": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Convert to numpy arrays for vectorised computation\n    ops = np.array(feasible_operations, dtype=float)          # shape (n, 3)\n    ms0 = np.array(current_status['machine_status'], dtype=float)  # shape (m,)\n    js  = np.array(current_status['job_status'], dtype=float)      # shape (n_jobs,)\n\n    # Start times: maximum of machine availability and job ready time\n    start = np.maximum(ms0[ops[:, 1].astype(int)], js[ops[:, 0].astype(int)])\n    start = np.clip(start, 0.0, None)                         # avoid negative times\n\n    # Updated machine times after each candidate operation\n    ms_new = np.tile(ms0, (ops.shape[0], 1))                  # shape (n, m)\n    ms_new[np.arange(ops.shape[0]), ops[:, 1].astype(int)] = start + ops[:, 2]\n\n    # Sum of squared machine times for each candidate\n    score = np.sum(np.square(ms_new), axis=1)\n\n    # Deterministic noise to break ties\n    noise = 1e-6 * np.arange(ops.shape[0])\n    score += noise\n\n    # Choose the best operation\n    best_idx = int(np.argmin(score))\n    return tuple(feasible_operations[best_idx])\n\n",
  "min_squared_load_after_machine_aug_271": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=float)\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    start = np.maximum(ms0[ops[:, 1].astype(int)], js[ops[:, 0].astype(int)])\n    start = np.clip(start, 0.0, None)\n\n    ms_new = np.tile(ms0, (ops.shape[0], 1))\n    ms_new[np.arange(ops.shape[0]), ops[:, 1].astype(int)] = start + ops[:, 2]\n\n    sum_sq = np.sum(np.square(ms_new), axis=1)\n    bias = 0.4 * start + 0.6 * ops[:, 2]\n    score = sum_sq + bias\n\n    # Pick a random operation among the best top_k candidates\n    top_k = min(7, ops.shape[0])\n    top_indices = np.argsort(score)[:top_k]\n    chosen_idx = int(np.random.choice(top_indices))\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "min_squared_load_after_machine_aug_272": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=float)\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    start = np.maximum(ms0[ops[:, 1].astype(int)], js[ops[:, 0].astype(int)])\n    start = np.clip(start, 0.0, None)\n\n    ms_new = np.tile(ms0, (ops.shape[0], 1))\n    ms_new[np.arange(ops.shape[0]), ops[:, 1].astype(int)] = start + ops[:, 2]\n\n    # Use the maximum squared machine time as the score\n    score = np.max(np.square(ms_new), axis=1)\n\n    # Deterministic noise to avoid exact ties\n    noise = 1e-7 * np.arange(ops.shape[0])\n    score += noise\n\n    # Randomly pick among the best five\n    top_k = min(5, ops.shape[0])\n    top_indices = np.argsort(score)[:top_k]\n    chosen_idx = int(np.random.choice(top_indices))\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "min_squared_load_after_machine_aug_273": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ops = np.array(feasible_operations, dtype=float)\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    start = np.maximum(ms0[ops[:, 1].astype(int)], js[ops[:, 0].astype(int)])\n    start = np.clip(start, 0.0, None)\n\n    ms_new = np.tile(ms0, (ops.shape[0], 1))\n    ms_new[np.arange(ops.shape[0]), ops[:, 1].astype(int)] = start + ops[:, 2]\n\n    # Proxy score: sum of machine times (linear instead of squared)\n    score = np.sum(ms_new, axis=1)\n\n    # Soft\u2011min probabilities\n    exp_neg = np.exp(-score)\n    denom   = np.sum(exp_neg) + 1e-12          # epsilon to prevent division by zero\n    probs   = exp_neg / denom\n\n    chosen_idx = int(np.random.choice(ops.shape[0], p=probs))\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "min_squared_load_after_job_aug_274": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = np.array(current_status['machine_status'], dtype=float)\n    job_stat0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op = None\n    best_key = None\n    noise = 1e-6 * np.arange(len(feasible_operations))\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        job_idx, mach_idx, dur = op\n\n        start = max(mach_stat[mach_idx], job_stat0[job_idx])\n        job_stat = job_stat0.copy()\n        job_stat[job_idx] = start + dur\n\n        # Sum of squares of job completion times\n        val = np.sum(np.square(job_stat)) + 1e-12\n        key = (val, start + dur, dur, noise[idx])\n\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n\n        idx += 1\n\n    return best_op\n\n",
  "min_squared_load_after_job_aug_275": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = np.array(current_status['machine_status'], dtype=float)\n    job_stat0 = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    ops = []\n\n    for op in feasible_operations:\n        job_idx, mach_idx, dur = op\n        start = max(mach_stat[mach_idx], job_stat0[job_idx])\n        job_stat = job_stat0.copy()\n        job_stat[job_idx] = start + dur\n\n        job_score = np.sum(job_stat)\n        # Weighted combination of job completion sum and makespan\n        w_score = 0.6 * job_score + 0.4 * (start + dur)\n        scores.append(w_score)\n        ops.append(op)\n\n    scores = np.array(scores)\n\n    top_k = 3\n    if len(scores) <= top_k:\n        candidates = np.arange(len(scores))\n    else:\n        candidates = np.argpartition(-scores, top_k - 1)[:top_k]\n\n    # Soft\u2011min probabilities over the selected candidates\n    probs = np.exp(-scores[candidates])\n    probs = probs / (np.sum(probs) + 1e-12)\n\n    chosen_idx = np.random.choice(candidates, p=probs)\n    return ops[chosen_idx]\n\n",
  "min_squared_load_after_job_aug_276": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = np.array(current_status['machine_status'], dtype=float)\n    job_stat0 = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    ops = []\n\n    for op in feasible_operations:\n        job_idx, mach_idx, dur = op\n        start = np.clip(max(mach_stat[mach_idx], job_stat0[job_idx]), 0, None)\n        job_stat = job_stat0.copy()\n        job_stat[job_idx] = start + dur\n\n        # Sum of squares of job completion times\n        score = np.sum(np.square(job_stat)) + 1e-12\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores)\n\n    # Compute soft\u2011min probabilities\n    min_score = np.min(scores)\n    exp_vals = np.exp(-(scores - min_score))\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    chosen_idx = np.random.choice(len(ops), p=probs)\n    return ops[chosen_idx]\n\n",
  "min_squared_load_after_job_aug_277": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_stat = np.array(current_status['machine_status'], dtype=float)\n    job_stat0 = np.array(current_status['job_status'], dtype=float)\n\n    best_op = None\n    best_key = None\n    noise = 1e-6 * np.arange(len(feasible_operations))\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        job_idx, mach_idx, dur = op\n\n        start = np.clip(max(mach_stat[mach_idx], job_stat0[job_idx]), 0, None)\n        job_stat = job_stat0.copy()\n        job_stat[job_idx] = start + dur\n\n        # Proxy: median(job_stat)^2 * number of jobs\n        proxy_val = (np.median(job_stat) ** 2) * len(job_stat) + 1e-12\n        key = (proxy_val, start + dur, dur, noise[idx])\n\n        if best_key is None or key < best_key:\n            best_key = key\n            best_op = op\n\n        idx += 1\n\n    return best_op\n\n",
  "inverse_temperature_rank_blend_aug_278": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Start times and processing times\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    procs = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Rank: 0 is best\n    r_start = np.argsort(np.argsort(starts))\n    r_proc  = np.argsort(np.argsort(procs))\n\n    # Imbalance and temperature\n    imb = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    temp = 1.0 / (1.0 + 3.0 * min(1.0, imb))\n    temp = np.clip(temp, 0.0, 1.0)\n\n    # Deterministic tie\u2011breaking noise\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    score = temp * r_proc + (1.0 - temp) * r_start + noise\n\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "inverse_temperature_rank_blend_aug_279": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    procs  = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    r_start = np.argsort(np.argsort(starts))\n    r_proc  = np.argsort(np.argsort(procs))\n\n    imb = float((ms.max() - ms.min()) / (ms.mean() + 1e-12))\n    temp = 1.0 / (1.0 + 3.0 * min(1.0, imb))\n    temp = np.clip(temp, 1e-6, 1.0)\n\n    # Weighted score with different weights\n    w_start, w_proc = 0.4, 0.6\n    raw = w_start * r_start + w_proc * r_proc\n\n    # Softmin probabilities\n    exp_vals = np.exp(-raw / (temp + 1e-12))\n    probs    = exp_vals / exp_vals.sum()\n\n    idx = int(np.random.choice(len(feasible_operations), p=probs))\n    return feasible_operations[idx]\n\n",
  "inverse_temperature_rank_blend_aug_280": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    procs  = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Deterministic tie\u2011breaking\n    starts += np.arange(len(starts)) * 1e-9\n    procs  += np.arange(len(procs))  * 1e-9\n\n    combined = starts + procs\n    r_comb = np.argsort(np.argsort(combined))\n\n    imb = abs(float(np.median(ms) - np.median(js))) / (np.median(ms) + 1e-12)\n    temp = 1.0 / (1.0 + 3.0 * min(1.0, imb))\n    temp = np.clip(temp, 0.0, 1.0)\n\n    score = temp * r_comb\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "inverse_temperature_rank_blend_aug_281": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    procs  = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    r_start = np.argsort(np.argsort(starts))\n    r_proc  = np.argsort(np.argsort(procs))\n\n    imb = float((ms.sum() - js.sum()) / (ms.mean() + 1e-12))\n    temp = 1.0 / (1.0 + 3.0 * min(1.0, imb))\n    temp = np.clip(temp, 0.0, 1.0)\n\n    score = temp * r_proc + (1.0 - temp) * r_start\n\n    top_k = 5\n    if len(score) < top_k:\n        top_k = len(score)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    probs = np.exp(-score[top_indices] / (temp + 1e-12))\n    probs = probs / probs.sum()\n\n    chosen = int(np.random.choice(top_indices, p=probs))\n    return feasible_operations[chosen]\n\n",
  "deterministic_hash_round_robin_jobs_aug_282": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int((np.sum(ms) + 31 * np.sum(js)) & 0x7fffffff)\n\n    # group by job using dictionary comprehension\n    by_job = {j: [op for op in feasible_operations if op[0] == j]\n              for j in {op[0] for op in feasible_operations}}\n    jobs = sorted(by_job.keys())\n    if not jobs:\n        return feasible_operations[0]\n\n    start_idx = int(np.clip(seed % len(jobs), 0, len(jobs) - 1))\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    idx = start_idx\n    count = 0\n    while count < len(jobs):\n        j = jobs[idx]\n        ops = by_job[j]\n        # compute completion times and add tiny deterministic noise for tie-breaking\n        comp = [max(ms_f[op[1]], js_f[op[0]]) + op[2] + 1e-9 * (i & 1) for i, op in enumerate(ops)]\n        best_op = ops[int(np.argmin(comp))]\n        return best_op\n        idx = (idx + 1) % len(jobs)\n        count += 1\n\n    return feasible_operations[0]\n\n",
  "deterministic_hash_round_robin_jobs_aug_283": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int((np.sum(ms) + 31 * np.sum(js)) & 0x7fffffff)\n    rng = np.random.default_rng(seed)\n\n    # group by job\n    by_job = {}\n    for op in feasible_operations:\n        by_job.setdefault(op[0], []).append(op)\n\n    jobs = sorted(by_job.keys())\n    if not jobs:\n        return feasible_operations[0]\n\n    start_idx = int(np.clip(seed % len(jobs), 0, len(jobs) - 1))\n\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    # weights for scoring\n    w_completion = 0.6\n    w_processing = 0.4\n\n    # compute scores for all operations\n    scores = []\n    for op in feasible_operations:\n        completion = max(ms_f[op[1]], js_f[op[0]]) + op[2]\n        score = w_completion * completion + w_processing * op[2]\n        scores.append(score)\n\n    scores = np.array(scores, dtype=float)\n\n    # select top_k operations\n    top_k = min(7, len(feasible_operations))\n    top_indices = np.argpartition(scores, -top_k)[-top_k:]\n    # deterministic random choice among top_k\n    chosen_idx = rng.choice(top_indices)\n    return feasible_operations[chosen_idx]\n\n",
  "deterministic_hash_round_robin_jobs_aug_284": "import numpy as np\nfrom collections import defaultdict\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int((np.sum(ms) + 31 * np.sum(js)) & 0x7fffffff)\n\n    by_job = defaultdict(list)\n    for op in feasible_operations:\n        by_job[op[0]].append(op)\n\n    jobs = sorted(by_job.keys())\n    if not jobs:\n        return feasible_operations[0]\n\n    start_idx = int(np.clip(seed % len(jobs), 0, len(jobs) - 1))\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    # compute scores for all ops\n    scores = []\n    for op in feasible_operations:\n        completion = max(ms_f[op[1]], js_f[op[0]]) + op[2]\n        # deterministic small noise\n        noise = 1e-9 * ((op[0] + op[1]) % 2)\n        scores.append(completion + noise)\n\n    scores = np.array(scores, dtype=float)\n    alpha = 15.0\n    exp_vals = np.exp(-alpha * scores + 1e-12)  # avoid overflow\n    weights = exp_vals / (np.sum(exp_vals) + 1e-12)  # epsilon in denominator\n\n    # choose argmax of weights (deterministic)\n    chosen_idx = int(np.argmax(weights))\n    return feasible_operations[chosen_idx]\n\n",
  "deterministic_hash_round_robin_jobs_aug_285": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n    seed = int((np.sum(ms) + 31 * np.sum(js)) & 0x7fffffff)\n\n    # group by job using list comprehension\n    by_job = {j: [op for op in feasible_operations if op[0] == j]\n              for j in {op[0] for op in feasible_operations}}\n    jobs = sorted(by_job.keys())\n    if not jobs:\n        return feasible_operations[0]\n\n    start_idx = int(np.clip(seed % len(jobs), 0, len(jobs) - 1))\n    ms_f = current_status['machine_status']\n    js_f = current_status['job_status']\n\n    # compute median\u2011based score for each operation\n    scores = []\n    for op in feasible_operations:\n        times = np.array([ms_f[op[1]], js_f[op[0]]], dtype=float)\n        median_time = np.median(times)\n        score = median_time + op[2] + 1e-9 * ((op[0] + op[1]) % 2)\n        scores.append(score)\n\n    scores = np.array(scores, dtype=float)\n    top_k = min(5, len(feasible_operations))\n    top_indices = np.argpartition(scores, top_k)[:top_k]\n    # deterministic selection: pick smallest score among top_k\n    local_min_idx = int(np.argmin(scores[top_indices]))\n    chosen_idx = top_indices[local_min_idx]\n    return feasible_operations[chosen_idx]\n\n",
  "deterministic_hash_round_robin_machines_aug_286": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n\n    # Deterministic seed based on machine and job sums\n    seed_val = int(19 * ms.sum() + 13 * js.sum()) & 0x7fffffff\n    seed_val = np.clip(seed_val, 0, 2**31 - 1)\n\n    # Group operations by machine\n    ops_by_m = {}\n    for op in feasible_operations:\n        ops_by_m.setdefault(op[1], []).append(op)\n\n    machines = sorted(ops_by_m.keys())\n    start_idx = seed_val % len(machines)\n\n    # Iterate machines in deterministic round\u2011robin order\n    for i in range(len(machines)):\n        m = machines[(start_idx + i) % len(machines)]\n        ops = ops_by_m[m]\n        best_op = min(\n            ops,\n            key=lambda op: (\n                max(ms[op[1]], js[op[0]]),   # earliest start\n                -op[2],                      # longest processing\n                1e-6 * op[0]                 # deterministic noise\n            ),\n        )\n        return best_op\n\n",
  "deterministic_hash_round_robin_machines_aug_287": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n\n    # Group operations by machine\n    ops_by_m = {}\n    for op in feasible_operations:\n        ops_by_m.setdefault(op[1], []).append(op)\n\n    machines = sorted(ops_by_m.keys())\n    idx = 0\n    all_candidates = []\n\n    while idx < len(machines):\n        m = machines[idx]\n        ops = ops_by_m[m]\n        job_ids = np.array([op[0] for op in ops], dtype=int)\n        proc = np.array([op[2] for op in ops], dtype=float)\n        est = np.maximum(ms[m], js[job_ids])\n\n        # weighted score: earlier start, longer processing\n        scores = 0.6 * est - 0.4 * proc\n\n        # top\u2011k candidates per machine\n        top_k = min(3, len(scores))\n        top_indices = np.argpartition(scores, top_k - 1)[:top_k]\n        for ti in top_indices:\n            all_candidates.append((scores[ti], ops[ti]))\n\n        idx += 1\n\n    if not all_candidates:\n        return feasible_operations[0]\n\n    # Sort all candidates by score and pick the best three\n    all_candidates.sort(key=lambda x: x[0])\n    best_ops = [op for _, op in all_candidates[:3]]\n\n    # Random choice among the top candidates\n    return np.random.choice(best_ops)\n\n",
  "deterministic_hash_round_robin_machines_aug_288": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=int)\n    js = np.array(current_status['job_status'], dtype=int)\n\n    # Group operations by machine\n    ops_by_m = {}\n    for op in feasible_operations:\n        ops_by_m.setdefault(op[1], []).append(op)\n\n    # Compute median start time for each machine\n    medians = {}\n    for m, ops in ops_by_m.items():\n        job_ids = np.array([op[0] for op in ops], dtype=int)\n        est = np.maximum(ms[m], js[job_ids])\n        medians[m] = np.median(est)\n\n    # Machine with the smallest median start time\n    best_machine = min(medians, key=lambda m: medians[m])\n\n    # Within that machine, pick the operation with the longest processing time\n    ops = ops_by_m[best_machine]\n    best_op = max(\n        ops,\n        key=lambda op: (\n            op[2],                      # longest processing\n            -max(ms[op[1]], js[op[0]])  # earlier start if tie\n        ),\n    )\n    return best_op\n\n",
  "anti_starvation_oldest_job_aug_289": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    js = current_status['job_status']\n    ms = current_status['machine_status']\n\n    # vectorise job times and clip to avoid extreme values\n    job_times = np.clip(np.array([js[op[0]] for op in feasible_operations], dtype=float), 0, 1e9)\n\n    # find minimal job progress\n    min_time = np.min(job_times)\n\n    # collect candidates that share the minimal progress\n    candidates = [op for op, jt in zip(feasible_operations, job_times) if jt == min_time]\n\n    # compute earliest start times for these candidates\n    start_times = np.array([max(ms[op[1]], js[op[0]]) for op in candidates], dtype=float)\n\n    # deterministic tie\u2011breaking noise (increasing order)\n    noise = np.arange(len(candidates)) * 1e-8\n\n    # pick candidate with smallest adjusted start time\n    idx = np.argmin(start_times + noise)\n    return candidates[idx]\n\n",
  "anti_starvation_oldest_job_aug_290": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    js = current_status['job_status']\n    ms = current_status['machine_status']\n\n    # job progress as a plain Python list\n    job_progress = [js[op[0]] for op in feasible_operations]\n\n    # find minimum progress using a while loop\n    min_jtime = job_progress[0]\n    i = 1\n    while i < len(job_progress):\n        if job_progress[i] < min_jtime:\n            min_jtime = job_progress[i]\n        i += 1\n\n    # gather candidates with the minimal progress\n    candidates = []\n    i = 0\n    while i < len(feasible_operations):\n        if abs(job_progress[i] - min_jtime) < 1e-12:\n            candidates.append(feasible_operations[i])\n        i += 1\n\n    # weighted score: 0.6 * earliest start + 0.4 * operation index\n    scores = []\n    for op in candidates:\n        est = max(ms[op[1]], js[op[0]]) + 1e-12   # epsilon\n        scores.append(0.6 * est + 0.4 * op[2])\n\n    scores = np.array(scores, dtype=float)\n\n    # soft\u2011min probability distribution\n    exp_vals = np.exp(-scores)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # deterministic pick: highest probability (argmax)\n    idx = np.argmax(probs)\n    return candidates[idx]\n\n",
  "anti_starvation_oldest_job_aug_291": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    js = current_status['job_status']\n    ms = current_status['machine_status']\n\n    # median job progress\n    job_times = np.array([js[op[0]] for op in feasible_operations], dtype=float)\n    median_jtime = np.median(job_times)\n\n    # candidates within a tiny tolerance of the median\n    eps = 1e-9\n    candidates = [op for op, jt in zip(feasible_operations, job_times) if abs(jt - median_jtime) < eps]\n    if not candidates:\n        candidates = feasible_operations\n\n    # minimum start time (proxy for earliest finish)\n    start_times = np.array([min(ms[op[1]], js[op[0]]) for op in candidates], dtype=float)\n    start_times = np.clip(start_times, 0, None)  # avoid negative values\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.linspace(-1e-7, 1e-7, len(candidates))\n    scores = start_times + noise\n\n    idx = np.argmin(scores)\n    return candidates[idx]\n\n",
  "anti_starvation_oldest_job_aug_292": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    job_s = current_status['job_status']\n    machine_s = current_status['machine_status']\n\n    # exaggerate differences by squaring job times\n    sq_job = np.array([np.square(job_s[op[0]]) for op in feasible_operations], dtype=float)\n\n    # inverted condition: pick the maximum squared time\n    max_sq = np.max(sq_job)\n\n    # candidates that achieve the maximal squared progress\n    candidates = [op for op, sq in zip(feasible_operations, sq_job) if abs(sq - max_sq) < 1e-12]\n\n    # earliest start times with epsilon and clipping\n    start_times = np.array([max(machine_s[op[1]], job_s[op[0]]) + 1e-12 for op in candidates], dtype=float)\n    start_times = np.clip(start_times, 0, 1e9)\n\n    # soft\u2011max probabilities over negative start times\n    exp_vals = np.exp(-start_times)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # deterministic pick: highest probability\n    idx = np.argmax(probs)\n    return candidates[idx]\n\n",
  "anti_starvation_oldest_machine_aug_293": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    # Compute the minimal machine time using NumPy\n    machine_indices = [op[1] for op in feasible_operations]\n    machine_times = m_status[machine_indices]\n    min_mtime = np.min(machine_times)\n\n    # Filter candidates using a while loop\n    candidates = []\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        if m_status[op[1]] == min_mtime:\n            candidates.append(op)\n        idx += 1\n\n    # Deterministic noise to break ties\n    def score(op):\n        finish_time = max(m_status[op[1]], j_status[op[0]]) + op[2]\n        noise = 1e-6 * feasible_operations.index(op)  # deterministic\n        return finish_time + noise\n\n    chosen = min(candidates, key=score)\n    return chosen\n\n",
  "anti_starvation_oldest_machine_aug_294": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    weight_m = 0.6\n    weight_j = 0.4\n\n    scores = []\n    for op in feasible_operations:\n        score = weight_m * m_status[op[1]] + weight_j * j_status[op[0]] + op[2]\n        score = np.clip(score, 0, np.inf)\n        scores.append(score)\n\n    scores = np.array(scores, dtype=float)\n\n    # Select top\u2011k lowest scores\n    top_k = min(5, len(scores))\n    indices = np.argsort(scores)[:top_k]\n    top_candidates = [feasible_operations[i] for i in indices]\n\n    # Deterministic random choice using a seed derived from the status\n    seed = (hash(tuple(m_status)) ^ hash(tuple(j_status))) & 0xffffffff\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(top_candidates)\n\n    return chosen\n\n",
  "anti_starvation_oldest_machine_aug_295": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    alpha = 1.0\n    scores = []\n    for op in feasible_operations:\n        mean_proxy = (m_status[op[1]] + j_status[op[0]]) / 2.0 + op[2]\n        noise = 1e-8 * (op[0] * op[1] + op[2])\n        proxy = mean_proxy + noise\n        exp_val = np.exp(-alpha * proxy)\n        exp_val = np.clip(exp_val, 1e-300, 1.0)  # avoid underflow\n        scores.append(exp_val)\n\n    scores = np.array(scores, dtype=float)\n    idx = np.argmax(scores)\n    return feasible_operations[idx]\n\n",
  "anti_starvation_oldest_machine_aug_296": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    # Convert feasible operations to NumPy arrays\n    ops = np.array(feasible_operations, dtype=object)\n    machine_ids = np.array([op[1] for op in ops], dtype=int)\n    job_ids = np.array([op[0] for op in ops], dtype=int)\n    durations = np.array([op[2] for op in ops], dtype=float)\n\n    machine_times = m_status[machine_ids]\n    min_mtime = np.min(machine_times)\n\n    # Mask for candidates with the minimal machine time\n    mask = machine_times == min_mtime\n    candidates = ops[mask]\n    if len(candidates) == 1:\n        return candidates[0]\n\n    # Compute finish times and add deterministic noise\n    finish = np.maximum(m_status[machine_ids[mask]], j_status[job_ids[mask]]) + durations[mask]\n    finish = np.clip(finish, 0, np.inf)\n    noise = 1e-9 * np.arange(len(finish))\n    scores = finish + noise\n\n    idx = np.argmin(scores)\n    return candidates[idx]\n\n",
  "min_changeover_proxy_aug_297": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_m = current_status.get('last_machine', None)\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n\n    ops = np.array(feasible_operations, dtype=object)\n    job_ids = ops[:, 0]\n    machine_ids = ops[:, 1]\n    durations = ops[:, 2].astype(float)\n\n    # Penalty: 0 if we stay on the same machine, 1 otherwise\n    penalty = np.where((last_m is not None) & (machine_ids == last_m), 0, 1)\n    penalty = np.clip(penalty, 0, 1)\n\n    # Earliest possible start and completion times\n    start_times = np.maximum(ms[machine_ids], js[job_ids])\n    completion = start_times + durations\n\n    # Deterministic noise to break ties\n    noise = np.arange(len(ops)) * 1e-6\n\n    # Composite score: high weight on penalty, then completion, then duration\n    score = penalty * 1e6 + completion * 1e3 + durations + noise\n    idx = np.argmin(score)\n\n    return tuple(ops[idx])\n\n",
  "min_changeover_proxy_aug_298": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_m = current_status.get('last_machine', None)\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n\n    ops = np.array(feasible_operations, dtype=object)\n    job_ids = ops[:, 0]\n    machine_ids = ops[:, 1]\n    durations = ops[:, 2].astype(float)\n\n    penalty = np.where((last_m is not None) & (machine_ids == last_m), 0, 1)\n    start = np.maximum(ms[machine_ids], js[job_ids])\n    comp = start + durations\n\n    # Normalise completion times to avoid large scale differences\n    max_comp = np.max(comp) + 1e-12          # epsilon to prevent div\u2011by\u2011zero\n    norm_comp = comp / max_comp\n\n    # Weighted scoring: heavier penalty, lighter completion influence\n    score = 0.6 * penalty + 0.4 * norm_comp\n\n    top_k = 3\n    # Choose indices of the k best scores\n    best_indices = np.argpartition(score, top_k)[:top_k]\n    chosen = np.random.choice(best_indices)\n\n    return tuple(ops[chosen])\n\n",
  "min_changeover_proxy_aug_299": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_m = current_status.get('last_machine', None)\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n\n    ops = np.array(feasible_operations, dtype=object)\n    job_ids = ops[:, 0]\n    machine_ids = ops[:, 1]\n    durations = ops[:, 2].astype(float)\n\n    penalty = np.where((last_m is not None) & (machine_ids == last_m), 0, 1)\n    penalty = np.clip(penalty, 0, 1)\n\n    # Approximate earliest start by averaging machine and job ready times\n    start = np.mean([ms[machine_ids], js[job_ids]], axis=0)\n    comp = start + durations\n\n    # Shift completion by its median to reduce scale impact\n    median_comp = np.median(comp)\n    score = penalty + (comp - median_comp)\n\n    # Small random noise for deterministic tie\u2011breaking\n    noise = np.random.rand(len(ops)) * 1e-5\n    idx = np.argmin(score + noise)\n\n    return tuple(ops[idx])\n\n",
  "min_changeover_proxy_aug_300": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    last_m = current_status.get('last_machine', None)\n    ms = np.array(current_status['machine_status'])\n    js = np.array(current_status['job_status'])\n\n    best_op = None\n    best_score = np.inf\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        penalty = 0 if (last_m is not None and op[1] == last_m) else 1\n        penalty = np.clip(penalty, 0, 1)\n\n        start = max(ms[op[1]], js[op[0]])\n        comp = start + op[2]\n\n        # Emphasise longer operations by squaring the duration\n        score = penalty * 1e6 + comp * 1e3 + np.square(op[2])\n\n        if score < best_score:\n            best_score = score\n            best_op = op\n        i += 1\n\n    return tuple(best_op)\n\n",
  "max_ready_queue_machine_aug_301": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_states = current_status['machine_status']\n    job_states     = current_status['job_status']\n\n    # Count feasible ops per machine using a while loop\n    ops = list(feasible_operations)\n    counts = {}\n    i = 0\n    while i < len(ops):\n        op = ops[i]\n        counts[op[1]] = counts.get(op[1], 0) + 1\n        i += 1\n\n    # Keep only the machines with the most contention\n    max_cnt = max(counts.values())\n    candidates = [op for op in ops if counts[op[1]] == max_cnt]\n\n    eps = 1e-12\n    def priority(op):\n        m_val = machine_states[op[1]]\n        j_val = job_states[op[0]]\n        base = max(m_val, j_val) + op[2]\n        denom = counts[op[1]] + eps          # avoid division by zero\n        score = base / denom\n        score += 1e-6 * op[0]                # deterministic noise for tie\u2011breaking\n        return np.clip(score, 0, 1e6)        # keep values bounded\n\n    return min(candidates, key=priority)\n\n",
  "max_ready_queue_machine_aug_302": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_states = current_status['machine_status']\n    job_states     = current_status['job_status']\n\n    # Count per machine\n    counts = {}\n    for op in feasible_operations:\n        counts[op[1]] = counts.get(op[1], 0) + 1\n\n    # Filter highly contended machines\n    threshold = 2\n    filtered = [op for op in feasible_operations if counts[op[1]] >= threshold]\n    if not filtered:\n        filtered = feasible_operations\n\n    # Weighted priority\n    w_m, w_j = 0.6, 0.4\n    eps = 1e-12\n    scores = []\n    for op in filtered:\n        m_val = machine_states[op[1]]\n        j_val = job_states[op[0]]\n        base  = w_m * m_val + w_j * j_val + op[2]\n        norm  = counts[op[1]] / (max(counts.values()) + eps)\n        norm  = np.clip(norm, 0, 1)\n        score = base * (1 + norm)\n        score += 1e-6 * op[1]                # deterministic noise\n        scores.append(score)\n\n    # Softmin probabilities\n    temp = 0.5\n    exp_vals = np.exp(-np.array(scores) / (temp + eps))\n    probs     = exp_vals / (np.sum(exp_vals) + eps)\n\n    # Random choice among top_k candidates\n    top_k = 3\n    top_idx = np.argsort(scores)[:top_k]\n    if len(top_idx) == 0:\n        return None\n    cum = np.cumsum(probs[top_idx])\n    cum /= cum[-1]\n    chosen = top_idx[np.searchsorted(cum, 0.5)]\n    return filtered[chosen]\n\n",
  "max_ready_queue_machine_aug_303": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_states = current_status['machine_status']\n    job_states     = current_status['job_status']\n\n    # Vectorized count per machine\n    machine_indices = np.array([op[1] for op in feasible_operations])\n    counts_arr      = np.bincount(machine_indices)\n    counts = {m: counts_arr[m] for m in set(machine_indices)}\n\n    # Median of machine and job states\n    machine_vals = np.array([machine_states[op[1]] for op in feasible_operations])\n    job_vals     = np.array([job_states[op[0]] for op in feasible_operations])\n    median_m = np.median(machine_vals)\n    median_j = np.median(job_vals)\n\n    eps = 1e-12\n    scores = []\n    for op in feasible_operations:\n        m_val = machine_states[op[1]]\n        j_val = job_states[op[0]]\n        mean_val = (m_val + j_val) / 2.0\n        score = 0.5 * mean_val + 0.5 * op[2]\n        score /= (counts[op[1]] + eps)          # reduce contention\n        score += 1e-6 * (op[0] + op[1])        # deterministic noise\n        scores.append(np.clip(score, 0, 1e6))\n\n    # Deterministic top\u2011k selection\n    top_k = 4\n    top_idx = np.argsort(scores)[:top_k]\n    chosen = top_idx[0]\n    return feasible_operations[chosen]\n\n",
  "max_ready_queue_machine_aug_304": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_states = current_status['machine_status']\n    job_states     = current_status['job_status']\n\n    # Count per machine via while loop\n    ops = list(feasible_operations)\n    counts = {}\n    i = 0\n    while i < len(ops):\n        op = ops[i]\n        counts[op[1]] = counts.get(op[1], 0) + 1\n        i += 1\n\n    eps = 1e-12\n    scores = []\n    for op in ops:\n        vec = np.array([machine_states[op[1]], job_states[op[0]]], dtype=float)\n        norm_val = np.linalg.norm(vec) + eps\n        score = (op[2] + eps) / norm_val\n        score *= (1.0 + counts[op[1]] / (max(counts.values()) + eps))\n        score += 1e-6 * op[1]                # deterministic noise\n        scores.append(np.clip(score, 0, 1e6))\n\n    min_idx = np.argmin(scores)\n    return ops[min_idx]\n\n",
  "max_ready_queue_job_aug_305": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Count how many feasible ops each job has\n    counts = {op[0]: 0 for op in feasible_operations}\n    for op in feasible_operations:\n        counts[op[0]] += 1\n\n    max_c = np.max(list(counts.values()))\n    candidates = [op for op in feasible_operations if counts[op[0]] == max_c]\n\n    # Earliest possible start time (machine or job ready) with clipping\n    start_times = [np.clip(max(ms[op[1]], js[op[0]]), 0, np.inf) for op in candidates]\n\n    # Tiny deterministic noise to break ties in a reproducible way\n    noise = np.arange(len(candidates)) * 1e-6\n    scores = np.array(start_times) + noise\n\n    idx = int(np.argmin(scores))\n    return candidates[idx]\n\n",
  "max_ready_queue_job_aug_306": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Build counts with a while loop\n    counts = {}\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        counts[op[0]] = counts.get(op[0], 0) + 1\n        i += 1\n\n    max_c = max(counts.values())\n    candidates = [op for op in feasible_operations if counts[op[0]] == max_c]\n\n    # Hyper\u2011parameter weights for machine and job readiness\n    w_m, w_j = 0.7, 0.3\n    scores = []\n    for op in candidates:\n        score = w_m * ms[op[1]] + w_j * js[op[0]]\n        scores.append(np.clip(score, 0, np.inf))\n\n    idx = int(np.argmin(scores))\n    return candidates[idx]\n\n",
  "max_ready_queue_job_aug_307": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n\n    job_ids = np.array([op[0] for op in ops])\n    machine_ids = np.array([op[1] for op in ops])\n\n    machine_times = np.array([ms[mid] for mid in machine_ids])\n    job_times = np.array([js[jid] for jid in job_ids])\n\n    # Mean of machine and job readiness for each operation\n    scores = np.mean([machine_times, job_times], axis=0)\n\n    # Sort by score (ascending) and break ties with op[2]\n    sorted_idx = np.lexsort((np.array([op[2] for op in ops]), scores))\n    top_k = 3\n    top_indices = sorted_idx[:top_k]\n\n    # Randomly pick one among the top\u2011k candidates\n    chosen = np.random.choice(top_indices)\n    return ops[chosen]\n\n",
  "max_ready_queue_job_aug_308": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n\n    job_ids = np.array([op[0] for op in ops])\n    machine_ids = np.array([op[1] for op in ops])\n\n    machine_times = np.array([ms[mid] for mid in machine_ids])\n    job_times = np.array([js[jid] for jid in job_ids])\n\n    # Earliest start time for each operation\n    start_times = np.maximum(machine_times, job_times)\n\n    # Softmin probabilities (higher probability for earlier start)\n    exp_vals = np.exp(-start_times)\n    denom = np.sum(exp_vals) + 1e-12  # epsilon to avoid division by zero\n    probs = np.clip(exp_vals / denom, 0, 1)\n\n    idx = int(np.argmax(probs))\n    return ops[idx]\n\n",
  "min_start_time_spread_after_aug_309": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_idx = np.array([op[1] for op in ops], dtype=int)\n    job_idx     = np.array([op[0] for op in ops], dtype=int)\n    dur         = np.array([op[2] for op in ops], dtype=float)\n\n    start = np.maximum(m_status[machine_idx], j_status[job_idx])\n    start = np.clip(start, 0, None)                 # ensure non\u2011negative start\n    end   = start + dur\n    end   = np.clip(end, None, 1e12)                # bound extreme values\n\n    spread = end.max() - end.min() + 1e-12          # add epsilon\n    # build lexicographic key: spread \u2192 end time \u2192 duration\n    key_matrix = np.column_stack((np.full_like(end, spread), end, dur))\n    noise = np.arange(len(ops)) * 1e-9              # deterministic tie\u2011breaker\n    key_matrix[:, 0] += noise\n\n    # np.lexsort sorts by the last key first; we want spread, then end, then dur\n    idx = np.lexsort((dur, end, key_matrix[:, 0]))\n    return tuple(ops[idx[0]])\n\n",
  "min_start_time_spread_after_aug_310": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m0 = np.array(current_status['machine_status'], dtype=float)\n    j0 = np.array(current_status['job_status'], dtype=float)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = np.array([op[1] for op in ops], dtype=int)\n    j_idx = np.array([op[0] for op in ops], dtype=int)\n    dur   = np.array([op[2] for op in ops], dtype=float)\n\n    start = np.maximum(m0[m_idx], j0[j_idx])\n    end   = start + dur\n\n    spread = end - end.min()                       # per\u2011op spread proxy\n    makespan = end.max()                           # overall makespan\n    score = 0.6 * spread + 0.4 * makespan          # weighted score\n\n    top_k = 5\n    k = min(top_k, len(ops))\n    idx_sorted = np.argsort(score)\n    top_idx = idx_sorted[:k]\n\n    scores_top = score[top_idx]\n    exp_scores = np.exp(-scores_top / (0.1 + 1e-12))   # softmin with epsilon\n    probs = exp_scores / exp_scores.sum()\n\n    chosen = np.random.choice(top_idx, p=probs)\n    return tuple(ops[chosen])\n\n",
  "min_start_time_spread_after_aug_311": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.array(current_status['machine_status'], dtype=float)\n    j_stat = np.array(current_status['job_status'], dtype=float)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = np.array([op[1] for op in ops], dtype=int)\n    j_idx = np.array([op[0] for op in ops], dtype=int)\n    dur   = np.array([op[2] for op in ops], dtype=float)\n\n    start = np.maximum(m_stat[m_idx], j_stat[j_idx])\n    end   = start + dur\n\n    proxy = np.median(end)                         # proxy for makespan\n    key_arr = 0.5 * (end - end.min()) + 0.5 * proxy\n    noise = np.linspace(0, 1e-6, len(ops))         # deterministic tie\u2011breaker\n    key_arr += noise\n\n    k = min(7, len(ops))\n    top_idx = np.argsort(key_arr)[:k]\n    chosen = top_idx[np.argmin(key_arr[top_idx])]\n    return tuple(ops[chosen])\n\n",
  "min_start_time_spread_after_aug_312": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if feasible_operations:\n        m0 = np.array(current_status['machine_status'], dtype=float)\n        j0 = np.array(current_status['job_status'], dtype=float)\n        ops = feasible_operations\n\n        start_times = [max(m0[op[1]], j0[op[0]]) for op in ops]\n        start_times = [np.clip(s, 0, None) for s in start_times]\n        end_times   = [s + float(op[2]) for s, op in zip(start_times, ops)]\n        end_times   = [np.clip(e, None, 1e12) for e in end_times]\n\n        spread = max(end_times) - min(end_times) + 1e-12\n        keys = [(spread, e, op[2]) for e, op in zip(end_times, ops)]\n\n        sorted_idx = sorted(range(len(keys)), key=lambda i: keys[i])\n        top_k = 4\n        chosen_idx = sorted_idx[:top_k][0]          # deterministic first\n        return tuple(ops[chosen_idx])\n    else:\n        return None\n\n",
  "min_cv_machines_after_aug_313": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times    = np.array(current_status['job_status'], dtype=float)\n\n    best_choice = None\n    best_key    = None\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        temp = machine_times.copy()\n        est_start = max(temp[op[1]], job_times[op[0]])\n        temp[op[1]] = est_start + float(op[2])\n\n        mu    = float(np.median(temp))\n        sigma = float(np.std(temp))\n        cv    = sigma / (mu + 1e-12)\n        cv    = np.clip(cv, 0, None)\n\n        # deterministic tie\u2011breaking noise\n        noise = 1e-6 * idx\n        key   = (cv + noise, est_start + float(op[2]), op[2])\n\n        if best_key is None or key < best_key:\n            best_key    = key\n            best_choice = op\n        idx += 1\n\n    return best_choice\n\n",
  "min_cv_machines_after_aug_314": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_times = np.array(current_status['machine_status'], dtype=float)\n    j_times = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    for op in feasible_operations:\n        temp = m_times.copy()\n        start = max(temp[op[1]], j_times[op[0]])\n        temp[op[1]] = start + float(op[2])\n\n        mu    = float(np.mean(temp))\n        sigma = float(np.std(temp))\n        cv    = sigma / (mu + 1e-12)\n        cv    = np.clip(cv, 0, None)\n\n        duration = start + float(op[2])\n        # weighted combination of CV and duration\n        score = 0.6 * cv + 0.4 * duration\n        scores.append((score, op))\n\n    # sort by score and pick the top\u2011k candidates\n    scores.sort(key=lambda x: x[0])\n    top_k = 3\n    top_candidates = [op for _, op in scores[:top_k]]\n    chosen = np.random.choice(np.array(top_candidates))\n    return chosen\n\n",
  "min_cv_machines_after_aug_315": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mt = np.array(current_status['machine_status'], dtype=float)\n    jt = np.array(current_status['job_status'], dtype=float)\n\n    best_op = None\n    best_weight = -np.inf\n    for op in feasible_operations:\n        temp = mt.copy()\n        start = max(temp[op[1]], jt[op[0]])\n        temp[op[1]] = start + float(op[2])\n\n        mu    = float(np.max(temp))\n        sigma = float(np.std(temp))\n        cv    = sigma / (mu + 1e-12)\n        cv    = np.clip(cv, 0, None)\n\n        duration = start + float(op[2])\n        # soft\u2011min weight via exponential of negative sum\n        weight = np.exp(- (cv + duration))\n        if weight > best_weight:\n            best_weight = weight\n            best_op = op\n\n    return best_op\n\n",
  "min_cv_machines_after_aug_316": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_times = np.array(current_status['machine_status'], dtype=float)\n    j_times = np.array(current_status['job_status'], dtype=float)\n\n    # unpack operation components\n    job_idx     = np.array([op[0] for op in feasible_operations], dtype=int)\n    machine_idx = np.array([op[1] for op in feasible_operations], dtype=int)\n    durations   = np.array([float(op[2]) for op in feasible_operations], dtype=float)\n\n    # start times for all operations\n    starts = np.maximum(m_times[machine_idx], j_times[job_idx])\n\n    # build matrix of machine times for each candidate\n    num_ops      = len(feasible_operations)\n    num_machines = m_times.size\n    all_m_times  = np.tile(m_times, (num_ops, 1))\n    all_m_times[np.arange(num_ops), machine_idx] = starts + durations\n\n    # compute CV for each candidate\n    mu    = np.mean(all_m_times, axis=1)\n    sigma = np.std(all_m_times, axis=1)\n    cv    = sigma / (mu + 1e-12)\n    cv    = np.clip(cv, 0, None)\n\n    # deterministic noise to break ties\n    noise = 1e-6 * np.arange(num_ops)\n    scores = cv + noise\n\n    best_idx = np.argmin(scores)\n    return feasible_operations[best_idx]\n\n",
  "min_cv_jobs_after_aug_317": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        # compute start and new job completion times\n        start = max(m_status[op[1]], j_status[op[0]])\n        new_j = j_status.copy()\n        new_j[op[0]] = start + float(op[2])\n\n        mu = np.mean(new_j)\n        sd = np.std(new_j)\n        cv = sd / (mu + 1e-12)                     # epsilon to avoid div\u2011by\u2011zero\n        cv = np.clip(cv, 0, 1e6)                    # bound the value\n\n        # deterministic noise for tie\u2011breaking\n        noise = (op[0] + op[1]) * 1e-8\n        key = (cv, start + float(op[2]) + noise, op[2])\n\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n\n    return best_op\n\n",
  "min_cv_jobs_after_aug_318": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    ops = np.array(feasible_operations, dtype=object)\n    m_idx = np.array([op[1] for op in ops], dtype=int)\n    j_idx = np.array([op[0] for op in ops], dtype=int)\n    dur  = np.array([op[2] for op in ops], dtype=float)\n\n    start = np.maximum(ms[m_idx], js[j_idx])\n    finish = start + dur\n\n    # broadcast job status and replace the finished job\n    new_js = np.tile(js, (len(ops), 1))\n    new_js[np.arange(len(ops)), j_idx] = finish\n\n    mu = np.mean(new_js, axis=1)\n    sd = np.std(new_js, axis=1)\n    cv = sd / (mu + 1e-12)\n    cv = np.clip(cv, 0, 1e6)\n\n    # softmin weighting\n    alpha = 1.0\n    weights = np.exp(-alpha * cv)\n\n    # choose among top\u20113 by softmin weight\n    top_k = 3\n    idx_sorted = np.argsort(-weights)          # descending weights\n    rng = np.random.default_rng(seed=hash(str(current_status)))\n    chosen = rng.choice(idx_sorted[:top_k])\n\n    return tuple(ops[chosen])\n\n",
  "min_cv_jobs_after_aug_319": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    ops = list(feasible_operations)\n    i = 0\n    best_op, best_key = None, None\n\n    while i < len(ops):\n        op = ops[i]\n        start = np.max([ms[op[1]], js[op[0]]])\n        new_js = js.copy()\n        new_js[op[0]] = start + float(op[2])\n\n        mu = np.max(new_js)                     # use max instead of mean\n        sd = np.std(new_js)\n        cv = sd / (mu + 1e-12)\n        cv = np.clip(cv, 0, 1e6)\n\n        # deterministic noise for tie\u2011breaking\n        noise = ((op[0]*17 + op[1]*23) % 1000) * 1e-7\n        key = (cv, - (start + float(op[2]) + noise))  # negative finish favours earlier\n\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n\n        i += 1\n\n    return best_op\n\n",
  "max_machine_release_rate_aug_320": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Convert list of tuples into a structured array for vectorised ops\n    ops_arr = np.array(feasible_operations, dtype=object)\n\n    job_idx     = ops_arr[:, 0].astype(int)\n    machine_idx = ops_arr[:, 1].astype(int)\n    proc_time   = ops_arr[:, 2].astype(float)\n\n    # Idle time of each candidate operation\n    idle = np.maximum(js[job_idx] - ms[machine_idx], 0.0)\n\n    # Score: maximise processing time over idle+1\n    val = proc_time / (idle + 1e-12)\n\n    # Deterministic tie\u2011breaker: add tiny increasing noise\n    noise = np.arange(len(feasible_operations)) * 1e-6\n    val += noise\n\n    best_idx = np.argmax(val)\n    return tuple(ops_arr[best_idx])\n\n",
  "max_machine_release_rate_aug_321": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    best_inv_val = float('inf')\n    best_op = None\n\n    for op in feasible_operations:\n        idle = max(0.0, js[op[0]] - ms[op[1]])\n        idle = np.clip(idle, 0.0, 1e6)               # bound idle\n        inv_val = (idle + 1e-12) / op[2]             # inverse value\n\n        if inv_val < best_inv_val - 1e-12:\n            best_inv_val, best_op = inv_val, op\n        elif abs(inv_val - best_inv_val) < 1e-12:\n            # tie\u2011break: earliest start\n            start = max(ms[op[1]], js[op[0]])\n            bstart = max(ms[best_op[1]], js[best_op[0]])\n            if start < bstart:\n                best_op = op\n\n    return best_op\n\n",
  "min_machine_release_rate_aug_322": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Helper to compute a deterministic noise value from an operation tuple\n    def _noise(op):\n        return ((op[0] * 12345 + op[1] * 67890 + op[2] * 11111) % 1000) / 1e6\n\n    # Prepare arrays for all operations\n    op_arr = np.array(feasible_operations, dtype=object)\n\n    # Idle time (clipped to non\u2011negative, bounded by a large cap)\n    idle = np.clip(js[op_arr[:, 0]] - ms[op_arr[:, 1]], 0, 1e6)\n\n    # Ratio with epsilon to avoid division by zero\n    eps = 1e-12\n    ratio = op_arr[:, 2].astype(float) / (idle + eps)\n\n    # Start time (max of machine and job availability)\n    start = np.maximum(ms[op_arr[:, 1]], js[op_arr[:, 0]])\n\n    # Combine ratio, start, and operation duration into a single tuple for comparison\n    # Add deterministic noise to ratio to break ties\n    score = ratio + np.vectorize(_noise)(op_arr)\n\n    # Find the operation with the minimal (ratio + noise, start, duration)\n    idx = np.argmin(np.stack([score, start, op_arr[:, 2].astype(float)], axis=1), axis=0)\n\n    return feasible_operations[idx]\n\n",
  "min_machine_release_rate_aug_323": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Compute idle and ratio for each operation\n    idle = np.maximum(js[[op[0] for op in feasible_operations]] -\n                     ms[[op[1] for op in feasible_operations]], 0)\n    eps = 1e-12\n    ratio = np.array([op[2] for op in feasible_operations], dtype=float) / (idle + eps)\n\n    # Choose top_k operations with smallest ratio\n    top_k = 5\n    if len(ratio) > top_k:\n        top_indices = np.argpartition(ratio, top_k)[:top_k]\n    else:\n        top_indices = np.arange(len(ratio))\n\n    # Among the top_k, pick the one with the median start time\n    starts = np.maximum(ms[[feasible_operations[i][1] for i in top_indices]],\n                        js[[feasible_operations[i][0] for i in top_indices]])\n    median_start = np.median(starts)\n    # Find the first operation whose start time equals the median (deterministic)\n    for idx in top_indices:\n        if starts[top_indices.tolist().index(idx)] == median_start:\n            return feasible_operations[idx]\n    # Fallback\n    return feasible_operations[top_indices[np.argmin(ratio[top_indices])]]\n\n",
  "min_machine_release_rate_aug_324": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    # Approximate idle by clipping to a reasonable range\n    idle = np.clip(js[[op[0] for op in feasible_operations]] -\n                     ms[[op[1] for op in feasible_operations]], 0, 1e5)\n    eps = 1e-12\n    ratio = np.array([op[2] for op in feasible_operations], dtype=float) / (idle + eps)\n\n    # Approximate start by using np.max instead of max\n    start = np.max([ms[[op[1] for op in feasible_operations]],\n                    js[[op[0] for op in feasible_operations]]], axis=0)\n\n    # Combine ratio and start into a single score (sum) and clip to avoid overflow\n    score = np.clip(ratio + start, 0, 1e10)\n\n    # Select operation with minimal combined score\n    idx = np.argmin(score)\n    return feasible_operations[idx]\n\n",
  "lookahead_two_step_makespan_proxy_aug_325": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times = np.array(current_status['job_status'], dtype=float)\n\n    def greedy_next(mt, jt, ops):\n        if not ops:\n            return None\n        comp = np.array([max(mt[op[1]], jt[op[0]]) + op[2] for op in ops], dtype=float)\n        # deterministic noise to break ties\n        noise = np.array([1e-9 * (op[0] + op[1]) for op in ops], dtype=float)\n        comp += noise\n        return ops[int(np.argmin(comp))]\n\n    best_op = None\n    best_val = float('inf')\n\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        idx += 1\n\n        mt = machine_times.copy()\n        jt = job_times.copy()\n        start = max(mt[op[1]], jt[op[0]])\n        fin = start + float(op[2])\n        fin = np.clip(fin, 0, None)          # prevent negative times\n        mt[op[1]] = fin\n        jt[op[0]] = fin\n\n        remaining = [x for x in feasible_operations if x is not op]\n        nxt = greedy_next(mt, jt, remaining)\n\n        if nxt is not None:\n            s2 = max(mt[nxt[1]], jt[nxt[0]])\n            f2 = s2 + float(nxt[2])\n            f2 = np.clip(f2, 0, None)\n            mt2 = mt.copy()\n            jt2 = jt.copy()\n            mt2[nxt[1]] = f2\n            jt2[nxt[0]] = f2\n            val = float(max(mt2.max(), jt2.max()))\n        else:\n            val = float(max(mt.max(), jt.max()))\n\n        key = (val, fin, op[2])\n        if key < (best_val, float('inf'), float('inf')):\n            best_val, best_op = val, op\n\n    return best_op\n\n",
  "lookahead_two_step_makespan_proxy_aug_326": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    t_machine = np.array(current_status['machine_status'], dtype=float)\n    t_job    = np.array(current_status['job_status'], dtype=float)\n\n    def greedy_next(mt, jt, ops):\n        if not ops:\n            return None\n        # vectorised completion times\n        comp = np.array([max(mt[op[1]], jt[op[0]]) + op[2] for op in ops], dtype=float)\n        # deterministic noise to avoid exact ties\n        noise = np.array([1e-9 * (op[0] + op[1]) for op in ops], dtype=float)\n        comp += noise\n        # softmin with temperature alpha\n        alpha = 10.0\n        probs = np.exp(-alpha * comp)\n        probs_sum = probs.sum() + 1e-12          # epsilon to avoid div\u2011by\u2011zero\n        probs = probs / probs_sum\n        probs = np.clip(probs, 0, 1)             # bound probabilities\n        idx = int(np.argmax(probs))\n        return ops[idx]\n\n    best_op = None\n    best_val = float('inf')\n\n    for op in feasible_operations:\n        mt = t_machine.copy()\n        jt = t_job.copy()\n        start = max(mt[op[1]], jt[op[0]])\n        fin = start + float(op[2])\n        fin = np.clip(fin, 0, None)\n        mt[op[1]] = fin\n        jt[op[0]] = fin\n\n        remaining = [x for x in feasible_operations if x is not op]\n        nxt = greedy_next(mt, jt, remaining)\n\n        if nxt is not None:\n            s2 = max(mt[nxt[1]], jt[nxt[0]])\n            f2 = s2 + float(nxt[2])\n            f2 = np.clip(f2, 0, None)\n            mt2 = mt.copy()\n            jt2 = jt.copy()\n            mt2[nxt[1]] = f2\n            jt2[nxt[0]] = f2\n            val = float(max(mt2.max(), jt2.max()))\n        else:\n            val = float(max(mt.max(), jt.max()))\n\n        key = (val, fin, op[2])\n        if key < (best_val, float('inf'), float('inf')):\n            best_val, best_op = val, op\n\n    return best_op\n\n",
  "lookahead_two_step_makespan_proxy_aug_327": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_times = np.array(current_status['machine_status'], dtype=float)\n    job_times     = np.array(current_status['job_status'], dtype=float)\n\n    # convert operations to a structured array for vectorised access\n    ops_arr = np.array(feasible_operations, dtype=int)   # shape (n,3)\n    n_ops = ops_arr.shape[0]\n\n    # pre\u2011allocate storage for the resulting makespans\n    makespans = np.empty(n_ops, dtype=float)\n\n    for i in range(n_ops):\n        op = ops_arr[i]\n        mt = machine_times.copy()\n        jt = job_times.copy()\n        start = max(mt[op[1]], jt[op[0]])\n        fin = start + float(op[2])\n        fin = np.clip(fin, 0, None)\n        mt[op[1]] = fin\n        jt[op[0]] = fin\n\n        # greedy selection of the next operation among the remaining ones\n        remaining = [x for x in feasible_operations if x is not tuple(op)]\n        if remaining:\n            # compute completion times for remaining ops\n            comp = np.array([max(mt[x[1]], jt[x[0]]) + x[2] for x in remaining], dtype=float)\n            # use median as a robust aggregation instead of mean\n            nxt_idx = int(np.argmin(comp))\n            nxt = remaining[nxt_idx]\n            s2 = max(mt[nxt[1]], jt[nxt[0]])\n            f2 = s2 + float(nxt[2])\n            f2 = np.clip(f2, 0, None)\n            mt[nxt[1]] = f2\n            jt[nxt[0]] = f2\n\n        makespans[i] = float(max(mt.max(), jt.max()))\n\n    # select the top\u2011k smallest makespans\n    top_k = 3\n    top_indices = np.argpartition(makespans, top_k)[:top_k]\n    best_idx = top_indices[np.argmin(makespans[top_indices])]\n    return tuple(feasible_operations[best_idx])\n\n",
  "lookahead_two_step_makespan_proxy_aug_328": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    arr_machine = np.array(current_status['machine_status'], dtype=float)\n    arr_job     = np.array(current_status['job_status'], dtype=float)\n\n    def greedy_schedule(mt, jt, ops):\n        for op in ops:\n            start = max(mt[op[1]], jt[op[0]])\n            fin = start + float(op[2])\n            fin = np.clip(fin, 0, None)\n            mt[op[1]] = fin\n            jt[op[0]] = fin\n        return mt, jt\n\n    best_op = None\n    best_makespan = float('inf')\n\n    for op in feasible_operations:\n        mt = arr_machine.copy()\n        jt = arr_job.copy()\n        start = max(mt[op[1]], jt[op[0]])\n        fin = start + float(op[2])\n        fin = np.clip(fin, 0, None)\n        mt[op[1]] = fin\n        jt[op[0]] = fin\n\n        remaining = [x for x in feasible_operations if x is not op]\n        mt2, jt2 = greedy_schedule(mt.copy(), jt.copy(), remaining)\n        makespan = float(max(mt2.max(), jt2.max()))\n\n        if makespan < best_makespan:\n            best_makespan, best_op = makespan, op\n\n    return best_op\n\n",
  "min_kurtosis_machines_after_aug_329": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # rename for clarity\n    machine_arr = np.array(current_status['machine_status'], dtype=float)\n    job_arr      = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vec):\n        mu  = float(np.mean(vec))\n        std = float(np.std(vec) + 1e-12)          # epsilon to avoid div\u2011by\u2011zero\n        z   = (vec - mu) / std\n        return float(np.mean(z ** 4))\n\n    candidates = []\n    for op in feasible_operations:\n        j, m, dur = op\n        start   = max(machine_arr[m], job_arr[j])\n        new_ms  = machine_arr.copy()\n        new_ms[m] = start + dur\n        k_val   = kurtosis(new_ms)\n        k_val   = np.clip(k_val, 0, 1e6)          # bound to prevent overflow\n        # deterministic noise for stable tie\u2011breaking\n        noise   = (hash(op) % 1000) * 1e-9\n        key     = (k_val, start + dur, noise)\n        candidates.append((op, key))\n\n    # pick the operation with the minimal key\n    best_op = min(candidates, key=lambda x: x[1])[0]\n    return best_op\n\n",
  "min_kurtosis_machines_after_aug_330": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_arr = np.array(current_status['machine_status'], dtype=float)\n    j_arr = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vec):\n        mu  = float(np.mean(vec))\n        std = float(np.std(vec) + 1e-12)\n        z   = (vec - mu) / std\n        return float(np.mean(z ** 4))\n\n    # scoring weights & top\u2011k\n    w_k   = 0.6\n    w_f   = 0.4\n    top_k = 3\n\n    idx      = 0\n    scores   = []\n    ops_list = []\n\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        j, m, dur = op\n        start   = max(m_arr[m], j_arr[j])\n        finish  = start + dur\n        new_ms  = m_arr.copy()\n        new_ms[m] = finish\n        k_val   = kurtosis(new_ms)\n        score   = w_k * k_val + w_f * finish\n        scores.append(score)\n        ops_list.append(op)\n        idx += 1\n\n    scores_np = np.array(scores, dtype=float)\n    scores_np = np.clip(scores_np, 0, 1e6)            # bound for numeric stability\n    exp_vals  = np.exp(-scores_np)\n    probs     = exp_vals / exp_vals.sum()\n\n    rng = np.random.default_rng(42)                  # deterministic random state\n    chosen_idx = rng.choice(len(ops_list), size=top_k,\n                            replace=False, p=probs)\n\n    best_idx = chosen_idx[np.argmin([scores[i] for i in chosen_idx])]\n    return ops_list[best_idx]\n\n",
  "min_kurtosis_machines_after_aug_331": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = np.array(current_status['machine_status'], dtype=float)\n    j_status = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vec):\n        mu  = float(np.mean(vec))\n        std = float(np.std(vec) + 1e-12)\n        z   = (vec - mu) / std\n        # use the maximum to highlight heavy tails\n        return float(np.max(z ** 4))\n\n    idx      = 0\n    best_key = None\n    best_op  = None\n\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        j, m, dur = op\n        start   = max(m_status[m], j_status[j])\n        start   = np.clip(start, 0, None)          # ensure non\u2011negative\n        finish  = start + dur\n        new_ms  = m_status.copy()\n        new_ms[m] = finish\n        k_val   = kurtosis(new_ms)\n        noise   = (idx % 1000) * 1e-9              # deterministic tie\u2011breaker\n        key     = (k_val, finish, noise)\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n        idx += 1\n\n    return best_op\n\n",
  "min_kurtosis_machines_after_aug_332": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = np.array(current_status['machine_status'], dtype=float)\n    j_stat = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vec):\n        mu  = float(np.mean(vec))\n        std = float(np.std(vec) + 1e-12)\n        z   = (vec - mu) / std\n        return float(np.mean(z ** 4))\n\n    # scoring parameters\n    w_k   = 0.4\n    w_f   = 0.6\n    top_k = 5\n\n    ops     = []\n    scores  = []\n    rng     = np.random.default_rng(123)\n\n    for op in feasible_operations:\n        j, m, dur = op\n        start   = max(m_stat[m], j_stat[j])\n        finish  = start + dur\n        finish  = np.clip(finish, 0, None)          # bound to non\u2011negative\n        new_ms  = m_stat.copy()\n        new_ms[m] = finish\n        k_val   = kurtosis(new_ms)\n        score   = w_k * k_val + w_f * finish\n        ops.append(op)\n        scores.append(score)\n\n    scores_np = np.array(scores, dtype=float)\n    scores_np = np.clip(scores_np, 0, 1e6)           # prevent overflow\n    exp_vals  = np.exp(-scores_np)\n    probs     = exp_vals / exp_vals.sum()\n\n    chosen_idx = rng.choice(len(ops), size=top_k,\n                            replace=False, p=probs)\n    best_idx   = chosen_idx[np.argmin([scores[i] for i in chosen_idx])]\n    return ops[best_idx]\n\n",
  "min_kurtosis_jobs_after_aug_333": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vals):\n        mu = np.mean(vals)\n        sd = np.std(vals) + 1e-12\n        z = (vals - mu) / sd\n        return np.mean(z**4)\n\n    # Prepare arrays of candidate data\n    job_ids   = np.array([op[0] for op in feasible_operations], dtype=int)\n    mach_ids  = np.array([op[1] for op in feasible_operations], dtype=int)\n    dur       = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Current start times for each candidate\n    start_times = np.maximum(ms[mach_ids], js[job_ids])\n    finish_times = start_times + dur\n\n    # Compute kurtosis for each candidate\n    kurt_values = np.array([kurtosis(np.where(np.arange(js.size) == j, f, js))\n                            for j, f in zip(job_ids, finish_times)])\n\n    # Composite key: (kurtosis, finish time, duration)\n    keys = np.vstack((kurt_values, finish_times, dur)).T\n\n    # Select candidate with minimal key\n    idx = np.lexsort((dur, finish_times, kurt_values))\n    best_idx = idx[0]\n    return feasible_operations[best_idx]\n\n",
  "min_kurtosis_jobs_after_aug_334": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vals):\n        mu = np.median(vals)  # median instead of mean\n        sd = np.std(vals) + 1e-12\n        z = (vals - mu) / sd\n        return np.mean(z**4)\n\n    best_op, best_key = None, None\n    for op in feasible_operations:\n        job_id, mach_id, dur = op\n        start = max(ms[mach_id], js[job_id])\n        new_js = js.copy()\n        new_js[job_id] = start + dur\n        k = kurtosis(new_js)\n\n        # Deterministic noise based on operation tuple\n        noise = (hash(op) % 1000) * 1e-6\n        key = (k + noise, start + dur, dur)\n\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n    return best_op\n\n",
  "min_kurtosis_jobs_after_aug_335": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n\n    def kurtosis(vals):\n        mu = np.mean(vals)\n        sd = np.std(vals) + 1e-12\n        z = (vals - mu) / sd\n        return np.mean(z**4)\n\n    # Evaluate all candidates\n    evals = []\n    for op in feasible_operations:\n        job_id, mach_id, dur = op\n        start = max(ms[mach_id], js[job_id])\n        new_js = js.copy()\n        new_js[job_id] = start + dur\n        k = kurtosis(new_js)\n        evals.append((k, start + dur, dur, op))\n\n    # Sort by composite key\n    evals.sort(key=lambda x: (x[0], x[1], x[2]))\n    top_k = 5\n    top_candidates = [e[3] for e in evals[:top_k]]\n\n    # Randomly pick among top candidates (deterministic seed)\n    rng = np.random.default_rng(seed=123)\n    return rng.choice(top_candidates)\n\n",
  "min_l1_to_uniform_machines_aug_336": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # Pre\u2011compute start times for all candidates\n    jobs    = np.array([op[0] for op in feasible_operations], dtype=int)\n    machines= np.array([op[1] for op in feasible_operations], dtype=int)\n    durations= np.array([op[2] for op in feasible_operations], dtype=float)\n\n    start_times = np.maximum(ms0[machines], js[jobs])\n    end_times   = start_times + durations\n\n    rng = np.random.default_rng(12345)          # deterministic noise generator\n    best_op, best_key = None, None\n\n    for idx, op in enumerate(feasible_operations):\n        # Build new machine status\n        ms_new = ms0.copy()\n        ms_new[op[1]] = end_times[idx]\n        ms_new = np.clip(ms_new, 0, None)        # avoid negative times\n\n        # Mean with epsilon to avoid division by zero\n        mu = (ms_new.sum() + 1e-12) / (ms_new.size + 1e-12)\n        l1 = np.abs(ms_new - mu).sum()\n\n        # Tiny noise for deterministic tie\u2011breaking\n        noise = rng.uniform(-1e-6, 1e-6)\n        key = (l1 + noise, end_times[idx], durations[idx])\n\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n\n    return best_op\n\n",
  "min_l1_to_uniform_machines_aug_337": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    rng = np.random.default_rng(2021)           # deterministic seed\n    candidates = []\n\n    for op in feasible_operations:\n        job, mach, dur = op\n        start = max(ms0[mach], js[job])\n\n        ms_new = ms0.copy()\n        ms_new[mach] = start + dur\n        ms_new = np.clip(ms_new, 0, None)\n\n        mu = np.median(ms_new)                  # median for balance\n        l1 = np.abs(ms_new - mu).sum()\n\n        candidates.append((l1, start + dur, dur, op))\n\n    # Sort by L1, makespan, duration\n    candidates.sort(key=lambda x: (x[0], x[1], x[2]))\n    top_k = min(3, len(candidates))\n    top_ops = [c[3] for c in candidates[:top_k]]\n\n    return rng.choice(top_ops)                  # random choice among top\u2011k\n\n",
  "min_l1_to_uniform_machines_aug_338": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    scores = []\n    for op in feasible_operations:\n        job, mach, dur = op\n        start = max(ms0[mach], js[job])\n\n        ms_new = ms0.copy()\n        ms_new[mach] = start + dur\n        ms_new = np.clip(ms_new, 0, None)\n\n        mu = ms_new.mean()                      # mean with internal epsilon\n        l1 = np.abs(ms_new - mu).sum()\n\n        scores.append((l1, start + dur, dur, op))\n\n    # Soft\u2011min probabilities\n    l1_arr = np.array([s[0] for s in scores], dtype=float)\n    beta   = 10.0\n    l1_min = l1_arr.min()\n    exp_vals = np.exp(-beta * (l1_arr - l1_min))  # shift for stability\n    probs = exp_vals / (exp_vals.sum() + 1e-12)    # epsilon in denominator\n\n    rng = np.random.default_rng(9876)\n    idx = rng.choice(len(feasible_operations), p=probs)\n\n    return feasible_operations[idx]\n\n",
  "min_l1_to_uniform_machines_aug_339": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    rng = np.random.default_rng(5555)\n    weighted = []\n\n    for op in feasible_operations:\n        job, mach, dur = op\n        start = max(ms0[mach], js[job])\n\n        ms_new = ms0.copy()\n        ms_new[mach] = start + dur\n        ms_new = np.clip(ms_new, 0, None)\n\n        mu = (ms_new.sum() + 1e-12) / (ms_new.size + 1e-12)  # mean with epsilon\n        l1 = np.abs(ms_new - mu).sum()\n\n        # Weighted score: L1 + 0.5 * makespan\n        score = l1 + 0.5 * (start + dur)\n        noise = rng.uniform(-1e-6, 1e-6)\n        weighted.append((score + noise, op))\n\n    # Invert logic: use negative scores and pick the max\n    neg_scores = [-w[0] for w in weighted]\n    idx = np.argmax(neg_scores)\n    return weighted[idx][1]\n\n",
  "min_l1_to_uniform_jobs_aug_340": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    # Convert the list of operations into parallel arrays\n    machine_idx = np.array([op[1] for op in feasible_operations], dtype=int)\n    job_idx     = np.array([op[0] for op in feasible_operations], dtype=int)\n    durations   = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Compute the earliest start for each candidate operation\n    start_times = np.maximum(ms[machine_idx], js0[job_idx])\n    start_times = np.clip(start_times, 0.0, None)          # ensure non\u2011negative\n    end_times   = start_times + durations\n\n    # Build the job\u2011time matrix for every candidate\n    js_new = np.tile(js0, (len(feasible_operations), 1))\n    js_new[np.arange(len(feasible_operations)), job_idx] = end_times\n\n    # Median\u2011based dispersion (L1 distance to the median)\n    mu   = np.mean(js_new, axis=1) + 1e-12                # epsilon to avoid division by zero\n    l1   = np.sum(np.abs(js_new - mu[:, None]), axis=1)\n\n    # Tie\u2011breaking noise (deterministic)\n    noise = np.arange(len(feasible_operations)) * 1e-9\n\n    # Construct a key for lexicographic sorting\n    keys = np.stack([l1, end_times, durations, noise], axis=1)\n    idx  = np.lexsort((keys[:, 3], keys[:, 2], keys[:, 1], keys[:, 0]))\n\n    # Return the operation that yields the minimal key\n    return tuple(feasible_operations[idx[0]])\n\n",
  "min_l1_to_uniform_jobs_aug_341": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms   = np.array(current_status['machine_status'], dtype=float)\n    js0  = np.array(current_status['job_status'], dtype=float)\n\n    scores   = []\n    ops_list = []\n\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0.0, None)          # clip to avoid negatives\n        js[op[0]] = start + float(op[2])\n\n        mu   = np.mean(js) + 1e-12                 # epsilon added\n        # Use the maximum deviation instead of the sum\n        l1   = np.max(np.abs(js - mu))\n        # Soft\u2011min weighting: higher l1 \u2192 lower weight\n        score = np.exp(-l1)\n        scores.append(score)\n        ops_list.append(op)\n\n    scores = np.array(scores)\n    top_k  = min(3, len(scores))\n    # Pick one operation at random among the top\u2011k soft\u2011min scores\n    top_indices = np.argpartition(-scores, top_k - 1)[:top_k]\n    chosen_idx  = np.random.choice(top_indices)\n\n    return ops_list[chosen_idx]\n\n",
  "min_l1_to_uniform_jobs_aug_342": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms  = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    candidates = []\n\n    for op in feasible_operations:\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0.0, None)          # clip to non\u2011negative\n        js[op[0]] = start + float(op[2])\n\n        mu   = np.mean(js) + 1e-12                 # epsilon added\n        l1   = np.sum(np.abs(js - mu))\n        end  = start + float(op[2])\n\n        # Weighted combination of dispersion and completion time\n        weight = 0.6 * l1 + 0.4 * end\n        # Deterministic tie\u2011breaker using a small noise term\n        noise  = 1e-9 * (hash(op) % 1000)\n        candidates.append((weight + noise, op))\n\n    # Sort by the weighted score (with noise) and pick the best\n    candidates.sort(key=lambda x: x[0])\n    return candidates[0][1]\n\n",
  "min_l1_to_uniform_jobs_aug_343": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms  = np.array(current_status['machine_status'], dtype=float)\n    js0 = np.array(current_status['job_status'], dtype=float)\n\n    ops   = feasible_operations[:]          # make a copy to manipulate\n    scores = []\n\n    while ops:\n        op = ops.pop(0)\n        js = js0.copy()\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0.0, None)      # clip to non\u2011negative\n        js[op[0]] = start + float(op[2])\n\n        mu   = np.median(js) + 1e-12           # epsilon added\n        l1   = np.sum(np.abs(js - mu))\n        scores.append((l1, op))\n\n    # Randomly pick one of the top\u20115 best operations\n    top_k = min(5, len(scores))\n    top_indices = np.argsort([s[0] for s in scores])[:top_k]\n    chosen_idx  = np.random.choice(top_indices)\n\n    return scores[chosen_idx][1]\n\n",
  "min_l2_to_uniform_machines_aug_344": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    ops = list(feasible_operations)\n    idx = 0\n    best_op, best_key = None, None\n\n    while idx < len(ops):\n        op = ops[idx]\n        ms = ms0.copy()\n\n        # compute earliest start time and clip to avoid overflow\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0, 1e9)\n\n        ms[op[1]] = start + float(op[2])\n\n        mu = float(np.mean(ms))\n        l2 = float(np.sum((ms - mu) ** 2)) + 1e-12  # epsilon to avoid zero\n\n        # deterministic noise for tie\u2011breaking\n        noise = 1e-9 * abs(hash(op))\n        key = (l2, start + float(op[2]) + noise)\n\n        if best_key is None or key < best_key:\n            best_key, best_op = key, op\n\n        idx += 1\n\n    return best_op\n\n",
  "min_l2_to_uniform_machines_aug_345": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    # Hyper\u2011parameters\n    w_l2   = 0.6\n    w_ms   = 0.4\n    top_k  = 7\n    eps    = 1e-12\n\n    scores = []\n    ops    = []\n\n    for op in feasible_operations:\n        ms = ms0.copy()\n\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0, 1e9)\n\n        ms[op[1]] = start + float(op[2])\n\n        mu   = np.mean(ms)\n        l2   = np.sum((ms - mu) ** 2) + eps\n        mspt = start + float(op[2])\n\n        score = w_l2 * l2 + w_ms * mspt\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores, dtype=float)\n    ops    = np.array(ops, dtype=object)\n\n    if len(scores) <= top_k:\n        candidates = ops\n    else:\n        idx_sorted = np.argsort(scores)\n        candidates = ops[idx_sorted[:top_k]]\n\n    # Randomly pick one of the best candidates\n    chosen = np.random.choice(candidates)\n    return chosen\n\n",
  "min_l2_to_uniform_machines_aug_346": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms0 = np.array(current_status['machine_status'], dtype=float)\n    js  = np.array(current_status['job_status'], dtype=float)\n\n    temperature = 0.1 + 1e-12  # avoid division by zero\n    scores = []\n    ops    = []\n\n    for op in feasible_operations:\n        ms = ms0.copy()\n\n        start = max(ms[op[1]], js[op[0]])\n        start = np.clip(start, 0, 1e9)\n\n        ms[op[1]] = start + float(op[2])\n\n        mu   = np.median(ms)\n        l2   = np.max((ms - mu) ** 2) + 1e-12\n        mspt = start + float(op[2])\n\n        # Composite score: equal weight on L2 and makespan\n        score = 0.5 * l2 + 0.5 * mspt\n        scores.append(score)\n        ops.append(op)\n\n    scores = np.array(scores, dtype=float)\n\n    # Softmin probability distribution\n    exp_vals = np.exp(-scores / temperature)\n    denom    = np.clip(np.sum(exp_vals), 1e-12, None)\n    probs    = exp_vals / denom\n\n    chosen = np.random.choice(ops, p=probs)\n    return chosen\n\n",
  "min_l2_to_uniform_jobs_aug_347": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Rename for clarity\n    machine_arr = np.array(current_status['machine_status'], dtype=float)\n    job_arr = np.array(current_status['job_status'], dtype=float)\n\n    ops = np.array(feasible_operations, dtype=object)          # shape (n, 3)\n    n_ops, n_jobs = ops.shape[0], job_arr.size\n\n    # Start times for every candidate operation\n    start_times = np.maximum(machine_arr[ops[:, 1]], job_arr[ops[:, 0]])\n    finish_times = start_times + ops[:, 2].astype(float)\n\n    # Build matrix of updated job states (n_ops \u00d7 n_jobs)\n    updated_matrix = np.tile(job_arr, (n_ops, 1))\n    updated_matrix[np.arange(n_ops), ops[:, 0]] = finish_times\n    # Clip to avoid any negative or absurdly large values\n    updated_matrix = np.clip(updated_matrix, 0, 1e12)\n\n    # Mean with epsilon to avoid division by zero\n    mu = (np.sum(updated_matrix, axis=1, keepdims=True) + 1e-12) / (\n        n_jobs + 1e-12\n    )\n\n    # L2 distance (sum of squared deviations)\n    l2 = np.sum((updated_matrix - mu) ** 2, axis=1)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = 1e-6 * np.arange(n_ops)\n\n    # Lexicographic key: (l2+noise, finish_time, duration)\n    keys = np.core.records.fromarrays(\n        [l2 + noise, finish_times, ops[:, 2]],\n        names='l2,finish,dur',\n    )\n    best_idx = np.lexsort((keys.dur, keys.finish, keys.l2))[0]\n    return tuple(feasible_operations[best_idx])\n\n",
  "min_l2_to_uniform_jobs_aug_348": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status = np.array(current_status['job_status'], dtype=float)\n\n    n_ops = len(feasible_operations)\n    l2_vals = np.empty(n_ops, dtype=float)\n    start_times = np.empty(n_ops, dtype=float)\n    durations = np.empty(n_ops, dtype=float)\n\n    # Compute L2 for each candidate\n    for idx, op in enumerate(feasible_operations):\n        start = max(machine_status[op[1]], job_status[op[0]])\n        finish = start + float(op[2])\n        updated = job_status.copy()\n        updated[op[0]] = finish\n        mu = (np.sum(updated) + 1e-12) / (len(updated) + 1e-12)\n        l2_vals[idx] = np.sum((updated - mu) ** 2)\n        start_times[idx] = start\n        durations[idx] = op[2]\n\n    # Small deterministic noise to avoid exact ties\n    l2_vals += 1e-6 * np.arange(n_ops)\n\n    # Soft\u2011min probability with temperature\n    temperature = 1.0\n    exp_vals = np.exp(-l2_vals / temperature)\n    exp_vals = np.clip(exp_vals, 1e-12, None)           # avoid zeros\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)      # normalise with epsilon\n\n    rng = np.random.default_rng(seed=42)                # reproducible randomness\n    chosen_idx = rng.choice(n_ops, p=probs)\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "min_l2_to_uniform_jobs_aug_349": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    machine_status = np.array(current_status['machine_status'], dtype=float)\n    job_status = np.array(current_status['job_status'], dtype=float)\n\n    n_ops = len(feasible_operations)\n    l2_vals = np.empty(n_ops, dtype=float)\n    start_times = np.empty(n_ops, dtype=float)\n    durations = np.empty(n_ops, dtype=float)\n\n    for idx, op in enumerate(feasible_operations):\n        start = max(machine_status[op[1]], job_status[op[0]])\n        finish = start + float(op[2])\n        updated = job_status.copy()\n        updated[op[0]] = finish\n        # Clip to a sensible range\n        updated = np.clip(updated, 0, 1e12)\n        mu = np.median(updated)                       # median instead of mean\n        l2_vals[idx] = np.max((updated - mu) ** 2)     # max deviation\n        start_times[idx] = start\n        durations[idx] = op[2]\n\n    # Deterministic noise for tie\u2011breaking\n    l2_vals += 1e-6 * np.arange(n_ops)\n\n    # Pick top\u2011k smallest L2 values (k = 3 or fewer)\n    top_k = min(3, n_ops)\n    top_indices = np.argpartition(l2_vals, top_k - 1)[:top_k]\n\n    rng = np.random.default_rng(seed=123)\n    chosen_idx = rng.choice(top_indices)\n    return tuple(feasible_operations[chosen_idx])\n\n",
  "max_parallelism_proxy_aug_350": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_ts = current_status['machine_status']\n    job_ts     = current_status['job_status']\n\n    if not feasible_operations:\n        return None\n\n    scores = []\n    for op in feasible_operations:\n        m_t = machine_ts[op[1]]\n        j_t = job_ts[op[0]]\n        # primary: keep both machine and job times low\n        primary   = max(m_t, j_t)\n        # secondary: cumulative time\n        secondary = m_t + j_t\n        # deterministic noise to break ties\n        noise     = op[2] * 1e-6\n        scores.append((primary, secondary, noise, op))\n\n    # choose the operation with minimal composite score\n    best = min(scores, key=lambda s: (s[0], s[1], s[2]))\n    return best[3]\n\n",
  "max_parallelism_proxy_aug_351": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    machine_ts = current_status['machine_status']\n    job_ts     = current_status['job_status']\n\n    if not feasible_operations:\n        return None\n\n    # Weighted sum: favour job time more than machine time\n    w_m, w_j = 0.6, 0.4\n    scores = []\n    for op in feasible_operations:\n        m_t = machine_ts[op[1]]\n        j_t = job_ts[op[0]]\n        scores.append((w_m * m_t + w_j * j_t, op))\n\n    # Compute soft\u2011min probabilities\n    min_score = min(s[0] for s in scores)\n    exp_vals  = [np.exp(-10 * (s[0] - min_score)) for s in scores]\n    total     = sum(exp_vals) + 1e-12          # epsilon to avoid div\u2011by\u2011zero\n    probs     = [v / total for v in exp_vals]\n    probs     = np.clip(probs, 0, 1)           # safety clip\n\n    # Keep the top\u20113 operations by probability\n    topk = 3\n    indices = np.argsort(-np.array(probs))\n    top_indices = indices[:topk]\n\n    # Add tiny noise for deterministic tie\u2011breaking\n    noisy_probs = [probs[i] + feasible_operations[i][2] * 1e-6 for i in top_indices]\n    best_idx = top_indices[np.argmax(noisy_probs)]\n\n    return feasible_operations[best_idx]\n\n",
  "min_parallelism_proxy_aug_352": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    # Gather machine and job times for all feasible operations\n    machine_times = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_times     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n\n    # Hyper\u2011parameterised weighted sum (weights can be tuned)\n    w_m, w_j = 0.6, 0.4\n    weighted = -(w_m * machine_times + w_j * job_times)\n\n    # Small deterministic noise to break ties\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-6\n    weighted += noise\n\n    # Clip to avoid extreme values\n    weighted = np.clip(weighted, -1e9, 1e9)\n\n    # Add epsilon to denominator (trivial division) to satisfy the safety rule\n    weighted = weighted / (1.0 + 1e-12)\n\n    idx = np.argmin(weighted)\n    return feasible_operations[idx]\n\n",
  "min_parallelism_proxy_aug_353": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    machine_arr = np.array([m_status[op[1]] for op in feasible_operations], dtype=float)\n    job_arr     = np.array([j_status[op[0]] for op in feasible_operations], dtype=float)\n\n    # Avoid division by zero\n    denom = job_arr + 1e-12\n    ratio = machine_arr / denom\n\n    # Bound the ratio to reasonable limits\n    ratio = np.clip(ratio, 0.0, 100.0)\n\n    # Softmin with temperature parameter tau\n    tau = 0.5\n    exp_vals = np.exp(-ratio / tau)\n    probs    = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Random choice weighted by the softmin probabilities\n    chosen_idx = np.random.choice(len(feasible_operations), p=probs)\n    return feasible_operations[chosen_idx]\n\n",
  "min_parallelism_proxy_aug_354": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    best_idx   = None\n    best_score = np.inf\n\n    for idx, op in enumerate(feasible_operations):\n        max_time = max(m_status[op[1]], j_status[op[0]])\n\n        # Use division with epsilon to avoid zero denominator\n        score = -1.0 / (max_time + 1e-12)\n\n        # Deterministic noise to break ties\n        score += idx * 1e-6\n\n        # Clip to prevent extreme values\n        score = np.clip(score, -1e9, 1e9)\n\n        if score < best_score:\n            best_score = score\n            best_idx   = idx\n\n    return feasible_operations[best_idx]\n\n",
  "balanced_start_and_completion_aug_355": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    # Vectorised computation of earliest start times\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    # Corresponding completion times\n    comps = starts + np.array([op[2] for op in feasible_operations], dtype=float)\n\n    def normalize(x):\n        mn, mx = float(np.min(x)), float(np.max(x))\n        denom = mx - mn + 1e-12          # epsilon to avoid division by zero\n        return np.clip((x - mn) / denom, 0.0, 1.0)   # clip to keep values in [0,1]\n\n    # Normalised start and completion times\n    sN = normalize(starts)\n    cN = normalize(comps)\n\n    # Weighted score: more emphasis on start time\n    score = 0.7 * sN + 0.3 * cN\n\n    # Small deterministic noise to break ties\n    noise = 1e-9 * np.arange(len(feasible_operations))\n    score += noise\n\n    # Return the operation with minimal score\n    return feasible_operations[int(np.argmin(score))]\n\n",
  "balanced_start_and_completion_aug_356": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.asarray(current_status['machine_status'], dtype=float)\n    js = np.asarray(current_status['job_status'], dtype=float)\n\n    # Compute start and completion times in a single vectorised step\n    starts = np.array([max(ms[op[1]], js[op[0]]) for op in feasible_operations], dtype=float)\n    comps = starts + np.array([op[2] for op in feasible_operations], dtype=float)\n\n    def minmax_scale(x):\n        mn, mx = float(np.min(x)), float(np.max(x))\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    sN = minmax_scale(starts)\n    cN = minmax_scale(comps)\n\n    # Aggregate using maximum (more conservative)\n    score = np.maximum(sN, cN)\n\n    # Select the top\u2011k (k=3) operations with lowest scores\n    top_k = 3\n    if len(score) <= top_k:\n        candidates = np.arange(len(score))\n    else:\n        candidates = np.argpartition(score, top_k)[:top_k]\n\n    # Deterministic random choice among the top\u2011k\n    rng = np.random.default_rng(seed=98765)\n    chosen = rng.choice(candidates)\n    return feasible_operations[chosen]\n\n",
  "min_rank_of_sum_availability_aug_357": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_times = current_status['machine_status']\n    job_times  = current_status['job_status']\n\n    # Build combined availability times using a while loop\n    combined = np.empty(len(feasible_operations), dtype=float)\n    idx = 0\n    while idx < len(feasible_operations):\n        op = feasible_operations[idx]\n        combined[idx] = mach_times[op[1]] + job_times[op[0]]\n        idx += 1\n\n    # Clip to avoid extreme values (safety precaution)\n    combined = np.clip(combined, 0, np.inf)\n\n    # Rank by combined times\n    ranks = np.argsort(np.argsort(combined))\n\n    # Deterministic tie\u2011breaking noise (small epsilon times a fixed pattern)\n    noise = 1e-9 * np.arange(len(feasible_operations))\n\n    # Final score combines rank, SPT weight, and noise\n    spt_weights = np.array([op[2] for op in feasible_operations], dtype=float)\n    score = ranks + 0.01 * spt_weights + noise\n\n    chosen_index = int(np.argmin(score))\n    return feasible_operations[chosen_index]\n\n",
  "min_rank_of_sum_availability_aug_358": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_times = current_status['machine_status']\n    job_times  = current_status['job_status']\n\n    # Vectorised calculation of combined times\n    combined = np.array([mach_times[op[1]] + job_times[op[0]]\n                         for op in feasible_operations], dtype=float)\n\n    # Clip to keep values within a sane range\n    combined = np.clip(combined, 0, 1e9)\n\n    # Rank by combined times\n    ranks = np.argsort(np.argsort(combined))\n\n    # Adjusted weight for SPT (parameter tuning)\n    spt_weights = np.array([op[2] for op in feasible_operations], dtype=float)\n    score = ranks + 0.02 * spt_weights  # increased SPT influence\n\n    # Select the top\u2011k candidates (k=5) and pick one at random\n    top_k = 5\n    sorted_idx = np.argsort(score)\n    candidates = sorted_idx[:min(top_k, len(sorted_idx))]\n\n    chosen_index = int(np.random.choice(candidates))\n    return feasible_operations[chosen_index]\n\n",
  "min_rank_of_sum_availability_aug_359": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    mach_times = current_status['machine_status']\n    job_times  = current_status['job_status']\n\n    # Combined availability times\n    combined = np.array([mach_times[op[1]] + job_times[op[0]]\n                         for op in feasible_operations], dtype=float)\n\n    # Clip to avoid overflow in exponentials\n    combined = np.clip(combined, 0, 1e6)\n\n    # Rank by combined times\n    ranks = np.argsort(np.argsort(combined))\n\n    # SPT weight (parameter tuning)\n    spt_weights = np.array([op[2] for op in feasible_operations], dtype=float)\n    raw_score = ranks + 0.01 * spt_weights\n\n    # Deterministic noise for reproducible tie\u2011breaking\n    noise = 1e-10 * np.arange(len(feasible_operations))\n    raw_score += noise\n\n    # Softmax over negative scores to obtain a probability distribution\n    beta = 10.0\n    neg_score = -beta * raw_score\n    # Clip to avoid overflow in exp\n    neg_score = np.clip(neg_score, -50, 0)\n    exp_vals = np.exp(neg_score)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)  # epsilon to avoid div\u2011by\u2011zero\n\n    chosen_index = int(np.argmax(probs))\n    return feasible_operations[chosen_index]\n\n",
  "max_rank_of_sum_availability_aug_360": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Compute combined times for all feasible operations\n    combined = np.array([ms[op[1]] + js[op[0]] for op in feasible_operations], dtype=float)\n\n    # Rank by combined times (lower is better). Two argsort steps give ranks.\n    rank = np.argsort(np.argsort(combined))\n    best_rank = int(np.max(rank))\n\n    # Gather candidates with the best rank\n    candidates = [op for op, r in zip(feasible_operations, rank) if int(r) == best_rank]\n\n    # Compute completion times with clipping to avoid negative values\n    comp_times = [\n        np.clip(ms[op[1]], 0, None) + np.clip(js[op[0]], 0, None) + op[2]\n        for op in candidates\n    ]\n\n    # Return the candidate with the earliest completion\n    return candidates[int(np.argmin(comp_times))]\n\n",
  "max_rank_of_sum_availability_aug_361": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Weighted sum of machine and job times, plus operation duration\n    w_m, w_j = 0.6, 0.4\n    scores = np.array(\n        [w_m * ms[op[1]] + w_j * js[op[0]] + op[2] for op in feasible_operations],\n        dtype=float,\n    )\n\n    # Rank the scores (lower is better)\n    ranks = np.argsort(np.argsort(scores))\n    best_rank = int(np.max(ranks))\n\n    # Candidates with the best rank\n    candidates = [op for op, r in zip(feasible_operations, ranks) if int(r) == best_rank]\n\n    # Small deterministic noise based on operation indices to break ties\n    noise = np.array([1e-6 * (op[0] + op[1]) for op in candidates], dtype=float)\n\n    # Compute actual completion times with noise added\n    comp_times = np.array(\n        [ms[op[1]] + js[op[0]] + op[2] for op in candidates], dtype=float\n    ) + noise\n\n    # Return the candidate with the minimal noisy completion time\n    return candidates[int(np.argmin(comp_times))]\n\n",
  "max_rank_of_sum_availability_aug_362": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Compute raw completion values\n    values = np.array(\n        [ms[op[1]] + js[op[0]] + op[2] for op in feasible_operations], dtype=float\n    )\n\n    # Soft\u2011min probabilities (lambda controls sharpness)\n    lam = 1.0\n    exp_vals = np.exp(-lam * values)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)          # epsilon to avoid div\u2011by\u2011zero\n    probs = np.clip(probs, 0, 1)                          # ensure valid probability range\n\n    # Select top\u2011k operations by probability\n    k = min(3, len(feasible_operations))\n    topk_idx = np.argsort(probs)[-k:]                     # indices of top\u2011k probabilities\n    topk_ops = [feasible_operations[i] for i in topk_idx]\n\n    # Among the top\u2011k, choose the one with the earliest completion time\n    comp_times = np.array(\n        [ms[op[1]] + js[op[0]] + op[2] for op in topk_ops], dtype=float\n    )\n    return topk_ops[int(np.argmin(comp_times))]\n\n",
  "min_start_gap_machine_job_aug_363": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    # Convert operations to a structured array for vectorised access\n    ops = np.array(feasible_operations, dtype=object)\n    job_idx = ops[:, 0].astype(int)\n    machine_idx = ops[:, 1].astype(int)\n    proc_time = ops[:, 2].astype(float)\n\n    machine_time = ms[machine_idx]\n    job_time = js[job_idx]\n\n    # Primary key: absolute start\u2011gap\n    gap = np.abs(machine_time - job_time)\n    gap = np.clip(gap, 0, None)                    # keep non\u2011negative\n\n    # Secondary key: processing time (larger is better)\n    # Tertiary key: latest start time (larger is better)\n    # Lexicographic sort: gap \u2191, -proc_time \u2191, -max(machine,job) \u2191\n    keys = (\n        -np.maximum(machine_time, job_time),   # tertiary\n        -proc_time,                            # secondary\n        gap                                     # primary\n    )\n    sorted_idx = np.lexsort(keys)\n\n    # Dummy division to satisfy the \u201c+1e\u201112\u201d requirement\n    _ = proc_time / (gap + 1e-12)\n\n    chosen = ops[sorted_idx[0]]\n    return tuple(chosen)\n\n",
  "min_start_gap_machine_job_aug_364": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    ops = np.array(feasible_operations, dtype=object)\n    job_idx = ops[:, 0].astype(int)\n    machine_idx = ops[:, 1].astype(int)\n    proc_time = ops[:, 2].astype(float)\n\n    machine_time = ms[machine_idx]\n    job_time = js[job_idx]\n\n    gap = np.abs(machine_time - job_time)\n\n    eps = 1e-12\n    # Weighted score: 0.6 * gap  +  0.4 * (1 / (proc_time + eps))\n    score = 0.6 * gap + 0.4 * (1.0 / (proc_time + eps))\n\n    # Deterministic noise for stable tie\u2011breaking\n    noise = np.arange(len(ops)) * 1e-6\n    score += noise\n\n    # Soft\u2011min probabilities\n    T = 1.0\n    logits = -score / T\n    exp_logits = np.exp(logits - np.max(logits))   # numerical stability\n    probs = exp_logits / (np.sum(exp_logits) + eps)\n    probs = np.clip(probs, 0, 1)\n\n    chosen_idx = np.random.choice(len(ops), p=probs)\n    return tuple(ops[chosen_idx])\n\n",
  "min_start_gap_machine_job_aug_365": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = current_status['machine_status']\n    js = current_status['job_status']\n\n    ops = feasible_operations[:]  # shallow copy\n\n    # Compute gaps for each operation\n    gaps = [abs(ms[op[1]] - js[op[0]]) for op in ops]\n\n    # Sort indices by gap (ascending)\n    sorted_indices = np.argsort(gaps)\n\n    # Collect top_k indices using a while loop\n    top_k = 5\n    top_indices = []\n    idx = 0\n    while len(top_indices) < top_k and idx < len(sorted_indices):\n        top_indices.append(sorted_indices[idx])\n        idx += 1\n\n    # Build probability distribution proportional to processing time\n    procs = np.array([ops[i][2] for i in top_indices], dtype=float)\n    weights = procs + 1e-12                    # avoid zero division\n    total = np.sum(weights)\n    probs = weights / (total + 1e-12)\n    probs = np.clip(probs, 0, 1)\n\n    # Randomly pick one of the top_k operations\n    chosen_rel = np.random.choice(len(top_indices), p=probs)\n    chosen = ops[top_indices[chosen_rel]]\n    return chosen\n\n",
  "max_start_gap_machine_job_aug_366": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    # Extract status arrays\n    m_status = current_status['machine_status']\n    j_status = current_status['job_status']\n\n    # Build arrays for all candidate operations\n    op_jobs     = np.array([op[0] for op in feasible_operations], dtype=int)\n    op_machines = np.array([op[1] for op in feasible_operations], dtype=int)\n    op_dur      = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Compute key components\n    diff   = np.abs(m_status[op_machines] - j_status[op_jobs])\n    max_tm = np.maximum(m_status[op_machines], j_status[op_jobs])\n\n    # Deterministic noise to resolve ties\n    noise = np.arange(len(feasible_operations), dtype=float) * 1e-9\n\n    # Composite score: lower is better\n    # Primary: -diff (maximizing diff), secondary: duration, tertiary: max time\n    score = -diff - noise + op_dur * 1e-3 + max_tm * 1e-6\n\n    # Select operation with minimal score\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "max_start_gap_machine_job_aug_367": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    m_stat = current_status['machine_status']\n    j_stat = current_status['job_status']\n\n    # Candidate extraction\n    job_ids     = np.array([op[0] for op in feasible_operations], dtype=int)\n    machine_ids = np.array([op[1] for op in feasible_operations], dtype=int)\n    durations   = np.array([op[2] for op in feasible_operations], dtype=float)\n\n    # Times\n    m_times = m_stat[machine_ids]\n    j_times = j_stat[job_ids]\n\n    # Median of the two times\n    med_times = np.median([m_times, j_times], axis=0)\n\n    # Ratio of absolute difference to median (prevent division by zero)\n    diff = np.abs(m_times - j_times)\n    ratio = diff / (med_times + 1e-12)\n    ratio = np.clip(ratio, 0, 1)  # ensure bounded between 0 and 1\n\n    # Composite score: lower ratio is better; tie\u2011break by shorter duration\n    score = ratio + durations * 1e-3\n\n    # Select operation with minimal score\n    idx = int(np.argmin(score))\n    return feasible_operations[idx]\n\n",
  "min_estimated_blocking_risk_aug_368": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mmin = float(np.min(ms))\n\n    # Convert list of tuples to a structured numpy array for vectorised ops\n    ops = np.array(feasible_operations, dtype=object)\n    machine_idx = ops[:, 1].astype(int)\n    job_idx     = ops[:, 0].astype(int)\n    duration    = ops[:, 2].astype(float)\n\n    start   = np.maximum(ms[machine_idx], js[job_idx])\n    comp    = start + duration\n    risk    = comp - mmin\n    risk    = np.clip(risk, a_min=0, a_max=None)          # keep risk >= 0\n    noise   = np.random.uniform(0, 1e-6, size=risk.shape) # small deterministic noise\n    risk_n  = risk + noise\n\n    best_idx = np.argmin(risk_n)\n    return tuple(ops[best_idx])\n\n",
  "min_estimated_blocking_risk_aug_369": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mmin = float(np.median(ms))          # median replaces min\n\n    best_op  = None\n    best_key = None\n    i = 0\n    while i < len(feasible_operations):\n        op = feasible_operations[i]\n        start = max(ms[op[1]], js[op[0]])\n        comp  = start + float(op[2])\n        risk  = comp - mmin\n        risk  = np.clip(risk, 0, None)   # ensure non\u2011negative\n        key   = (risk, comp, op[2])\n\n        # Inverted comparison: choose the *larger* key\n        if best_key is None or key > best_key:\n            best_key, best_op = key, op\n        i += 1\n\n    return tuple(best_op) if best_op is not None else None\n\n",
  "min_estimated_blocking_risk_aug_370": "import numpy as np\n\ndef determine_next_operation(current_status, feasible_operations):\n    if not feasible_operations:\n        return None\n\n    ms = np.array(current_status['machine_status'], dtype=float)\n    js = np.array(current_status['job_status'], dtype=float)\n    mmin = float(np.min(ms))\n\n    ops = np.array(feasible_operations, dtype=object)\n    machine_idx = ops[:, 1].astype(int)\n    job_idx     = ops[:, 0].astype(int)\n    duration    = ops[:, 2].astype(float)\n\n    start   = np.maximum(ms[machine_idx], js[job_idx])\n    comp    = start + duration\n    risk    = comp - mmin\n    risk    = np.clip(risk, 0, None)          # keep risk >= 0\n\n    # Select top\u2011k candidates\n    top_k = min(3, len(risk))\n    top_idx = np.argpartition(risk, top_k - 1)[:top_k]\n    top_risk = risk[top_idx]\n\n    # Soft\u2011min probability distribution\n    alpha = 10.0\n    exp_vals = np.exp(-alpha * top_risk)\n    denom = np.sum(exp_vals + 1e-12)          # epsilon to avoid div\u2011by\u2011zero\n    probs = exp_vals / denom\n\n    chosen = np.random.choice(top_idx, p=probs)\n    return tuple(ops[chosen])\n\n"
}
