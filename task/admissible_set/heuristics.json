{
  "ones_count_sanity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer vectors whose number of 1s is closest to w (sanity/robustness).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    c = int(x.sum())\n    return -float(abs(c - w))\n",
  "lexicographic_earliest_ones": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer earlier 1 positions (left-heavy supports).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    return -float(idx.sum())\n",
  "lexicographic_latest_ones": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer later 1 positions (right-heavy supports).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    return float(idx.sum())\n",
  "center_mass_closest_to_middle": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer center-of-mass of 1s close to the middle index.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    cm = float(idx.mean())\n    mid = 0.5 * (n - 1)\n    return -float(abs(cm - mid))\n",
  "center_mass_far_from_middle": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer center-of-mass far from middle (edge-biased).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    cm = float(idx.mean())\n    mid = 0.5 * (n - 1)\n    return float(abs(cm - mid))\n",
  "spread_maximize_span": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Maximize span between first and last 1 (wide coverage).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    return float(idx.max() - idx.min())\n",
  "spread_minimize_span": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Minimize span between first and last 1 (compact support).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    return -float(idx.max() - idx.min())\n",
  "gap_variance_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer nearly-uniform gaps between successive 1 positions (low gap variance).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size <= 2:\n        return 0.0\n    gaps = np.diff(idx)\n    return -float(np.var(gaps))\n",
  "gap_variance_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer irregular gaps between 1 positions (high gap variance).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size <= 2:\n        return 0.0\n    gaps = np.diff(idx)\n    return float(np.var(gaps))\n",
  "max_run_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize long consecutive runs of 1s (lower max run is better).\"\"\"\n    best = 0\n    cur = 0\n    for b in el[:n]:\n        if b:\n            cur += 1\n            if cur > best:\n                best = cur\n        else:\n            cur = 0\n    return -float(best)\n",
  "max_run_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward long consecutive runs of 1s (higher max run is better).\"\"\"\n    best = 0\n    cur = 0\n    for b in el[:n]:\n        if b:\n            cur += 1\n            if cur > best:\n                best = cur\n        else:\n            cur = 0\n    return float(best)\n",
  "alternation_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward frequent bit alternations (0101...), discourages flat structure.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    return float(np.sum(x[1:] != x[:-1]))\n",
  "alternation_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize frequent alternations (prefer smoother blocks).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    return -float(np.sum(x[1:] != x[:-1]))\n",
  "autocorrelation_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low cyclic autocorrelation (treat 1 as +1, 0 as -1).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    s = 0.0\n    for shift in range(1, N):\n        s += abs(float(np.dot(x, np.roll(x, shift))))\n    return -float(s / (N * max(1, N - 1)))\n",
  "autocorrelation_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high cyclic autocorrelation (periodic/structured patterns).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    s = 0.0\n    for shift in range(1, N):\n        s += abs(float(np.dot(x, np.roll(x, shift))))\n    return float(s / (N * max(1, N - 1)))\n",
  "residue_class_diversity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward using many residue classes modulo small numbers (index-spread proxy).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if not idx:\n        return -1e9\n    score = 0.0\n    for m in (3, 4, 5, 7):\n        score += len(set(i % m for i in idx)) / float(m)\n    return float(score)\n",
  "prime_index_bonus": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward 1s at prime indices (simple structured diversity).\"\"\"\n    def is_prime(k: int) -> bool:\n        if k < 2:\n            return False\n        if k % 2 == 0:\n            return k == 2\n        r = int(math.isqrt(k))\n        f = 3\n        while f <= r:\n            if k % f == 0:\n                return False\n            f += 2\n        return True\n\n    s = 0.0\n    for i, b in enumerate(el[:n]):\n        if b and is_prime(i):\n            s += 1.0\n    return float(s)\n",
  "power_of_two_index_bonus": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward 1s at power-of-two indices (basis-like structure).\"\"\"\n    s = 0.0\n    for i, b in enumerate(el[:n]):\n        if b and i > 0 and (i & (i - 1)) == 0:\n            s += 1.0\n    return float(s)\n",
  "gray_code_smoothness": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer patterns whose 1-index list changes smoothly (small successive index jumps).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 1:\n        return 0.0\n    idx.sort()\n    jumps = [abs(idx[i+1] - idx[i]) for i in range(len(idx)-1)]\n    return -float(sum(jumps))\n",
  "edge_mass_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward putting 1s near edges (0 and n-1) rather than center.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    mid = 0.5 * (n - 1)\n    return float(np.sum(np.abs(idx - mid)))\n",
  "center_mass_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward putting 1s near the center (clustered around mid).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return -1e9\n    mid = 0.5 * (n - 1)\n    return -float(np.sum(np.abs(idx - mid)))\n",
  "fourier_highfreq_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer higher-frequency energy in the DFT magnitude of +/-1 signal.\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size == 0:\n        return 0.0\n    X = np.fft.rfft(x)\n    mag2 = (X.real * X.real + X.imag * X.imag)\n    if mag2.size <= 2:\n        return 0.0\n    cut = max(1, mag2.size // 3)\n    high = float(np.sum(mag2[cut:]))\n    tot = float(np.sum(mag2) + 1e-12)\n    return float(high / tot)\n",
  "fourier_lowfreq_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer lower-frequency energy in the DFT magnitude of +/-1 signal.\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size == 0:\n        return 0.0\n    X = np.fft.rfft(x)\n    mag2 = (X.real * X.real + X.imag * X.imag)\n    if mag2.size <= 2:\n        return 0.0\n    cut = max(1, mag2.size // 3)\n    low = float(np.sum(mag2[:cut]))\n    tot = float(np.sum(mag2) + 1e-12)\n    return float(low / tot)\n",
  "hash_based_tiebreaker": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Deterministic pseudo-random score from the bit pattern (useful as a tie-breaker).\"\"\"\n    m = 0\n    for i, b in enumerate(el[:n]):\n        if b:\n            m |= (1 << i)\n    # 64-bit mix\n    x = (m ^ (m >> 33)) & ((1 << 64) - 1)\n    x = (x * 0xff51afd7ed558ccd) & ((1 << 64) - 1)\n    x = (x ^ (x >> 33)) & ((1 << 64) - 1)\n    x = (x * 0xc4ceb9fe1a85ec53) & ((1 << 64) - 1)\n    x = (x ^ (x >> 33)) & ((1 << 64) - 1)\n    return float(x / float(1 << 64))\n",
  "alternating_parity_balance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer balanced number of 1s on even vs odd indices.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    even = int(x[0::2].sum())\n    odd = int(x[1::2].sum())\n    return -float(abs(even - odd))\n",
  "mirror_symmetry_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward symmetry: bits match their mirror positions.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size == 0:\n        return 0.0\n    return float(np.sum(x == x[::-1]))\n",
  "mirror_symmetry_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize symmetry: prefer asymmetric patterns.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size == 0:\n        return 0.0\n    return -float(np.sum(x == x[::-1]))\n",
  "palindrome_ones_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward palindromic support (1-positions mirror).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size == 0:\n        return 0.0\n    mir = (n - 1) - idx\n    # how many mirrored indices are also ones\n    s = set(int(i) for i in idx)\n    return float(sum(1 for i in mir if int(i) in s))\n",
  "boundary_transition_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward having transitions near boundaries (encourages edge diversity).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    t = (x[1:] != x[:-1]).astype(np.int8)\n    # weight transitions closer to edges more\n    pos = np.arange(t.size)\n    edge_dist = np.minimum(pos, (t.size - 1) - pos)\n    wts = 1.0 / (1.0 + edge_dist)\n    return float(np.dot(t.astype(float), wts))\n",
  "boundary_transition_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize transitions near boundaries (prefer stable edges).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    t = (x[1:] != x[:-1]).astype(np.int8)\n    pos = np.arange(t.size)\n    edge_dist = np.minimum(pos, (t.size - 1) - pos)\n    wts = 1.0 / (1.0 + edge_dist)\n    return -float(np.dot(t.astype(float), wts))\n",
  "normalized_l1_variation": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Total variation (L1) normalized by n (encourages richer structure).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    tv = float(np.sum(np.abs(x[1:] - x[:-1])))\n    return tv / float(max(1, x.size - 1))\n",
  "normalized_l1_variation_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low total variation (smoother, blocky patterns).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 1:\n        return 0.0\n    tv = float(np.sum(np.abs(x[1:] - x[:-1])))\n    return -tv / float(max(1, x.size - 1))\n",
  "zeros_run_balance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer balanced zero-run lengths (uniform spacing of 1-blocks).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    # compute zero-run lengths\n    runs = []\n    cur = 0\n    for b in x:\n        if b == 0:\n            cur += 1\n        else:\n            if cur > 0:\n                runs.append(cur)\n            cur = 0\n    if cur > 0:\n        runs.append(cur)\n    if len(runs) <= 1:\n        return 0.0\n    return -float(np.var(np.asarray(runs, dtype=float)))\n",
  "ones_run_balance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer balanced one-run lengths (uniform block sizes).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    runs = []\n    cur = 0\n    for b in x:\n        if b == 1:\n            cur += 1\n        else:\n            if cur > 0:\n                runs.append(cur)\n            cur = 0\n    if cur > 0:\n        runs.append(cur)\n    if len(runs) <= 1:\n        return 0.0\n    return -float(np.var(np.asarray(runs, dtype=float)))\n",
  "circular_gap_uniformity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Uniformity of circular gaps (treat indices modulo n).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size <= 1:\n        return 0.0\n    idx = np.sort(idx)\n    gaps = np.diff(idx)\n    gaps = np.append(gaps, (idx[0] + n) - idx[-1])\n    return -float(np.var(gaps.astype(float)))\n",
  "circular_gap_irregularity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer irregular circular gaps (diverse cyclic structure).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size <= 1:\n        return 0.0\n    idx = np.sort(idx)\n    gaps = np.diff(idx)\n    gaps = np.append(gaps, (idx[0] + n) - idx[-1])\n    return float(np.var(gaps.astype(float)))\n",
  "pairwise_distance_from_arithmetic_progressions": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize supports that contain many 3-term arithmetic progressions.\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    s = set(idx)\n    cnt = 0\n    m = len(idx)\n    for a_i in range(m):\n        for b_i in range(a_i + 1, m):\n            a = idx[a_i]\n            b = idx[b_i]\n            c2 = 2*b - a\n            if 0 <= c2 < n and c2 in s:\n                cnt += 1\n    return -float(cnt)\n",
  "arithmetic_progression_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward supports that contain many 3-term arithmetic progressions (structured).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    s = set(idx)\n    cnt = 0\n    m = len(idx)\n    for a_i in range(m):\n        for b_i in range(a_i + 1, m):\n            a = idx[a_i]\n            b = idx[b_i]\n            c2 = 2*b - a\n            if 0 <= c2 < n and c2 in s:\n                cnt += 1\n    return float(cnt)\n",
  "avoid_small_periodicity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize small-period repetition by checking mismatches for periods 1..min(8,n//2).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 2:\n        return 0.0\n    Pmax = int(min(8, x.size // 2))\n    if Pmax < 1:\n        return 0.0\n    best_match = 0.0\n    for p in range(1, Pmax + 1):\n        y = np.roll(x, p)\n        match = float(np.mean(x == y))\n        if match > best_match:\n            best_match = match\n    return -best_match\n",
  "prefer_small_periodicity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward small-period repetition by checking matches for periods 1..min(8,n//2).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size <= 2:\n        return 0.0\n    Pmax = int(min(8, x.size // 2))\n    if Pmax < 1:\n        return 0.0\n    best_match = 0.0\n    for p in range(1, Pmax + 1):\n        y = np.roll(x, p)\n        match = float(np.mean(x == y))\n        if match > best_match:\n            best_match = match\n    return best_match\n",
  "weighted_edge_ones": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Heavily reward 1s near edges using a convex weight profile.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    pos = np.arange(x.size)\n    d = np.minimum(pos, (x.size - 1) - pos).astype(float)\n    wts = 1.0 / (1.0 + d*d)\n    return float(np.dot(x.astype(float), wts))\n",
  "weighted_center_ones": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Heavily reward 1s near center using a convex weight profile.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    pos = np.arange(x.size)\n    mid = 0.5 * (x.size - 1)\n    d = np.abs(pos - mid).astype(float)\n    wts = 1.0 / (1.0 + d*d)\n    return float(np.dot(x.astype(float), wts))\n",
  "binomial_loglik_peak_mid": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Score by log-likelihood under position-dependent Bernoulli peaking at center.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    pos = np.arange(x.size).astype(float)\n    mid = 0.5 * (x.size - 1)\n    # peak at center, min near edges\n    p = 0.15 + 0.70 * (1.0 - (np.abs(pos - mid) / max(1.0, mid)))\n    p = np.clip(p, 1e-6, 1 - 1e-6)\n    ll = x * np.log(p) + (1 - x) * np.log(1 - p)\n    return float(ll.sum())\n",
  "binomial_loglik_peak_edges": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Score by log-likelihood under position-dependent Bernoulli peaking at edges.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    pos = np.arange(x.size).astype(float)\n    mid = 0.5 * (x.size - 1)\n    # peak at edges, low at center\n    p = 0.15 + 0.70 * (np.abs(pos - mid) / max(1.0, mid))\n    p = np.clip(p, 1e-6, 1 - 1e-6)\n    ll = x * np.log(p) + (1 - x) * np.log(1 - p)\n    return float(ll.sum())\n",
  "minhash_signature_spread": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Compute several simple minhashes of the support; reward large spread among them.\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if not idx:\n        return -1e9\n    idx = np.asarray(idx, dtype=np.int64)\n    # simple universal hashes: (a*i + b) mod large\n    P = 2147483647\n    hashes = []\n    params = [(3, 17), (5, 23), (7, 31), (11, 41), (13, 47), (17, 59)]\n    for a, b in params:\n        h = (a * idx + b) % P\n        hashes.append(int(h.min()))\n    hashes = np.asarray(hashes, dtype=np.int64)\n    return float(hashes.max() - hashes.min())\n",
  "support_second_moment": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward higher second moment of 1 positions (push mass outward).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x).astype(float)\n    if idx.size == 0:\n        return -1e9\n    mid = 0.5 * (n - 1)\n    return float(np.mean((idx - mid) ** 2))\n",
  "support_second_moment_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward lower second moment of 1 positions (pull mass inward).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x).astype(float)\n    if idx.size == 0:\n        return -1e9\n    mid = 0.5 * (n - 1)\n    return -float(np.mean((idx - mid) ** 2))\n",
  "low_discrete_laplacian_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low Laplacian energy (smoothness): sum (x[i-1]-2x[i]+x[i+1])^2.\"\"\"\n    x = np.asarray(el[:n], dtype=float)\n    if x.size < 3:\n        return 0.0\n    lap = x[:-2] - 2.0 * x[1:-1] + x[2:]\n    return -float(np.sum(lap * lap))\n",
  "high_discrete_laplacian_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high Laplacian energy (wiggliness).\"\"\"\n    x = np.asarray(el[:n], dtype=float)\n    if x.size < 3:\n        return 0.0\n    lap = x[:-2] - 2.0 * x[1:-1] + x[2:]\n    return float(np.sum(lap * lap))\n",
  "circular_convolution_peakiness": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Compute circular autocorrelation via FFT; reward low peakiness (flatter is better).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size <= 1:\n        return 0.0\n    X = np.fft.fft(x)\n    ac = np.fft.ifft(X * np.conj(X)).real\n    # exclude zero-shift peak; measure how dominant the max sidelobe is\n    sidelobes = np.asarray(ac[1:], dtype=float)\n    if sidelobes.size == 0:\n        return 0.0\n    peak = float(np.max(np.abs(sidelobes)))\n    avg = float(np.mean(np.abs(sidelobes)) + 1e-12)\n    return -float(peak / avg)\n",
  "circular_convolution_peakiness_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward high autocorrelation peakiness (structured/periodic).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size <= 1:\n        return 0.0\n    X = np.fft.fft(x)\n    ac = np.fft.ifft(X * np.conj(X)).real\n    sidelobes = np.asarray(ac[1:], dtype=float)\n    if sidelobes.size == 0:\n        return 0.0\n    peak = float(np.max(np.abs(sidelobes)))\n    avg = float(np.mean(np.abs(sidelobes)) + 1e-12)\n    return float(peak / avg)\n",
  "triple_gap_signature_entropy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Entropy of binned gaps (encourages rich gap distribution).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    idx = np.flatnonzero(x)\n    if idx.size <= 2:\n        return 0.0\n    gaps = np.diff(np.sort(idx))\n    # bin gaps into {1,2,3,>=4}\n    bins = np.minimum(gaps, 4)\n    counts = np.bincount(bins, minlength=5).astype(float)\n    p = counts / float(np.sum(counts) + 1e-12)\n    p = p[p > 0]\n    H = -float(np.sum(p * np.log2(p)))\n    return H\n",
  "rle_compressibility_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer patterns that compress well under run-length encoding (more regular).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size == 0:\n        return 0.0\n    runs = 1\n    for i in range(1, x.size):\n        if x[i] != x[i-1]:\n            runs += 1\n    # fewer runs => more compressible\n    return -float(runs)\n",
  "rle_compressibility_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer patterns that compress poorly under run-length encoding (higher complexity).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size == 0:\n        return 0.0\n    runs = 1\n    for i in range(1, x.size):\n        if x[i] != x[i-1]:\n            runs += 1\n    # more runs => more complex\n    return float(runs)\n",
  "lz78_complexity_proxy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"LZ78-like dictionary growth as a small-string complexity proxy.\"\"\"\n    s = ''.join('1' if b else '0' for b in el[:n])\n    dic = set()\n    i = 0\n    phrases = 0\n    while i < len(s):\n        j = i + 1\n        while j <= len(s) and s[i:j] in dic:\n            j += 1\n        dic.add(s[i:j])\n        phrases += 1\n        i = j\n    return float(phrases)\n",
  "bit_entropy_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Shannon entropy of bit distribution (max near 50/50).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if x.size == 0:\n        return 0.0\n    p = float(x.mean())\n    p = min(max(p, 1e-12), 1 - 1e-12)\n    H = -(p * math.log2(p) + (1 - p) * math.log2(1 - p))\n    return float(H)\n",
  "prefix_random_walk_balance_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Treat 1->+1, 0->-1; prefer low max prefix deviation (balanced walk).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    walk = np.cumsum(np.where(x == 1, 1, -1))\n    if walk.size == 0:\n        return 0.0\n    return -float(np.max(np.abs(walk)))\n",
  "prefix_random_walk_balance_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high max prefix deviation (front-loaded structure).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    walk = np.cumsum(np.where(x == 1, 1, -1))\n    if walk.size == 0:\n        return 0.0\n    return float(np.max(np.abs(walk)))\n",
  "longest_zero_run_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward having a long contiguous zero-run (big empty interval).\"\"\"\n    best = 0\n    cur = 0\n    for b in el[:n]:\n        if not b:\n            cur += 1\n            if cur > best:\n                best = cur\n        else:\n            cur = 0\n    return float(best)\n",
  "longest_zero_run_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize having a long contiguous zero-run (avoid large gaps).\"\"\"\n    best = 0\n    cur = 0\n    for b in el[:n]:\n        if not b:\n            cur += 1\n            if cur > best:\n                best = cur\n        else:\n            cur = 0\n    return -float(best)\n",
  "min_gap_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward large minimum gap between consecutive 1s (spreading).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 1:\n        return 0.0\n    idx.sort()\n    ming = min(idx[i+1] - idx[i] for i in range(len(idx)-1))\n    return float(ming)\n",
  "min_gap_penalty": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize large minimum gap (encourage clumping).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 1:\n        return 0.0\n    idx.sort()\n    ming = min(idx[i+1] - idx[i] for i in range(len(idx)-1))\n    return -float(ming)\n",
  "gaps_gcd_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward gap GCD close to 1 (avoids strong periodic lattices).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 2:\n        return 0.0\n    idx.sort()\n    g = 0\n    for i in range(len(idx)-1):\n        d = idx[i+1] - idx[i]\n        g = math.gcd(g, d)\n    # prefer gcd=1 -> higher score\n    return 1.0 / float(max(1, g))\n",
  "gaps_gcd_periodicity_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward large gap GCD (strong periodic structure).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 2:\n        return 0.0\n    idx.sort()\n    g = 0\n    for i in range(len(idx)-1):\n        d = idx[i+1] - idx[i]\n        g = math.gcd(g, d)\n    return float(g)\n",
  "spectral_flatness_fft": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Spectral flatness of +/-1 signal (flatter ~ noise-like).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size == 0:\n        return 0.0\n    X = np.fft.rfft(x)\n    p = (X.real * X.real + X.imag * X.imag) + 1e-12\n    gmean = float(np.exp(np.mean(np.log(p))))\n    amean = float(np.mean(p))\n    return float(gmean / amean)\n",
  "spectral_centroid_fft": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Spectral centroid of +/-1 signal (higher means more high-frequency content).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size <= 1:\n        return 0.0\n    X = np.fft.rfft(x)\n    p = (X.real * X.real + X.imag * X.imag) + 1e-12\n    freqs = np.arange(p.size, dtype=float)\n    return float(np.dot(freqs, p) / float(np.sum(p)))\n",
  "spectral_rolloff_85": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Spectral rolloff index where 85% of energy is accumulated (higher -> more high-freq).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size <= 1:\n        return 0.0\n    X = np.fft.rfft(x)\n    p = (X.real * X.real + X.imag * X.imag) + 1e-12\n    c = np.cumsum(p)\n    thr = 0.85 * float(c[-1])\n    k = int(np.searchsorted(c, thr))\n    return float(k)\n",
  "dct2_highfreq_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"High-frequency energy using a simple DCT-II (no external libs).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    k = np.arange(N, dtype=float)\n    n0 = np.arange(N, dtype=float)\n    C = np.cos((math.pi / N) * (n0[:, None] + 0.5) * k[None, :])\n    X = C.T @ x\n    E = (X * X)\n    cut = max(1, N // 3)\n    return float(np.sum(E[cut:]) / float(np.sum(E) + 1e-12))\n",
  "chirp_correlation_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize correlation with a fixed quadratic-phase chirp (avoid that structure).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    t = np.arange(N, dtype=float)\n    chirp = np.cos(2.0 * math.pi * (t * t) / float(max(1, N)))\n    corr = float(abs(np.dot(x, chirp)))\n    return -corr / float(N)\n",
  "chirp_correlation_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward correlation with a fixed quadratic-phase chirp (seek that structure).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    t = np.arange(N, dtype=float)\n    chirp = np.cos(2.0 * math.pi * (t * t) / float(max(1, N)))\n    corr = float(abs(np.dot(x, chirp)))\n    return corr / float(N)\n",
  "star_discrepancy_proxy_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Low-discrepancy proxy: ones as points in [0,1]; prefer low max CDF deviation.\"\"\"\n    idx = sorted([i for i, b in enumerate(el[:n]) if b])\n    m = len(idx)\n    if m == 0:\n        return -1e9\n    pts = np.asarray([(i + 0.5) / float(n) for i in idx], dtype=float)\n    # empirical CDF deviation at points\n    dev = 0.0\n    for j, u in enumerate(pts, start=1):\n        dev = max(dev, abs((j / float(m)) - u), abs(((j - 1) / float(m)) - u))\n    return -float(dev)\n",
  "star_discrepancy_proxy_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Opposite of low-discrepancy: prefer high max CDF deviation (clumped).\"\"\"\n    idx = sorted([i for i, b in enumerate(el[:n]) if b])\n    m = len(idx)\n    if m == 0:\n        return -1e9\n    pts = np.asarray([(i + 0.5) / float(n) for i in idx], dtype=float)\n    dev = 0.0\n    for j, u in enumerate(pts, start=1):\n        dev = max(dev, abs((j / float(m)) - u), abs(((j - 1) / float(m)) - u))\n    return float(dev)\n",
  "latin_bins_one_per_bin": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Split into w bins; reward having ~1 one per bin (coverage-like).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    if w <= 0 or x.size == 0:\n        return 0.0\n    bins = int(min(w, x.size))\n    edges = np.linspace(0, x.size, bins + 1).astype(int)\n    score = 0.0\n    for i in range(bins):\n        c = int(x[edges[i]:edges[i+1]].sum())\n        score -= float(abs(c - 1))\n    return float(score)\n",
  "window_uniqueness_k4": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Count unique length-4 windows (higher suggests richer local patterns).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    L = 4\n    if x.size < L:\n        return 0.0\n    seen = set()\n    for i in range(0, x.size - L + 1):\n        # pack into int\n        v = 0\n        for j in range(L):\n            v = (v << 1) | int(x[i + j])\n        seen.add(v)\n    return float(len(seen))\n",
  "window_uniqueness_k6": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Count unique length-6 windows (richer local patterns at larger scale).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    L = 6\n    if x.size < L:\n        return 0.0\n    seen = set()\n    for i in range(0, x.size - L + 1):\n        v = 0\n        for j in range(L):\n            v = (v << 1) | int(x[i + j])\n        seen.add(v)\n    return float(len(seen))\n",
  "mask_hash_variance_family": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Compute several deterministic mixed hashes of the bitmask; reward high variance/spread.\"\"\"\n    m = 0\n    for i, b in enumerate(el[:n]):\n        if b:\n            m |= (1 << i)\n    def mix64(x: int) -> int:\n        x &= (1 << 64) - 1\n        x ^= (x >> 30)\n        x = (x * 0xbf58476d1ce4e5b9) & ((1 << 64) - 1)\n        x ^= (x >> 27)\n        x = (x * 0x94d049bb133111eb) & ((1 << 64) - 1)\n        x ^= (x >> 31)\n        return x\n    hs = []\n    for s in (0x9e3779b97f4a7c15, 0x243f6a8885a308d3, 0xb7e151628aed2a6b, 0x3c6ef372fe94f82b, 0xa54ff53a5f1d36f1):\n        hs.append(mix64(m ^ s))\n    a = np.asarray(hs, dtype=np.float64)\n    return float(np.std(a) / (np.mean(a) + 1e-12))\n",
  "bit_reversal_balance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Compare pattern to its bit-reversal permutation; reward similarity (self-similar) or dissimilarity by toggling sign.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    # bit-reversal indices for length N (not necessarily power-of-two): reverse bits of i in enough bits, then mod N\n    b = int(math.ceil(math.log2(max(1, N))))\n    perm = []\n    for i in range(N):\n        r = 0\n        v = i\n        for _ in range(b):\n            r = (r << 1) | (v & 1)\n            v >>= 1\n        perm.append(r % N)\n    y = x[np.asarray(perm, dtype=int)]\n    return float(np.sum(x == y))\n",
  "kernel_convolution_variance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Convolve with a fixed kernel; reward high output variance (responsive structure).\"\"\"\n    x = np.asarray(el[:n], dtype=float)\n    if x.size == 0:\n        return 0.0\n    k = np.asarray([1.0, -2.0, 3.0, -2.0, 1.0], dtype=float)\n    y = np.convolve(x, k, mode='same')\n    return float(np.var(y))\n",
  "kernel_convolution_variance_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Convolve with a fixed kernel; reward low output variance (stable structure).\"\"\"\n    x = np.asarray(el[:n], dtype=float)\n    if x.size == 0:\n        return 0.0\n    k = np.asarray([1.0, -2.0, 3.0, -2.0, 1.0], dtype=float)\n    y = np.convolve(x, k, mode='same')\n    return -float(np.var(y))\n",
  "quadratic_form_pseudorandom": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Deterministic pseudo-random quadratic form x^T A x (fixed by n) as a scoring landscape.\"\"\"\n    x = np.asarray(el[:n], dtype=float)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    # build a deterministic symmetric matrix A using a hash-like generator\n    A = np.zeros((N, N), dtype=float)\n    seed = 1469598103934665603  # FNV offset basis\n    for i in range(N):\n        for j in range(i, N):\n            v = (seed ^ (i * 1315423911) ^ (j * 2654435761)) & ((1 << 64) - 1)\n            v ^= (v >> 33)\n            v = (v * 0xff51afd7ed558ccd) & ((1 << 64) - 1)\n            v ^= (v >> 33)\n            # map to [-1,1]\n            a = ((v / float(1 << 64)) * 2.0) - 1.0\n            A[i, j] = a\n            A[j, i] = a\n    return float(x @ A @ x)\n",
  "two_level_block_uniformity": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Measure uniformity across coarse blocks and fine blocks; reward being balanced at both scales.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    # coarse: 3 blocks\n    Bc = 3\n    edges_c = np.linspace(0, N, Bc + 1).astype(int)\n    coarse = np.array([int(x[edges_c[i]:edges_c[i+1]].sum()) for i in range(Bc)], dtype=float)\n    # fine: 5 blocks (or fewer)\n    Bf = int(min(5, N))\n    edges_f = np.linspace(0, N, Bf + 1).astype(int)\n    fine = np.array([int(x[edges_f[i]:edges_f[i+1]].sum()) for i in range(Bf)], dtype=float)\n    # target per-block count proportional to length\n    targ_c = np.array([(edges_c[i+1] - edges_c[i]) * (w / float(N)) for i in range(Bc)], dtype=float)\n    targ_f = np.array([(edges_f[i+1] - edges_f[i]) * (w / float(N)) for i in range(Bf)], dtype=float)\n    err = float(np.sum(np.abs(coarse - targ_c)) + np.sum(np.abs(fine - targ_f)))\n    return -err\n",
  "sparse_derivative_energy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Energy of first derivative of +/-1 signal; favors textured patterns without full noise.\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size <= 1:\n        return 0.0\n    d = x[1:] - x[:-1]\n    return float(np.sum(d * d) / float(x.size - 1))\n",
  "balanced_k_blocks_k_equals_w": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Split indices into w blocks; reward having exactly 1 one per block (fine-grained spread).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0 or w <= 0:\n        return 0.0\n    B = int(min(w, N))\n    edges = np.linspace(0, N, B + 1).astype(int)\n    score = 0.0\n    for i in range(B):\n        c = int(x[edges[i]:edges[i+1]].sum())\n        score -= float(abs(c - 1))\n    return float(score)\n",
  "balanced_k_blocks_k_equals_w_coarse": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Split indices into ceil(w/2) blocks; reward matching expected ones per block.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    B = int(min(N, max(1, int(math.ceil(w / 2.0)))))\n    edges = np.linspace(0, N, B + 1).astype(int)\n    p = w / float(N)\n    score = 0.0\n    for i in range(B):\n        L = int(edges[i+1] - edges[i])\n        targ = p * L\n        c = float(np.sum(x[edges[i]:edges[i+1]]))\n        score -= abs(c - targ)\n    return float(score)\n",
  "balanced_sliding_window_counts": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward uniform density across all length-k windows (k ~= n/3).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    k = int(max(2, round(N / 3)))\n    if N < k:\n        return 0.0\n    targ = (w / float(N)) * k\n    # sliding sums\n    s = np.convolve(x.astype(float), np.ones(k, dtype=float), mode='valid')\n    return -float(np.mean(np.abs(s - targ)))\n",
  "max_sliding_window_deviation_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low worst-case window deviation from expected density.\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    k = int(max(2, round(N / 4)))\n    if N < k:\n        return 0.0\n    targ = (w / float(N)) * k\n    s = np.convolve(x.astype(float), np.ones(k, dtype=float), mode='valid')\n    return -float(np.max(np.abs(s - targ)))\n",
  "max_sliding_window_deviation_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high worst-case window deviation (strong local concentration).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    k = int(max(2, round(N / 4)))\n    if N < k:\n        return 0.0\n    targ = (w / float(N)) * k\n    s = np.convolve(x.astype(float), np.ones(k, dtype=float), mode='valid')\n    return float(np.max(np.abs(s - targ)))\n",
  "min_window_count_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward high minimum ones across all windows (avoid empty windows).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    k = int(max(2, round(N / 3)))\n    if N < k:\n        return 0.0\n    s = np.convolve(x.astype(float), np.ones(k, dtype=float), mode='valid')\n    return float(np.min(s))\n",
  "max_window_count_reward": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward high maximum ones in any window (seek dense clusters).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    k = int(max(2, round(N / 3)))\n    if N < k:\n        return 0.0\n    s = np.convolve(x.astype(float), np.ones(k, dtype=float), mode='valid')\n    return float(np.max(s))\n",
  "autocorr_sidelobe_rms_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low RMS of autocorrelation sidelobes (sequence-design style).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    X = np.fft.fft(x)\n    ac = np.fft.ifft(X * np.conj(X)).real\n    sidelobes = ac[1:]\n    rms = float(np.sqrt(np.mean(sidelobes * sidelobes)))\n    return -rms\n",
  "autocorr_sidelobe_rms_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high RMS of autocorrelation sidelobes (more structured).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    X = np.fft.fft(x)\n    ac = np.fft.ifft(X * np.conj(X)).real\n    sidelobes = ac[1:]\n    rms = float(np.sqrt(np.mean(sidelobes * sidelobes)))\n    return rms\n",
  "max_cyclic_shift_match_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Penalize being similar to any nontrivial cyclic shift of itself (avoid periodicity).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    best = 0.0\n    for s in range(1, N):\n        y = np.roll(x, s)\n        best = max(best, float(np.mean(x == y)))\n    return -best\n",
  "max_cyclic_shift_match_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward being similar to some cyclic shift (periodic/self-similar patterns).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N <= 1:\n        return 0.0\n    best = 0.0\n    for s in range(1, N):\n        y = np.roll(x, s)\n        best = max(best, float(np.mean(x == y)))\n    return best\n",
  "support_spacing_geometric_mean": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward large geometric mean of gaps between successive ones.\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 1:\n        return 0.0\n    idx.sort()\n    gaps = [idx[i+1] - idx[i] for i in range(len(idx)-1)]\n    gaps = np.asarray(gaps, dtype=float)\n    return float(np.exp(np.mean(np.log(gaps + 1e-12))))\n",
  "support_spacing_harmonic_mean": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Reward large harmonic mean of gaps (penalizes tiny gaps strongly).\"\"\"\n    idx = [i for i, b in enumerate(el[:n]) if b]\n    if len(idx) <= 1:\n        return 0.0\n    idx.sort()\n    gaps = [idx[i+1] - idx[i] for i in range(len(idx)-1)]\n    gaps = np.asarray(gaps, dtype=float)\n    return float(len(gaps) / float(np.sum(1.0 / (gaps + 1e-12))))\n",
  "moment_matching_third_central": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low skew (3rd central moment) of 1-index distribution.\"\"\"\n    idx = np.asarray([i for i, b in enumerate(el[:n]) if b], dtype=float)\n    if idx.size == 0:\n        return -1e9\n    m = float(np.mean(idx))\n    c3 = float(np.mean((idx - m) ** 3))\n    return -abs(c3)\n",
  "moment_matching_kurtosis_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer low kurtosis (less peaky) of 1-index distribution.\"\"\"\n    idx = np.asarray([i for i, b in enumerate(el[:n]) if b], dtype=float)\n    if idx.size < 2:\n        return 0.0\n    m = float(np.mean(idx))\n    v = float(np.mean((idx - m) ** 2) + 1e-12)\n    c4 = float(np.mean((idx - m) ** 4))\n    kurt = c4 / (v * v)\n    return -kurt\n",
  "moment_matching_kurtosis_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer high kurtosis (peaky clusters) of 1-index distribution.\"\"\"\n    idx = np.asarray([i for i, b in enumerate(el[:n]) if b], dtype=float)\n    if idx.size < 2:\n        return 0.0\n    m = float(np.mean(idx))\n    v = float(np.mean((idx - m) ** 2) + 1e-12)\n    c4 = float(np.mean((idx - m) ** 4))\n    kurt = c4 / (v * v)\n    return kurt\n",
  "bits_as_integer_midrange": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Interpret bits as integer; prefer values near the middle of range (anti-extreme).\"\"\"\n    N = int(min(n, len(el)))\n    m = 0\n    for i in range(N):\n        if el[i]:\n            m |= (1 << i)\n    mid = (1 << max(1, N - 1))\n    return -float(abs(m - mid))\n",
  "bits_as_integer_extreme": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Interpret bits as integer; prefer extremes (near 0 or near max).\"\"\"\n    N = int(min(n, len(el)))\n    m = 0\n    for i in range(N):\n        if el[i]:\n            m |= (1 << i)\n    mx = (1 << N) - 1\n    return float(max(m, mx - m))\n",
  "monte_carlo_projection_variance": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Project +/-1 signal onto a few deterministic random directions; reward high variance of projections.\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    # deterministic RNG seed from bits\n    seed = 0\n    for i, b in enumerate(el[:n]):\n        if b:\n            seed ^= (0x9e3779b97f4a7c15 ^ (i * 0xBF58476D1CE4E5B9)) & ((1 << 64) - 1)\n    rng = np.random.default_rng(seed % (1 << 32))\n    K = int(min(12, max(3, N)))\n    proj = []\n    for _ in range(K):\n        r = rng.normal(size=N)\n        proj.append(float(np.dot(x, r)))\n    proj = np.asarray(proj, dtype=float)\n    return float(np.var(proj))\n",
  "sign_changes_in_derivative": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Count sign-changes in first difference of +/-1 signal (captures oscillatory style).\"\"\"\n    x = np.asarray([1.0 if b else -1.0 for b in el[:n]], dtype=float)\n    if x.size < 3:\n        return 0.0\n    d = x[1:] - x[:-1]\n    # ignore zeros in d by small epsilon\n    d = np.where(d == 0.0, 1e-9, d)\n    sc = np.sum(np.sign(d[1:]) != np.sign(d[:-1]))\n    return float(sc)\n",
  "support_nearest_neighbor_std_low": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer uniform nearest-neighbor distances among 1 positions (low std of NN gaps).\"\"\"\n    idx = np.asarray([i for i, b in enumerate(el[:n]) if b], dtype=float)\n    if idx.size <= 2:\n        return 0.0\n    idx = np.sort(idx)\n    gaps = np.diff(idx)\n    # nearest neighbor for interior points is min(left,right), ends have only one\n    nn = []\n    nn.append(gaps[0])\n    for i in range(1, gaps.size):\n        nn.append(min(gaps[i-1], gaps[i]))\n    nn.append(gaps[-1])\n    nn = np.asarray(nn, dtype=float)\n    return -float(np.std(nn))\n",
  "support_nearest_neighbor_std_high": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Prefer varied nearest-neighbor distances among 1 positions (high std of NN gaps).\"\"\"\n    idx = np.asarray([i for i, b in enumerate(el[:n]) if b], dtype=float)\n    if idx.size <= 2:\n        return 0.0\n    idx = np.sort(idx)\n    gaps = np.diff(idx)\n    nn = []\n    nn.append(gaps[0])\n    for i in range(1, gaps.size):\n        nn.append(min(gaps[i-1], gaps[i]))\n    nn.append(gaps[-1])\n    nn = np.asarray(nn, dtype=float)\n    return float(np.std(nn))\n",
  "binned_support_histogram_entropy": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Entropy of the histogram of 1s over fixed bins (higher => more evenly spread).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    B = int(min(6, N))\n    edges = np.linspace(0, N, B + 1).astype(int)\n    counts = []\n    for i in range(B):\n        counts.append(float(np.sum(x[edges[i]:edges[i+1]])))\n    counts = np.asarray(counts, dtype=float)\n    s = float(np.sum(counts))\n    if s <= 0:\n        return 0.0\n    p = counts / s\n    p = p[p > 0]\n    return -float(np.sum(p * np.log2(p)))\n",
  "binned_support_histogram_chi2": "import math\nimport numpy as np\n\ndef priority(el: tuple[int, ...], n: int = 15, w: int = 10) -> float:\n    \"\"\"Negative chi-square distance from uniform bin counts (higher => closer to uniform).\"\"\"\n    x = np.asarray(el[:n], dtype=np.int8)\n    N = int(x.size)\n    if N == 0:\n        return 0.0\n    B = int(min(6, N))\n    edges = np.linspace(0, N, B + 1).astype(int)\n    counts = np.array([float(np.sum(x[edges[i]:edges[i+1]])) for i in range(B)], dtype=float)\n    expected = (float(w) / float(N)) * np.array([(edges[i+1] - edges[i]) for i in range(B)], dtype=float)\n    chi2 = float(np.sum((counts - expected) ** 2 / (expected + 1e-12)))\n    return -chi2\n"
}



