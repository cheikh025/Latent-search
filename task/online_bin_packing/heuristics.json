{
  "best_fit_negative_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit: prefer smallest nonnegative slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -slack\n    score[slack < 0] = -np.inf\n    return score\n",
  "best_fit_inverse_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit with inverse slack (strong pull to tight fits).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    eps = 1e-12\n    score = 1.0 / (slack + eps)\n    score[slack < 0] = -np.inf\n    return score\n",
  "best_fit_quadratic_penalty": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit with quadratic penalty on leftover space.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -(slack ** 2)\n    score[slack < 0] = -np.inf\n    return score\n",
  "best_fit_exponential_decay": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit via exp(-slack) (smooth, scale-robust).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.exp(-np.maximum(slack, 0.0))\n    score[slack < 0] = -np.inf\n    return score\n",
  "worst_fit_positive_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Worst-Fit: prefer largest slack among feasible bins.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = slack\n    score[slack < 0] = -np.inf\n    return score\n",
  "worst_fit_sqrt_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Worst-Fit with diminishing returns via sqrt(slack).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.sqrt(np.maximum(slack, 0.0))\n    score[slack < 0] = -np.inf\n    return score\n",
  "almost_worst_fit_second_best": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Almost-Worst-Fit flavor: de-emphasize the emptiest bin.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = slack.copy()\n    score[slack < 0] = -np.inf\n    if np.isfinite(score).any():\n        j = int(np.nanargmax(score))\n        score[j] = score[j] - (np.nanstd(score[np.isfinite(score)]) + 1e-9)\n    return score\n",
  "minimize_waste_with_sliver_guard": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit, but avoid leaving tiny unusable slivers.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -slack\n    score[slack < 0] = -np.inf\n    finite = np.isfinite(score)\n    if finite.any():\n        cap_ref = np.nanmax(bins[finite]) + 1e-12\n        sliver = 0.05 * cap_ref\n        score[(slack >= 0) & (slack < sliver)] -= 0.5 * cap_ref\n    return score\n",
  "mid_slack_target_fraction": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer leaving remainder near 15% of bin capacity.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    target = 0.15 * np.maximum(bins, 1e-12)\n    score = -np.abs(slack - target)\n    score[slack < 0] = -np.inf\n    return score\n",
  "tight_fit_then_balance": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tight fits first; among them, balance post-slack around median.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    feasible = slack >= 0\n    score = np.full_like(bins, -np.inf, dtype=float)\n    if feasible.any():\n        primary = -slack\n        med = np.median(slack[feasible])\n        secondary = -np.abs(slack - med)\n        score[feasible] = primary[feasible] + 0.05 * secondary[feasible]\n    return score\n",
  "capacity_normalized_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit using slack fraction (slack/bin).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    frac = slack / np.maximum(bins, 1e-12)\n    score = -frac\n    score[slack < 0] = -np.inf\n    return score\n",
  "prefer_exact_fit_bonus": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-Fit with a huge bonus for exact (or near-exact) fits.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -slack\n    score[slack < 0] = -np.inf\n    tol = 1e-9\n    score[np.abs(slack) <= tol] += 1e6\n    return score\n",
  "large_item_roomy_small_item_tight": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Large items -> roomy bins; small items -> tight bins.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        cap_ref = np.nanmax(bins[feasible]) + 1e-12\n        big = item >= 0.6 * cap_ref\n        score[feasible] = (slack[feasible] if big else -slack[feasible])\n    return score\n",
  "quantile_target_slack_25": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Target slack near the 25th percentile of feasible slacks.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        target = np.quantile(slack[feasible], 0.25)\n        score[feasible] = -np.abs(slack[feasible] - target)\n    return score\n",
  "zscore_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer tighter-than-average feasible bins via slack z-score.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        mu = np.mean(s)\n        sd = np.std(s) + 1e-12\n        score[feasible] = -(s - mu) / sd\n    return score\n",
  "guard_band_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack in a middle band; avoid tiny or huge remainders.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        cap_ref = np.nanmax(bins[feasible]) + 1e-12\n        low, high = 0.02 * cap_ref, 0.35 * cap_ref\n        mid = 0.5 * (low + high)\n        score[feasible] = -np.abs(slack[feasible] - mid) - 0.1 * slack[feasible]\n        score[(slack >= 0) & (slack < low)] -= cap_ref\n        score[(slack > high)] -= 0.25 * cap_ref\n    return score\n",
  "spread_remaining_capacities": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Encourage spread in post-slacks to reduce later dead-ends.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        mu = np.mean(slack[feasible])\n        score[feasible] = np.abs(slack[feasible] - mu) - 0.05 * slack[feasible]\n    return score\n",
  "temperature_scaled_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tight-fit score scaled by slack std (acts like a temperature).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        temp = np.std(slack[feasible]) + 1e-9\n        score[feasible] = -slack[feasible] / temp\n    return score\n",
  "harmonic_tight_and_not_too_small": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Combine tightness and avoiding very small bins.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        a = slack[feasible] + 1e-12\n        b = 1.0 / (bins[feasible] + 1e-12)\n        score[feasible] = 2.0 / (a + b)\n    return score\n",
  "small_items_best_large_items_worst": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Small items: best-fit; large items: worst-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        cap_ref = np.nanmax(bins[feasible]) + 1e-12\n        large = item >= 0.5 * cap_ref\n        score[feasible] = (slack[feasible] if large else -slack[feasible])\n    return score\n",
  "capacity_near_small_integer_multiple_of_item": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer bins whose capacity is close to k*item for small k.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        k = np.clip(np.round(bins / max(item, 1e-12)), 1, 5)\n        target = k * item\n        score[feasible] = -np.abs(bins[feasible] - target[feasible]) - 0.05 * slack[feasible]\n    return score\n",
  "penalize_too_small_gap_relative_item": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit, but penalize leaving gaps smaller than item/4.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = -slack\n    score[slack < 0] = -np.inf\n    small_gap = (slack >= 0) & (slack < 0.25 * item)\n    score[small_gap] -= 10.0 * (0.25 * item - slack[small_gap])\n    return score\n",
  "worst_fit_with_big_gap_penalty": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Worst-fit, but penalize overly large gaps above 80th percentile.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = slack\n    score[slack < 0] = -np.inf\n    feasible = slack >= 0\n    if feasible.any():\n        hi = np.quantile(slack[feasible], 0.80)\n        too_big = slack > hi\n        score[too_big] -= (slack[too_big] - hi)\n    return score\n",
  "rank_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Rank feasible bins by slack (tightest gets highest).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        order = np.argsort(s)\n        ranks = np.empty_like(order, dtype=float)\n        ranks[order] = np.arange(order.size, dtype=float)\n        score[feasible] = -ranks\n    return score\n",
  "rank_worst_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Rank feasible bins by slack descending (loosest gets highest).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        order = np.argsort(-s)\n        ranks = np.empty_like(order, dtype=float)\n        ranks[order] = np.arange(order.size, dtype=float)\n        score[feasible] = -ranks\n    return score\n",
  "best_fit_with_deterministic_jitter": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit with deterministic tiny jitter to break ties.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = -slack\n    score[slack < 0] = -np.inf\n    feasible = slack >= 0\n    if feasible.any():\n        idx = np.arange(bins.size, dtype=float)\n        jitter = np.sin((idx + 1.0) * (item + 1.234567)) * 1e-6\n        score[feasible] += jitter[feasible]\n    return score\n",
  "huber_slack_penalty": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Huber-style penalty on slack (quadratic near 0, linear far).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        delta = np.median(slack[feasible]) + 1e-12\n        s = slack[feasible]\n        huber = np.where(s <= delta, -(s**2)/(2*delta), -(s - delta/2))\n        score[feasible] = huber\n    return score\n",
  "tight_fit_plus_capacity_skew_control": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tight fit plus gentle pull toward mean capacity (reduces skew).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        mu = np.mean(bins[feasible])\n        cap_term = -np.abs(bins - mu)\n        score[feasible] = -slack[feasible] + 0.01 * cap_term[feasible]\n    return score\n",
  "cdf_quantile_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Use empirical CDF of slack; prefer lower-quantile slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        order = np.argsort(s)\n        ranks = np.empty_like(order, dtype=float)\n        ranks[order] = np.arange(order.size, dtype=float)\n        q = ranks / max(1.0, order.size - 1.0)\n        score[feasible] = -q\n    return score\n",
  "sigmoid_negative_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Bounded score: sigmoid(-slack) for stability across scales.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    z = -np.maximum(slack, 0.0)\n    score = 1.0 / (1.0 + np.exp(-z))\n    score[slack < 0] = -np.inf\n    return score\n",
  "log_barrier_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit via log-barrier: strongly prefers very small positive slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    eps = 1e-12\n    score = -np.log(slack + eps)\n    score[slack < 0] = -np.inf\n    return score\n",
  "robust_mad_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Robust z-tightness using MAD of feasible slacks (outlier-resistant).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        med = np.median(s)\n        mad = np.median(np.abs(s - med)) + 1e-12\n        z = (s - med) / (1.4826 * mad)\n        score[feasible] = -z\n    return score\n",
  "reserve_large_bins_top_decile": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tight fit, but reserve very large bins (top decile) unless needed.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -slack\n    score[slack < 0] = -np.inf\n    feasible = slack >= 0\n    if feasible.any():\n        q90 = np.quantile(bins[feasible], 0.90)\n        big = (bins >= q90) & feasible\n        score[big] -= 0.25 * (bins[big] - q90)\n    return score\n",
  "capacity_aware_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit with explicit bias toward smaller-capacity bins (save big bins).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        cap_scale = np.mean(bins[feasible]) + 1e-12\n        score[feasible] = -slack[feasible] - 0.05 * (bins[feasible] / cap_scale)\n    return score\n",
  "fill_ratio_then_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer higher fill ratio (item/bin); tie-break with tightness.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = item / np.maximum(bins, 1e-12)\n        score[feasible] = 10.0 * fill[feasible] - slack[feasible]\n    return score\n",
  "avoid_half_full_deadzone": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer post-fill far from ~50% to reduce ambiguous medium remainders.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = (bins - slack) / np.maximum(bins, 1e-12)\n        score[feasible] = -slack[feasible] + 0.1 * np.abs(fill[feasible] - 0.5)\n    return score\n",
  "target_complementary_gap_equal_item": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer leaving slack close to item (encourages future pairing of same size).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = -np.abs(slack - item)\n    score[slack < 0] = -np.inf\n    return score\n",
  "adaptive_sigmoid_target_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Sigmoid centered at an adaptive target slack (median feasible slack).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        target = np.median(s)\n        scale = (np.std(s) + 1e-9)\n        z = (target - slack) / scale\n        score[feasible] = 1.0 / (1.0 + np.exp(-z[feasible]))\n    return score\n",
  "kde_rarity_slack_preference": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer rarer (low-density) feasible slacks via simple Gaussian KDE.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        h = (np.std(s) + 1e-9)\n        diffs = (s[:, None] - s[None, :]) / h\n        density = np.sum(np.exp(-0.5 * diffs**2), axis=1)\n        score[feasible] = -density\n    return score\n",
  "variance_reduction_post_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Choose bin that moves post-slack toward the feasible mean (variance reduction).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        mu = np.mean(slack[feasible])\n        score[feasible] = -(slack[feasible] - mu) ** 2 - 0.01 * slack[feasible]\n    return score\n",
  "heavy_tail_penalty_on_extreme_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Penalize extreme feasible slacks with a cubic (heavy-tail) cost.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        mu = np.mean(s)\n        sd = np.std(s) + 1e-12\n        z = (s - mu) / sd\n        score[feasible] = -np.abs(z) ** 3 - 0.02 * s\n    return score\n",
  "piecewise_small_item_spread_large_item_tight": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. If item is small vs median bin, spread; if large, go tight.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        med_bin = np.median(bins[feasible])\n        small = item <= 0.25 * med_bin\n        if small:\n            mu = np.mean(slack[feasible])\n            score[feasible] = np.abs(slack[feasible] - mu) - 0.01 * slack[feasible]\n        else:\n            score[feasible] = -slack[feasible]\n    return score\n",
  "exponential_overflow_guard": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tightness minus exp(slack/scale): strongly discourages roomy placements.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        scale = (np.mean(slack[feasible]) + 1e-9)\n        score[feasible] = -slack[feasible] - np.exp(slack[feasible] / scale)\n    return score\n",
  "triangular_peak_at_quantile_40": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Triangular preference peaking at the 40th percentile feasible slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        peak = np.quantile(s, 0.40)\n        width = (np.quantile(s, 0.90) - np.quantile(s, 0.10)) + 1e-9\n        score[feasible] = 1.0 - (np.abs(slack[feasible] - peak) / width)\n    return score\n",
  "cosine_match_bin_slack_profile": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Cosine similarity between (bin, slack) and a target profile (mu_bin, mu_slack).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        mu_bin = np.mean(bins[feasible])\n        mu_slack = np.mean(slack[feasible])\n        v1 = np.stack([bins[feasible], slack[feasible]], axis=1)\n        v2 = np.array([mu_bin, mu_slack], dtype=float)\n        num = v1 @ v2\n        den = (np.linalg.norm(v1, axis=1) * (np.linalg.norm(v2) + 1e-12) + 1e-12)\n        score[feasible] = num / den - 0.02 * slack[feasible]\n    return score\n",
  "lexicographic_rank_then_capacity_center": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Primary: rank by tightness; secondary: closeness to median feasible bin size.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        order = np.argsort(s)\n        ranks = np.empty_like(order, dtype=float)\n        ranks[order] = np.arange(order.size, dtype=float)\n        medb = np.median(bins[feasible])\n        center = -np.abs(bins[feasible] - medb)\n        score[feasible] = -ranks + 0.001 * center\n    return score\n",
  "quantized_slack_prefer_round_remainders": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer remainders close to a multiple of a dynamic quantum (median slack/4).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        q = (np.median(s) / 4.0) + 1e-9\n        k = np.round(slack / q)\n        dist = np.abs(slack - k * q)\n        score[feasible] = -dist[feasible] - 0.05 * slack[feasible]\n    return score\n",
  "softmin_slack_with_logsumexp_scale": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Softmin-style: -slack scaled by log(1+n) * mean slack (smooth across sizes).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        scale = (np.mean(s) + 1e-9) * np.log(1.0 + s.size)\n        score[feasible] = -slack[feasible] / scale\n    return score\n",
  "golden_ratio_dithered_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit plus tiny quasi-random dither (golden ratio) for exploration/tie-breaks.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = -slack\n    score[slack < 0] = -np.inf\n    feasible = slack >= 0\n    if feasible.any():\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        idx = np.arange(bins.size, dtype=float) + 1.0\n        d = np.mod(idx * phi, 1.0)\n        score[feasible] += 1e-6 * (d[feasible] - 0.5)\n    return score\n",
  "percentile_guard_avoid_tails": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack within [p15, p85]; penalize tail slacks to avoid extremes.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        lo = np.quantile(s, 0.15)\n        hi = np.quantile(s, 0.85)\n        mid = 0.5 * (lo + hi)\n        score[feasible] = -np.abs(slack[feasible] - mid) - 0.02 * slack[feasible]\n        left = feasible & (slack < lo)\n        right = feasible & (slack > hi)\n        score[left] -= (lo - slack[left])\n        score[right] -= (slack[right] - hi)\n    return score\n",
  "entropy_flatten_slack_histogram": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer feasible slacks that are currently underrepresented (histogram flattening).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        lo, hi = np.min(s), np.max(s)\n        if hi - lo < 1e-12:\n            score[feasible] = 0.0\n            return score\n        nb = 10\n        edges = np.linspace(lo, hi, nb + 1)\n        idx = np.clip(np.digitize(s, edges) - 1, 0, nb - 1)\n        counts = np.bincount(idx, minlength=nb).astype(float)\n        rarity = 1.0 / (counts[idx] + 1e-12)\n        score[feasible] = rarity - 0.01 * s\n    return score\n",
  "tukey_biweight_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Robust Tukey biweight around median slack (downweights outliers).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        med = np.median(s)\n        mad = np.median(np.abs(s - med)) + 1e-12\n        c = 4.685\n        u = (s - med) / (c * 1.4826 * mad)\n        w = (1 - u**2)\n        w[np.abs(u) >= 1] = 0.0\n        w = w**2\n        score[feasible] = w - 0.02 * s\n    return score\n",
  "cauchy_target_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Cauchy-shaped preference centered at the median feasible slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        target = np.median(s)\n        scale = np.std(s) + 1e-9\n        z = (slack[feasible] - target) / scale\n        score[feasible] = 1.0 / (1.0 + z**2) - 0.01 * s\n    return score\n",
  "borda_rank_slack_and_capacity": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Combine ranks: (tight slack rank) + (middle-capacity rank).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        b = bins[feasible]\n        r_slack = np.argsort(np.argsort(s))  # smaller slack -> lower rank\n        medb = np.median(b)\n        r_mid = np.argsort(np.argsort(np.abs(b - medb)))\n        score[feasible] = -(r_slack + 0.5 * r_mid).astype(float)\n    return score\n",
  "capacity_outlier_penalty_plus_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tight fit, but penalize choosing capacity outliers among feasible bins.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        mu, sd = np.mean(b), (np.std(b) + 1e-12)\n        out = np.abs(b - mu) / sd\n        score[feasible] = -slack[feasible] - 0.1 * out\n    return score\n",
  "avoid_ultra_tight_bottom_decile_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit but avoid the very tightest feasible slacks (bottom decile) unless necessary.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -slack\n    score[slack < 0] = -np.inf\n    feasible = slack >= 0\n    if feasible.any():\n        p10 = np.quantile(slack[feasible], 0.10)\n        ultra_tight = feasible & (slack <= p10)\n        score[ultra_tight] -= (p10 - slack[ultra_tight] + 1e-12) * 0.5\n    return score\n",
  "softplus_barrier_target_fraction_20": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Softplus barrier around target slack = 20% of capacity (smooth piecewise).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        target = 0.20 * np.maximum(bins, 1e-12)\n        k = 8.0\n        x = k * (np.abs(slack - target) / (np.maximum(bins, 1e-12)))\n        softplus = np.log1p(np.exp(x))\n        score[feasible] = -softplus[feasible] - 0.01 * slack[feasible]\n    return score\n",
  "logit_fill_target_70": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer placements whose post-fill ratio is near 0.70 via a logistic bump.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = item / np.maximum(bins, 1e-12)\n        target = 0.70\n        z = -(np.abs(fill - target)) * 12.0\n        score[feasible] = 1.0 / (1.0 + np.exp(-z[feasible])) - 0.02 * slack[feasible]\n    return score\n",
  "minimize_fractional_slack_squared": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Minimize (slack/bin)^2 (scale-invariant tightness).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    frac = slack / np.maximum(bins, 1e-12)\n    score = -(frac ** 2)\n    score[slack < 0] = -np.inf\n    return score\n",
  "sawtooth_modulo_item_multiple_bias": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer bins where slack is close to a multiple of item (encourages repeated packing sizes).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any() and item > 1e-12:\n        k = np.round(slack[feasible] / item)\n        dist = np.abs(slack[feasible] - k * item)\n        score[feasible] = -dist - 0.05 * slack[feasible]\n    return score\n",
  "prefer_power_of_two_fraction_remainder": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack fraction near 1/2^k (k=1..5) to form 'clean' remainder scales.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        frac = slack[feasible] / np.maximum(bins[feasible], 1e-12)\n        targets = np.array([0.5, 0.25, 0.125, 0.0625, 0.03125], dtype=float)\n        d = np.min(np.abs(frac[:, None] - targets[None, :]), axis=1)\n        score[feasible] = -d - 0.02 * slack[feasible]\n    return score\n",
  "two_sided_guard_band_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack within a band: not too tiny (<0.2*item) and not too huge (>p80).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        hi = np.quantile(s, 0.80)\n        lo = 0.20 * item\n        center = 0.5 * (lo + hi)\n        score[feasible] = -np.abs(slack[feasible] - center)\n        score[feasible & (slack < lo)] -= (lo - slack[feasible & (slack < lo)])\n        score[feasible & (slack > hi)] -= (slack[feasible & (slack > hi)] - hi)\n    return score\n",
  "harmonic_slack_capped": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Harmonic pull to small slack, but capped to reduce extreme preference.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    eps = 1e-12\n    raw = 1.0 / (slack + eps)\n    raw[slack < 0] = -np.inf\n    finite = np.isfinite(raw)\n    if finite.any():\n        cap = np.quantile(raw[finite], 0.95)\n        raw[finite] = np.minimum(raw[finite], cap)\n    return raw\n",
  "sqrt_tightness_smooth": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Smooth best-fit: prefers small slack via -sqrt(slack).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -np.sqrt(np.maximum(slack, 0.0))\n    score[slack < 0] = -np.inf\n    return score\n",
  "dynamic_alpha_tightness_by_bin_cv": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tightness exponent adapts to capacity CV: more variability -> stronger best-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        cv = (np.std(b) / (np.mean(b) + 1e-12))\n        p = 1.0 + 2.0 * np.clip(cv, 0.0, 1.0)\n        score[feasible] = -(slack[feasible] ** p)\n    return score\n",
  "middle_capacity_preference_with_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer bins near feasible median capacity, with secondary best-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        med = np.median(b)\n        score[feasible] = -np.abs(b - med) - 0.2 * slack[feasible]\n    return score\n",
  "reserve_bottom_quartile_for_small_items": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. For small items, avoid the smallest feasible bins (reserve them); otherwise best-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        q25 = np.quantile(b, 0.25)\n        cap_ref = np.max(b) + 1e-12\n        is_small = item <= 0.15 * cap_ref\n        base = -slack[feasible]\n        score[feasible] = base\n        if is_small:\n            small_bins = feasible & (bins <= q25)\n            score[small_bins] -= 0.5 * (q25 - bins[small_bins])\n    return score\n",
  "quadrant_rule_high_fill_or_low_waste": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer either very high fill (>=0.85) or very low waste (slack <= p25).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = item / np.maximum(bins, 1e-12)\n        p25 = np.quantile(slack[feasible], 0.25)\n        good = (fill >= 0.85) | (slack <= p25)\n        score[feasible] = -slack[feasible]\n        score[feasible & good] += 0.2\n    return score\n",
  "projected_pairing_probability_exp": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Assume future items resemble current item; prefer slack near item (exp similarity).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        scale = max(item, 1e-9)\n        sim = np.exp(-((slack[feasible] - item) / scale) ** 2)\n        score[feasible] = sim - 0.03 * slack[feasible]\n    return score\n",
  "temperature_scaled_boltzmann_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Boltzmann score exp(-slack/T) with T set by feasible IQR (adaptive scale).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        q1, q3 = np.quantile(s, 0.25), np.quantile(s, 0.75)\n        T = (q3 - q1) + 1e-9\n        score[feasible] = np.exp(-s / T)\n    return score\n",
  "minimize_relative_slack_to_item_target_20pct": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack about 20% of item (relative remainder control).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any() and item > 1e-12:\n        rel = slack[feasible] / item\n        score[feasible] = -np.abs(rel - 0.20) - 0.02 * slack[feasible]\n    return score\n",
  "percentile_rank_slack_then_penalize_edges": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Use slack percentile rank (prefers low rank), with extra penalty near 0 and 1 extremes.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        order = np.argsort(s)\n        r = np.empty_like(order, dtype=float)\n        r[order] = np.linspace(0.0, 1.0, num=order.size)\n        edge_pen = np.minimum(r, 1.0 - r)\n        score[feasible] = -(r + 0.2 * (0.5 - edge_pen))\n    return score\n",
  "l1_target_vector_bin_and_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Minimize L1 distance to (median bin, median slack) target state.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        s = slack[feasible]\n        tb, ts = np.median(b), np.median(s)\n        score[feasible] = -(np.abs(b - tb) + np.abs(s - ts))\n    return score\n",
  "bimodal_preference_tight_or_roomy": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Encourage either very tight (<=p20 slack) or very roomy (>=p80 slack), avoid middle.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        p20, p80 = np.quantile(s, 0.20), np.quantile(s, 0.80)\n        tight = slack[feasible] <= p20\n        roomy = slack[feasible] >= p80\n        mid = ~(tight | roomy)\n        out = np.zeros_like(s)\n        out[tight] = 1.0 - (s[tight] / (p20 + 1e-12))\n        out[roomy] = 0.5 + (s[roomy] - p80) / (np.max(s) - p80 + 1e-12)\n        out[mid] = -0.5 - np.abs(s[mid] - np.median(s)) / (np.std(s) + 1e-12)\n        score[feasible] = out\n    return score\n",
  "inverse_capacity_weighted_tightness": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit, but scaled by inverse capacity so large bins are harder to consume.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        invcap = 1.0 / (bins[feasible] + 1e-12)\n        score[feasible] = -slack[feasible] * (1.0 + 5.0 * (1.0 - invcap / np.max(invcap)))\n    return score\n",
  "gini_like_balance_proxy": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Proxy for lowering inequality of slacks: prefer slack near median and within IQR.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        med = np.median(s)\n        q1, q3 = np.quantile(s, 0.25), np.quantile(s, 0.75)\n        iqr = (q3 - q1) + 1e-12\n        z = np.abs(s - med) / iqr\n        score[feasible] = -z - 0.01 * s\n    return score\n",
  "minimize_slack_times_capacity_deviation": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Tightness coupled with capacity deviation: -slack * (1 + |bin-median|/median).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        medb = np.median(bins[feasible]) + 1e-12\n        dev = np.abs(bins[feasible] - medb) / medb\n        score[feasible] = -slack[feasible] * (1.0 + 0.5 * dev)\n    return score\n",
  "softmaxed_best_fit_temperature_by_scale": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Softmax-style score: exp(-slack/T) but returned as log-score (-slack/T).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        T = (np.mean(s) + 1e-9)\n        score[feasible] = -s / T\n    return score\n",
  "huber_loss_around_target_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Huber loss around target slack (median feasible slack) for robustness.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        target = np.median(s)\n        delta = (np.std(s) + 1e-9)\n        r = s - target\n        huber = np.where(np.abs(r) <= delta, 0.5 * r**2, delta * (np.abs(r) - 0.5 * delta))\n        score[feasible] = -huber - 0.01 * s\n    return score\n",
  "winsorized_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit but winsorize slack at p95 to reduce domination by huge slacks.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        cap = np.quantile(s, 0.95)\n        s2 = np.minimum(s, cap)\n        score[feasible] = -s2\n    return score\n",
  "maximize_post_fill_margin_from_quarters": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer post-fill fraction far from 0.25/0.50/0.75 (avoid 'quarter' attractors).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = item / np.maximum(bins, 1e-12)\n        anchors = np.array([0.25, 0.50, 0.75])\n        d = np.min(np.abs(fill[feasible][:, None] - anchors[None, :]), axis=1)\n        score[feasible] = d - 0.05 * slack[feasible]\n    return score\n",
  "knee_point_preference_on_sorted_slacks": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slacks near the 'knee' (elbow) in sorted feasible slacks curve.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        ss = np.sort(s)\n        n = ss.size\n        if n <= 2:\n            score[feasible] = -s\n            return score\n        x = np.linspace(0.0, 1.0, n)\n        y = (ss - ss[0]) / (ss[-1] - ss[0] + 1e-12)\n        line = x\n        knee = np.argmax(np.abs(y - line))\n        target = ss[knee]\n        score[feasible] = -np.abs(s - target) - 0.01 * s\n    return score\n",
  "minimize_second_order_slack_difference": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack close to mean slack, but with squared penalty on deviation.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        mu = np.mean(s)\n        score[feasible] = -(s - mu) ** 2 - 0.02 * s\n    return score\n",
  "quantile_band_pass_then_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer bins whose slack lies in [p30,p70]; otherwise fall back to best-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        p30, p70 = np.quantile(s, 0.30), np.quantile(s, 0.70)\n        in_band = feasible & (slack >= p30) & (slack <= p70)\n        score[feasible] = -slack[feasible]\n        score[in_band] += 0.2\n    return score\n",
  "prefer_geometric_mean_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack close to geometric mean of feasible slacks (scale-aware center).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible] + 1e-12\n        gm = np.exp(np.mean(np.log(s)))\n        score[feasible] = -np.abs((slack[feasible] + 1e-12) - gm) - 0.01 * slack[feasible]\n    return score\n",
  "rank_by_slack_then_penalize_high_capacity": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Rank on tightness, then subtract penalty proportional to capacity percentile.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        b = bins[feasible]\n        order = np.argsort(s)\n        ranks = np.empty_like(order, dtype=float)\n        ranks[order] = np.arange(order.size, dtype=float)\n        cap_rank = np.argsort(np.argsort(b)).astype(float) / max(b.size - 1, 1)\n        score[feasible] = -ranks - 0.3 * cap_rank\n    return score\n",
  "slope_limited_linear_penalty": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Linear best-fit but penalty slope saturates beyond a threshold slack.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        thr = np.quantile(s, 0.60)\n        penal = np.minimum(s, thr) + 0.2 * np.maximum(s - thr, 0.0)\n        score[feasible] = -penal\n    return score\n",
  "prefer_slack_near_item_iqr_scaled": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer leaving slack near item, scaled by IQR of feasible slacks.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        q1, q3 = np.quantile(s, 0.25), np.quantile(s, 0.75)\n        iqr = (q3 - q1) + 1e-9\n        score[feasible] = -np.abs(s - item) / iqr - 0.01 * s\n    return score\n",
  "minimize_slack_times_log_capacity": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Penalize slack more in large bins via slack * log(capacity).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        w = np.log(np.maximum(bins[feasible], 1e-12) + 1.0)\n        score[feasible] = -(slack[feasible] * w)\n    return score\n",
  "prefer_small_bin_if_multiple_feasible_else_roomy": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. If many feasible, prefer smaller bins; if few, prefer larger slack to avoid dead-ends.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    k = int(np.sum(feasible))\n    if k > 0:\n        if k >= 4:\n            score[feasible] = -bins[feasible] - 0.1 * slack[feasible]\n        else:\n            score[feasible] = slack[feasible] - 0.05 * bins[feasible]\n    return score\n",
  "piecewise_penalize_mid_slack_interval": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Penalize slacks in the middle interval [p40,p60] to encourage diversity of remainders.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        p40, p60 = np.quantile(s, 0.40), np.quantile(s, 0.60)\n        score[feasible] = -s\n        mid = feasible & (slack >= p40) & (slack <= p60)\n        score[mid] -= 0.3 * (p60 - p40 + 1e-12)\n    return score\n",
  "max_margin_from_feasible_min_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer bins whose slack is close to the minimum feasible slack but not equal (margin).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        mn = np.min(s)\n        margin = np.abs(s - (mn + 0.05 * (np.max(s) - mn + 1e-12)))\n        score[feasible] = -margin - 0.01 * s\n    return score\n",
  "prefer_slack_near_capacity_percentile_35": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Target slack equal to 35th percentile of feasible bin capacities (couples slack & cap).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        target = np.quantile(b, 0.35)\n        score[feasible] = -np.abs(slack[feasible] - 0.15 * target) - 0.02 * slack[feasible]\n    return score\n",
  "minimize_lognormalized_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Use -log(1+slack) (compresses scale, favors tighter but not excessively).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = -np.log1p(np.maximum(slack, 0.0))\n    score[slack < 0] = -np.inf\n    return score\n",
  "prefer_slack_near_mean_capacity_minus_item": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer slack close to (mean feasible bin - item) (ties placement to typical capacity).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        mu_b = np.mean(bins[feasible])\n        target = max(mu_b - item, 0.0)\n        score[feasible] = -np.abs(slack[feasible] - target) - 0.01 * slack[feasible]\n    return score\n",
  "asymmetric_penalty_small_slack_over_big_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Penalize small slack more than large slack (avoid slivers), but still prefer moderate tightness.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        cap = np.max(bins[feasible]) + 1e-12\n        sliver = 0.05 * cap\n        penalty = np.where(s < sliver, 5.0 * (sliver - s), 0.2 * s)\n        score[feasible] = -penalty\n    return score\n",
  "median_absolute_deviation_capacity_centering": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer capacities near median using MAD, with secondary best-fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        b = bins[feasible]\n        med = np.median(b)\n        mad = np.median(np.abs(b - med)) + 1e-12\n        z = np.abs(b - med) / (1.4826 * mad)\n        score[feasible] = -z - 0.1 * slack[feasible]\n    return score\n",
  "prefer_slack_near_triangular_median_iqr": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Triangular bump centered at median slack with width = IQR.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        med = np.median(s)\n        q1, q3 = np.quantile(s, 0.25), np.quantile(s, 0.75)\n        width = (q3 - q1) + 1e-9\n        score[feasible] = 1.0 - (np.abs(s - med) / width) - 0.02 * s\n    return score\n",
  "prefer_high_fill_and_low_capacity": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Joint objective: maximize fill ratio while minimizing capacity consumed.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        fill = item / np.maximum(bins[feasible], 1e-12)\n        cap_norm = bins[feasible] / (np.max(bins[feasible]) + 1e-12)\n        score[feasible] = 2.0 * fill - 0.8 * cap_norm - 0.05 * slack[feasible]\n    return score\n",
  "minimize_slack_to_capacity_ratio_then_exact_bonus": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Minimize slack/bin with a small bonus for near-exact fit.\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        frac = slack[feasible] / np.maximum(bins[feasible], 1e-12)\n        score[feasible] = -frac\n        tol = 1e-9\n        near = feasible & (np.abs(slack) <= tol)\n        score[near] += 10.0\n    return score\n",
  "prefer_capacity_near_item_plus_median_slack": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Prefer capacities near (item + median feasible slack) (align capacity to typical post-state).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    item = float(item)\n    slack = bins - item\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        med_slack = np.median(slack[feasible])\n        target_cap = item + med_slack\n        score[feasible] = -np.abs(bins[feasible] - target_cap) - 0.05 * slack[feasible]\n    return score\n",
  "iqr_normalized_best_fit": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n    \"\"\"Higher is better. Best-fit normalized by IQR of feasible slacks (stable across distributions).\"\"\"\n    bins = np.asarray(bins, dtype=float)\n    slack = bins - float(item)\n    score = np.full_like(bins, -np.inf, dtype=float)\n    feasible = slack >= 0\n    if feasible.any():\n        s = slack[feasible]\n        q1, q3 = np.quantile(s, 0.25), np.quantile(s, 0.75)\n        iqr = (q3 - q1) + 1e-9\n        score[feasible] = -(s / iqr)\n    return score\n"
}



