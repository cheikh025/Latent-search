{
  "adaptive_nn_dest_bias": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    alpha = 0.25 + 1.75 * progress\n    score = d_cur + alpha * d_dest\n\n    return int(unv[int(np.argmin(score))])\n",
  "farthest_early_nearest_late": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.5:\n        k = max(1, int(np.ceil(0.10 * n_rem)))\n        far_idx = np.argsort(-d_cur)[:k]\n        pick = far_idx[int(np.argmin(d_dest[far_idx]))]\n        return int(unv[int(pick)])\n\n    score = d_cur + 0.75 * d_dest\n    return int(unv[int(np.argmin(score))])\n",
  "mean_proximity_to_remaining": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    beta = 1.5 * (1.0 - progress) + 0.1\n    score = d_cur + beta * mean_to_unv\n\n    return int(unv[int(np.argmin(score))])\n",
  "outlier_sweep_then_cluster": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = mean_to_unv / (np.mean(mean_to_unv) + 1e-12)\n\n    if progress < 0.6:\n        score = -m_norm + 0.35 * d_norm\n        return int(unv[int(np.argmin(score))])\n\n    score = d_norm + 0.75 * m_norm\n    return int(unv[int(np.argmin(score))])\n",
  "variance_anchor": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    var_to_unv = D.var(axis=1)\n\n    score = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.60 * (var_to_unv / (np.mean(var_to_unv) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "entropy_seeker": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    row_sum = D.sum(axis=1) + 1e-12\n    P = D / row_sum[:, None]\n    entropy = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    e_norm = entropy / (np.mean(entropy) + 1e-12)\n\n    score = d_norm - 0.85 * e_norm\n    return int(unv[int(np.argmin(score))])\n",
  "regret_gap_guard": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    two = np.partition(D, 1, axis=1)[:, :2]\n    regret = two[:, 1] - two[:, 0]\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    r_norm = regret / (np.mean(regret) + 1e-12)\n\n    score = d_norm - 0.70 * r_norm\n    return int(unv[int(np.argmin(score))])\n",
  "two_step_best_next": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    best_next = D.min(axis=1)\n\n    score = d_cur + best_next\n    return int(unv[int(np.argmin(score))])\n",
  "two_step_balanced_with_dest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    best_next = D.min(axis=1)\n\n    score = d_cur + best_next + 0.35 * d_dest\n    return int(unv[int(np.argmin(score))])\n",
  "minimax_centrality": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, 0.0)\n    max_to_unv = D.max(axis=1)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = max_to_unv / (np.mean(max_to_unv) + 1e-12)\n\n    score = d_norm + 0.85 * m_norm\n    return int(unv[int(np.argmin(score))])\n",
  "triangle_slack_min": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cd = float(distance_matrix[current_node, destination_node])\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    slack = np.abs(d_cur + d_dest - d_cd)\n    score = slack + 0.05 * d_cur\n\n    return int(unv[int(np.argmin(score))])\n",
  "cosine_alignment_to_dest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, unv]\n    c = distance_matrix[unv, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    score = (-cos_theta) + 0.03 * (b / (np.mean(b) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "augmented_savings": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cd = float(distance_matrix[current_node, destination_node])\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    savings = d_cd - (d_cur + d_dest)\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    s_norm = savings / (np.mean(np.abs(savings)) + 1e-12)\n    m_norm = mean_to_unv / (np.mean(mean_to_unv) + 1e-12)\n\n    score = (-s_norm) + 0.55 * m_norm\n    return int(unv[int(np.argmin(score))])\n",
  "median_step_match": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    med = float(np.median(d_cur))\n    score = np.abs(d_cur - med) + 0.10 * d_dest\n\n    return int(unv[int(np.argmin(score))])\n",
  "percentile_band_random": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    lo = np.percentile(d_cur, 30)\n    hi = np.percentile(d_cur, 70)\n    band_mask = (d_cur >= lo) & (d_cur <= hi)\n\n    cand = unv[band_mask] if np.any(band_mask) else unv\n    d_dest_c = distance_matrix[cand, destination_node]\n\n    seed = (int(current_node) * 73856093) ^ (int(destination_node) * 19349663) ^ (int(unv.size) * 83492791)\n    rng = np.random.default_rng(seed % (2**32))\n\n    k = min(int(cand.size), 5)\n    best_k = np.argsort(d_dest_c)[:k]\n    pick = int(rng.integers(0, k))\n\n    return int(cand[int(best_k[pick])])\n",
  "softmin_temperature_sample": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    frac = n_rem / max(1, n_total)\n\n    score = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.35 * (d_dest / (np.mean(d_dest) + 1e-12)) + 0.35 * (mean_to_unv / (np.mean(mean_to_unv) + 1e-12))\n\n    temp = (0.15 + 1.85 * frac) * (np.std(score) + 1e-12)\n\n    w = np.exp(-(score - score.min()) / (temp + 1e-12))\n    w = w / (w.sum() + 1e-12)\n\n    seed = (int(current_node) * 2654435761) ^ (int(destination_node) * 2246822519) ^ (int(n_rem) * 3266489917)\n    rng = np.random.default_rng(seed % (2**32))\n\n    pick = int(rng.choice(np.arange(unv.size), p=w))\n    return int(unv[pick])\n",
  "rank_geometric_choice": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    blended = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.55 * (d_dest / (np.mean(d_dest) + 1e-12))\n    order = np.argsort(blended)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    p = float(np.clip(0.15 + 0.70 * progress, 0.05, 0.95))\n\n    ranks = np.arange(order.size, dtype=float)\n    w = (1.0 - p) ** ranks * p\n    w = w / (w.sum() + 1e-12)\n\n    seed = (int(current_node) * 1597334677) ^ (int(destination_node) * 3812015801) ^ (int(n_rem) * 9586897)\n    rng = np.random.default_rng(seed % (2**32))\n\n    pick_rank = int(rng.choice(np.arange(order.size), p=w))\n    return int(unv[int(order[pick_rank])])\n",
  "k_nearest_switch": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    k = 3 if progress < 0.33 else (2 if progress < 0.66 else 1)\n    k = min(k, int(unv.size))\n\n    order = np.argsort(d_cur)\n    kth = order[k - 1]\n\n    kth_val = d_cur[kth]\n    tie = np.where(np.isclose(d_cur, kth_val))[0]\n    if tie.size > 1:\n        kth = tie[int(np.argmin(d_dest[tie]))]\n\n    return int(unv[int(kth)])\n",
  "isolation_priority": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    isolation = D.min(axis=1)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    iso_norm = isolation / (np.mean(isolation) + 1e-12)\n\n    score = d_norm - 0.90 * iso_norm\n    return int(unv[int(np.argmin(score))])\n",
  "destination_pulse": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    mode = (int(current_node) + int(destination_node) + int(unv.size)) & 1\n\n    if mode == 0:\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.95 * (d_dest / (np.mean(d_dest) + 1e-12))\n    else:\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.95 * (mean_to_unv / (np.mean(mean_to_unv) + 1e-12))\n\n    return int(unv[int(np.argmin(score))])\n",
  "hash_jitter_tiebreak": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    base = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.35 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    jitter = np.sin(unv * 12.9898 + current_node * 78.233 + destination_node * 37.719)\n    jitter = jitter / (np.max(np.abs(jitter)) + 1e-12)\n\n    score = base + 0.02 * jitter\n    return int(unv[int(np.argmin(score))])\n",
  "edge_length_equalizer": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    avg_cur = float(np.mean(d_cur))\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    avg_cand = D.mean(axis=1)\n\n    target = 0.55 * avg_cur + 0.45 * avg_cand\n    score = np.abs(d_cur - target)\n\n    return int(unv[int(np.argmin(score))])\n",
  "normalized_multiobjective": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_unv = D.mean(axis=1)\n\n    def norm(x):\n        x = x.astype(float)\n        mn = float(x.min())\n        mx = float(x.max())\n        return (x - mn) / (mx - mn + 1e-12)\n\n    s1 = norm(d_cur)\n    s2 = norm(d_dest)\n    s3 = norm(mean_to_unv)\n\n    score = 0.55 * s1 + 0.25 * s2 + 0.20 * s3\n    return int(unv[int(np.argmin(score))])\n",
  "bottleneck_edge_prevent": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    q = np.percentile(D, 10, axis=1)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    q_norm = q / (np.mean(q) + 1e-12)\n\n    score = d_norm + 0.80 * q_norm\n    return int(unv[int(np.argmin(score))])\n",
  "two_ring_corridor": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    d_cur = distance_matrix[current_node, unv]\n\n    score = np.abs(r - r0) + 0.10 * d_cur\n    return int(unv[int(np.argmin(score))])\n",
  "antipodal_then_smooth": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, unv]\n    c = distance_matrix[unv, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.5:\n        score = cos_theta + 0.08 * (b / (np.mean(b) + 1e-12))\n        return int(unv[int(np.argmin(score))])\n\n    r0 = a\n    score = np.abs(c - r0) + 0.08 * b\n    return int(unv[int(np.argmin(score))])\n",
  "regret_weighted_earliness": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # For each candidate, find two smallest edges to remaining (best/second-best).\n    part = np.partition(D, 1, axis=1)\n    best = part[:, 0]\n    second = part[:, 1]\n    regret = second - best\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    r_norm = regret / (np.mean(regret) + 1e-12)\n\n    # High regret => serve earlier => subtract regret.\n    score = d_norm - 0.90 * r_norm\n    return int(unv[int(np.argmin(score))])\n",
  "trimmed_candidate_set_future_pull": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    n_rem = int(unv.size)\n    k = int(max(2, min(n_rem, np.ceil(0.18 * n_rem))))\n    cand_idx = np.argsort(d_cur)[:k]\n\n    cand = unv[cand_idx]\n    Dc = distance_matrix[np.ix_(cand, unv)]\n\n    # Harmonic mean of distances to remaining (smaller is better).\n    hm = float(Dc.shape[1]) / (np.sum(1.0 / (Dc + 1e-12), axis=1) + 1e-12)\n\n    score = (d_cur[cand_idx] / (np.mean(d_cur[cand_idx]) + 1e-12)) + 0.85 * (hm / (np.mean(hm) + 1e-12))\n    return int(cand[int(np.argmin(score))])\n",
  "triangle_slack_to_destination": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cd = float(distance_matrix[current_node, destination_node])\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    # Slack >= 0 by triangle inequality in metric-ish cases; still usable generally.\n    slack = (d_cur + d_dest) - d_cd\n\n    s_norm = slack / (np.mean(slack) + 1e-12)\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    # Prefer small slack (destination-consistent), but keep steps short too.\n    score = 0.70 * c_norm + 0.90 * s_norm\n    return int(unv[int(np.argmin(score))])\n",
  "mst_edge_proxy_step": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    attach_cost = D.min(axis=1)  # cheapest edge to connect candidate into remaining\n\n    a_norm = attach_cost / (np.mean(attach_cost) + 1e-12)\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    # Move cheaply now, and also choose nodes that are easy to connect later.\n    score = c_norm + 0.95 * a_norm\n    return int(unv[int(np.argmin(score))])\n",
  "bridge_balance_ratio": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = int(unv.size)\n    k = int(max(2, min(n - 1, np.ceil(0.12 * n))))\n\n    near = np.partition(D, k - 1, axis=1)[:, :k].mean(axis=1)\n    far = np.partition(D, n - k - 1, axis=1)[:, -k:].mean(axis=1)\n\n    ratio = near / (far + 1e-12)  # closer to 1 => balanced\n    balance = np.abs(ratio - 1.0)\n\n    b_norm = balance / (np.mean(balance) + 1e-12)\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    score = c_norm + 0.80 * b_norm\n    return int(unv[int(np.argmin(score))])\n",
  "median_radial_progress": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    radial = d_dest - d_cur\n    target = float(np.median(radial))\n\n    # Preference: stay near the typical radial change while keeping steps modest.\n    score = np.abs(radial - target) + 0.25 * (d_cur / (np.mean(d_cur) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "hash_jittered_softmin": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    base = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.65 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    # Hash-like jitter in [0,1): stable across runs, varies with state and candidate id.\n    seed = (int(current_node) * 1315423911) ^ (int(destination_node) * 2654435761) ^ (int(unv.size) * 97531)\n    x = (unv.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    jitter = ((x * np.int64(1103515245) + np.int64(12345)) & np.int64(0x7FFFFFFF)).astype(np.float64)\n    jitter = (jitter / (2.0**31))\n\n    # Temperature adapts to remaining size: more exploration early.\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    temp = 0.55 - 0.45 * progress\n\n    score = base + temp * (jitter - 0.5)\n    return int(unv[int(np.argmin(score))])\n",
  "k_nearest_density_schedule": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    k = int(max(2, min(n_rem - 1, np.ceil(0.10 * n_rem))))\n    knn = np.partition(D, k - 1, axis=1)[:, :k].mean(axis=1)\n\n    # Larger knn mean => sparser neighborhood.\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    knn_norm = knn / (np.mean(knn) + 1e-12)\n\n    # Early: prefer sparse (subtract), late: prefer dense (add).\n    w = 1.10 * (0.5 - progress)\n    score = c_norm + w * knn_norm\n    return int(unv[int(np.argmin(score))])\n",
  "ranked_destination_gate": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Destination rank among remaining (0 = closest to destination).\n    order = np.argsort(d_dest)\n    rank = np.empty_like(order)\n    rank[order] = np.arange(order.size)\n    rank = rank.astype(np.float64)\n    rank_norm = rank / (np.mean(rank) + 1e-12)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    # Early allow wandering (small penalty), late enforce destination-closeness (big penalty).\n    gate = 0.20 + 1.60 * progress\n    score = c_norm + gate * rank_norm\n    return int(unv[int(np.argmin(score))])\n",
  "two_step_to_destination_minplus": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_to_dest = distance_matrix[unv, destination_node]\n\n    if n == 1:\n        return int(unv[0])\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # For each candidate i, compute min_j (D[i,j] + d_to_dest[j]).\n    future = np.min(D + d_to_dest[None, :], axis=1)\n\n    score = d_cur + 0.95 * future\n    return int(unv[int(np.argmin(score))])\n",
  "perimeter_first_closure": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mean_to_all = D.mean(axis=1)  # larger => more 'peripheral'\n\n    if progress < 0.55:\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) - 0.95 * (mean_to_all / (np.mean(mean_to_all) + 1e-12))\n        return int(unv[int(np.argmin(score))])\n\n    score = d_cur + 0.85 * d_dest\n    return int(unv[int(np.argmin(score))])\n",
  "destination_rank_bandit": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n = int(unv.size)\n    band = int(max(2, min(n, np.ceil(0.20 * n))))\n    best_to_dest_idx = np.argsort(d_dest)[:band]\n\n    cand = unv[best_to_dest_idx]\n    dc = d_cur[best_to_dest_idx]\n    dd = d_dest[best_to_dest_idx]\n\n    # Within band, prefer short step but also keep destination very close.\n    score = (dc / (np.mean(dc) + 1e-12)) + 1.10 * (dd / (np.mean(dd) + 1e-12))\n    return int(cand[int(np.argmin(score))])\n",
  "inverse_square_potential_field": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    # Repulsion: sum 1/(d^2) to all others (bigger => crowded area).\n    repulse = np.sum(1.0 / (D * D + 1e-9), axis=1)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    a_norm = d_dest / (np.mean(d_dest) + 1e-12)\n    r_norm = repulse / (np.mean(repulse) + 1e-12)\n\n    # Prefer short move + destination attraction, and avoid very crowded zones early.\n    score = c_norm + 0.75 * a_norm + 0.35 * r_norm\n    return int(unv[int(np.argmin(score))])\n",
  "cheapest_insertion_proxy": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cd = float(distance_matrix[current_node, destination_node])\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    insertion_cost = (d_cur + d_dest) - d_cd\n\n    # Add a mild preference to keep future connections easy.\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    attach = D.min(axis=1)\n\n    ins_norm = insertion_cost / (np.mean(np.abs(insertion_cost)) + 1e-12)\n    att_norm = attach / (np.mean(attach) + 1e-12)\n\n    score = ins_norm + 0.35 * att_norm\n    return int(unv[int(np.argmin(score))])\n",
  "local_two_opt_risk": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    # Compare to swapping via best other node j: cur->j + j->dest.\n    alt = distance_matrix[current_node, unv] + distance_matrix[unv, destination_node]\n    best_alt = float(np.min(alt))\n\n    risk = (d_cur + d_dest) - best_alt\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    r_norm = risk / (np.mean(np.abs(risk)) + 1e-12)\n\n    score = 0.65 * c_norm + 0.90 * r_norm\n    return int(unv[int(np.argmin(score))])\n",
  "min_sum_of_two_closest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    two = np.partition(D, 1, axis=1)[:, :2]\n    sum2 = two.sum(axis=1)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    s_norm = sum2 / (np.mean(sum2) + 1e-12)\n\n    score = c_norm + 0.90 * s_norm\n    return int(unv[int(np.argmin(score))])\n",
  "destination_overshoot_penalty": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    d_cur = distance_matrix[current_node, unv]\n\n    overshoot = np.maximum(0.0, r - r0)\n\n    o_norm = overshoot / (np.mean(overshoot) + 1e-12)\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    # Strongly avoid moves that increase distance-to-destination; still keep steps short.\n    score = c_norm + 1.25 * o_norm\n    return int(unv[int(np.argmin(score))])\n",
  "quantile_target_edge": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Early aim higher quantile (longer hops), late aim lower quantile (short hops).\n    q = 0.75 - 0.55 * progress\n    target = float(np.quantile(d_cur, q))\n\n    score = np.abs(d_cur - target)\n    return int(unv[int(np.argmin(score))])\n",
  "destination_cone_filter": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, unv]\n    c = distance_matrix[unv, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    # Cone threshold tightens over time.\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    thr = 0.05 + 0.85 * progress  # late -> require strong alignment\n\n    aligned = np.where(cos_theta >= thr)[0]\n\n    if aligned.size > 0:\n        idx = aligned\n        score = (b[idx] / (np.mean(b[idx]) + 1e-12)) + 0.70 * (c[idx] / (np.mean(c[idx]) + 1e-12))\n        return int(unv[int(idx[int(np.argmin(score))])])\n\n    # Fallback: smallest triangle slack.\n    slack = (b + c) - a\n    score = slack + 0.10 * b\n    return int(unv[int(np.argmin(score))])\n",
  "barycentric_pull_then_clip": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, unv]\n\n    # Rank-based centrality: average rank of distances to others (lower rank => more central).\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n    central_rank = ranks.mean(axis=1)\n\n    # Clip to a near set to avoid huge moves.\n    n = int(unv.size)\n    k = int(max(2, min(n, np.ceil(0.25 * n))))\n    near_idx = np.argsort(d_cur)[:k]\n\n    c = unv[near_idx]\n    cr = central_rank[near_idx]\n    dc = d_cur[near_idx]\n\n    score = (dc / (np.mean(dc) + 1e-12)) + 0.80 * (cr / (np.mean(cr) + 1e-12))\n    return int(c[int(np.argmin(score))])\n",
  "destination_differential_greedy": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, unv]\n    r1 = distance_matrix[unv, destination_node]\n\n    gain = r0 - r1  # positive => progress toward destination\n    eff = step / (gain + 1e-12)  # smaller is better\n\n    # Prefer positive gain; if all negative, fall back to shortest step.\n    if np.all(gain <= 1e-12):\n        return int(unv[int(np.argmin(step))])\n\n    eff = np.where(gain > 1e-12, eff, np.inf)\n    return int(unv[int(np.argmin(eff))])\n",
  "softmax_sampling_deterministic": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    base = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.85 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    # Gumbel-like deterministic noise in (0,1)\n    seed = (int(current_node) * 1000003) ^ (int(destination_node) * 9176) ^ (int(unv.size) * 6151)\n    x = (unv.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    u = ((x * np.int64(1664525) + np.int64(1013904223)) & np.int64(0xFFFFFFFF)).astype(np.float64) / (2.0**32)\n    u = np.clip(u, 1e-12, 1.0 - 1e-12)\n    g = -np.log(-np.log(u))\n\n    # Temperature increases early, decreases late.\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    tau = 0.85 - 0.65 * progress\n\n    score = base - tau * g\n    return int(unv[int(np.argmin(score))])\n",
  "min_cycle_closure_risk": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Proxy: discourage candidates that are simultaneously close to current and destination (may create short loops).\n    unv = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    loopiness = 1.0 / (d_cur + 1e-12) + 1.0 / (d_dest + 1e-12)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    l_norm = loopiness / (np.mean(loopiness) + 1e-12)\n\n    score = c_norm + 0.55 * l_norm\n    return int(unv[int(np.argmin(score))])\n",
  "min_geometric_mean_step_dest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    rem = distance_matrix[unv, destination_node]\n\n    score = np.sqrt((step + 1e-12) * (rem + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_l1_rank_mix": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    central = D.mean(axis=1)\n\n    r_step = np.argsort(np.argsort(step)).astype(np.float64)\n    r_dest = np.argsort(np.argsort(dest)).astype(np.float64)\n    r_cent = np.argsort(np.argsort(central)).astype(np.float64)\n\n    score = r_step + 0.9 * r_dest + 0.6 * r_cent\n    return int(unv[int(np.argmin(score))])\n",
  "max_margin_to_nearest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    part = np.partition(D, 2, axis=1)\n    d1, d3 = part[:, 0], part[:, 2]\n    margin = d3 - d1\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    m_norm = margin / (np.mean(margin) + 1e-12)\n\n    # Larger margin => serve earlier.\n    score = s_norm - 0.80 * m_norm\n    return int(unv[int(np.argmin(score))])\n",
  "min_destination_curvature": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    cd = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, unv]\n    rem = distance_matrix[unv, destination_node]\n\n    curvature = (step + rem) / (cd + 1e-12)\n    score = curvature + 0.05 * (step / (np.mean(step) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_quantile_attach_cost": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    q75 = np.percentile(D, 75, axis=1)\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    q_norm = q75 / (np.mean(q75) + 1e-12)\n\n    score = s_norm + 0.70 * q_norm\n    return int(unv[int(np.argmin(score))])\n",
  "destination_monotone_filter": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    ok = np.where(r <= r0 + 1e-12)[0]\n    if ok.size > 0:\n        idx = ok\n        score = step[idx] + 0.55 * r[idx]\n        return int(unv[int(idx[int(np.argmin(score))])])\n\n    # fallback: minimal triangle slack\n    slack = (step + r) - r0\n    score = slack + 0.10 * step\n    return int(unv[int(np.argmin(score))])\n",
  "centrality_then_isolation_switch": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    central = D.mean(axis=1)\n    isolation = D.min(axis=1)\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    c_norm = central / (np.mean(central) + 1e-12)\n    i_norm = isolation / (np.mean(isolation) + 1e-12)\n\n    if progress < 0.55:\n        score = s_norm + 0.85 * c_norm\n    else:\n        score = s_norm - 0.85 * i_norm\n\n    return int(unv[int(np.argmin(score))])\n",
  "destination_rank_smoothing": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    order = np.argsort(d_dest)\n    rank = np.empty_like(order)\n    rank[order] = np.arange(order.size)\n    rank = rank.astype(np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Sigmoid center shifts with progress.\n    x = (rank / max(1.0, float(n_rem)))\n    center = 0.65 - 0.45 * progress\n    steep = 10.0\n    penalty = 1.0 / (1.0 + np.exp(-steep * (x - center)))\n\n    score = (step / (np.mean(step) + 1e-12)) + 1.10 * penalty\n    return int(unv[int(np.argmin(score))])\n",
  "min_destination_hinge_loss": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    margin = 0.05 * (np.mean(r) + 1e-12)\n    hinge = np.maximum(0.0, r - (r0 + margin))\n\n    score = (step / (np.mean(step) + 1e-12)) + 1.00 * (hinge / (np.mean(hinge) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "trimmed_mean_centrality": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    n = int(unv.size)\n    if n <= 6:\n        central = D.mean(axis=1)\n    else:\n        lo = int(np.floor(0.15 * n))\n        hi = int(np.ceil(0.85 * n))\n        sorted_row = np.sort(D, axis=1)\n        central = sorted_row[:, lo:hi].mean(axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.85 * (central / (np.mean(central) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "kcore_proxy_degree": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Radius = median of all pairwise distances in remaining.\n    radius = float(np.median(D[np.isfinite(D)]))\n    deg = np.sum(D <= radius, axis=1).astype(np.float64)\n\n    # Target medium degree ~ median.\n    target = float(np.median(deg))\n    score = np.abs(deg - target) / (np.mean(np.abs(deg - target)) + 1e-12) + 0.35 * (step / (np.mean(step) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_aligned_pair_min": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n    if n == 1:\n        return int(unv[0])\n\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # For each i, allow j only if d_dest[j] <= d_dest[i] (toward destination).\n    allow = (d_dest[None, :] <= d_dest[:, None])\n    masked = np.where(allow, D, np.inf)\n    future = np.min(masked, axis=1)\n\n    score = step + 0.95 * future\n    return int(unv[int(np.argmin(score))])\n",
  "local_spread_minimizer": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = int(unv.size)\n    k = int(max(3, min(n - 1, np.ceil(0.12 * n))))\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    spread = knn.std(axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.80 * (spread / (np.mean(spread) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_ring_quantized": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    # Ring width based on IQR of remaining destination distances.\n    iqr = float(np.subtract(*np.percentile(r, [75, 25]))) + 1e-12\n    w = 0.35 * iqr\n\n    ring0 = np.floor(r0 / w)\n    ring = np.floor(r / w)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Early: stay in same ring; late: prefer smaller ring index.\n    if progress < 0.55:\n        penalty = np.abs(ring - ring0)\n    else:\n        penalty = ring\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.85 * (penalty / (np.mean(penalty) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_destination_pareto_front": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    dest = distance_matrix[unv, destination_node]\n\n    # Identify non-dominated points (min step and min dest).\n    idx = np.argsort(step)\n    best_dest = np.inf\n    nd = []\n    for i in idx:\n        if dest[i] < best_dest - 1e-12:\n            nd.append(i)\n            best_dest = dest[i]\n\n    nd = np.array(nd, dtype=int)\n    if nd.size == 1:\n        return int(unv[int(nd[0])])\n\n    # Tie-break by mean distance to remaining (prefer smaller = more central).\n    D = distance_matrix[np.ix_(unv, unv)]\n    central = D.mean(axis=1)\n\n    s = step[nd] / (np.mean(step[nd]) + 1e-12)\n    c = central[nd] / (np.mean(central[nd]) + 1e-12)\n    d = dest[nd] / (np.mean(dest[nd]) + 1e-12)\n\n    score = 0.55 * s + 0.55 * d + 0.35 * c\n    return int(unv[int(nd[int(np.argmin(score))])])\n",
  "max_future_min_progress": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n    if n == 1:\n        return int(unv[0])\n\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    k = int(max(2, min(n - 1, np.ceil(0.10 * n))))\n    knn_idx = np.argpartition(D, k - 1, axis=1)[:, :k]\n\n    # For each i, consider its k-nearest neighbors; compute minimum progress advantage.\n    adv = np.empty(n, dtype=np.float64)\n    for i in range(n):\n        neigh = knn_idx[i]\n        adv[i] = np.min(d_dest[i] - d_dest[neigh])\n\n    # Larger adv (less negative / more positive) is better; convert to minimization.\n    a_norm = adv / (np.mean(np.abs(adv)) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    score = s_norm - 0.75 * a_norm\n    return int(unv[int(np.argmin(score))])\n",
  "closest_to_median_pairwise": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    med = np.median(D, axis=1)\n    mad = np.median(np.abs(D - med[:, None]), axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.90 * (mad / (np.mean(mad) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "anti_hub_preference": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Small radius = 25th percentile of finite distances.\n    finite = D[np.isfinite(D)]\n    r = float(np.percentile(finite, 25)) + 1e-12\n    degree = np.sum(D <= r, axis=1).astype(np.float64)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.75 * (degree / (np.mean(degree) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "max_gap_in_destination_ranks": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_dest = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    order = np.argsort(d_dest)\n    sd = d_dest[order]\n    gaps = np.diff(sd)\n    if gaps.size == 0:\n        return int(unv[int(np.argmin(step))])\n\n    cut = int(np.argmax(gaps))\n    # Candidate set: around the boundary (two on each side).\n    lo = max(0, cut - 1)\n    hi = min(order.size - 1, cut + 2)\n    band_idx = order[lo:hi+1]\n\n    score = (step[band_idx] / (np.mean(step[band_idx]) + 1e-12)) + 0.85 * (d_dest[band_idx] / (np.mean(d_dest[band_idx]) + 1e-12))\n    return int(unv[int(band_idx[int(np.argmin(score))])])\n",
  "min_expected_next_step": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    exp_next = D.mean(axis=1)\n\n    score = step + 0.70 * exp_next\n    return int(unv[int(np.argmin(score))])\n",
  "min_worst_kNN": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = int(unv.size)\n    k = int(max(2, min(n - 1, np.ceil(0.10 * n))))\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    radius = knn.max(axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.95 * (radius / (np.mean(radius) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_hysteresis": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    # Threshold derived from remaining dest-distance distribution.\n    thr = float(np.percentile(d_dest, 35))\n\n    if r0 <= thr + 1e-12:\n        score = step + 1.15 * d_dest\n    else:\n        D = distance_matrix[np.ix_(unv, unv)]\n        central = D.mean(axis=1)\n        score = (step / (np.mean(step) + 1e-12)) + 0.90 * (central / (np.mean(central) + 1e-12))\n\n    return int(unv[int(np.argmin(score))])\n",
  "min_span_proxy": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, 0.0)\n    mx = D.max(axis=1)\n    mn = np.where(D == 0.0, np.inf, D).min(axis=1)\n    span = mx - mn\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.85 * (span / (np.mean(span) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "quantile_balanced_step": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    finite = D[np.isfinite(D)]\n    if finite.size == 0:\n        return int(unv[int(np.argmin(step))])\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    q = 0.35 + 0.40 * (1.0 - progress)  # early higher\n    target = float(np.quantile(finite, q))\n\n    score = np.abs(step - target)\n    return int(unv[int(np.argmin(score))])\n",
  "min_logsumexp_future": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n\n    # Temperature on remaining size.\n    n = int(unv.size)\n    tau = 0.35 + 0.25 * (n / max(1, int(distance_matrix.shape[0])))\n\n    x = -D / (tau + 1e-12)\n    m = np.max(x, axis=1)\n    lse = m + np.log(np.sum(np.exp(x - m[:, None]), axis=1) + 1e-12)\n    softmin = -tau * lse\n\n    score = step + 0.55 * softmin\n    return int(unv[int(np.argmin(score))])\n",
  "min_destination_betweenness_proxy": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    # For each candidate i, count how many j satisfy d(j,i)+d(i,dest) <= (1+eps)*d(j,dest)\n    d_i_dest = distance_matrix[unv, destination_node]\n    Dji = distance_matrix[np.ix_(unv, unv)]  # j->i\n    d_j_dest = d_i_dest.copy()\n\n    eps = 0.08\n    # Broadcast: for each i (col), compare for all j (row)\n    on_path = (Dji + d_i_dest[None, :]) <= (1.0 + eps) * d_j_dest[:, None] + 1e-12\n    count = on_path.sum(axis=0).astype(np.float64)  # per i\n\n    # Prefer higher count (more 'bridge' to destination)\n    c_norm = count / (np.mean(count) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    score = s_norm - 0.75 * c_norm\n    return int(unv[int(np.argmin(score))])\n",
  "min_detour_ratio": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    cd = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, unv]\n    rem = distance_matrix[unv, destination_node]\n\n    ratio = (step + rem) / (cd + 1e-12)\n    score = ratio + 0.05 * (step / (np.mean(step) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "max_interiority_score": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    med = np.median(D, axis=1)\n    interior = np.sum(D <= med[:, None], axis=1).astype(np.float64)\n\n    # Prefer higher interiority; still keep step short.\n    i_norm = interior / (np.mean(interior) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    score = s_norm - 0.70 * i_norm\n    return int(unv[int(np.argmin(score))])\n",
  "min_border_crossing": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    # Current's profile vs remaining\n    cur_prof = distance_matrix[current_node, unv]\n    qcur = float(np.quantile(cur_prof, 0.35))\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    q = np.quantile(D, 0.35, axis=1)\n\n    step = distance_matrix[current_node, unv]\n    score = np.abs(q - qcur) + 0.20 * (step / (np.mean(step) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_late_commitment": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    isolation = D.min(axis=1)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Smooth step function\n    pivot = 1.0 / (1.0 + np.exp(-12.0 * (progress - 0.65)))\n\n    score = (1.0 - pivot) * (step - 0.85 * isolation) + pivot * (step + 1.05 * d_dest)\n    return int(unv[int(np.argmin(score))])\n",
  "max_spacing_then_fill": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.45:\n        # Choose among top-farthest 15% and pick the one most central to remaining.\n        k = int(max(1, np.ceil(0.15 * n_rem)))\n        far = np.argsort(-step)[:k]\n        D = distance_matrix[np.ix_(unv, unv)]\n        central = D.mean(axis=1)\n        cand = far\n        score = central[cand] + 0.10 * step[cand]\n        return int(unv[int(cand[int(np.argmin(score))])])\n\n    return int(unv[int(np.argmin(step))])\n",
  "min_two_hop_diameter": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    Dij = distance_matrix[np.ix_(unv, unv)]\n    # For each i, compute max over j of min(Dij[i,j], d_dest[j])\n    cap = np.maximum.reduce(np.minimum(Dij, d_dest[None, :]), axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.85 * (cap / (np.mean(cap) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "entropy_of_ranks": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n\n    # Normalize ranks to a pseudo-probability distribution per row.\n    row_sum = ranks.sum(axis=1) + 1e-12\n    P = ranks / row_sum[:, None]\n    ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) - 0.85 * (ent / (np.mean(ent) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_anchor_then_wander": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.40:\n        k = int(max(2, min(n_rem, np.ceil(0.18 * n_rem))))\n        idx = np.argsort(d_dest)[:k]\n        score = step[idx] + 0.95 * d_dest[idx]\n        return int(unv[int(idx[int(np.argmin(score))])])\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    bottleneck = np.percentile(D, 20, axis=1)\n    score = (step / (np.mean(step) + 1e-12)) + 0.80 * (bottleneck / (np.mean(bottleneck) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_variance_of_knn": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = int(unv.size)\n    k = int(max(3, min(n - 1, np.ceil(0.12 * n))))\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    v = knn.var(axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.85 * (v / (np.mean(v) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_regret_over_two_hops": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n    if n == 1:\n        return int(unv[0])\n\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    Dij = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(Dij, np.inf)\n\n    twohop = Dij + d_dest[None, :]\n    part = np.partition(twohop, 1, axis=1)\n    best = part[:, 0]\n    second = part[:, 1]\n    regret = second - best\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    r_norm = regret / (np.mean(regret) + 1e-12)\n\n    score = s_norm - 0.85 * r_norm\n    return int(unv[int(np.argmin(score))])\n",
  "destination_time_window": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    d_dest = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Target dest-distance slides from high quantile to low quantile.\n    hi = float(np.quantile(d_dest, 0.80))\n    lo = float(np.quantile(d_dest, 0.20))\n    target = (1.0 - progress) * hi + progress * lo\n\n    width = (0.55 - 0.40 * progress) * (hi - lo + 1e-12)\n    penalty = np.maximum(0.0, np.abs(d_dest - target) - width)\n\n    score = (step / (np.mean(step) + 1e-12)) + 1.05 * (penalty / (np.mean(penalty) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "nearest_neighbor_with_blacklist_radius": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Micro radius = 15th percentile of remaining pairwise distances.\n    finite = D[np.isfinite(D)]\n    r = float(np.percentile(finite, 15)) + 1e-12\n    crowd = np.sum(D <= r, axis=1).astype(np.float64)\n\n    # Allow some crowding early, avoid late.\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    limit = (1.0 - progress) * np.percentile(crowd, 80) + progress * np.percentile(crowd, 40)\n\n    mask = crowd <= limit + 1e-12\n    if np.any(mask):\n        idx = np.where(mask)[0]\n        return int(unv[int(idx[int(np.argmin(step[idx]))])])\n\n    return int(unv[int(np.argmin(step))])\n",
  "destination_funnel_kbest": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(unv.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    k = int(max(2, min(n_rem, np.ceil((0.30 - 0.22 * progress) * n_rem))))\n    idx = np.argsort(step)[:k]\n\n    pick = idx[int(np.argmin(d_dest[idx]))]\n    return int(unv[int(pick)])\n",
  "destination_divergence_penalty": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[unv, destination_node]\n    step = distance_matrix[current_node, unv]\n\n    gain = r0 - r\n    best_gain = float(np.max(gain))\n    divergence = (best_gain - gain)\n\n    # Prefer big gain, small step.\n    score = (step / (np.mean(step) + 1e-12)) + 0.95 * (divergence / (np.mean(divergence) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_congestion_cost": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    scale = float(np.median(D[np.isfinite(D)])) + 1e-12\n    density = np.sum(np.exp(-D / scale), axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.80 * (density / (np.mean(density) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "max_coverage_jump": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Coverage radius = 30th percentile of pairwise distances.\n    finite = D[np.isfinite(D)]\n    rad = float(np.percentile(finite, 30)) + 1e-12\n    cover = np.sum(D <= rad, axis=1).astype(np.float64)\n\n    # Prefer higher cover (serve cluster core), but keep step bounded.\n    c_norm = cover / (np.mean(cover) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    score = s_norm - 0.75 * c_norm\n    return int(unv[int(np.argmin(score))])\n",
  "robust_minimax_two_quantiles": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    q80 = np.percentile(D, 80, axis=1)\n    mx = D.max(axis=1)\n    tail = 0.65 * q80 + 0.35 * mx\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.95 * (tail / (np.mean(tail) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_cross_cluster_pull": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)].copy()\n    np.fill_diagonal(D, np.inf)\n    nn = D.min(axis=1)\n\n    # Higher nn => boundary / sparse.\n    n_norm = nn / (np.mean(nn) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    score = s_norm - 0.85 * n_norm\n    return int(unv[int(np.argmin(score))])\n",
  "destination_biased_kmedian": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    med = np.median(D, axis=1)\n\n    score = (step / (np.mean(step) + 1e-12)) + 0.75 * (med / (np.mean(med) + 1e-12)) + 0.55 * (d_dest / (np.mean(d_dest) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "max_distance_dispersion": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    mu = D.mean(axis=1) + 1e-12\n    sigma = D.std(axis=1)\n    disp = sigma / mu\n\n    score = (step / (np.mean(step) + 1e-12)) - 0.75 * (disp / (np.mean(disp) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "min_geodesic_deviation": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n    step = distance_matrix[current_node, unv]\n\n    if n < 3:\n        return int(unv[int(np.argmin(step))])\n\n    # Current profile to remaining\n    pc = step\n    pc = pc - pc.mean()\n    pc_norm = np.sqrt(np.sum(pc * pc)) + 1e-12\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    corr = np.empty(n, dtype=np.float64)\n\n    for i in range(n):\n        pi = D[i] - D[i].mean()\n        denom = (np.sqrt(np.sum(pi * pi)) + 1e-12) * pc_norm\n        corr[i] = float(np.sum(pi * pc) / denom)\n\n    # Prefer high correlation; keep step short.\n    score = (step / (np.mean(step) + 1e-12)) + 0.35 * ((1.0 - corr) / (np.mean(1.0 - corr) + 1e-12))\n    return int(unv[int(np.argmin(score))])\n",
  "destination_intercept_ratio": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, unv]\n    r = distance_matrix[unv, destination_node]\n\n    gain = np.maximum(1e-12, r0 - r)\n    ratio = step / gain\n\n    # If no positive gain, fall back to shortest step.\n    if np.all(r0 - r <= 1e-12):\n        return int(unv[int(np.argmin(step))])\n\n    ratio = np.where(r0 - r > 1e-12, ratio, np.inf)\n    return int(unv[int(np.argmin(ratio))])\n",
  "late_stage_endgame_lock": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    n = int(unv.size)\n\n    step = distance_matrix[current_node, unv]\n    d_dest = distance_matrix[unv, destination_node]\n\n    if n <= 6:\n        # Evaluate choosing i now and then best (i->j + j->dest).\n        D = distance_matrix[np.ix_(unv, unv)].copy()\n        np.fill_diagonal(D, np.inf)\n        future = np.min(D + d_dest[None, :], axis=1)\n        score = step + future\n        return int(unv[int(np.argmin(score))])\n\n    # Otherwise simple: step + moderate destination pull.\n    score = step + 0.85 * d_dest\n    return int(unv[int(np.argmin(score))])\n",
  "edge_contrast_balancer": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    unv = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, unv]\n\n    D = distance_matrix[np.ix_(unv, unv)]\n    med = np.median(D, axis=1)\n\n    score = np.abs(step - med) / (np.mean(np.abs(step - med)) + 1e-12)\n    return int(unv[int(np.argmin(score))])\n",
  "adaptive_nn_dest_bias_aug_0": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    alpha = 0.25 + 1.75 * progress\n    score = d_cur + alpha * d_dest\n\n    # deterministic noise to break ties\n    noise = np.arange(candidates.size, dtype=float) * 1e-6\n    return int(candidates[np.argmin(score + noise)])\n\n",
  "adaptive_nn_dest_bias_aug_1": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    alpha = 0.2 + 1.8 * progress   # tuned weights\n    score = d_cur + alpha * d_dest\n\n    # select top\u2011k smallest scores\n    k = min(7, cand.size)\n    top_k_idx = np.argpartition(score, k - 1)[:k]\n\n    # deterministic random choice among top\u2011k\n    seed = int((current_node + destination_node) * 1234567)\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(top_k_idx)\n    return int(cand[chosen])\n\n",
  "adaptive_nn_dest_bias_aug_2": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    alpha = 0.3 + 1.7 * progress\n    score = d_cur + alpha * d_dest\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.arange(cand.size, dtype=float) * 1e-7\n    score_noisy = score + noise\n\n    # choose among top\u20113 smallest\n    k = min(3, cand.size)\n    top_k_idx = np.argpartition(score_noisy, k - 1)[:k]\n    seed = int((current_node - destination_node) * 7654321)\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(top_k_idx)\n    return int(cand[chosen])\n\n",
  "adaptive_nn_dest_bias_aug_3": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = np.mean([1.0 - (n_rem / max(1, n_total))])  # mean of single value\n\n    alpha = np.clip(0.25 + 1.75 * progress, 0.0, 2.0)   # clip to avoid extremes\n    score = d_cur + alpha * d_dest\n\n    # deterministic noise\n    noise = np.arange(cand.size, dtype=float) * 1e-5\n    return int(cand[np.argmin(score + noise)])\n\n",
  "adaptive_nn_dest_bias_aug_4": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    alpha = 0.25 + 1.75 * progress\n    score = d_cur + alpha * d_dest\n\n    # softmax weights (deterministic)\n    max_score = np.max(score) + 1e-12\n    weights = np.exp(-(score - max_score) / (max_score + 1e-12))\n    top_k = min(5, cand.size)\n    top_idx = np.argpartition(weights, -top_k)[-top_k:]\n\n    seed = int((current_node + destination_node) * 9876543)\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(top_idx)\n    return int(cand[chosen])\n\n",
  "farthest_early_nearest_late_aug_5": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Invert conditional logic\n    if progress >= 0.5:\n        # Greedy tightening: use a slightly heavier weight on the destination distance\n        scores = dist_mat[current_node, candidates] + 0.8 * dist_mat[candidates, destination_node]\n        idx = int(np.argmin(scores))\n        return int(candidates[idx])\n    else:\n        # Farthest\u2011exploration early\n        k = max(1, int(np.ceil(0.10 * n_rem)))\n        far_idx = np.argsort(-dist_mat[current_node, candidates])[:k]\n        dest_dists = dist_mat[candidates[far_idx], destination_node]\n        idx = int(np.argmin(dest_dists))\n        return int(candidates[far_idx[idx]])\n\n",
  "farthest_early_nearest_late_aug_6": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(candidates.size, dtype=float) * 1e-6\n\n    if progress < 0.5:\n        k = max(1, int(np.ceil(0.15 * n_rem)))\n        far_idx = np.argsort(-dist_mat[current_node, candidates])[:k]\n        dest_dists = dist_mat[candidates[far_idx], destination_node] + noise[far_idx]\n        idx = int(np.argmin(dest_dists))\n        return int(candidates[far_idx[idx]])\n    else:\n        # Greedy tightening using a while loop and softmin selection\n        i = 0\n        min_score = np.inf\n        min_idx   = 0\n        while i < candidates.size:\n            score = (dist_mat[current_node, candidates[i]] +\n                     0.75 * dist_mat[candidates[i], destination_node] + noise[i])\n            if score < min_score:\n                min_score = score\n                min_idx   = i\n            i += 1\n        return int(candidates[min_idx])\n\n",
  "farthest_early_nearest_late_aug_7": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = np.clip(distance_matrix, 0, 1e6)\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.5:\n        k = max(1, int(np.ceil(0.12 * n_rem)))  # top\u2011k \u2248 7 for typical sizes\n        far_idx = np.argsort(-dist_mat[current_node, candidates])[:k]\n        dest_dists = dist_mat[candidates[far_idx], destination_node]\n        median_dist = np.median(dest_dists)\n        close_idx = np.where(np.abs(dest_dists - median_dist) < 1e-8)[0]\n        rng = np.random.default_rng(seed=current_node + destination_node)\n        pick = int(rng.choice(close_idx) if close_idx.size > 0 else np.argmin(dest_dists))\n        return int(candidates[far_idx[pick]])\n    else:\n        scores = dist_mat[current_node, candidates] + 0.75 * dist_mat[candidates, destination_node]\n        k = max(1, int(np.ceil(0.10 * n_rem)))\n        topk_idx = np.argpartition(scores, k-1)[:k]\n        rng = np.random.default_rng(seed=current_node + destination_node)\n        pick = int(rng.choice(topk_idx))\n        return int(candidates[pick])\n\n",
  "farthest_early_nearest_late_aug_8": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Invert conditional: use proxy when progress is high\n    if progress >= 0.5:\n        # Proxy: take the maximum of the two distances\n        proxy = np.maximum(dist_mat[current_node, candidates],\n                           dist_mat[candidates, destination_node])\n        idx = int(np.argmin(proxy))\n        return int(candidates[idx])\n    else:\n        k = max(1, int(np.ceil(0.15 * n_rem)))\n        far_idx = np.argsort(-dist_mat[current_node, candidates])[:k]\n        dest_dists = dist_mat[candidates[far_idx], destination_node]\n        noise = np.arange(far_idx.size, dtype=float) * 1e-6\n        dest_dists += noise\n        idx = int(np.argmin(dest_dists))\n        return int(candidates[far_idx[idx]])\n\n",
  "farthest_early_nearest_late_aug_9": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.5:\n        k = max(1, int(np.ceil(0.12 * n_rem)))\n        far_idx = np.argpartition(-dist_mat[current_node, candidates], k-1)[:k]\n        dest_dists = dist_mat[candidates[far_idx], destination_node]\n        idx = int(np.argmin(dest_dists))\n        return int(candidates[far_idx[idx]])\n    else:\n        scores = dist_mat[current_node, candidates] + 0.75 * dist_mat[candidates, destination_node]\n        # Softmax weighting with temperature\n        temp = 0.5\n        exp_scores = np.exp(-scores / temp)\n        denom = np.sum(exp_scores) + 1e-12   # epsilon to avoid division by zero\n        probs = exp_scores / denom\n        rng = np.random.default_rng(seed=current_node + destination_node)\n        idx = int(rng.choice(candidates.size, p=probs))\n        return int(candidates[idx])\n\n",
  "mean_proximity_to_remaining_aug_10": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    mean_to_cand = D.mean(axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / (n_total + 1e-12))\n\n    beta = 1.5 * (1.0 - progress) + 0.1\n    beta = np.clip(beta, 0.0, 2.0)          # keep beta bounded\n\n    score = d_cur + beta * mean_to_cand\n\n    # deterministic tie\u2011breaking noise\n    noise = 1e-6 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "mean_proximity_to_remaining_aug_11": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    mean_to_cand = D.mean(axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / (n_total + 1e-12))\n\n    beta = 2.0 * (1.0 - progress) + 0.2\n    beta = np.clip(beta, 0.0, 3.0)\n\n    score = d_cur + beta * mean_to_cand\n\n    # Top\u2011k selection and softmin probability\n    top_k = min(7, score.size)\n    idx_top = np.argpartition(score, top_k-1)[:top_k]\n    top_scores = score[idx_top]\n\n    temp = 0.5\n    weights = np.exp(-top_scores / (temp + 1e-12))\n    weights /= weights.sum()\n\n    rng = np.random.default_rng(12345)\n    chosen = rng.choice(idx_top, p=weights)\n\n    return int(cand[chosen])\n\n",
  "mean_proximity_to_remaining_aug_12": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    median_to_cand = np.median(D, axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / (n_total + 1e-12))\n\n    beta = 1.8 * (1.0 - progress) + 0.15\n    beta = np.clip(beta, 0.0, 2.5)\n\n    # Proxy: distance to destination\n    d_dest = distance_matrix[destination_node, cand]\n\n    score = d_cur + beta * median_to_cand + 0.5 * d_dest\n\n    noise = 1e-6 * np.arange(score.size)\n    score += noise\n\n    # Softmin over all candidates\n    temp = 0.7\n    weights = np.exp(-score / (temp + 1e-12))\n    weights /= weights.sum()\n\n    rng = np.random.default_rng(98765)\n    chosen = rng.choice(cand, p=weights)\n\n    return int(chosen)\n\n",
  "mean_proximity_to_remaining_aug_13": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    max_to_cand  = np.max(D, axis=1)\n    sum_to_cand  = np.sum(D, axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / (n_total + 1e-12))\n\n    beta = 0.9 * (1.0 - progress) + 0.05\n    beta = np.clip(beta, 0.0, 1.5)\n\n    score = d_cur + beta * max_to_cand + 0.2 * sum_to_cand\n\n    # Clip scores to avoid extreme values\n    score = np.clip(score, 0.0, 1e6)\n\n    return int(cand[np.argmin(score)])\n\n",
  "mean_proximity_to_remaining_aug_14": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / (n_total + 1e-12))\n\n    beta = 1.2 * (1.0 - progress) + 0.1\n    beta = np.clip(beta, 0.0, 2.0)\n\n    scores = np.empty(cand.size, dtype=float)\n    idx = 0\n    while idx < cand.size:\n        cur = cand[idx]\n        d_cur = distance_matrix[current_node, cur]\n        D = distance_matrix[cur, cand]\n        mean_to_cand = D.mean()\n        scores[idx] = d_cur + beta * mean_to_cand\n        idx += 1\n\n    # deterministic tie\u2011breaking noise\n    noise = 1e-6 * np.arange(scores.size)\n    scores += noise\n\n    return int(cand[np.argmin(scores)])\n\n",
  "outlier_sweep_then_cluster_aug_15": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_cur = dist_mat[current_node, candidates]\n    D = dist_mat[np.ix_(candidates, candidates)]\n    mean_to_cand = D.mean(axis=1)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = mean_to_cand / (np.mean(mean_to_cand) + 1e-12)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.arange(candidates.size) * 1e-6\n\n    if progress < 0.6:\n        score = -m_norm + 0.35 * d_norm\n    else:\n        score = d_norm + 0.75 * m_norm\n\n    idx = int(np.argmin(score + noise))\n    return int(candidates[idx])\n\n",
  "outlier_sweep_then_cluster_aug_16": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    # Build d_cur with a while loop\n    d_cur = np.empty(candidates.size, dtype=float)\n    i = 0\n    while i < candidates.size:\n        d_cur[i] = dist_mat[current_node, candidates[i]]\n        i += 1\n\n    D = dist_mat[np.ix_(candidates, candidates)]\n    mean_to_cand = np.median(D, axis=1)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = mean_to_cand / (np.mean(mean_to_cand) + 1e-12)\n\n    if progress < 0.6:\n        score = -m_norm + 0.4 * d_norm\n    else:\n        score = d_norm + 0.6 * m_norm\n\n    # Softmin selection with probability clipping\n    exp_vals = np.exp(-score)\n    probs    = np.clip(exp_vals / (np.sum(exp_vals) + 1e-12), 0, 1)\n    chosen   = int(np.random.choice(candidates, p=probs))\n    return chosen\n\n",
  "outlier_sweep_then_cluster_aug_17": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_cur = np.array([dist_mat[current_node, c] for c in candidates])\n    D     = np.array([[dist_mat[i, j] for j in candidates] for i in candidates])\n    mean_to_cand = D.sum(axis=1) / max(1, D.shape[1])\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = mean_to_cand / (np.mean(mean_to_cand) + 1e-12)\n\n    if progress < 0.6:\n        score = -m_norm + 0.5 * d_norm\n    else:\n        score = d_norm + 0.5 * m_norm\n\n    top_k = min(7, len(candidates))\n    indices = np.argsort(score)[:top_k]\n    chosen = int(np.random.choice(candidates[indices]))\n    return chosen\n\n",
  "outlier_sweep_then_cluster_aug_18": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_cur = dist_mat[current_node, candidates]\n    D     = dist_mat[np.ix_(candidates, candidates)]\n    mean_to_cand = D.max(axis=1)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = mean_to_cand / (np.mean(mean_to_cand) + 1e-12)\n\n    # Inverted conditional logic\n    if progress >= 0.6:\n        score = -m_norm + 0.3 * d_norm\n    else:\n        score = d_norm + 0.8 * m_norm\n\n    noise = np.arange(candidates.size) * 1e-6\n    idx = int(np.argmin(score + noise))\n    return int(candidates[idx])\n\n",
  "outlier_sweep_then_cluster_aug_19": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_cur   = dist_mat[current_node, candidates]\n    d_cur_sq = np.square(d_cur)\n\n    D = dist_mat[np.ix_(candidates, candidates)]\n    mean_to_cand = np.median(D, axis=1)\n    mean_to_cand_sq = np.square(mean_to_cand)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    d_norm = d_cur_sq / (np.mean(d_cur_sq) + 1e-12)\n    m_norm = mean_to_cand_sq / (np.mean(mean_to_cand_sq) + 1e-12)\n\n    if progress < 0.7:\n        score = -m_norm + 0.45 * d_norm\n    else:\n        score = d_norm + 0.55 * m_norm\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "variance_anchor_aug_20": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    # distances from current node to candidates\n    d_cur = dist_mat[current_node, candidates]\n\n    # sub\u2011matrix of distances among candidates\n    D = dist_mat[np.ix_(candidates, candidates)]\n\n    # variance of each candidate to the remaining ones\n    var_to_cand = np.var(D, axis=1)\n\n    # use median instead of mean to reduce influence of outliers\n    med_d   = np.median(d_cur) + 1e-12\n    med_var = np.median(var_to_cand) + 1e-12\n\n    # score combines distance and variance\n    score = (d_cur / med_d) + 0.6 * (var_to_cand / med_var)\n\n    # deterministic noise for stable tie\u2011breaking\n    noise = np.arange(candidates.size) * 1e-9\n    score += noise\n\n    # pick the candidate with minimal score\n    idx = np.argmin(score)\n    return int(candidates[idx])\n\n",
  "variance_anchor_aug_21": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename for readability\n    nodes = unvisited_nodes.astype(int)\n    mat   = distance_matrix\n\n    # sum of distances from current node to each candidate\n    d_sum = np.sum(mat[current_node, nodes]) + 1e-12\n    d_cur = mat[current_node, nodes] / d_sum\n\n    # pairwise distances among candidates\n    pair = mat[np.ix_(nodes, nodes)]\n    var  = np.sum(pair, axis=1)  # use sum instead of variance\n\n    # score with simple weights\n    score = 0.5 * d_cur + 0.5 * (var / (np.sum(var) + 1e-12))\n\n    # add small deterministic noise to break ties\n    noise = np.linspace(0, 1e-8, nodes.size)\n    score += noise\n\n    # choose uniformly among the best top\u20115\n    top_k = 5\n    best_idx = np.argpartition(score, top_k)[:top_k]\n    chosen = np.random.choice(best_idx)\n    return int(nodes[chosen])\n\n",
  "variance_anchor_aug_22": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # variable names\n    idxs = unvisited_nodes.astype(int)\n    dmat = distance_matrix\n\n    # squared distances from current node to each candidate\n    d_sq = np.square(dmat[current_node, idxs])\n\n    # sub\u2011matrix of squared distances among candidates\n    sub_sq = np.square(dmat[np.ix_(idxs, idxs)])\n\n    # use mean absolute deviation as a proxy for variance\n    mad = np.mean(np.abs(sub_sq - np.mean(sub_sq, axis=1, keepdims=True)), axis=1)\n\n    # clip values to keep them bounded\n    d_sq = np.clip(d_sq, 0, 1e6)\n    mad  = np.clip(mad, 0, 1e6)\n\n    # max instead of mean for aggregation\n    max_d = np.max(d_sq) + 1e-12\n    max_m = np.max(mad) + 1e-12\n\n    # weighted score\n    score = 0.7 * (d_sq / max_d) + 0.3 * (mad / max_m)\n\n    # pick the candidate with minimal score\n    chosen = np.argmin(score)\n    return int(idxs[chosen])\n\n",
  "variance_anchor_aug_23": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename for clarity\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    # distance from current node to each candidate\n    d = dist[current_node, cand]\n\n    # approximate variance: squared difference from mean of pairwise distances\n    pair = dist[np.ix_(cand, cand)]\n    mean_pair = np.mean(pair, axis=1, keepdims=True)\n    approx_var = np.mean(np.square(pair - mean_pair), axis=1)\n\n    # use equal weights\n    w_dist = 0.5\n    w_var  = 0.5\n\n    # compute score with epsilon\n    mean_d = np.mean(d) + 1e-12\n    mean_v = np.mean(approx_var) + 1e-12\n    score = w_dist * (d / mean_d) + w_var * (approx_var / mean_v)\n\n    # deterministic tie\u2011breaker: add tiny increasing offset\n    offset = np.arange(cand.size) * 1e-10\n    score += offset\n\n    # select minimal score\n    idx = np.argmin(score)\n    return int(cand[idx])\n\n",
  "entropy_seeker_aug_24": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size != 0:\n        candidates = unvisited_nodes.astype(int)\n\n        # Current distances to the candidates\n        d_cur = distance_matrix[current_node, candidates]\n\n        # Build the sub\u2011distance matrix with a list comprehension\n        D = np.array([[distance_matrix[i, j] for j in candidates] for i in candidates])\n        row_tot = D.sum(axis=1) + 1e-12\n        P = D / row_tot[:, None]\n        P = np.clip(P, 1e-12, 1.0)                     # avoid log(0)\n        entropy = -(P * np.log(P)).sum(axis=1)\n\n        d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n        e_norm = entropy / (np.mean(entropy) + 1e-12)\n\n        # Deterministic tie\u2011breaking noise\n        noise = np.arange(len(entropy)) * 1e-6\n        score = d_norm - 0.7 * e_norm + noise\n        return int(candidates[int(np.argmin(score))])\n    else:\n        return int(destination_node)\n\n",
  "entropy_seeker_aug_25": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n\n    # Sub\u2011matrix via np.ix_\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    row_sum = D.sum(axis=1) + 1e-12\n    P = D / row_sum[:, None]\n    P = np.clip(P, 1e-12, 1.0)\n    entropy = -(P * np.log(P)).sum(axis=1)\n\n    d_norm = d_cur / (np.median(d_cur) + 1e-12)\n    e_norm = entropy / (np.median(entropy) + 1e-12)\n\n    # Softmin probabilities and random weighted choice\n    softmin = np.exp(-(d_norm - 0.5 * e_norm))\n    softmin /= softmin.sum() + 1e-12\n\n    rng = np.random.default_rng(123)\n    return int(candidates[rng.choice(len(candidates), p=softmin)])\n\n",
  "entropy_seeker_aug_26": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = np.square(distance_matrix[current_node, candidates])   # use squared distance\n\n    # Max distance as a proxy for entropy\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    max_dist = D.max(axis=1) + 1e-12\n\n    d_norm = d_cur / (np.max(d_cur) + 1e-12)\n    e_norm = max_dist / (np.max(max_dist) + 1e-12)\n\n    score = d_norm - 0.6 * e_norm\n\n    # Random tie\u2011breaking among the best 7 candidates\n    top_k = 7\n    idx = np.argsort(score)[:top_k]\n    rng = np.random.default_rng(42)\n    return int(candidates[rng.choice(idx)])\n\n",
  "entropy_seeker_aug_27": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    row_sum = D.sum(axis=1) + 1e-12\n    P = D / row_sum[:, None]\n    P = np.clip(P, 1e-12, 1.0)\n    entropy = -(P * np.log(P)).sum(axis=1)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    e_norm = entropy / (np.median(entropy) + 1e-12)\n\n    # Softmax over a weighted combination\n    logits = - (0.4 * d_norm + 0.6 * e_norm)\n    exp_logits = np.exp(logits - np.max(logits))\n    probs = exp_logits / (exp_logits.sum() + 1e-12)\n\n    rng = np.random.default_rng(999)\n    return int(candidates[rng.choice(len(candidates), p=probs)])\n\n",
  "regret_gap_guard_aug_28": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, candidates]\n\n    # Distance matrix among the remaining candidates\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    # Regret: difference between second\u2011best and best neighbour distances\n    two_best = np.partition(sub_mat, 1, axis=1)[:, :2]\n    regret = two_best[:, 1] - two_best[:, 0]\n\n    # Normalise by the median to reduce the influence of outliers\n    d_norm = dist_cur / (np.median(dist_cur) + 1e-12)\n    r_norm = regret / (np.median(regret) + 1e-12)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = 1e-9 * np.arange(candidates.size)\n\n    # Final score: close nodes are preferred, but large regret penalises them\n    score = d_norm - 0.75 * r_norm + noise\n\n    chosen_index = int(np.argmin(score))\n    return int(candidates[chosen_index])\n\n",
  "regret_gap_guard_aug_29": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    opts = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, opts]\n\n    # Submatrix of distances between remaining nodes\n    sub = distance_matrix[np.ix_(opts, opts)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    # Regret: second\u2011best minus best neighbour distance\n    two = np.partition(sub, 1, axis=1)[:, :2]\n    regret = two[:, 1] - two[:, 0]\n\n    # Normalisation with the sum of the values\n    d_norm = d_cur / (np.sum(d_cur) + 1e-12)\n    r_norm = regret / (np.sum(regret) + 1e-12)\n\n    # Composite score with tuned weights\n    score = 0.6 * d_norm + 0.4 * r_norm\n\n    # Randomly choose one of the top\u2011k lowest scores\n    top_k = 3\n    k_indices = np.argpartition(score, top_k)[:top_k]\n    chosen = int(opts[np.random.choice(k_indices)])\n\n    return chosen\n\n",
  "regret_gap_guard_aug_30": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, cand]\n\n    # Distance matrix among candidates\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    # Regret as difference of the two smallest distances\n    two = np.partition(sub, 1, axis=1)[:, :2]\n    regret = two[:, 1] - two[:, 0]\n\n    # Normalise using the maximum to keep values bounded\n    d_norm = dist_cur / (np.max(dist_cur) + 1e-12)\n    r_norm = regret / (np.max(regret) + 1e-12)\n\n    # Soft\u2011min weighting\n    temp = 0.5\n    weight = np.exp(-temp * (d_norm + r_norm))\n    weight = np.clip(weight, 0, 1)          # bound the weight\n    prob = weight / (np.sum(weight) + 1e-12)\n\n    # Sample a node according to the probability distribution\n    chosen = int(cand[np.random.choice(cand.size, p=prob)])\n\n    return chosen\n\n",
  "regret_gap_guard_aug_31": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    dist_cur = np.sqrt(distance_matrix[current_node, nodes])   # use sqrt of distance\n\n    # Submatrix of distances between remaining nodes\n    sub = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    # Regret: sum of two smallest distances minus the smallest\n    two = np.partition(sub, 1, axis=1)[:, :2]\n    regret = np.sum(two, axis=1) - np.min(two, axis=1)\n\n    # Normalise with the sum\n    d_norm = dist_cur / (np.sum(dist_cur) + 1e-12)\n    r_norm = regret / (np.sum(regret) + 1e-12)\n\n    # Deterministic noise proportional to node id\n    noise = 1e-6 * nodes\n\n    # Final score\n    score = 0.5 * d_norm + 0.5 * r_norm + noise\n\n    chosen_idx = int(np.argmin(score))\n    return int(nodes[chosen_idx])\n\n",
  "two_step_best_next_aug_32": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # distance from the current node to each candidate\n    d_cur = np.array([distance_matrix[current_node, i] for i in cand])\n\n    # distance from each candidate to its nearest other candidate\n    best_next = []\n    for i in cand:\n        others = [distance_matrix[i, j] for j in cand if j != i]\n        best_next.append(min(others))\n    best_next = np.array(best_next)\n\n    # weighted score\n    score = d_cur * 0.7 + best_next * 0.3\n\n    # deterministic tie\u2011breaking noise\n    noise = np.arange(len(score)) * 1e-6\n    score += noise\n\n    # clip to avoid extreme values\n    score = np.clip(score, 0, 1e6)\n\n    return int(cand[np.argmin(score)])\n\n",
  "two_step_best_next_aug_33": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n\n    sub = distance_matrix[np.ix_(cand, cand)]\n    np.fill_diagonal(sub, np.inf)\n    best_next = sub.min(axis=1)\n\n    score = d_cur + best_next\n\n    # soft\u2011min probabilities\n    tau = 1.0\n    exp_scores = np.exp(-score / (tau + 1e-12))\n    probs = exp_scores / (exp_scores.sum() + 1e-12)\n\n    # choose among the top\u2011k lowest scores\n    top_k = 5\n    idx_sorted = np.argsort(score)\n    top_indices = idx_sorted[:min(top_k, len(idx_sorted))]\n\n    # weighted random choice among the top\u2011k\n    chosen = np.random.choice(\n        top_indices,\n        p=probs[top_indices] / (probs[top_indices].sum() + 1e-12)\n    )\n\n    return int(cand[chosen])\n\n",
  "two_step_best_next_aug_34": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n    sub = distance_matrix[np.ix_(cand, cand)]\n    np.fill_diagonal(sub, np.inf)\n\n    best_next = np.median(sub, axis=1)\n\n    # normalise d_cur by its mean\n    mean_d = np.mean(d_cur)\n    score = (d_cur - mean_d) * 0.6 + best_next * 0.4\n\n    # clip to avoid extreme values\n    score = np.clip(score, 0, 1e6)\n\n    return int(cand[np.argmin(score)])\n\n",
  "two_step_best_next_aug_35": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n\n    sub = distance_matrix[np.ix_(cand, cand)]\n    np.fill_diagonal(sub, np.inf)\n\n    # proxy for the nearest\u2011neighbour distance\n    best_next = sub.sum(axis=1)\n\n    score = d_cur * 0.5 + best_next * 0.5\n\n    # deterministic tie\u2011breaking noise\n    noise = np.linspace(0, 1e-5, len(score))\n    score += noise\n\n    # clip to keep values bounded\n    score = np.clip(score, 0, 1e6)\n\n    return int(cand[np.argmin(score)])\n\n",
  "two_step_balanced_with_dest_aug_36": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables for clarity\n    cand = unvisited_nodes.astype(int)\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n\n    # Build distance matrix among candidates\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Best next distance (minimal)\n    best_next = D.min(axis=1)\n\n    # Weighted scoring with deterministic noise\n    score = 0.6 * d_cur + 0.4 * best_next + 0.35 * d_dest\n    score += 1e-6 * np.arange(len(cand))          # tie\u2011breaking noise\n    score = np.clip(score, 0, None)               # prevent negative values\n    score = score / (1.0 + 1e-12)                 # epsilon on denominator\n\n    return int(cand[np.argmin(score)])\n\n",
  "two_step_balanced_with_dest_aug_37": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur  = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Use median distance as a proxy for the next hop\n    best_next = np.median(D, axis=1)\n\n    # Raw score and deterministic noise\n    raw_score = 0.5 * d_cur + 0.5 * best_next + 0.35 * d_dest\n    raw_score += 1e-7 * np.arange(len(cand))\n\n    # Soft\u2011min probabilities\n    eps = 1e-12\n    exp_vals = np.exp(-raw_score / (1.0 + eps))\n    probs = exp_vals / (np.sum(exp_vals) + eps)\n    probs = np.clip(probs, 0, 1)                 # bounded probabilities\n\n    # Deterministically pick the highest probability\n    idx = int(np.argmax(probs))\n    return int(cand[idx])\n\n",
  "two_step_balanced_with_dest_aug_38": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur  = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Proxy: sum of distances to all other candidates\n    best_next = D.sum(axis=1)\n\n    # Max\u2011based aggregation and deterministic noise\n    score = np.maximum(0.4 * d_cur + 0.6 * best_next, 0.0) + 0.35 * d_dest\n    score += 1e-8 * np.arange(len(cand))\n    score = np.clip(score, 0, None)                   # bound below\n    score = score / (1.0 + 1e-12)                     # epsilon on denominator\n\n    return int(cand[np.argmin(score)])\n\n",
  "two_step_balanced_with_dest_aug_39": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size > 0:\n        cand = unvisited_nodes.astype(int)\n        d_cur  = distance_matrix[current_node, cand]\n        d_dest = distance_matrix[cand, destination_node]\n\n        D = distance_matrix[np.ix_(cand, cand)].copy()\n        np.fill_diagonal(D, np.inf)\n        best_next = D.min(axis=1)\n\n        # Manual search for minimal score\n        min_score = np.inf\n        best_idx  = 0\n        for i in range(len(cand)):\n            score = (0.55 * d_cur[i] + 0.45 * best_next[i] + 0.35 * d_dest[i])\n            score += 1e-9 * i                           # deterministic tie\u2011break\n            score = np.clip(score, 0, None)              # bound below\n            score = score / (1.0 + 1e-12)                # epsilon on denominator\n            if score < min_score:\n                min_score = score\n                best_idx = i\n\n        return int(cand[best_idx])\n    else:\n        return int(destination_node)\n\n",
  "minimax_centrality_aug_40": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename for clarity\n    candidates = unvisited_nodes.astype(int)\n\n    # distances from current node to every candidate\n    d_cur = distance_matrix[current_node, candidates]\n\n    # pairwise distances among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n    max_to_cand = D.max(axis=1)\n\n    # normalise by the mean of the current distances\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = max_to_cand / (np.mean(max_to_cand) + 1e-12)\n\n    # score with a different weight mix\n    scores = []\n    for idx, cand in enumerate(candidates):\n        score = 0.6 * d_norm[idx] + 0.4 * m_norm[idx]\n        # deterministic tie\u2011breaker: add a tiny noise\n        score += np.random.uniform(0, 1e-8)\n        scores.append(score)\n\n    best_idx = int(np.argmin(scores))\n    return int(candidates[best_idx])\n\n",
  "minimax_centrality_aug_41": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n    max_to_cand = D.max(axis=1)\n\n    # clip to avoid any unexpected negative values\n    max_to_cand = np.clip(max_to_cand, 0, None)\n\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    m_norm = max_to_cand / (np.mean(max_to_cand) + 1e-12)\n\n    # stronger emphasis on distance\n    score = 0.7 * d_norm + 0.3 * m_norm\n\n    # top\u2011k deterministic choice\n    top_k = 5\n    if score.size > top_k:\n        kth_val = np.partition(score, top_k - 1)[top_k - 1]\n        mask = score <= kth_val\n        chosen_candidates = candidates[mask]\n        chosen = np.random.choice(chosen_candidates)\n    else:\n        chosen = np.random.choice(candidates)\n\n    return int(chosen)\n\n",
  "triangle_slack_min_aug_42": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    d_cd   = float(distance_matrix[current_node, destination_node])\n    d_cur  = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    # triangle slack, clipped to avoid negative values\n    slack = np.abs(d_cur + d_dest - d_cd)\n    slack = np.clip(slack, 0, None)\n\n    # score = slack + 0.05 * distance to current node\n    score = slack + 0.05 * d_cur\n\n    # deterministic noise to break ties\n    noise = np.arange(score.size) * 1e-8\n    score += noise\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "triangle_slack_min_aug_43": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cd   = float(distance_matrix[current_node, destination_node])\n    d_cur  = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    slack = np.abs(d_cur + d_dest - d_cd)\n    slack = np.clip(slack, 0, None)\n\n    score = slack + 0.05 * d_cur\n\n    # soft\u2011min: convert scores to probabilities\n    temp = 1.0\n    exp_scores = np.exp(-score / (temp + 1e-12))\n    probs = exp_scores / (np.sum(exp_scores) + 1e-12)\n\n    idx = int(np.random.choice(cand.size, p=probs))\n    return int(cand[idx])\n\n",
  "triangle_slack_min_aug_44": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cd   = float(distance_matrix[current_node, destination_node])\n    d_cur  = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    slack = np.abs(d_cur + d_dest - d_cd)\n    slack = np.clip(slack, 0, None)\n\n    score = slack + 0.05 * d_cur\n\n    top_k = min(7, score.size)          # hyper\u2011parameter tuning\n    top_indices = np.argpartition(score, top_k)[:top_k]\n    chosen = int(cand[np.random.choice(top_indices)])\n    return chosen\n\n",
  "triangle_slack_min_aug_45": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cd  = distance_matrix[current_node, destination_node]   # proxy for slack\n    d_cur = distance_matrix[current_node, cand]\n\n    # new weighting: higher influence of d_cur\n    score = d_cd + 0.1 * d_cur\n\n    # choose node whose score is closest to the median (semantic diversity)\n    median_score = np.median(score)\n    diff = np.abs(score - median_score)\n    idx = int(np.argmin(diff))\n    return int(cand[idx])\n\n",
  "cosine_alignment_to_dest_aug_46": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    eps = 1e-12\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, candidates]\n    c = distance_matrix[candidates, destination_node]\n\n    denom = 2.0 * a * (b + eps) + eps\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    score = -cos_theta + 0.05 * (b / (np.mean(b) + eps))\n    # deterministic tie\u2011breaking noise\n    noise = 1e-8 * np.arange(len(candidates))\n    score += noise\n    return int(candidates[int(np.argmin(score))])\n\n",
  "cosine_alignment_to_dest_aug_47": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    eps = 1e-12\n    scores = []\n\n    for node in unvisited_nodes:\n        a = float(distance_matrix[current_node, destination_node])\n        b = distance_matrix[current_node, int(node)]\n        c = distance_matrix[int(node), destination_node]\n\n        denom = 2.0 * a * (b + eps) + eps\n        cos_theta = (a * a + b * b - c * c) / denom\n        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n        norm_b = b / (np.median(distance_matrix[current_node, unvisited_nodes]) + eps)\n        score = -cos_theta + 0.07 * norm_b\n        scores.append(score)\n\n    scores = np.array(scores)\n    top_k = 6\n    if scores.size <= top_k:\n        chosen = np.argmin(scores)\n    else:\n        top_indices = np.argpartition(scores, top_k)[:top_k]\n        chosen = int(np.random.choice(top_indices))\n    return int(unvisited_nodes[chosen])\n\n",
  "cosine_alignment_to_dest_aug_48": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    eps = 1e-12\n    a = float(distance_matrix[current_node, destination_node])\n    candidates = unvisited_nodes.astype(int)\n    b = distance_matrix[current_node, candidates]\n    c = distance_matrix[candidates, destination_node]\n\n    denom = 2.0 * a * (b + eps) + eps\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    baseline = np.max(b) + eps\n    score = -cos_theta + 0.04 * (b / baseline)\n\n    # deterministic noise for reproducibility\n    noise = 1e-9 * np.arange(len(candidates))\n    score += noise\n\n    temp = 0.5\n    probs = np.exp(-score / temp)\n    probs /= np.sum(probs)\n    chosen_idx = int(np.argmax(probs))\n    return int(candidates[chosen_idx])\n\n",
  "cosine_alignment_to_dest_aug_49": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    eps = 1e-12\n    a = float(distance_matrix[current_node, destination_node])\n    candidates = unvisited_nodes.astype(int)\n    b = distance_matrix[current_node, candidates]\n    c = distance_matrix[candidates, destination_node]\n\n    denom = 2.0 * a * (b + eps) + eps\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    norm_b = b / (np.sum(b) + eps)\n    score = -cos_theta + 0.06 * norm_b\n\n    noise = 1e-7 * np.arange(len(candidates))\n    score += noise\n\n    top_k = 4\n    if score.size <= top_k:\n        chosen = np.argmin(score)\n    else:\n        top_indices = np.argpartition(score, top_k)[:top_k]\n        chosen = int(np.random.choice(top_indices))\n    return int(candidates[chosen])\n\n",
  "median_step_match_aug_50": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables for clarity\n    candidates = unvisited_nodes.astype(int)\n\n    # Vectorised distance extraction\n    d_cur = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    # Median-based scoring\n    med = np.median(d_cur)\n    score = np.abs(d_cur - med) + 0.10 * d_dest\n\n    # Small deterministic noise for tie\u2011breaking\n    score += np.random.rand(len(candidates)) * 1e-6\n\n    return int(candidates[np.argmin(score)])\n\n",
  "median_step_match_aug_51": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n\n    # Select the best 7 candidates based on proximity to the current node\n    top_k = min(7, len(candidates))\n    top_indices = np.argsort(d_cur)[:top_k]\n    top_cand = candidates[top_indices]\n    d_cur_top = d_cur[top_indices]\n    d_dest_top = distance_matrix[top_cand, destination_node]\n\n    # Weighted score: 40% current distance, 60% destination distance\n    score = 0.4 * d_cur_top + 0.6 * d_dest_top\n\n    # Softmin probability distribution\n    temperature = 1.0\n    exp_vals = np.exp(-score / temperature)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)  # epsilon to avoid div\u2011by\u2011zero\n\n    chosen_idx = np.random.choice(len(top_cand), p=probs)\n    return int(top_cand[chosen_idx])\n\n",
  "median_step_match_aug_52": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    # Mean\u2011based deviation scoring\n    d_mean = np.mean(d_cur)\n    score = np.abs(d_cur - d_mean) + 0.2 * d_dest\n\n    # Softmin with temperature and clipping to avoid overflow\n    temp = 0.5\n    exp_vals = np.exp(-np.clip(score / temp, -700, 700))\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    chosen_idx = np.random.choice(len(candidates), p=probs)\n    return int(candidates[chosen_idx])\n\n",
  "median_step_match_aug_53": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    # Squared distances (proxy approximation)\n    d_cur_sq = np.square(distance_matrix[current_node, candidates])\n    d_dest_sq = np.square(distance_matrix[candidates, destination_node])\n\n    # Weighted score using squared distances\n    score = 0.7 * d_cur_sq + 0.3 * d_dest_sq\n\n    # Deterministic selection: smallest score\n    sorted_idx = np.argsort(score)\n    return int(candidates[sorted_idx[0]])\n\n",
  "percentile_band_random_aug_54": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # Short names for clarity\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Base case: no nodes left\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Distances from current node and to destination\n    d_from_cur = dist_mat[current_node, candidates]\n    d_to_dest = dist_mat[candidates, destination_node]\n\n    # Band defined by 30th and 70th percentiles\n    lo = np.percentile(d_from_cur, 30)\n    hi = np.percentile(d_from_cur, 70)\n    band_mask = (d_from_cur >= lo) & (d_from_cur <= hi)\n\n    # If no candidates in band, fall back to all candidates\n    band_candidates = candidates[band_mask] if np.any(band_mask) else candidates\n    d_band_to_dest = dist_mat[band_candidates, destination_node]\n\n    # Deterministic seed based on node indices and count\n    seed = (current_node * 73856093) ^ (destination_node * 19349663) ^ (candidates.size * 83492791)\n    rng = np.random.default_rng(seed % (2**32))\n\n    # Add tiny deterministic noise to break ties uniformly\n    noise = rng.random(d_band_to_dest.shape) * 1e-6\n    d_noisy = d_band_to_dest + noise\n\n    # Pick the smallest distance within the band\n    idx = int(np.argmin(d_noisy))\n    return int(band_candidates[idx])\n\n",
  "percentile_band_random_aug_55": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    d_cur = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Wider band: 25th\u201375th percentiles\n    lo = np.percentile(d_cur, 25)\n    hi = np.percentile(d_cur, 75)\n    band_mask = (d_cur >= lo) & (d_cur <= hi)\n\n    band_cand = candidates[band_mask] if np.any(band_mask) else candidates\n    d_band_dest = dist_mat[band_cand, destination_node]\n\n    # Softmin weighting with temperature beta\n    beta = 5.0\n    exp_vals = np.exp(-beta * d_band_dest)\n    denom = exp_vals.sum() + 1e-12          # epsilon to avoid division by zero\n    probs = exp_vals / denom\n    probs = np.clip(probs, 1e-12, 1.0)      # ensure no zero probability\n\n    seed = (current_node * 73856093) ^ (destination_node * 19349663) ^ (candidates.size * 83492791)\n    rng = np.random.default_rng(seed % (2**32))\n    chosen_idx = rng.choice(len(band_cand), p=probs)\n    return int(band_cand[chosen_idx])\n\n",
  "percentile_band_random_aug_56": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    d_from_cur = dist_mat[current_node, candidates]\n    d_to_dest = dist_mat[candidates, destination_node]\n\n    # Band defined by median \u00b1 25% of range\n    med = np.median(d_from_cur)\n    rng = np.ptp(d_from_cur) * 0.25\n    lo, hi = med - rng, med + rng\n    band_mask = (d_from_cur >= lo) & (d_from_cur <= hi)\n\n    band_cand = candidates[band_mask] if np.any(band_mask) else candidates\n    d_band_dest = dist_mat[band_cand, destination_node]\n\n    # Randomly pick among top 5 closest within band\n    top_k = min(5, band_cand.size)\n    idxs = np.argsort(d_band_dest)[:top_k]\n\n    # Deterministic noise for tie\u2011breaking\n    seed = (current_node * 73856093) ^ (destination_node * 19349663) ^ (candidates.size * 83492791)\n    rng = np.random.default_rng(seed % (2**32))\n    pick = rng.integers(0, top_k)\n\n    return int(band_cand[idxs[pick]])\n\n",
  "percentile_band_random_aug_57": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Immediate return if no nodes remain\n    if candidates.size == 0:\n        return int(destination_node)\n\n    d_cur = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Band via logical AND (vectorized)\n    lo = np.percentile(d_cur, 30)\n    hi = np.percentile(d_cur, 70)\n    band_mask = np.logical_and(d_cur >= lo, d_cur <= hi)\n\n    band_cand = candidates[band_mask] if np.any(band_mask) else candidates\n    d_band_dest = dist_mat[band_cand, destination_node]\n\n    # Deterministic seed using a simple hash\n    seed = ((current_node << 13) ^ (destination_node << 7) ^ candidates.size) & 0xffffffff\n    rng = np.random.default_rng(seed)\n\n    # Randomly choose one of the top 5 candidates\n    top_k = min(5, band_cand.size)\n    top_idxs = np.argsort(d_band_dest)[:top_k]\n    chosen = rng.integers(0, top_k)\n    return int(band_cand[top_idxs[chosen]])\n\n",
  "softmin_temperature_sample_aug_58": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    cur_to_cand = distance_matrix[current_node, candidates]\n    cand_to_dest = distance_matrix[candidates, destination_node]\n\n    submat = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = np.mean(submat, axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem = candidates.size\n    frac = n_rem / max(1, n_total)\n\n    # Weighted score components\n    w_cur = 0.55\n    w_dest = 0.25\n    w_mean = 0.20\n\n    score = (cur_to_cand / (np.mean(cur_to_cand) + 1e-12)) * w_cur \\\n          + (cand_to_dest / (np.mean(cand_to_dest) + 1e-12)) * w_dest \\\n          + (mean_to_cand / (np.mean(mean_to_cand) + 1e-12)) * w_mean\n\n    temp = (0.10 + 1.90 * frac) * (np.std(score) + 1e-12)\n    temp = np.clip(temp, 1e-12, None)\n\n    weights = np.exp(-(score - score.min()) / (temp + 1e-12))\n    weights = weights / (weights.sum() + 1e-12)\n\n    seed = (current_node * 2654435761) ^ (destination_node * 2246822519) ^ (n_rem * 3266489917)\n    rng = np.random.default_rng(seed % (2**32))\n\n    choice_idx = int(rng.choice(np.arange(candidates.size), p=weights))\n    return int(candidates[choice_idx])\n\n",
  "softmin_temperature_sample_aug_59": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    cur_to_cand = distance_matrix[current_node, candidates]\n    cand_to_dest = distance_matrix[candidates, destination_node]\n\n    submat = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = np.median(submat, axis=1)\n\n    n_total = distance_matrix.shape[0]\n    n_rem = candidates.size\n    frac = n_rem / max(1, n_total)\n\n    score = (cur_to_cand / (np.median(cur_to_cand) + 1e-12)) \\\n          + 0.3 * (cand_to_dest / (np.median(cand_to_dest) + 1e-12)) \\\n          + 0.3 * (mean_to_cand / (np.median(mean_to_cand) + 1e-12))\n\n    temp = (0.20 + 1.70 * frac) * (np.std(score) + 1e-12)\n    temp = np.clip(temp, 1e-12, None)\n\n    probs = np.exp(-(score - score.min()) / (temp + 1e-12))\n    probs = probs / (probs.sum() + 1e-12)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(candidates.size) * 1e-6\n    probs += noise\n    probs = probs / (probs.sum() + 1e-12)\n\n    # Randomly pick top\u2011k\n    top_k = 5\n    top_indices = np.argpartition(probs, -top_k)[-top_k:]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (top_probs.sum() + 1e-12)\n\n    seed = (current_node * 11400714819323198485) ^ (destination_node * 14029467366897019727) ^ (n_rem * 1609587929392839161)\n    rng = np.random.default_rng(seed % (2**32))\n\n    chosen = int(rng.choice(top_indices, p=top_probs))\n    return int(candidates[chosen])\n\n",
  "softmin_temperature_sample_aug_60": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    cur_to_cand = distance_matrix[current_node, candidates]\n    cand_to_dest = distance_matrix[candidates, destination_node]\n\n    submat = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = np.max(submat, axis=1)\n\n    score = 0.6 * (cur_to_cand / (np.mean(cur_to_cand) + 1e-12)) \\\n          + 0.2 * (cand_to_dest / (np.mean(cand_to_dest) + 1e-12)) \\\n          + 0.2 * (mean_to_cand / (np.mean(mean_to_cand) + 1e-12))\n\n    min_score = score.min()\n    best_indices = np.where(np.abs(score - min_score) < 1e-8)[0]\n\n    if best_indices.size == 1:\n        chosen_idx = best_indices[0]\n    else:\n        # deterministic noise for tie\u2011breaking\n        noise = np.arange(candidates.size) * 1e-7\n        score_tied = score[best_indices] + noise[best_indices]\n        chosen_idx = int(best_indices[np.argmin(score_tied)])\n\n    return int(candidates[chosen_idx])\n\n",
  "softmin_temperature_sample_aug_61": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    cur_to_cand = distance_matrix[current_node, candidates]\n    cand_to_dest = distance_matrix[candidates, destination_node]\n\n    submat = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = np.sum(submat, axis=1) / (submat.shape[1] + 1e-12)\n\n    n_total = distance_matrix.shape[0]\n    n_rem = candidates.size\n    frac = n_rem / max(1, n_total)\n\n    score = (cur_to_cand / (np.mean(cur_to_cand) + 1e-12)) \\\n          + 0.4 * (cand_to_dest / (np.mean(cand_to_dest) + 1e-12)) \\\n          + 0.3 * (mean_to_cand / (np.mean(mean_to_cand) + 1e-12))\n\n    temp = (0.12 + 1.88 * frac) * (np.std(score) + 1e-12)\n    temp = np.clip(temp, 1e-12, None)\n\n    probs = np.exp(-(score - score.min()) / (temp + 1e-12))\n    probs = probs / (probs.sum() + 1e-12)\n\n    # Add deterministic noise\n    noise = np.sin(np.arange(candidates.size)) * 1e-6\n    probs += noise\n    probs = probs / (probs.sum() + 1e-12)\n\n    top_k = 4\n    top_indices = np.argpartition(probs, -top_k)[-top_k:]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (top_probs.sum() + 1e-12)\n\n    seed = (current_node * 2654435761) ^ (destination_node * 2246822519) ^ (n_rem * 3266489917)\n    rng = np.random.default_rng(seed % (2**32))\n\n    chosen = int(rng.choice(top_indices, p=top_probs))\n    return int(candidates[chosen])\n\n",
  "rank_geometric_choice_aug_62": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for clarity\n    cand = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n\n    # Use median instead of mean for scaling and add deterministic noise\n    scale_cur = np.median(d_cur) + 1e-12\n    scale_dest = np.median(d_dest) + 1e-12\n    noise = np.arange(cand.size, dtype=float) * 1e-8\n\n    blended = (d_cur / scale_cur) + 0.6 * (d_dest / scale_dest) + noise\n\n    # Soft\u2011min weighting (more greedy for larger blended scores)\n    w = np.exp(-blended * 4.0)\n    w = w / (w.sum() + 1e-12)\n\n    # Deterministic seed based on the current state\n    seed = (int(current_node) * 123456789) ^ \\\n           (int(destination_node) * 987654321) ^ \\\n           (int(cand.size) * 55555555)\n    rng = np.random.default_rng(seed % (2**32))\n\n    return int(rng.choice(cand, p=w))\n\n",
  "rank_geometric_choice_aug_63": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    scores = np.empty(cand.size, dtype=float)\n\n    for i, node in enumerate(cand):\n        cur_dist = distance_matrix[current_node, node]\n        dest_dist = distance_matrix[node, destination_node]\n        denom = np.max([cur_dist, dest_dist]) + 1e-12\n        scores[i] = (0.6 * cur_dist + 0.4 * dest_dist) / denom\n\n    # Deterministic noise to break ties\n    scores += np.arange(cand.size, dtype=float) * 1e-9\n\n    # Select the best top_k candidates\n    top_k = 7\n    if top_k > cand.size:\n        top_k = cand.size\n    sorted_idx = np.argsort(scores)\n    top_candidates = cand[sorted_idx[:top_k]]\n\n    # Deterministic seed for reproducibility\n    seed = (int(current_node) * 192837465) ^ \\\n           (int(destination_node) * 564738291) ^ \\\n           (int(cand.size) * 11111111)\n    rng = np.random.default_rng(seed % (2**32))\n\n    return int(rng.choice(top_candidates))\n\n",
  "rank_geometric_choice_aug_64": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if not unvisited_nodes.size:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n\n    blended = (d_cur / (np.mean(d_cur) + 1e-12)) + \\\n              0.5 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    order = np.argsort(blended)\n\n    n_total = distance_matrix.shape[0]\n    n_rem   = cand.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    p = float(np.clip(0.10 + 0.80 * progress, 0.05, 0.95))\n\n    ranks = np.arange(order.size, dtype=float)\n    w = (1.0 - p) ** ranks * p\n    w = w / (w.sum() + 1e-12)\n\n    seed = (int(current_node) * 271828182) ^ \\\n           (int(destination_node) * 314159265) ^ \\\n           (int(n_rem) * 161803398)\n    rng = np.random.default_rng(seed % (2**32))\n\n    pick_rank = int(rng.choice(np.arange(order.size), p=w))\n    return int(cand[int(order[pick_rank])])\n\n",
  "rank_geometric_choice_aug_65": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur  = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    blended = (d_cur / (np.sum(d_cur) + 1e-12)) + \\\n              0.55 * (d_dest / (np.sum(d_dest) + 1e-12))\n\n    # Deterministic noise for tie\u2011breaking\n    blended += np.arange(cand.size, dtype=float) * 5e-9\n\n    # Soft\u2011max weighting\n    exp_vals = np.exp(blended - blended.max())\n    w = exp_vals / (exp_vals.sum() + 1e-12)\n\n    # Mix with a uniform distribution to keep the choice stochastic\n    p = float(np.clip(0.20 + 0.60 * (1.0 - (cand.size / max(1, distance_matrix.shape[0]))),\n                      0.05, 0.95))\n    w = p * w + (1.0 - p) * (1.0 / cand.size)\n\n    seed = (int(current_node) * 314159265) ^ \\\n           (int(destination_node) * 271828182) ^ \\\n           (int(cand.size) * 577215664)\n    rng = np.random.default_rng(seed % (2**32))\n\n    return int(rng.choice(cand, p=w))\n\n",
  "k_nearest_switch_aug_66": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # Variable renaming\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n\n    # Progress (avoid div\u2011by\u2011zero, clip to [0,1])\n    progress = 1.0 - (n_rem / (max(1, n_total) + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Dynamic k selection (inverted logic)\n    if progress < 0.33:\n        k = 4\n    elif progress < 0.66:\n        k = 2\n    else:\n        k = 1\n    k = min(k, int(candidates.size))\n\n    # Distance arrays\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Order by current distance\n    order = np.argsort(d_cur)\n    kth_idx = order[k - 1]\n    kth_val = d_cur[kth_idx]\n\n    # Tie\u2011break with deterministic noise\n    ties = np.where(np.isclose(d_cur, kth_val, atol=1e-8))[0]\n    if ties.size > 1:\n        noise = np.arange(ties.size) * 1e-9\n        chosen = ties[np.argmin(d_dest[ties] + noise)]\n        return int(candidates[int(chosen)])\n\n    return int(candidates[int(kth_idx)])\n\n",
  "k_nearest_switch_aug_67": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n\n    progress = 1.0 - (n_rem / (max(1, n_total) + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Tuned top_k based on progress\n    top_k = 7 if progress < 0.2 else (5 if progress < 0.5 else 3)\n    top_k = min(top_k, int(candidates.size))\n\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Combined score with tuned weights\n    score = 0.6 * d_cur + 0.4 * d_dest\n\n    # Get smallest top_k scores efficiently\n    idx_part = np.argpartition(score, top_k - 1)[:top_k]\n    best_idx = idx_part[np.argmin(score[idx_part])]\n\n    # Deterministic noise for tie\u2011breaking\n    best_val = score[best_idx]\n    ties = np.where(np.isclose(score, best_val, atol=1e-8))[0]\n    if ties.size > 1:\n        noise = np.arange(ties.size) * 1e-9\n        chosen = ties[np.argmin(score[ties] + noise)]\n        return int(candidates[int(chosen)])\n\n    return int(candidates[int(best_idx)])\n\n",
  "k_nearest_switch_aug_68": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    rng = np.random.default_rng(42)\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n\n    progress = 1.0 - (n_rem / (max(1, n_total) + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Top\u2011k determined by a median of preset values\n    top_k = int(np.clip(np.median([1, 3, 5, 7]), 1, int(candidates.size)))\n\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Median of current and destination distances\n    score = np.median(np.stack([d_cur, d_dest], axis=1), axis=1)\n\n    # Choose top_k smallest indices\n    idx_top = np.argpartition(score, top_k - 1)[:top_k]\n\n    # Randomly pick one of them\n    chosen_idx = rng.choice(idx_top)\n\n    return int(candidates[int(chosen_idx)])\n\n",
  "k_nearest_switch_aug_69": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n\n    progress = 1.0 - (n_rem / (max(1, n_total) + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Inverted logic for k\n    k = 1 + int(np.floor((1.0 - progress) * 3))\n    k = min(k, int(candidates.size))\n\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Soft\u2011min weighting\n    alpha = 5.0\n    weights = np.exp(-alpha * d_cur)\n    weights = weights / (np.sum(weights) + 1e-12)\n\n    # Expected index\n    exp_idx = np.sum(weights * np.arange(candidates.size))\n    idx = int(np.clip(np.round(exp_idx), 0, candidates.size - 1))\n\n    # Ensure idx is within top\u2011k\n    if idx >= k:\n        order = np.argsort(d_cur)\n        idx = int(order[k - 1])\n\n    # Deterministic tie\u2011break with noise\n    best_val = d_cur[idx]\n    ties = np.where(np.isclose(d_cur, best_val, atol=1e-8))[0]\n    if ties.size > 1:\n        noise = np.arange(ties.size) * 1e-9\n        chosen = ties[np.argmin(d_dest[ties] + noise)]\n        return int(candidates[int(chosen)])\n\n    return int(candidates[int(idx)])\n\n",
  "isolation_priority_aug_70": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # Build isolation matrix\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    isolation = D.min(axis=1)\n\n    # Normalisation\n    mean_d   = np.mean(d_cur)   + 1e-12\n    mean_iso = np.mean(isolation) + 1e-12\n    d_norm   = d_cur / mean_d\n    iso_norm = isolation / mean_iso\n\n    # Score with original weight\n    score = d_norm - 0.90 * iso_norm\n\n    # Deterministic tie\u2011breaking using the index\n    idx = np.argmin(score + 1e-8 * np.arange(len(score)))\n    return int(cand[idx])\n\n",
  "isolation_priority_aug_71": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # Isolation matrix\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    isolation = D.min(axis=1)\n\n    # Normalisation using median\n    med_d   = np.median(d_cur)   + 1e-12\n    med_iso = np.median(isolation) + 1e-12\n    d_norm   = d_cur / med_d\n    iso_norm = isolation / med_iso\n\n    # Weighted score\n    score = 0.60 * d_norm + 0.40 * iso_norm\n    score = np.clip(score, -1e6, 1e6)          # safeguard\n\n    # Top\u2011k random selection\n    top_k = 7\n    if len(score) <= top_k:\n        chosen_idx = np.argmax(score)\n    else:\n        top_idx = np.argpartition(score, -top_k)[-top_k:]\n        chosen_idx = np.random.choice(top_idx)\n\n    return int(cand[chosen_idx])\n\n",
  "destination_pulse_aug_72": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    # distances among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = D.mean(axis=1)\n\n    # parity mode (inverted logic)\n    mode = ((current_node + destination_node + candidates.size) & 1)\n\n    # tuned weights\n    w_dest = 0.9\n    w_cluster = 0.1\n\n    if mode == 1:  # inverted\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + \\\n                w_dest * (d_dest / (np.mean(d_dest) + 1e-12))\n    else:\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + \\\n                w_cluster * (mean_to_cand / (np.mean(mean_to_cand) + 1e-12))\n\n    # deterministic noise for tie\u2011breaking\n    noise = 1e-9 * np.arange(candidates.size)\n    score = score + noise\n\n    # clip to avoid negative or overflow values\n    score = np.clip(score, 0, np.inf)\n\n    return int(candidates[int(np.argmin(score))])\n\n",
  "destination_pulse_aug_73": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_cand = D.max(axis=1)  # use max instead of mean\n\n    mode = ((current_node + destination_node + candidates.size) & 1)\n\n    w_dest = 0.8\n    w_cluster = 0.2\n\n    if mode == 1:  # inverted logic\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + \\\n                w_dest * (d_dest / (np.mean(d_dest) + 1e-12))\n    else:\n        score = (d_cur / (np.mean(d_cur) + 1e-12)) + \\\n                w_cluster * (mean_to_cand / (np.mean(mean_to_cand) + 1e-12))\n\n    # small random noise for tie\u2011breaking\n    rng = np.random.default_rng()\n    noise = rng.uniform(-1e-8, 1e-8, size=candidates.size)\n    score = score + noise\n\n    # clip to avoid invalid values\n    score = np.clip(score, 0, np.inf)\n\n    # find minimal score indices\n    min_val = np.min(score)\n    best_idx = np.where(score == min_val)[0]\n    chosen = rng.choice(best_idx)\n\n    return int(candidates[chosen])\n\n",
  "hash_jitter_tiebreak_aug_74": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Pre\u2011compute means for normalisation\n    mean_cur = np.mean(dist_mat[current_node, candidates]) + 1e-12\n    mean_dest = np.mean(dist_mat[candidates, destination_node]) + 1e-12\n\n    # Compute base scores in a loop\n    base_scores = []\n    for idx in candidates:\n        d_cur = dist_mat[current_node, idx]\n        d_dest = dist_mat[idx, destination_node]\n        base = (d_cur / mean_cur) + 0.35 * (d_dest / mean_dest)\n        base_scores.append(base)\n    base_scores = np.array(base_scores)\n\n    # Deterministic jitter via sine, clipped to [-1, 1]\n    jitter = np.sin(candidates * 12.9898 + current_node * 78.233 +\n                    destination_node * 37.719)\n    jitter = np.clip(jitter, -1.0, 1.0)\n\n    score = base_scores + 0.02 * jitter\n\n    # Top\u2011k selection (k = 7)\n    top_k = 7\n    if top_k >= len(candidates):\n        top_indices = np.arange(len(candidates))\n    else:\n        top_indices = np.argpartition(score, top_k)[:top_k]\n\n    # Resolve ties deterministically: pick smallest candidate value\n    min_score = np.min(score[top_indices])\n    tie_indices = top_indices[score[top_indices] == min_score]\n    chosen_idx = tie_indices[0]  # first in sorted order\n    return int(candidates[chosen_idx])\n\n",
  "hash_jitter_tiebreak_aug_75": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Normalisation by sum of distances\n    sum_cur = np.sum(dist_mat[current_node, candidates]) + 1e-12\n    sum_dest = np.sum(dist_mat[candidates, destination_node]) + 1e-12\n\n    scores = []\n    for idx in candidates:\n        d_cur = dist_mat[current_node, idx]\n        d_dest = dist_mat[idx, destination_node]\n        base = (d_cur / sum_cur) + 0.35 * (d_dest / sum_dest)\n        # Small deterministic noise to help with ties\n        noise = (idx % 7) / 100.0\n        scores.append(base + noise)\n    scores = np.array(scores)\n\n    # Randomly pick among the top 5 candidates\n    top_k = 5\n    if top_k >= len(candidates):\n        top_indices = np.arange(len(candidates))\n    else:\n        top_indices = np.argpartition(-scores, top_k)[:top_k]  # descending order\n\n    rng = np.random.default_rng(123)          # deterministic seed\n    chosen_idx = rng.choice(top_indices)\n    return int(candidates[chosen_idx])\n\n",
  "hash_jitter_tiebreak_aug_76": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    d_cur = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # Normalise by the maximum distance to avoid outliers dominating\n    base = (d_cur / (np.max(d_cur) + 1e-12)) + 0.35 * \\\n           (d_dest / (np.max(d_dest) + 1e-12))\n\n    # Deterministic jitter via sine, clipped to [-1, 1]\n    jitter = np.sin(candidates * 12.9898 + current_node * 78.233 +\n                    destination_node * 37.719)\n    jitter = np.clip(jitter, -1.0, 1.0)\n\n    score = base + 0.02 * jitter\n\n    # argmin with deterministic tie\u2011breaking: smallest candidate value\n    min_score = np.min(score)\n    tied_mask = score == min_score\n    tied_candidates = candidates[tied_mask]\n    chosen_val = np.min(tied_candidates)   # smallest index\n    return int(chosen_val)\n\n",
  "edge_length_equalizer_aug_77": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Distance from current node to each candidate\n    d_cur = distance_matrix[current_node, cand]\n\n    # Median\u2011based averages with safe division\n    avg_cur = (np.sum(d_cur) + 1e-12) / (d_cur.size + 1e-12)\n\n    # Sub\u2011matrix of candidate\u2011to\u2011candidate distances\n    D = distance_matrix[np.ix_(cand, cand)]\n    avg_cand = (np.sum(D, axis=1) + 1e-12) / (D.shape[1] + 1e-12)\n\n    # Blend with different weights\n    target = 0.6 * avg_cur + 0.4 * avg_cand\n    target = np.clip(target, 0, np.max(distance_matrix))\n\n    # Absolute deviation score + deterministic noise for tie\u2011breaking\n    score = np.abs(d_cur - target)\n    noise = np.arange(score.size) * 1e-6\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "edge_length_equalizer_aug_78": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    avg_cur = np.mean(d_cur)\n    D = distance_matrix[np.ix_(cand, cand)]\n    avg_cand = np.mean(D, axis=1)\n\n    target = 0.8 * avg_cur + 0.2 * avg_cand\n    target = np.clip(target, 0, np.max(distance_matrix))\n\n    score = np.abs(d_cur - target)\n\n    # Soft\u2011min probabilities\n    eps = 1e-12\n    exp_neg = np.exp(-score / (np.max(score) + eps))\n    probs = exp_neg / (np.sum(exp_neg) + eps)\n\n    # Random weighted choice\n    return int(cand[np.random.choice(cand.size, p=probs)])\n\n",
  "edge_length_equalizer_aug_79": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # Max\u2011based aggregation\n    avg_cur = np.max(d_cur)\n    D = distance_matrix[np.ix_(cand, cand)]\n    avg_cand = np.max(D, axis=1)\n\n    target = 0.5 * avg_cur + 0.5 * avg_cand\n    target = np.clip(target, 0, np.max(distance_matrix))\n\n    score = np.abs(d_cur - target)\n\n    # Softmax weighting (unused but kept for variety)\n    eps = 1e-12\n    exp_pos = np.exp(score - np.max(score))\n    _ = exp_pos / (np.sum(exp_pos) + eps)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.linspace(0, 1e-5, score.size)\n    weighted_score = score + noise\n\n    return int(cand[np.argmin(weighted_score)])\n\n",
  "edge_length_equalizer_aug_80": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # Median aggregation\n    avg_cur = np.median(d_cur)\n    D = distance_matrix[np.ix_(cand, cand)]\n    avg_cand = np.median(D, axis=1)\n\n    target = 0.55 * avg_cur + 0.45 * avg_cand\n    target = np.clip(target, 0, np.max(distance_matrix))\n\n    score = np.abs(d_cur - target)\n\n    # Top\u2011k selection with random tie\u2011breaking\n    top_k = 3\n    idx_sorted = np.argsort(score)\n    top_indices = idx_sorted[:top_k]\n    chosen = np.random.choice(top_indices)\n\n    return int(cand[chosen])\n\n",
  "normalized_multiobjective_aug_81": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    mean_to_cand = np.mean(sub_mat, axis=1)\n\n    def norm(x):\n        x = x.astype(float)\n        mn = float(x.min())\n        mx = float(x.max())\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    s_cur  = norm(d_cur)\n    s_dest = norm(d_dest)\n    s_mean = norm(mean_to_cand)\n\n    # Soft\u2011min with a temperature parameter\n    temp = 0.4\n    raw = 0.55 * s_cur + 0.25 * s_dest + 0.20 * s_mean\n\n    # Small deterministic noise to break ties\n    raw += 1e-9 * np.arange(raw.size)\n\n    # Final selection (argmin on the noisy raw score)\n    return int(cand[np.argmin(raw)])\n\n",
  "normalized_multiobjective_aug_82": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    median_to_cand = np.median(sub_mat, axis=1)\n\n    def norm(x):\n        x = x.astype(float)\n        mn = float(x.min())\n        mx = float(x.max())\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    s1 = norm(d_cur)\n    s2 = norm(d_dest)\n    s3 = norm(median_to_cand)\n\n    score = 0.6 * s1 + 0.3 * s2 + 0.1 * s3\n\n    # Deterministic tie\u2011breaking with a tiny epsilon\n    score += 1e-8 * np.arange(score.size)\n    return int(cand[np.argmin(score)])\n\n",
  "normalized_multiobjective_aug_83": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, cand]\n    d_dest  = distance_matrix[cand, destination_node]\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    mean_to_cand = np.mean(sub_mat, axis=1)\n\n    def norm(x):\n        x = x.astype(float)\n        mn = float(x.min())\n        mx = float(x.max())\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    s_cur  = norm(d_cur)\n    s_dest = norm(d_dest)\n    s_mean = norm(mean_to_cand)\n\n    score = 0.55 * s_cur + 0.25 * s_dest + 0.20 * s_mean\n\n    # Pick the top\u2011k candidates\n    top_k = 5\n    if top_k > score.size:\n        top_k = score.size\n    top_idx = np.argpartition(score, top_k - 1)[:top_k]\n\n    # Deterministic pseudo\u2011random selection based on node indices\n    rng = np.random.default_rng(current_node + destination_node)\n    chosen = rng.choice(top_idx)\n    return int(cand[chosen])\n\n",
  "normalized_multiobjective_aug_84": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Compute distances using explicit loops\n    d_cur  = []\n    d_dest = []\n    for idx in cand:\n        d_cur.append(distance_matrix[current_node, idx])\n        d_dest.append(distance_matrix[idx, destination_node])\n    d_cur  = np.array(d_cur, dtype=float)\n    d_dest = np.array(d_dest, dtype=float)\n\n    # Build the sub\u2011matrix via a list comprehension\n    sub = np.array([[distance_matrix[i, j] for j in cand] for i in cand], dtype=float)\n    max_to_cand = np.max(sub, axis=1)\n\n    def norm(x):\n        mn = float(x.min())\n        mx = float(x.max())\n        denom = mx - mn + 1e-12\n        return np.clip((x - mn) / denom, 0.0, 1.0)\n\n    s1 = norm(d_cur)\n    s2 = norm(d_dest)\n    s3 = norm(max_to_cand)\n\n    score = 0.7 * s1 + 0.2 * s2 + 0.1 * s3\n\n    # Deterministic tie\u2011breaking\n    score += 1e-7 * np.arange(score.size)\n    return int(cand[np.argmin(score)])\n\n",
  "bottleneck_edge_prevent_aug_85": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Syntactic rename and vectorised flow\n    candidates = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, candidates]\n\n    # Pairwise distances among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # 10\u2011percentile distance as a local density proxy\n    q = np.percentile(D, 10, axis=1)\n\n    # Normalisation with safe denominators\n    d_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    q_norm = q / (np.mean(q) + 1e-12)\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.random.uniform(0, 1e-6, size=q_norm.shape)\n\n    # Weighted score\n    score = 0.6 * d_norm + 0.4 * q_norm + noise\n    return int(candidates[np.argmin(score)])\n\n",
  "bottleneck_edge_prevent_aug_86": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # Pairwise distances and 10\u2011percentile\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    q = np.percentile(D, 10, axis=1)\n\n    # Sum\u2011based normalisation (hyper\u2011parameter tweak)\n    d_norm = d_cur / (np.sum(d_cur) + 1e-12)\n    q_norm = q / (np.sum(q) + 1e-12)\n\n    # Weighted score\n    score = 0.8 * d_norm + 0.2 * q_norm\n\n    # Select among the best top\u2011k candidates randomly\n    top_k = 7\n    idx_sorted = np.argsort(score)\n    top_idx = idx_sorted[:top_k]\n    chosen = np.random.choice(top_idx)\n    return int(cand[chosen])\n\n",
  "bottleneck_edge_prevent_aug_87": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, nodes]\n\n    # 10\u2011percentile of pairwise distances\n    D = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(D, np.inf)\n    q = np.percentile(D, 10, axis=1)\n\n    # Median\u2011based normalisation\n    d_norm = d_cur / (np.median(d_cur) + 1e-12)\n    q_norm = q / (np.median(q) + 1e-12)\n\n    # Softmin (probabilistic choice) with temperature\n    temp = 0.5\n    logits = -(0.5 * d_norm + 0.5 * q_norm)\n    logits -= np.max(logits)                     # numerical stability\n    probs = np.exp(logits / temp)\n    probs /= np.sum(probs)\n\n    chosen = np.random.choice(len(nodes), p=probs)\n    return int(nodes[chosen])\n\n",
  "bottleneck_edge_prevent_aug_88": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, nodes]\n\n    # Approximate local density by mean distance to other candidates\n    D = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(D, np.inf)\n    q = np.mean(D, axis=1)\n\n    # Max\u2011based normalisation and clipping\n    d_norm = d_cur / (np.max(d_cur) + 1e-12)\n    q_norm = q / (np.max(q) + 1e-12)\n    d_norm = np.clip(d_norm, 0, np.inf)\n    q_norm = np.clip(q_norm, 0, np.inf)\n\n    # Weighted score\n    score = 0.7 * d_norm + 0.3 * q_norm\n    return int(nodes[np.argmin(score)])\n\n",
  "two_ring_corridor_aug_89": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # renamed variables for clarity\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # base case: no candidates left\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # clip values to avoid overflow during arithmetic\n    r0 = float(np.clip(dist_mat[current_node, destination_node],\n                       0, 1e12))\n    r   = np.clip(dist_mat[candidates, destination_node], 0, 1e12)\n    d_cur = np.clip(dist_mat[current_node, candidates], 0, 1e12)\n\n    # compute score vector\n    score = np.abs(r - r0) + 0.10 * d_cur\n\n    # find index of the minimum score using a while loop\n    min_idx = 0\n    min_val = score[0]\n    for i in range(1, score.size):\n        if score[i] < min_val:\n            min_val = score[i]\n            min_idx = i\n\n    return int(candidates[min_idx])\n\n",
  "two_ring_corridor_aug_90": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Clip to keep values in a sane range\n    r0 = float(np.clip(dist_mat[current_node, destination_node], 0, 1e12))\n    r   = np.clip(dist_mat[candidates, destination_node], 0, 1e12)\n    d_cur = np.clip(dist_mat[current_node, candidates], 0, 1e12)\n\n    # weighted score with tuned coefficient\n    score = np.abs(r - r0) + 0.15 * d_cur\n\n    # deterministic noise to break ties\n    noise = 1e-6 * np.arange(candidates.size)\n    score += noise\n\n    # keep only the best 7 candidates (top\u2011k)\n    top_k = 7\n    if top_k < candidates.size:\n        idx_sorted = np.argpartition(score, top_k - 1)[:top_k]\n        score = score[idx_sorted]\n        candidates = candidates[idx_sorted]\n\n    # final argmin\n    return int(candidates[np.argmin(score)])\n\n",
  "two_ring_corridor_aug_91": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    rng = np.random.default_rng()\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # clip values\n    r0 = float(np.clip(dist_mat[current_node, destination_node], 0, 1e12))\n    r   = np.clip(dist_mat[candidates, destination_node], 0, 1e12)\n    d_cur = np.clip(dist_mat[current_node, candidates], 0, 1e12)\n\n    # score with tuned weight\n    score = np.abs(r - r0) + 0.10 * d_cur\n\n    # soft\u2011min probabilities\n    temp = 0.5\n    exp_scores = np.exp(-score / (temp + 1e-12))\n    probs = exp_scores / (np.sum(exp_scores) + 1e-12)\n\n    # weighted random choice\n    chosen_idx = rng.choice(candidates.size, p=probs)\n    return int(candidates[chosen_idx])\n\n",
  "two_ring_corridor_aug_92": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # clip values to prevent extreme numbers\n    r0 = float(np.clip(dist_mat[current_node, destination_node], 0, 1e12))\n    r   = np.clip(dist_mat[candidates, destination_node], 0, 1e12)\n    d_cur = np.clip(dist_mat[current_node, candidates], 0, 1e12)\n\n    # use median instead of mean for the distance component\n    median_d = np.median(d_cur)\n\n    # weighted score with a different coefficient\n    score = np.abs(r - r0) + 0.20 * median_d\n\n    # deterministic noise for tie breaking\n    noise = 1e-8 * np.arange(candidates.size)\n    score += noise\n\n    # keep only the best 5 candidates\n    top_k = 5\n    if top_k < candidates.size:\n        idx_sorted = np.argpartition(score, top_k - 1)[:top_k]\n        score = score[idx_sorted]\n        candidates = candidates[idx_sorted]\n\n    return int(candidates[np.argmin(score)])\n\n",
  "antipodal_then_smooth_aug_93": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.arange(cand.size) * 1e-9\n\n    if progress >= 0.5:          # early phase logic\n        mean_b = np.median(b)\n        score = cos_theta + 0.10 * (b / (mean_b + 1e-12)) + noise\n        idx   = int(np.argmin(score))\n    else:                        # late phase logic\n        r0    = a\n        score = np.abs(c - r0) + 0.10 * b + noise\n        idx   = int(np.argmin(score))\n\n    return int(cand[idx])\n\n",
  "antipodal_then_smooth_aug_94": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # deterministic noise from a seeded RNG\n    seed = (current_node << 16) ^ destination_node\n    rng  = np.random.default_rng(seed)\n    noise = rng.uniform(0, 1e-9, size=cand.size)\n\n    if progress < 0.6:                     # early phase\n        max_b = np.max(b)\n        score = cos_theta + 0.12 * (b / (max_b + 1e-12)) + noise\n    else:                                 # late phase\n        r0 = a\n        score = np.abs(c - r0) + 0.12 * b + noise\n\n    idx = int(np.argmin(score))\n    return int(cand[idx])\n\n",
  "antipodal_then_smooth_aug_95": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    # approximate denominator (proxy)\n    denom = 2.0 * a * b + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.5:                     # early phase\n        mean_b = np.mean(b)\n        raw = cos_theta + 0.05 * (b / (mean_b + 1e-12))\n    else:                                 # late phase\n        r0 = a\n        raw = np.abs(c - r0) + 0.05 * b\n\n    # pick top\u2011k smallest raw scores\n    top_k = 5\n    indices = np.argpartition(raw, top_k)[:top_k]\n\n    # deterministic choice among the top\u2011k\n    seed = (current_node * 13 + destination_node * 29) % (2**32 - 1)\n    rng  = np.random.default_rng(seed)\n    chosen = rng.choice(indices)\n\n    return int(cand[chosen])\n\n",
  "regret_weighted_earliness_aug_96": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables for clarity\n    cand = unvisited_nodes.astype(int)\n    cur_to_cand = distance_matrix[current_node, cand]\n\n    # distance matrix among candidates\n    cand_mat = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(cand_mat, np.inf)\n\n    # best and second best edges for each candidate\n    part = np.partition(cand_mat, 1, axis=1)\n    best = part[:, 0]\n    second = part[:, 1]\n    regret = second - best\n\n    # normalise by median (semantic change)\n    d_norm = cur_to_cand / (np.median(cur_to_cand) + 1e-12)\n    r_norm = regret / (np.median(regret) + 1e-12)\n\n    # weighted score with a different weight\n    score = d_norm - 0.85 * r_norm\n\n    # deterministic tie\u2011breaking noise\n    noise = 1e-9 * np.arange(score.size)\n    score += noise\n\n    # soft\u2011min selection\n    probs = np.exp(-10 * score)\n    probs /= np.clip(probs.sum(), 1e-12, None)  # prevent division by zero\n    idx = np.random.choice(score.size, p=probs)\n\n    return int(cand[idx])\n\n",
  "regret_weighted_earliness_aug_97": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    cur_to_cand = distance_matrix[current_node, cand]\n\n    # candidate\u2011to\u2011candidate distances\n    cand_mat = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(cand_mat, np.inf)\n\n    # compute best and second best using list comprehensions\n    best = np.array([cand_mat[i].min() for i in range(cand_mat.shape[0])])\n    second = np.array([np.partition(cand_mat[i], 1)[1] for i in range(cand_mat.shape[0])])\n    regret = second - best\n\n    # normalisation by the maximum (different aggregation)\n    d_norm = cur_to_cand / (np.max(cur_to_cand) + 1e-12)\n    r_norm = regret / (np.max(regret) + 1e-12)\n\n    # new weight combination\n    score = 0.7 * d_norm + 0.3 * r_norm\n\n    # pick top\u2011k candidates and choose randomly among them\n    top_k = 7\n    top_indices = np.argpartition(score, top_k)[:top_k]\n    idx = np.random.choice(top_indices)\n\n    return int(cand[idx])\n\n",
  "regret_weighted_earliness_aug_98": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, nodes]\n\n    # distance matrix between remaining nodes\n    mat = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(mat, np.inf)\n\n    part = np.partition(mat, 1, axis=1)\n    best = part[:, 0]\n    second = part[:, 1]\n    regret = second - best\n\n    # use median for normalisation (semantic change)\n    d_norm = dist_cur / (np.median(dist_cur) + 1e-12)\n    r_norm = regret / (np.median(regret) + 1e-12)\n\n    # adjusted weighting\n    score = 0.6 * d_norm + 0.4 * r_norm\n\n    # deterministic noise for tie breaking\n    noise = 1e-8 * np.arange(score.size)\n    score += noise\n\n    # soft\u2011min probability distribution\n    probs = np.exp(-5 * score)\n    probs /= np.clip(probs.sum(), 1e-12, None)\n    idx = np.random.choice(score.size, p=probs)\n\n    return int(nodes[idx])\n\n",
  "triangle_slack_to_destination_aug_99": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist_mat    = distance_matrix\n\n    # Basic distance components\n    d_cd  = float(dist_mat[current_node, destination_node])\n    d_cur = dist_mat[current_node, candidates]\n    d_dst = dist_mat[candidates, destination_node]\n\n    # Slack calculation\n    slack = (d_cur + d_dst) - d_cd\n\n    # Median based normalisation (robust to outliers)\n    s_norm = slack / (np.median(slack) + 1e-12)\n    c_norm = d_cur   / (np.median(d_cur)   + 1e-12)\n\n    # Weighted score with deterministic tie\u2011breaking noise\n    weight = 0.6 * c_norm + 0.8 * s_norm\n    noise  = np.arange(candidates.size, dtype=float) * 1e-6   # deterministic\n    score  = weight + noise\n\n    return int(candidates[np.argmin(score)])\n\n",
  "triangle_slack_to_destination_aug_100": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_cd = float(dist_mat[current_node, destination_node])\n\n    # Initialise arrays\n    d_cur   = np.empty(candidates.size, dtype=float)\n    d_dst   = np.empty(candidates.size, dtype=float)\n    slack   = np.empty(candidates.size, dtype=float)\n\n    # Compute distances and slack in a for\u2011loop\n    for i, node in enumerate(candidates):\n        d_cur[i] = dist_mat[current_node, node]\n        d_dst[i] = dist_mat[node, destination_node]\n        slack[i] = d_cur[i] + d_dst[i] - d_cd\n\n    # Sum\u2011based normalisation with epsilon\n    s_norm = slack / (np.sum(slack) + 1e-10)\n    c_norm = d_cur   / (np.sum(d_cur)   + 1e-10)\n\n    # Clip to avoid extreme values\n    s_norm = np.clip(s_norm, 0, 1)\n    c_norm = np.clip(c_norm, 0, 1)\n\n    # Weighted score + deterministic index noise for tie\u2011breaking\n    score = 0.5 * c_norm + 0.7 * s_norm + np.arange(candidates.size, dtype=float) * 1e-8\n\n    return int(candidates[np.argmin(score)])\n\n",
  "triangle_slack_to_destination_aug_101": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes   = unvisited_nodes.astype(int)\n    dist    = distance_matrix\n    d_cd    = float(dist[current_node, destination_node])\n\n    d_cur = dist[current_node, nodes]\n    d_dst = dist[nodes, destination_node]\n    slack = d_cur + d_dst - d_cd\n\n    # Normalisation using median\n    s_norm = slack / (np.median(slack) + 1e-12)\n    c_norm = d_cur   / (np.median(d_cur)   + 1e-12)\n\n    # Weighted score\n    score = 0.4 * c_norm + 0.6 * s_norm\n\n    # Pick the best among the smallest k slacks\n    top_k = 7\n    if nodes.size > top_k:\n        idx_k = np.argpartition(slack, top_k)[:top_k]\n    else:\n        idx_k = np.arange(nodes.size)\n\n    # Resolve ties randomly (deterministically using modulo of index)\n    best_idx = idx_k[np.argmin(score[idx_k] + np.mod(idx_k, 5) * 1e-9)]\n    return int(nodes[best_idx])\n\n",
  "mst_edge_proxy_step_aug_102": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # renamed variables for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, candidates]\n\n    # attachment cost: cheapest edge to connect candidate into the remaining set\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n    attach_cost = sub_mat.min(axis=1)\n\n    # normalise with median to dampen outliers\n    med_attach = np.median(attach_cost) + 1e-12\n    med_dist   = np.median(dist_cur)   + 1e-12\n    norm_attach = attach_cost / med_attach\n    norm_dist   = dist_cur   / med_dist\n\n    # soft\u2011min weighting\n    w_dist   = 0.8\n    w_attach = 0.2\n    logits = - (w_dist * norm_dist + w_attach * norm_attach)\n\n    # probabilities, with small jitter for deterministic tie\u2011breaking\n    probs = np.exp(logits - np.max(logits))\n    probs /= probs.sum() + 1e-12\n    jitter = np.random.uniform(-1e-4, 1e-4, size=probs.shape)\n    probs = np.clip(probs + jitter, 0, None)\n    probs /= probs.sum() + 1e-12\n\n    chosen_idx = int(np.random.choice(len(candidates), p=probs))\n    return int(candidates[chosen_idx])\n\n",
  "mst_edge_proxy_step_aug_103": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, cand]\n\n    # attachment cost matrix\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n    attach = sub.min(axis=1)\n\n    # normalise via sum\n    sum_dist   = dist_cur.sum()   + 1e-12\n    sum_attach = attach.sum()     + 1e-12\n    norm_dist   = dist_cur / sum_dist\n    norm_attach = attach / sum_attach\n\n    # weighted score\n    w_d = 0.6\n    w_a = 0.4\n    score = w_d * norm_dist + w_a * norm_attach\n\n    # clip to a sane range\n    score = np.clip(score, 0, 1)\n\n    # pick a random candidate among the top\u2011k\n    top_k = 5\n    if top_k > len(score):\n        top_k = len(score)\n    top_indices = np.argpartition(-score, top_k - 1)[:top_k]\n    chosen_idx = int(np.random.choice(top_indices))\n    return int(cand[chosen_idx])\n\n",
  "mst_edge_proxy_step_aug_104": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # candidate list\n    cand = [int(v) for v in unvisited_nodes]\n    dist_cur = np.array([distance_matrix[current_node, v] for v in cand], dtype=float)\n\n    # attachment cost\n    sub_mat = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n    attach = np.array([sub_mat[i, :].min() for i in range(len(cand))], dtype=float)\n\n    # normalise with max (emphasises larger values)\n    max_dist   = dist_cur.max()   + 1e-12\n    max_attach = attach.max()     + 1e-12\n    norm_dist   = dist_cur / max_dist\n    norm_attach = attach / max_attach\n\n    # heavier weight on attachment\n    w_d = 0.1\n    w_a = 0.9\n    score = w_d * norm_dist + w_a * norm_attach\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.linspace(-1e-6, 1e-6, num=len(score))\n    score_noisy = score + noise\n\n    chosen_idx = int(np.argmax(score_noisy))\n    return int(cand[chosen_idx])\n\n",
  "mst_edge_proxy_step_aug_105": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, cand]\n\n    # attachment cost sub\u2011matrix\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n    attach = sub.min(axis=1)\n\n    # normalise via mean\n    mean_dist   = dist_cur.mean()   + 1e-12\n    mean_attach = attach.mean()     + 1e-12\n    norm_dist   = dist_cur / mean_dist\n    norm_attach = attach / mean_attach\n\n    # weighted score\n    w_d = 0.7\n    w_a = 0.3\n    score = w_d * norm_dist + w_a * norm_attach\n\n    # sort descending and pick random among top\u20113\n    sorted_idx = np.argsort(-score)\n    top_k = min(3, len(score))\n    top_candidates = sorted_idx[:top_k]\n    chosen_idx = int(np.random.choice(top_candidates))\n    return int(cand[chosen_idx])\n\n",
  "bridge_balance_ratio_aug_106": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = cand.size\n    k = max(2, min(n - 1, int(np.ceil(0.12 * n))))\n\n    near = np.partition(D, k - 1, axis=1)[:, :k].mean(axis=1)\n    far = np.partition(D, n - k - 1, axis=1)[:, -k:].mean(axis=1)\n\n    ratio = near / (far + 1e-12)\n    ratio = np.clip(ratio, 0.1, 10.0)\n\n    balance = np.abs(ratio - 1.0)\n    b_norm = balance / (np.median(balance) + 1e-12)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    score = c_norm + 0.75 * b_norm\n\n    # deterministic tie\u2011breaking noise\n    noise = np.arange(score.size) * 1e-6\n    score += noise\n\n    return int(cand[int(np.argmin(score))])\n\n",
  "bridge_balance_ratio_aug_107": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = cand.size\n    k = min(n - 1, 7) if n > 1 else 1\n\n    near = np.partition(D, k - 1, axis=1)[:, :k].mean(axis=1)\n    far = np.partition(D, n - k - 1, axis=1)[:, -k:].sum(axis=1)\n\n    ratio = near / (far + 1e-12)\n    ratio = np.clip(ratio, 0.05, 20.0)\n\n    balance = np.abs(ratio - 1.0)\n    b_norm = balance / (np.mean(balance) + 1e-12)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    score = 0.6 * b_norm + 0.4 * c_norm\n\n    probs = np.exp(-score)\n    probs /= np.clip(probs.sum(), 1e-12, None)\n\n    idx = np.random.choice(cand.size, p=probs)\n    return int(cand[idx])\n\n",
  "bridge_balance_ratio_aug_108": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = cand.size\n    k = min(n - 1, 5) if n > 1 else 1\n\n    near = np.partition(D, k - 1, axis=1)[:, :k].mean(axis=1)\n    far = np.partition(D, n - k - 1, axis=1)[:, -k:].max(axis=1)\n\n    ratio = near / (far + 1e-12)\n    ratio = np.clip(ratio, 0.1, 5.0)\n\n    balance = np.abs(ratio - 1.0)\n    b_norm = balance / (np.max(balance) + 1e-12)\n\n    c_norm = d_cur / (np.max(d_cur) + 1e-12)\n\n    score = 0.5 * b_norm + 0.5 * c_norm\n\n    noise = np.random.uniform(-1e-6, 1e-6, size=score.shape)\n    score += noise\n\n    top_indices = np.argpartition(score, k - 1)[:k]\n    chosen = np.random.choice(top_indices)\n    return int(cand[chosen])\n\n",
  "bridge_balance_ratio_aug_109": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = cand.size\n    k = max(2, min(n - 1, int(np.ceil(0.10 * n))))\n\n    near_vals = [np.mean(np.partition(D[i], k - 1)[:k]) for i in range(n)]\n    far_vals = [np.mean(np.partition(D[i], n - k - 1)[-k:]) for i in range(n)]\n    near = np.array(near_vals)\n    far = np.array(far_vals)\n\n    ratio = near / (far + 1e-12)\n    ratio = np.clip(ratio, 0.01, 50.0)\n\n    balance = np.abs(ratio - 1.0)\n    b_norm = balance / (np.mean(balance) + 1e-12)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n\n    score = 0.8 * b_norm + 0.2 * c_norm\n\n    exp_score = np.exp(-score)\n    probs = exp_score / np.clip(exp_score.sum(), 1e-12, None)\n\n    idx = np.random.choice(cand.size, p=probs)\n    return int(cand[idx])\n\n",
  "median_radial_progress_aug_110": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for readability\n    cur   = current_node\n    dest  = destination_node\n    cand  = unvisited_nodes.astype(int)\n    dist  = distance_matrix\n\n    # Compute radial difference\n    radial = dist[cand, dest] - dist[cur, cand]\n    target = float(np.median(radial))\n\n    # Score: absolute radial deviation + weighted distance ratio\n    mean_dist = np.mean(dist[cur, cand]) + 1e-12\n    score = np.abs(radial - target) + 0.25 * (dist[cur, cand] / mean_dist)\n\n    # Pick the candidate with the lowest score\n    return int(cand[np.argmin(score)])\n\n",
  "median_radial_progress_aug_111": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    rng = np.random.default_rng(seed=42)  # deterministic randomness\n    cur   = current_node\n    dest  = destination_node\n    cand  = unvisited_nodes.astype(int)\n    dist  = distance_matrix\n\n    radial = dist[cand, dest] - dist[cur, cand]\n    target = float(np.median(radial))\n\n    mean_dist = np.mean(dist[cur, cand]) + 1e-12\n    # Tuned weights and noise for tie\u2011breaking\n    score = 0.6 * np.abs(radial - target) + 0.4 * (dist[cur, cand] / mean_dist)\n    score += rng.normal(loc=0.0, scale=1e-6, size=radial.shape)\n\n    # Take the top_k lowest scores and choose one at random\n    top_k = 7\n    idx_top = np.argpartition(score, top_k)[:top_k]\n    chosen = rng.choice(idx_top)\n    return int(cand[chosen])\n\n",
  "median_radial_progress_aug_112": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    rng = np.random.default_rng(seed=123)\n    cur   = current_node\n    dest  = destination_node\n    cand  = unvisited_nodes.astype(int)\n    dist  = distance_matrix\n\n    radial = dist[cand, dest] - dist[cur, cand]\n    target = float(np.median(radial))\n\n    max_dist = np.max(dist[cur, cand]) + 1e-12\n    sum_dist = np.sum(dist[cur, cand]) + 1e-12\n    score = 0.5 * np.abs(radial - target) + 0.5 * (dist[cur, cand] / max_dist)\n    # Add tiny noise for deterministic tie\u2011breaking\n    score += rng.uniform(-1e-6, 1e-6, size=radial.shape)\n\n    # Randomly pick among the five best candidates\n    top_k = 5\n    idx_top = np.argpartition(score, top_k)[:top_k]\n    chosen = rng.choice(idx_top)\n    return int(cand[chosen])\n\n",
  "median_radial_progress_aug_113": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur   = current_node\n    dest  = destination_node\n    cand  = unvisited_nodes.astype(int)\n    dist  = distance_matrix\n\n    # Proxy radial using squared distances\n    radial = (dist[cand, dest] ** 2) - (dist[cur, cand] ** 2)\n    radial = np.clip(radial, -1e6, 1e6)  # prevent extreme values\n    target = float(np.median(radial))\n\n    max_dist = np.max(dist[cur, cand]) + 1e-12\n    ratio = dist[cur, cand] / max_dist\n    ratio = np.clip(ratio, 0.0, 1.0)\n\n    score = 0.7 * np.abs(radial - target) + 0.3 * ratio\n    return int(cand[np.argmin(score)])\n\n",
  "hash_jittered_softmin_aug_114": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_cur = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    base = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.7 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    # deterministic jitter based on node ids and candidate ids\n    seed = (current_node * 1315423911) ^ (destination_node * 2654435761) ^ (candidates.size * 97531)\n    x = (candidates.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    jitter = ((x * np.int64(1103515245) + np.int64(12345)) & np.int64(0x7FFFFFFF)).astype(np.float64)\n    jitter = jitter / (2.0**31)\n    jitter = np.clip(jitter, 0.0, 1.0)\n\n    n_total = dist_mat.shape[0]\n    n_rem = candidates.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n    temp = 0.5 - 0.4 * progress\n\n    score = base + temp * (jitter - 0.5)\n\n    # soft\u2011min probabilities and deterministic pseudo\u2011random choice\n    probs = np.exp(-score)\n    probs /= np.sum(probs)\n\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(candidates, p=probs)\n    return int(chosen)\n\n",
  "hash_jittered_softmin_aug_115": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    d_cur = dm[current_node, cand]\n    d_dest = dm[cand, destination_node]\n\n    base = (d_cur / (np.median(d_cur) + 1e-12)) + 0.5 * (d_dest / (np.median(d_dest) + 1e-12))\n\n    seed = (current_node * 2654435761) ^ (destination_node * 1315423911) ^ (cand.size * 12345)\n    x = (cand.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    jitter = ((x * np.int64(1103515245) + np.int64(12345)) & np.int64(0x7FFFFFFF)).astype(np.float64)\n    jitter = jitter / (2.0**31)\n    jitter = np.clip(jitter, 0.0, 1.0)\n\n    n_total = dm.shape[0]\n    n_rem = cand.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n    temp = 0.6 - 0.5 * progress\n\n    score = base + temp * (jitter - 0.5)\n\n    top_k = 7\n    if cand.size <= top_k:\n        idx = np.argmin(score)\n        return int(cand[idx])\n\n    idx_top = np.argpartition(score, top_k)[:top_k]\n    rng = np.random.default_rng(seed + 1)\n    chosen = rng.choice(cand[idx_top])\n    return int(chosen)\n\n",
  "hash_jittered_softmin_aug_116": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    d_cur = dm[current_node, cand]\n    d_dest = dm[cand, destination_node]\n\n    base = (d_cur / (np.max(d_cur) + 1e-12)) + 0.4 * (d_dest / (np.max(d_dest) + 1e-12))\n\n    seed = (current_node * 97531) ^ (destination_node * 97531) ^ (cand.size * 97531)\n    x = (cand.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    jitter = ((x * np.int64(1103515245) + np.int64(12345)) & np.int64(0x7FFFFFFF)).astype(np.float64)\n    jitter = jitter / (2.0**31)\n    jitter = np.clip(jitter, 0.0, 1.0)\n\n    n_total = dm.shape[0]\n    n_rem = cand.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n    temp = 0.55 - 0.45 * progress\n\n    score = base + temp * (jitter - 0.5)\n\n    # deterministic tie\u2011breaking noise\n    noise = 1e-9 * cand\n    score += noise\n\n    top_k = 3\n    if cand.size <= top_k:\n        idx = np.argmin(score)\n        return int(cand[idx])\n\n    idx_top = np.argpartition(score, top_k)[:top_k]\n    rng = np.random.default_rng(seed + 2)\n    chosen = rng.choice(cand[idx_top])\n    return int(chosen)\n\n",
  "hash_jittered_softmin_aug_117": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    d_cur = np.array([dm[current_node, i] for i in cand])\n    d_dest = np.array([dm[i, destination_node] for i in cand])\n\n    base = (d_cur / (np.mean(d_cur) + 1e-12)) + 0.6 * (d_dest / (np.mean(d_dest) + 1e-12))\n\n    seed = (current_node * 1315423911) ^ (destination_node * 2654435761) ^ (cand.size * 97531)\n    x = (cand.astype(np.int64) ^ np.int64(seed)) & np.int64(0xFFFFFFFF)\n    jitter = ((x * np.int64(1103515245) + np.int64(12345)) & np.int64(0x7FFFFFFF)).astype(np.float64)\n    jitter = jitter / (2.0**31)\n    jitter = np.clip(jitter, 0.0, 1.0)\n\n    n_total = dm.shape[0]\n    n_rem = cand.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n    temp = 0.6 - 0.5 * progress\n\n    score = base + temp * (jitter - 0.5)\n\n    # deterministic tie\u2011breaking\n    noise = 1e-9 * cand\n    score += noise\n\n    # find minimum using a while loop\n    min_idx = 0\n    min_val = score[0]\n    i = 1\n    while i < score.size:\n        if score[i] < min_val:\n            min_val = score[i]\n            min_idx = i\n        i += 1\n\n    return int(cand[min_idx])\n\n",
  "k_nearest_density_schedule_aug_118": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_cur = dist_mat[current_node, cand]\n    n_total = dist_mat.shape[0]\n    n_rem = cand.size\n    progress = np.clip(1.0 - (n_rem / max(1, n_total)), 0.0, 1.0)\n\n    k = int(max(2, min(n_rem - 1, np.ceil(0.10 * n_rem))))\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    knn = np.partition(D, k - 1, axis=1)[:, :k].median(axis=1)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    knn_norm = knn / (np.mean(knn) + 1e-12)\n\n    w = 1.10 * (0.5 - progress)\n    score = c_norm + w * knn_norm\n\n    # Deterministic noise to break ties\n    noise = 1e-6 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "k_nearest_density_schedule_aug_119": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_cur = dist_mat[current_node, cand]\n    n_total = dist_mat.shape[0]\n    n_rem = cand.size\n    progress = np.clip(1.0 - (n_rem / max(1, n_total)), 0.0, 1.0)\n\n    k = int(max(3, min(n_rem - 1, np.ceil(0.15 * n_rem))))\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    knn = np.partition(D, k - 1, axis=1)[:, :k].sum(axis=1)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    knn_norm = knn / (np.mean(knn) + 1e-12)\n\n    w = 0.90 * (0.4 - progress)\n    score = c_norm + w * knn_norm\n\n    sorted_idx = np.argsort(score)\n    topk_idx = sorted_idx[:k]\n    rng = np.random.default_rng(42)\n    chosen = rng.choice(topk_idx)\n\n    return int(cand[chosen])\n\n",
  "k_nearest_density_schedule_aug_120": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # Use squared distances as a cheap proxy\n    d_cur = np.square(dist_mat[current_node, cand])\n    n_total = dist_mat.shape[0]\n    n_rem = cand.size\n    progress = np.clip(1.0 - (n_rem / max(1, n_total)), 0.0, 1.0)\n\n    k = int(max(2, min(n_rem - 1, np.ceil(0.12 * n_rem))))\n    D = np.square(dist_mat[np.ix_(cand, cand)])\n    np.fill_diagonal(D, np.inf)\n    knn = np.partition(D, k - 1, axis=1)[:, :k].median(axis=1)\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    knn_norm = knn / (np.mean(knn) + 1e-12)\n\n    w = 1.05 * (0.45 - progress)\n    score = c_norm + w * knn_norm\n\n    sorted_idx = np.argsort(score)\n    topk_idx = sorted_idx[:3]\n    rng = np.random.default_rng(99)\n    chosen = rng.choice(topk_idx)\n\n    return int(cand[chosen])\n\n",
  "k_nearest_density_schedule_aug_121": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_cur = np.square(dist_mat[current_node, cand])\n    n_total = dist_mat.shape[0]\n    n_rem = cand.size\n    progress = np.clip(1.0 - (n_rem / max(1, n_total)), 0.0, 1.0)\n\n    k = int(max(2, min(n_rem - 1, np.ceil(0.08 * n_rem))))\n    D = np.square(dist_mat[np.ix_(cand, cand)])\n    np.fill_diagonal(D, np.inf)\n\n    # Compute k\u2011nearest\u2011neighbour median with an explicit loop\n    knn = np.empty(n_rem, dtype=float)\n    for i in range(n_rem):\n        row = D[i]\n        idx = np.argpartition(row, k - 1)[:k]\n        knn[i] = np.median(row[idx])\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    knn_norm = knn / (np.mean(knn) + 1e-12)\n\n    w = 1.20 * (0.5 - progress)\n    score = c_norm + w * knn_norm\n\n    # Soft\u2011min weighting for stochastic but deterministic choice\n    temp = 0.5\n    weights = np.exp(-score / temp)\n    weights /= np.clip(np.sum(weights), 1e-12, None)\n\n    rng = np.random.default_rng(123)\n    r = rng.random()\n    cum = np.cumsum(weights)\n    idx = np.searchsorted(cum, r)\n\n    return int(cand[idx])\n\n",
  "ranked_destination_gate_aug_122": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # Early\u2011exit inverted\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    candidates   = unvisited_nodes.astype(int)\n    dist_mat     = distance_matrix\n\n    # Distances from current node and to destination node\n    d_from_curr = dist_mat[current_node, candidates]\n    d_to_dest   = dist_mat[candidates, destination_node]\n\n    # Progress measure\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Destination rank (0 = closest)\n    order = np.argsort(d_to_dest)\n    rank  = np.empty_like(order)\n    rank[order] = np.arange(order.size, dtype=int)\n\n    # Normalisation with epsilon\n    rank_norm = rank.astype(np.float64) / (np.mean(rank) + 1e-12)\n    cur_norm  = d_from_curr.astype(np.float64) / (np.mean(d_from_curr) + 1e-12)\n\n    # Gate factor\n    gate = 0.20 + 1.60 * progress\n    score = cur_norm + gate * rank_norm\n\n    # Choose the candidate with minimal score\n    chosen_idx = int(np.argmin(score))\n    return int(candidates[chosen_idx])\n\n",
  "ranked_destination_gate_aug_123": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand   = unvisited_nodes.astype(int)\n    dist   = distance_matrix\n\n    d_curr = dist[current_node, cand]\n    d_dest = dist[cand, destination_node]\n\n    n_total = int(dist.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Ranking by distance to destination\n    order = np.argsort(d_dest)\n    rank  = np.empty_like(order)\n    rank[order] = np.arange(order.size, dtype=int)\n\n    # Normalisation using sum instead of mean\n    rank_norm = rank.astype(np.float64) / (np.sum(rank) + 1e-12)\n    curr_norm = d_curr.astype(np.float64) / (np.sum(d_curr) + 1e-12)\n\n    # Tuned gate: more aggressive penalty later\n    gate = 0.25 + 1.75 * progress\n    score = curr_norm + gate * rank_norm\n\n    idx = int(np.argmin(score))\n    return int(cand[idx])\n\n",
  "ranked_destination_gate_aug_124": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_from = dist_mat[current_node, candidates]\n    d_to   = dist_mat[candidates, destination_node]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Rank of each candidate by distance to destination\n    order = np.argsort(d_to)\n    rank  = np.empty_like(order)\n    rank[order] = np.arange(order.size, dtype=int)\n\n    # Normalise with epsilon\n    rank_norm = rank.astype(np.float64) / (np.mean(rank) + 1e-12)\n    curr_norm = d_from.astype(np.float64) / (np.mean(d_from) + 1e-12)\n\n    # Gate coefficient\n    gate = 0.20 + 1.60 * progress\n    score = curr_norm + gate * rank_norm\n\n    # Add deterministic noise (e.g., index value) to break ties\n    noise = np.arange(score.size) * 1e-9\n    score = score + noise\n\n    # Soft\u2011min probability distribution\n    exp_neg = np.exp(-score)\n    probs   = exp_neg / (np.sum(exp_neg) + 1e-12)\n\n    # Deterministic sampling with a fixed seed\n    rng = np.random.default_rng(0)\n    chosen = int(rng.choice(candidates, p=probs))\n    return chosen\n\n",
  "ranked_destination_gate_aug_125": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # List comprehension for candidate indices\n    cand = [int(v) for v in unvisited_nodes]\n    dist = distance_matrix\n\n    # While\u2011loop to compute distances iteratively\n    d_curr = np.empty(len(cand), dtype=float)\n    d_dest = np.empty(len(cand), dtype=float)\n    idx = 0\n    while idx < len(cand):\n        d_curr[idx] = dist[current_node, cand[idx]]\n        d_dest[idx] = dist[cand[idx], destination_node]\n        idx += 1\n\n    n_total = int(dist.shape[0])\n    n_rem   = int(len(cand))\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Rank calculation with np.max for normalisation\n    order = np.argsort(d_dest)\n    rank  = np.empty_like(order)\n    rank[order] = np.arange(order.size, dtype=int)\n\n    rank_norm = rank.astype(np.float64) / (np.max(rank) + 1e-12)\n    curr_norm = d_curr.astype(np.float64) / (np.max(d_curr) + 1e-12)\n\n    gate = 0.20 + 1.60 * progress\n    score = curr_norm + gate * rank_norm\n\n    # Clip scores to avoid extreme values before argmin\n    score = np.clip(score, a_min=0, a_max=None)\n\n    chosen_idx = int(np.argmin(score))\n    return int(cand[chosen_idx])\n\n",
  "two_step_to_destination_minplus_aug_126": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    n = cand.size\n\n    d_cur = distance_matrix[current_node, cand]\n\n    if n == 1:\n        return int(cand[0])\n\n    d_to_dst = distance_matrix[cand, destination_node]\n\n    # Build candidate\u2011to\u2011candidate matrix and avoid self\u2011loops\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Future cost estimated by the mean of (candidate \u2192 other + other \u2192 dest)\n    future = np.mean(D + d_to_dst[None, :], axis=1)\n\n    # Small noise for deterministic tie\u2011breaking\n    noise = np.random.uniform(-1e-6, 1e-6, size=future.shape)\n\n    score = 0.9 * d_cur + 0.1 * future + noise\n    idx = int(np.argmin(score))\n    return int(cand[idx])\n\n",
  "two_step_to_destination_minplus_aug_127": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    n = nodes.size\n\n    cur_to = distance_matrix[current_node, nodes]\n\n    if n == 1:\n        return int(nodes[0])\n\n    to_dst = distance_matrix[nodes, destination_node]\n\n    # Candidate\u2011to\u2011candidate distances\n    cand_mat = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(cand_mat, np.inf)\n\n    # Future cost: minimal detour via any other unvisited node\n    future = np.min(cand_mat + to_dst[None, :], axis=1)\n\n    # Weighted score\n    score = cur_to + 0.95 * future\n\n    # Softmin with temperature\n    temp = 0.5\n    exp_scores = np.exp(-score / (temp + 1e-12))  # epsilon to avoid division by zero\n    probs = exp_scores / np.clip(exp_scores.sum(), 1e-12, None)\n\n    # Randomly pick according to probabilities\n    idx = int(np.random.choice(len(nodes), p=probs))\n    return int(nodes[idx])\n\n",
  "two_step_to_destination_minplus_aug_128": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n = candidates.size\n\n    d_cur = distance_matrix[current_node, candidates]\n\n    if n == 1:\n        return int(candidates[0])\n\n    d_to_dest = distance_matrix[candidates, destination_node]\n\n    # Build matrix of candidate-to-candidate distances\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Future cost estimated by the maximum detour (worst case)\n    future = np.max(D + d_to_dest[None, :], axis=1)\n\n    # Clip to keep values bounded and avoid overflow\n    future = np.clip(future, 0, 1e6)\n\n    # Weighted score with heavier emphasis on future cost\n    score = 0.6 * d_cur + 0.4 * future\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "two_step_to_destination_minplus_aug_129": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    n = nodes.size\n\n    cur_to = distance_matrix[current_node, nodes]\n\n    if n == 1:\n        return int(nodes[0])\n\n    to_dst = distance_matrix[nodes, destination_node]\n\n    # Candidate\u2011to\u2011candidate distances\n    mat = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(mat, np.inf)\n\n    # Future cost: sum over all other candidates (proxy for diversity)\n    future = np.sum(mat + to_dst[None, :], axis=1)\n\n    # Weighted score with sum aggregation\n    score = 0.7 * cur_to + 0.3 * future\n\n    # Find indices with minimal score\n    min_score = score.min()\n    best_indices = np.where(np.abs(score - min_score) < 1e-12)[0]\n\n    # If multiple, pick the one with the smallest index (deterministic)\n    idx = int(best_indices[0])\n    return int(nodes[idx])\n\n",
  "perimeter_first_closure_aug_130": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n_total = distance_matrix.shape[0]\n    n_rem   = candidates.size\n    progress = 1.0 - n_rem / max(1, n_total)\n\n    d_cur  = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    median_to_all = D.median(axis=1)\n\n    if progress < 0.55:\n        denom_cur = d_cur.mean() + 1e-12\n        denom_mid = median_to_all.mean() + 1e-12\n        score = (d_cur / denom_cur) - 0.95 * (median_to_all / denom_mid)\n    else:\n        score = d_cur + 0.85 * d_dest\n\n    # deterministic tie\u2011breaking with tiny uniform noise\n    score += np.random.uniform(-1e-6, 1e-6, size=score.shape)\n    return int(candidates[np.argmin(score)])\n\n",
  "perimeter_first_closure_aug_131": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n_total = distance_matrix.shape[0]\n    n_rem   = candidates.size\n    progress = 1.0 - n_rem / max(1, n_total)\n\n    d_cur  = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    max_to_all = D.max(axis=1)\n\n    scores = np.empty(candidates.size, dtype=float)\n    idx = 0\n    while idx < candidates.size:\n        if progress < 0.55:\n            scores[idx] = (d_cur[idx] / (d_cur.mean() + 1e-12)) \\\n                          - 0.70 * (max_to_all[idx] / (max_to_all.mean() + 1e-12))\n        else:\n            scores[idx] = d_cur[idx] + 0.90 * d_dest[idx]\n        idx += 1\n\n    # deterministic tie\u2011breaking with incremental noise\n    scores += 1e-8 * np.arange(candidates.size)\n    return int(candidates[np.argmin(scores)])\n\n",
  "perimeter_first_closure_aug_132": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n_total = distance_matrix.shape[0]\n    n_rem   = candidates.size\n    progress = 1.0 - n_rem / max(1, n_total)\n\n    d_cur  = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    mean_to_all = D.mean(axis=1)\n\n    if progress < 0.55:\n        denom = mean_to_all.mean() + 1e-12\n        score = (d_cur / (d_cur.mean() + 1e-12)) \\\n                - 0.60 * (mean_to_all / denom)\n    else:\n        score = d_cur + 0.80 * d_dest\n\n    # soft\u2011min probabilities\n    probs = np.exp(-score - score.min())\n    probs /= probs.sum()\n\n    rng = np.random.default_rng(0)  # deterministic seed\n    chosen = rng.choice(candidates, p=probs)\n    return int(chosen)\n\n",
  "perimeter_first_closure_aug_133": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n_total = distance_matrix.shape[0]\n    n_rem   = candidates.size\n    progress = 1.0 - n_rem / max(1, n_total)\n\n    d_cur  = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    sum_to_all = D.sum(axis=1)\n\n    if progress < 0.55:\n        denom = sum_to_all.mean() + 1e-12\n        score = (d_cur / (d_cur.mean() + 1e-12)) \\\n                - 0.50 * (sum_to_all / denom)\n    else:\n        score = d_cur + 0.75 * d_dest\n\n    # clip to avoid overflow in exp\n    score = np.clip(score, -1e3, 1e3)\n    probs = np.exp(-score - score.min())\n    probs /= probs.sum()\n\n    # deterministic selection among the top\u20113 probabilities\n    k = min(3, len(probs))\n    topk = np.argsort(probs)[-k:]\n    chosen_idx = np.argmax(probs[topk])\n    return int(candidates[topk[chosen_idx]])\n\n",
  "destination_rank_bandit_aug_134": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    cand = unvisited_nodes.astype(int)\n\n    # Distances\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Band size (25\u202f% of remaining nodes, at least 2)\n    n = cand.size\n    band = max(2, min(n, int(np.floor(0.25 * n))))\n\n    # Select band of nodes closest to the destination\n    idx_band = np.argsort(d_dest)[:band]\n    selected = cand[idx_band]\n    cur_band = d_cur[idx_band]\n    dest_band = d_dest[idx_band]\n\n    # Median\u2011based scaling with tuned weights\n    med_cur = np.median(cur_band) + 1e-12\n    med_dest = np.median(dest_band) + 1e-12\n    score = 0.6 * (cur_band / med_cur) + 0.4 * (dest_band / med_dest)\n\n    # Add deterministic noise for tie\u2011breaking\n    noise = np.arange(len(score)) * 1e-6\n    score += noise\n\n    # Randomly pick among the top 3 candidates\n    top_k = min(3, len(score))\n    top_indices = np.argsort(score)[:top_k]\n    chosen = selected[np.random.choice(top_indices)]\n    return int(chosen)\n\n",
  "destination_rank_bandit_aug_135": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename and clip distances to avoid negative values\n    nodes = unvisited_nodes.astype(int)\n    d_cur = np.clip(distance_matrix[current_node, nodes], a_min=0, a_max=None)\n    d_dest = np.clip(distance_matrix[nodes, destination_node], a_min=0, a_max=None)\n\n    # Band size (30\u202f% of remaining nodes, at least 2)\n    n = nodes.size\n    band = max(2, min(n, int(np.floor(0.30 * n))))\n\n    # Band of nodes closest to the destination\n    band_idx = np.argsort(d_dest)[:band]\n    selected = nodes[band_idx]\n    cur_band = d_cur[band_idx]\n    dest_band = d_dest[band_idx]\n\n    # Max\u2011based scaling with tuned weights\n    max_cur = np.max(cur_band) + 1e-12\n    max_dest = np.max(dest_band) + 1e-12\n    score = 0.8 * (cur_band / max_cur) + 0.2 * (dest_band / max_dest)\n\n    # Deterministic tie\u2011breaking using a fixed RNG\n    rng = np.random.default_rng(42)\n    noise = rng.uniform(0, 1e-8, size=score.shape)\n    chosen = selected[np.argmin(score + noise)]\n    return int(chosen)\n\n",
  "inverse_square_potential_field_aug_136": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    D = dist_mat[np.ix_(candidates, candidates)]\n    repulse = np.sum(1.0 / (np.square(D) + 1e-12), axis=1)\n\n    c_norm = d_cur / (np.median(d_cur) + 1e-12)\n    a_norm = d_dest / (np.median(d_dest) + 1e-12)\n    r_norm = repulse / (np.max(repulse) + 1e-12)\n\n    score = 0.6 * c_norm + 0.4 * a_norm + 0.2 * r_norm\n\n    # Choose among the best top_k candidates\n    top_k = 7\n    if score.size > top_k:\n        top_indices = np.argpartition(score, top_k)[:top_k]\n        chosen_idx = np.random.choice(top_indices)\n    else:\n        chosen_idx = np.argmin(score)\n\n    return int(candidates[chosen_idx])\n\n",
  "inverse_square_potential_field_aug_137": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    d_cur  = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    D = dist_mat[np.ix_(candidates, candidates)]\n    # Proxy repulsion using 1/(d+eps)\n    repulse = np.sum(1.0 / (D + 1e-12), axis=1)\n\n    c_norm = d_cur / (np.median(d_cur) + 1e-12)\n    a_norm = d_dest / (np.median(d_dest) + 1e-12)\n    r_norm = repulse / (np.median(repulse) + 1e-12)\n\n    score = 0.5 * c_norm + 0.3 * a_norm + 0.2 * r_norm\n\n    # Deterministic tie\u2011breaking: lexicographically sort by score then index\n    indices = np.arange(candidates.size)\n    sorted_idx = np.lexsort((indices, score))\n    chosen_idx = sorted_idx[0]\n    return int(candidates[chosen_idx])\n\n",
  "cheapest_insertion_proxy_aug_138": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dm   = distance_matrix\n    n    = cand.size\n\n    # insertion costs via explicit loop\n    ins_cost = np.empty(n, dtype=float)\n    for i, v in enumerate(cand):\n        d_cur = dm[current_node, v]\n        d_dest = dm[v, destination_node]\n        d_cd = dm[current_node, destination_node]\n        ins_cost[i] = (d_cur + d_dest) - d_cd\n\n    # attachment cost: maximum distance to other candidates\n    pairwise = dm[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pairwise, -np.inf)\n    attach = np.max(pairwise, axis=1)\n    attach = np.clip(attach, a_min=0, a_max=None)          # avoid negative\n\n    # normalisation\n    ins_norm = ins_cost / (np.mean(ins_cost) + 1e-12)\n    att_norm = attach / (np.mean(attach) + 1e-12)\n\n    score = 0.6 * ins_norm + 0.4 * att_norm\n\n    # choose randomly among the three best scores\n    top_k = min(3, n)\n    idxs = np.argsort(score)[:top_k]\n    chosen = np.random.choice(idxs)\n    return int(cand[chosen])\n\n",
  "local_two_opt_risk_aug_139": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, candidates]\n    d_dest  = distance_matrix[candidates, destination_node]\n    alt     = d_cur + d_dest\n    best_alt = np.min(alt)\n\n    risk = (d_cur + d_dest) - best_alt\n\n    c_norm = d_cur / (np.mean(d_cur) + 1e-12)\n    risk_norm_den = np.clip(np.mean(np.abs(risk)), 1e-12, np.inf)\n    r_norm = risk / risk_norm_den\n\n    score = 0.5 * c_norm + 0.7 * r_norm\n\n    # deterministic tie\u2011breaker\n    noise = 1e-6 * np.arange(len(candidates))\n    score += noise\n\n    return int(candidates[np.argmin(score)])\n\n",
  "local_two_opt_risk_aug_140": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    d_cur   = distance_matrix[current_node, candidates]\n    d_dest  = distance_matrix[candidates, destination_node]\n    alt     = d_cur + d_dest\n    best_alt = np.min(alt)\n\n    risk = (d_cur + d_dest) - best_alt\n\n    c_norm = d_cur / (np.mean(distance_matrix[current_node, candidates]) + 1e-12)\n    risk_norm_den = np.clip(np.max(np.abs(risk)), 1e-12, np.inf)\n    r_norm = risk / risk_norm_den\n\n    scores = 0.4 * c_norm + 0.6 * r_norm\n\n    # deterministic tie\u2011breaker\n    noise = 1e-7 * np.arange(len(candidates))\n    scores += noise\n\n    # choose randomly among the best few\n    top_k = 5\n    top_indices = np.argsort(scores)[:top_k]\n    chosen = np.random.choice(top_indices)\n\n    return int(candidates[chosen])\n\n",
  "min_sum_of_two_closest_aug_141": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n\n    # pairwise distances among candidates\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    # two closest neighbours per candidate\n    two_nei = np.partition(sub, 1, axis=1)[:, :2]\n    # use median of the two neighbours as a proxy\n    neigh_median = np.median(two_nei, axis=1)\n\n    # normalise\n    norm_d = d_cur / (np.mean(d_cur) + 1e-12)\n    norm_n = neigh_median / (np.mean(neigh_median) + 1e-12)\n\n    # weighted score\n    score = 0.6 * norm_d + 0.4 * norm_n\n\n    # deterministic tie\u2011breaking noise\n    noise = np.random.uniform(0, 1e-6, size=score.shape)\n    score = np.clip(score + noise, 0, None)\n\n    return int(cand[int(np.argmin(score))])\n\n",
  "min_sum_of_two_closest_aug_142": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, nodes]\n\n    # pairwise sub\u2011matrix\n    sub = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    two_nei = np.partition(sub, 1, axis=1)[:, :2]\n    sum_two = two_nei.sum(axis=1)\n\n    norm_d = d_cur / (np.mean(d_cur) + 1e-12)\n    norm_s = sum_two / (np.mean(sum_two) + 1e-12)\n\n    scores = 0.8 * norm_d + 0.2 * norm_s\n    scores = np.clip(scores, 0, None)\n\n    # choose among the top\u2011k lowest scores\n    top_k = 5\n    if nodes.size <= top_k:\n        candidates = np.arange(nodes.size)\n    else:\n        candidates = np.argpartition(scores, top_k)[:top_k]\n\n    chosen = np.random.choice(candidates)\n    return int(nodes[chosen])\n\n",
  "min_sum_of_two_closest_aug_143": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, nodes]\n\n    sub = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    two_nei = np.partition(sub, 1, axis=1)[:, :2]\n    max_two = np.max(two_nei, axis=1)\n\n    norm_d = d_cur / (np.mean(d_cur) + 1e-12)\n    norm_m = max_two / (np.mean(max_two) + 1e-12)\n\n    raw_score = 0.5 * norm_d + 0.5 * norm_m\n    raw_score = np.clip(raw_score, 0, 1e6)\n\n    # add tiny deterministic noise before softmin\n    noise = np.random.uniform(0, 1e-8, size=raw_score.shape)\n    raw_score += noise\n\n    temp = 0.3\n    exp_vals = np.exp(-raw_score / temp)\n    probs = exp_vals / exp_vals.sum()\n\n    idx = np.random.choice(len(nodes), p=probs)\n    return int(nodes[idx])\n\n",
  "min_sum_of_two_closest_aug_144": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # pre\u2011compute neighbour sums for all candidates\n    sub_mat = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n    two_nei = np.partition(sub_mat, 1, axis=1)[:, :2]\n    sum_nei_vec = two_nei.sum(axis=1)\n\n    mean_d = np.mean(distance_matrix[current_node, cand]) + 1e-12\n    mean_s = np.mean(sum_nei_vec) + 1e-12\n\n    scores = np.empty(cand.size, dtype=np.float64)\n\n    for i, node in enumerate(cand):\n        d = distance_matrix[current_node, node]\n        scores[i] = 0.9 * (d / mean_d) + 0.1 * (sum_nei_vec[i] / mean_s)\n\n    scores = np.clip(scores, 0, None)\n\n    # deterministic tie\u2011breaking noise\n    noise = np.random.uniform(0, 1e-7, size=scores.shape)\n    scores += noise\n\n    top_k = 7\n    if cand.size <= top_k:\n        chosen_idx = np.argmin(scores)\n    else:\n        top_idx = np.argpartition(scores, top_k)[:top_k]\n        chosen_idx = top_idx[np.argmin(scores[top_idx])]\n\n    return int(cand[chosen_idx])\n\n",
  "destination_overshoot_penalty_aug_145": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming and vectorised calculations\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    base_dist = float(dist_mat[current_node, destination_node])\n    dist_from_cur = dist_mat[current_node, candidates]\n    dist_to_dest = dist_mat[candidates, destination_node]\n\n    # Overshoot and normalisation with median (robust to outliers)\n    overshoot = np.maximum(0.0, dist_to_dest - base_dist)\n    o_norm = overshoot / (np.median(overshoot) + 1e-12)\n    c_norm = dist_from_cur / (np.median(dist_from_cur) + 1e-12)\n\n    # Clip normalised values to keep them bounded\n    o_norm = np.clip(o_norm, 0, 1e3)\n    c_norm = np.clip(c_norm, 0, 1e3)\n\n    # Weighted scoring\n    score = c_norm + 1.25 * o_norm\n\n    # Greedy selection of the best candidate\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "destination_overshoot_penalty_aug_146": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables and sum\u2011based normalisation\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    base_dist = float(dist_mat[current_node, destination_node])\n    dist_from_cur = dist_mat[current_node, candidates]\n    dist_to_dest = dist_mat[candidates, destination_node]\n\n    overshoot = np.maximum(0.0, dist_to_dest - base_dist)\n\n    o_norm = overshoot / (np.sum(overshoot) + 1e-12)\n    c_norm = dist_from_cur / (np.sum(dist_from_cur) + 1e-12)\n\n    # Clip to avoid extreme values\n    o_norm = np.clip(o_norm, 0, 1e3)\n    c_norm = np.clip(c_norm, 0, 1e3)\n\n    # Tuned weighting and deterministic tie\u2011breaking noise\n    score = 0.6 * c_norm + 0.4 * o_norm\n    noise = np.arange(len(candidates)) * 1e-8\n\n    # Top\u2011k selection\n    top_k = 7\n    sorted_idx = np.argsort(score)\n    top_indices = sorted_idx[:min(top_k, len(candidates))]\n    top_scores = score[top_indices] + noise[top_indices]\n\n    best_local_idx = int(np.argmin(top_scores))\n    best_idx = int(top_indices[best_local_idx])\n\n    return int(candidates[best_idx])\n\n",
  "destination_overshoot_penalty_aug_147": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # List\u2011comprehension based distance extraction\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    base_dist = float(dist_mat[current_node, destination_node])\n\n    dist_from_cur = np.array([dist_mat[current_node, v] for v in candidates], dtype=float)\n    dist_to_dest = np.array([dist_mat[v, destination_node] for v in candidates], dtype=float)\n\n    overshoot = np.maximum(0.0, dist_to_dest - base_dist)\n\n    o_norm = overshoot / (np.sum(overshoot) + 1e-12)\n    c_norm = dist_from_cur / (np.sum(dist_from_cur) + 1e-12)\n\n    # Clip to keep values bounded\n    o_norm = np.clip(o_norm, 0, 1e3)\n    c_norm = np.clip(c_norm, 0, 1e3)\n\n    # Weighted scoring and deterministic noise\n    score = 0.5 * c_norm + 0.5 * o_norm\n    noise = np.arange(len(candidates)) * 1e-7\n\n    # Top\u2011k selection\n    top_k = 5\n    sorted_idx = np.argsort(score)\n    top_indices = sorted_idx[:min(top_k, len(candidates))]\n    top_scores = score[top_indices] + noise[top_indices]\n\n    best_local_idx = int(np.argmin(top_scores))\n    best_idx = int(top_indices[best_local_idx])\n\n    return int(candidates[best_idx])\n\n",
  "quantile_target_edge_aug_148": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for readability\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # Current distances to all candidates\n    d_cur = dist_mat[current_node, candidates]\n\n    # Progress (0 at start, 1 when all visited)\n    n_total = int(dist_mat.shape[0] + 1e-12)          # epsilon to avoid div\u20110\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    # Early aim higher quantile, late aim lower quantile\n    q = np.clip(0.75 - 0.55 * progress, 0.0, 1.0)     # np.clip to keep 0\u20111\n    target = float(np.quantile(d_cur, q))\n\n    # Deterministic noise to break ties (very small)\n    noise = np.arange(d_cur.size, dtype=float) * 1e-8\n\n    # Score is distance from the target plus noise\n    score = np.abs(d_cur - target) + noise\n    return int(candidates[np.argmin(score)])\n\n",
  "quantile_target_edge_aug_149": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n    d_cur      = dist_mat[current_node, candidates]\n\n    # Tunable weights and threshold\n    w_dist = 0.6\n    w_log  = 0.4\n    top_k  = 7\n\n    # Scoring: linear distance + log component\n    score = w_dist * d_cur + w_log * np.log(d_cur + 1e-12)\n\n    # Select top\u2011k smallest scores\n    k = min(top_k, score.size)\n    idx_sorted = np.argsort(score)\n    top_idx    = idx_sorted[:k]\n\n    # Soft\u2011min probabilities\n    temp = np.clip(0.5, 0.1, 10.0)          # temperature bounded by np.clip\n    probs = np.exp(-score[top_idx] / (temp + 1e-12))\n    probs /= np.sum(probs + 1e-12)          # avoid div\u20110\n\n    rng = np.random.default_rng(0)          # deterministic RNG\n    chosen = rng.choice(top_idx, p=probs)\n    return int(candidates[chosen])\n\n",
  "quantile_target_edge_aug_150": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n    d_cur      = dist_mat[current_node, candidates]\n\n    # Target is the mean distance (aggregation change)\n    target = float(np.mean(d_cur))\n\n    # Small deterministic noise for tie\u2011breaking\n    noise = np.arange(d_cur.size, dtype=float) * 1e-7\n\n    # Score and soft\u2011min probabilities\n    score = np.abs(d_cur - target) + noise\n    temp  = np.clip(1.0, 0.1, 10.0)\n    probs = np.exp(-score / (temp + 1e-12))\n    probs /= np.sum(probs + 1e-12)\n\n    rng = np.random.default_rng(1)          # deterministic RNG\n    chosen = rng.choice(candidates.size, p=probs)\n    return int(candidates[chosen])\n\n",
  "quantile_target_edge_aug_151": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n    d_cur      = dist_mat[current_node, candidates]\n\n    # Choose the 5 nearest candidates\n    top_k = 5\n    k = min(top_k, d_cur.size)\n    idx_sorted = np.argsort(d_cur)\n    top_idx    = idx_sorted[:k]\n\n    rng = np.random.default_rng(2)          # deterministic RNG\n    chosen = rng.choice(top_idx)\n    return int(candidates[chosen])\n\n",
  "destination_cone_filter_aug_152": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for clarity\n    cand = unvisited_nodes.astype(int)\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    # Cosine of the angle at the current node\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    # Progress\u2011dependent cone threshold\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    thr = 0.05 + 0.85 * progress\n\n    aligned_idx = np.where(cos_theta >= thr)[0]\n\n    # If no candidate is aligned, fall back to slack minimisation\n    if aligned_idx.size == 0:\n        slack = (b + c) - a\n        score = slack + 0.10 * b\n        return int(cand[np.argmin(score)])\n\n    # Score inside the cone\n    aligned_b = b[aligned_idx]\n    aligned_c = c[aligned_idx]\n    mean_b = np.median(aligned_b) + 1e-12\n    mean_c = np.median(aligned_c) + 1e-12\n    score = (aligned_b / mean_b) + 0.70 * (aligned_c / mean_c)\n\n    # Deterministic tie\u2011breaking noise\n    noise = 1e-9 * np.arange(aligned_idx.size)\n    idx_min = np.argmin(score + noise)\n    return int(cand[aligned_idx[idx_min]])\n\n",
  "destination_cone_filter_aug_153": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    thr = 0.10 + 0.90 * progress\n\n    aligned_idx = np.where(cos_theta >= thr)[0]\n\n    if aligned_idx.size > 0:\n        # Randomly choose among the best 5 aligned candidates\n        aligned_b = b[aligned_idx]\n        aligned_c = c[aligned_idx]\n        score = (aligned_b / (np.max(aligned_b) + 1e-12)) + 0.65 * (aligned_c / (np.max(aligned_c) + 1e-12))\n        top_k = min(5, aligned_idx.size)\n        top_idx = np.argsort(score)[:top_k]\n        chosen = aligned_idx[np.random.choice(top_idx)]\n        return int(cand[chosen])\n\n    # Fallback: choose among the 5 lowest slack candidates\n    slack = (b + c) - a\n    score = slack + 0.12 * b\n    top_k = min(5, cand.size)\n    top_idx = np.argsort(score)[:top_k]\n    chosen = cand[np.random.choice(top_idx)]\n    return int(chosen)\n\n",
  "destination_cone_filter_aug_154": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    a = float(distance_matrix[current_node, destination_node])\n    b = distance_matrix[current_node, cand]\n    c = distance_matrix[cand, destination_node]\n\n    denom = 2.0 * a * (b + 1e-12) + 1e-12\n    cos_theta = (a * a + b * b - c * c) / denom\n    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    thr = 0.08 + 0.88 * progress\n\n    aligned_idx = np.where(cos_theta >= thr)[0]\n\n    if aligned_idx.size == 0:\n        slack = (b + c) - a\n        score = slack + 0.15 * b\n        # Soft\u2011min weighting\n        weights = np.exp(-score)\n        idx = np.argmax(weights)\n        return int(cand[idx])\n\n    aligned_b = b[aligned_idx]\n    aligned_c = c[aligned_idx]\n    score = (aligned_b / (np.sum(aligned_b) + 1e-12)) + 0.50 * (aligned_c / (np.sum(aligned_c) + 1e-12))\n\n    # Deterministic noise for stable tie\u2011breaking\n    noise = 1e-8 * np.arange(aligned_idx.size)\n    idx = np.argmin(score + noise)\n    return int(cand[aligned_idx[idx]])\n\n",
  "destination_cone_filter_aug_155": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    a = float(distance_matrix[current_node, destination_node])\n\n    best_idx = None\n    best_score = np.inf\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem   = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    thr = 0.20 + 0.80 * progress\n\n    for idx, node in enumerate(cand):\n        b = distance_matrix[current_node, node]\n        c = distance_matrix[node, destination_node]\n        denom = 2.0 * a * (b + 1e-12) + 1e-12\n        cos_theta = (a * a + b * b - c * c) / denom\n        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n\n        if cos_theta >= thr:\n            mean_b = np.max(b) + 1e-12  # single value, so max == b\n            mean_c = np.max(c) + 1e-12\n            score = (b / mean_b) + 0.70 * (c / mean_c)\n        else:\n            slack = (b + c) - a\n            score = slack + 0.10 * b\n\n        # Add tiny random noise for deterministic tie\u2011breaking\n        score += 1e-7 * idx\n        if score < best_score:\n            best_score = score\n            best_idx = node\n\n    return int(best_idx)\n\n",
  "barycentric_pull_then_clip_aug_156": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for clarity\n    candidates = unvisited_nodes.astype(int)\n\n    # Distance from the current node to each candidate\n    d_cur = distance_matrix[current_node, candidates]\n\n    # Pairwise distances among candidates (diagonal set to inf)\n    pair_dist = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    # Rank each candidate relative to the others\n    ranks = np.argsort(np.argsort(pair_dist, axis=1), axis=1).astype(np.float64)\n    centrality = np.median(ranks, axis=1)          # use median instead of mean\n\n    # Select a small \u201cnear\u201d subset (\u224825\u202f% of the remaining nodes)\n    n = candidates.size\n    k = int(max(2, min(n, int(np.ceil(0.25 * n)))))\n    sorted_idx = np.argsort(d_cur)\n    near_idx = []\n    i = 0\n    while len(near_idx) < k and i < n:\n        near_idx.append(sorted_idx[i])\n        i += 1\n    near_idx = np.array(near_idx, dtype=int)\n\n    # Candidate data for the near set\n    c = candidates[near_idx]\n    cr = centrality[near_idx]\n    dc = d_cur[near_idx]\n\n    # Deterministic tie\u2011breaking noise\n    noise = 1e-6 * np.arange(len(c))\n\n    # Scoring: distance + 0.8\u202f\u00d7\u202fcentrality, scaled by medians\n    score = (dc / (np.median(dc) + 1e-12)) + \\\n            0.8 * (cr / (np.median(cr) + 1e-12)) + noise\n\n    return int(c[np.argmin(score)])\n\n",
  "barycentric_pull_then_clip_aug_157": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n\n    pair = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair, np.inf)\n\n    # Rank matrix \u2013 use maximum rank for a more \u201cextreme\u201d centrality\n    ranks = np.argsort(np.argsort(pair, axis=1), axis=1).astype(np.float64)\n    central = np.max(ranks, axis=1)\n\n    # Choose a larger near\u2011set (\u224835\u202f% of the remaining nodes, capped at 7)\n    n = cand.size\n    k = int(min(n, max(2, int(np.ceil(0.35 * n)))))\n    k = min(k, 7)\n\n    idx_sorted = np.argsort(d_cur)\n    near = idx_sorted[:k]\n    c = cand[near]\n    cr = central[near]\n    dc = d_cur[near]\n\n    # Scoring with sum\u2011based normalisation and a 0.4 weight on centrality\n    score = (dc / (np.sum(dc) + 1e-12)) + \\\n            0.4 * (cr / (np.sum(cr) + 1e-12))\n\n    # Randomly pick among the three best candidates (deterministic seed)\n    sorted_scores = np.argsort(score)\n    top3 = sorted_scores[:3]\n    rng = np.random.default_rng(42)\n    chosen = rng.choice(top3)\n\n    return int(c[chosen])\n\n",
  "barycentric_pull_then_clip_aug_158": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n\n    d_current = distance_matrix[current_node, nodes]\n\n    mat = distance_matrix[np.ix_(nodes, nodes)].copy()\n    np.fill_diagonal(mat, np.inf)\n\n    rank_arr = np.argsort(np.argsort(mat, axis=1), axis=1).astype(np.float64)\n    centrality = np.median(rank_arr, axis=1)\n\n    n = nodes.size\n    k = int(max(2, min(n, int(np.ceil(0.20 * n)))))\n\n    # Build the near\u2011set with a simple for\u2011loop\n    sorted_idx = np.argsort(d_current)\n    near = []\n    for i in range(k):\n        near.append(sorted_idx[i])\n    near = np.array(near, dtype=int)\n\n    c = nodes[near]\n    cr = centrality[near]\n    dc = d_current[near]\n\n    noise = 1e-6 * np.arange(len(c))\n    # Use maximum distance for normalisation\n    score = (dc / (np.max(dc) + 1e-12)) + \\\n            0.8 * (cr / (np.median(cr) + 1e-12)) + noise\n\n    return int(c[np.argmin(score)])\n\n",
  "barycentric_pull_then_clip_aug_159": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n\n    # Approximate centrality by the mean distance to other candidates\n    pair = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair, np.inf)\n    centrality = np.mean(pair, axis=1)\n\n    n = cand.size\n    k = min(5, n)                     # fixed small near\u2011set\n    sorted_idx = np.argsort(d_cur)\n    near = sorted_idx[:k]\n    c = cand[near]\n    cr = centrality[near]\n    dc = d_cur[near]\n\n    # Combined score (equal weight on distance and centrality)\n    score = 0.5 * (dc / (np.mean(dc) + 1e-12)) + \\\n            0.5 * (cr / (np.mean(cr) + 1e-12))\n\n    # Softmin probabilities (\u03b2 controls sharpness)\n    beta = 15.0\n    exp_vals = np.exp(-beta * score)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Deterministic tie\u2011breaking noise\n    noise = 1e-6 * np.arange(len(c))\n    probs = np.clip(probs + noise, 0, 1)\n\n    chosen = np.argmax(probs)\n    return int(c[chosen])\n\n",
  "destination_differential_greedy_aug_160": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    step = distance_matrix[current_node, candidates]\n    r1   = distance_matrix[candidates, destination_node]\n    gain = r0 - r1\n\n    # Positive progress mask\n    pos_mask = gain > 1e-12\n\n    # If no positive progress, fall back to the nearest step\n    if not np.any(pos_mask):\n        return int(candidates[np.argmin(step)])\n\n    # Efficiency: step per unit gain\n    eff = np.where(pos_mask,\n                   step / (gain + 1e-12),\n                   np.inf)\n\n    # Clip to avoid extreme values and add tiny noise for deterministic tie\u2011breaking\n    eff = np.clip(eff, 0, 1e12)\n    eff += np.random.uniform(0, 1e-6, size=eff.shape)\n\n    return int(candidates[np.argmin(eff)])\n\n",
  "destination_differential_greedy_aug_161": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0   = float(distance_matrix[current_node, destination_node])\n\n    step = distance_matrix[current_node, cand]\n    r1   = distance_matrix[cand, destination_node]\n    gain = r0 - r1\n\n    pos_mask = gain > 1e-12\n    if not np.any(pos_mask):\n        return int(cand[np.argmin(step)])\n\n    cost = np.where(pos_mask,\n                    step / (gain + 1e-12),\n                    np.inf)\n\n    # Clip cost to avoid overflow in exp\n    cost = np.clip(cost, 0, 1e3)\n\n    # Softmin probabilities\n    weights = np.exp(-cost)\n    weights = np.where(pos_mask, weights, 0.0)\n\n    # Normalise and pick the best\n    total = np.sum(weights)\n    if total == 0:\n        return int(cand[np.argmin(step)])\n\n    probs = weights / total\n    chosen = np.argmax(probs)\n    return int(cand[chosen])\n\n",
  "destination_differential_greedy_aug_162": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0   = float(distance_matrix[current_node, destination_node])\n\n    step = distance_matrix[current_node, cand]\n    r1   = distance_matrix[cand, destination_node]\n    gain = r0 - r1\n\n    # Score: 0.6 * step + 0.4 * gain\n    score = 0.6 * step + 0.4 * gain\n    score = np.clip(score, 0, 1e12)\n\n    # Select top\u2011k candidates\n    top_k = 5\n    if cand.size <= top_k:\n        top_indices = np.arange(cand.size)\n    else:\n        top_indices = np.argpartition(score, -top_k)[-top_k:]\n    # Random choice among top\u2011k\n    chosen_idx = np.random.choice(top_indices)\n    return int(cand[chosen_idx])\n\n",
  "destination_differential_greedy_aug_163": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0   = float(distance_matrix[current_node, destination_node])\n\n    step = distance_matrix[current_node, cand]\n    r1   = distance_matrix[cand, destination_node]\n    gain = r0 - r1\n\n    pos_mask = gain > 1e-12\n    if not np.any(pos_mask):\n        return int(cand[np.argmin(step)])\n\n    # Proxy efficiency: sqrt(step) / (gain + epsilon)\n    eff = np.where(pos_mask,\n                   np.sqrt(step) / (gain + 1e-12),\n                   np.inf)\n\n    # Median filtering to remove extreme values\n    median_eff = np.median(eff[eff != np.inf])\n    eff = np.where(eff == np.inf, median_eff * 1e3, eff)\n\n    # Clip to avoid overflow\n    eff = np.clip(eff, 0, 1e12)\n\n    # Randomly pick among the three lowest efficiencies\n    top_k = 3\n    if cand.size <= top_k:\n        top_indices = np.arange(cand.size)\n    else:\n        top_indices = np.argpartition(eff, top_k)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    return int(cand[chosen_idx])\n\n",
  "softmax_sampling_deterministic_aug_164": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Distances from the current node and to the destination\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Normalization with the median (avoids outliers)\n    norm_cur = d_cur / (np.median(d_cur) + 1e-12)\n    norm_dest = d_dest / (np.median(d_dest) + 1e-12)\n\n    # Weighted base score\n    base = 0.75 * norm_cur + 0.25 * norm_dest\n\n    # Deterministic Gumbel noise\n    seed = (current_node * 1234567) ^ (destination_node * 7654321) ^ (cand.size * 54321)\n    rng = np.random.default_rng(seed)\n    noise = rng.random(cand.size)\n    noise = np.clip(noise, 1e-12, 1 - 1e-12)\n    gumbel = -np.log(-np.log(noise))\n\n    # Temperature schedule that cools over time\n    n_total = distance_matrix.shape[0]\n    n_rem = cand.size\n    progress = 1.0 - (n_rem / max(1, n_total))\n    tau = 0.9 - 0.7 * progress\n\n    # Final score\n    score = base - tau * gumbel\n    return int(cand[int(np.argmin(score))])\n\n",
  "softmax_sampling_deterministic_aug_165": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Sum\u2011based normalization\n    norm_cur = d_cur / (np.sum(d_cur) + 1e-12)\n    norm_dest = d_dest / (np.sum(d_dest) + 1e-12)\n\n    # Weighted base score\n    base = 0.60 * norm_cur + 0.40 * norm_dest\n\n    # Identify top\u2011k candidates\n    top_k = min(7, cand.size)\n    top_indices = np.argpartition(base, top_k - 1)[:top_k]\n\n    # Deterministic random choice among the top\u2011k\n    seed = (current_node * 9876543) ^ (destination_node * 1234567) ^ (cand.size * 4321)\n    rng = np.random.default_rng(seed)\n    chosen = rng.choice(top_indices)\n\n    return int(cand[chosen])\n\n",
  "softmax_sampling_deterministic_aug_166": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Squared distances\n    d_cur = np.square(distance_matrix[current_node, cand])\n    d_dest = np.square(distance_matrix[cand, destination_node])\n\n    # Max\u2011based normalization\n    norm_cur = d_cur / (np.max(d_cur) + 1e-12)\n    norm_dest = d_dest / (np.max(d_dest) + 1e-12)\n\n    # Weighted base score\n    base = 0.50 * norm_cur + 0.50 * norm_dest\n\n    # Tiny deterministic noise for deterministic tie\u2011breaking\n    seed = (current_node * 19260817) ^ (destination_node * 11223344) ^ (cand.size * 314159)\n    rng = np.random.default_rng(seed)\n    noise = rng.standard_normal(cand.size) * 1e-6\n\n    score = base + noise\n    return int(cand[int(np.argmin(score))])\n\n",
  "softmax_sampling_deterministic_aug_167": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Mean\u2011based normalization\n    norm_cur = d_cur / (np.mean(d_cur) + 1e-12)\n    norm_dest = d_dest / (np.mean(d_dest) + 1e-12)\n\n    # Weighted base score\n    base = 0.70 * norm_cur + 0.30 * norm_dest\n\n    # Deterministic tiny noise\n    seed = (current_node * 31415926) ^ (destination_node * 27182818) ^ (cand.size * 271828)\n    rng = np.random.default_rng(seed)\n    noise = rng.uniform(-1e-5, 1e-5, size=cand.size)\n\n    score = base + noise\n    return int(cand[int(np.argmin(score))])\n\n",
  "min_cycle_closure_risk_aug_168": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_cur = distance_matrix[current_node, candidates]\n    dist_dest = distance_matrix[candidates, destination_node]\n\n    loopiness = 1.0 / (dist_cur + 1e-12) + 1.0 / (dist_dest + 1e-12)\n\n    # Normalise using mean distances\n    norm_cur  = dist_cur  / (np.mean(dist_cur) + 1e-12)\n    norm_loop = loopiness / (np.mean(loopiness) + 1e-12)\n\n    # Score list comprehension\n    scores = [norm_cur[i] + 0.55 * norm_loop[i] for i in range(len(candidates))]\n    scores = np.clip(scores, 0, None)\n\n    return int(candidates[np.argmin(scores)])\n\n",
  "min_cycle_closure_risk_aug_169": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_cur = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    loopiness = 1.0 / (d_cur + 1e-12) + 1.0 / (d_dest + 1e-12)\n\n    norm_cur  = d_cur  / (np.mean(d_cur) + 1e-12)\n    norm_loop = loopiness / (np.mean(loopiness) + 1e-12)\n\n    score = norm_cur + 0.4 * norm_loop\n\n    top_k = 7\n    if top_k > len(cand):\n        top_k = len(cand)\n\n    # Obtain indices of the top_k lowest scores\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    return int(cand[chosen_idx])\n\n",
  "min_geometric_mean_step_dest_aug_170": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = np.clip(distance_matrix[current_node, cand], eps, None)\n    rem  = np.clip(distance_matrix[cand, destination_node], eps, None)\n\n    # Linear weighted sum (balance between step and remaining)\n    score = 0.6 * step + 0.4 * rem\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-9 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_geometric_mean_step_dest_aug_171": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = np.clip(distance_matrix[current_node, cand], eps, None)\n    rem  = np.clip(distance_matrix[cand, destination_node], eps, None)\n\n    # Geometric mean score\n    score = np.sqrt((step + eps) * (rem + eps))\n\n    # Randomly pick among the top\u2011k smallest scores\n    sorted_idx = np.argsort(score)\n    top_k = 7\n    top_candidates = cand[sorted_idx[:top_k]]\n\n    rng = np.random.default_rng(12345)  # deterministic\n    return int(rng.choice(top_candidates))\n\n",
  "min_geometric_mean_step_dest_aug_172": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = np.clip(distance_matrix[current_node, cand], eps, None)\n    rem  = np.clip(distance_matrix[cand, destination_node], eps, None)\n\n    # Log\u2011sum to avoid overflow and use median centering\n    score = np.log(step + eps) + np.log(rem + eps)\n    median_val = np.median(score)\n    score -= median_val\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-8 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_geometric_mean_step_dest_aug_173": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    cand = [int(v) for v in unvisited_nodes]\n    if not cand:\n        return int(destination_node)\n\n    step = np.clip(distance_matrix[current_node, cand], eps, None)\n    rem  = np.clip(distance_matrix[cand, destination_node], eps, None)\n\n    # Max\u2011plus\u2011min weighted score\n    max_part = np.maximum(step, rem)\n    min_part = np.minimum(step, rem)\n    score = 0.5 * max_part + 0.5 * min_part\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-9 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_l1_rank_mix_aug_174": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Direct distance computations\n    step_dist = distance_matrix[current_node, cand]\n    dest_dist = distance_matrix[cand, destination_node]\n\n    # Centrality: average distance to all other candidates\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    centrality = sub_mat.sum(axis=1) / (sub_mat.shape[1] + 1e-12)\n\n    # Rank each component\n    r_step = np.argsort(np.argsort(step_dist)).astype(np.float64)\n    r_dest = np.argsort(np.argsort(dest_dist)).astype(np.float64)\n    r_cent = np.argsort(np.argsort(centrality)).astype(np.float64)\n\n    # Small deterministic noise to break ties\n    noise = np.arange(cand.size) * 1e-6\n    score = r_step + 0.7 * r_dest + 0.5 * r_cent + noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_l1_rank_mix_aug_175": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step_dist = distance_matrix[current_node, cand]\n    dest_dist = distance_matrix[cand, destination_node]\n\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    centrality = sub_mat.median(axis=1)\n\n    # Rank each component\n    r_step = np.argsort(np.argsort(step_dist)).astype(np.float64)\n    r_dest = np.argsort(np.argsort(dest_dist)).astype(np.float64)\n    r_cent = np.argsort(np.argsort(centrality)).astype(np.float64)\n\n    score = r_step + 0.6 * r_dest + 0.4 * r_cent\n\n    # Soft\u2011min with temperature\n    temp = 0.5\n    exp_vals = np.exp(-score / (temp + 1e-12))\n    probs = exp_vals / (exp_vals.sum() + 1e-12)\n\n    # Randomly pick from the top\u2011k candidates\n    top_k = 5\n    top_indices = np.argpartition(-probs, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices,\n                              p=probs[top_indices] / probs[top_indices].sum())\n    return int(cand[chosen])\n\n",
  "min_l1_rank_mix_aug_176": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Compute distances via list comprehension for clarity\n    step_dist = np.array([distance_matrix[current_node, i] for i in cand],\n                         dtype=np.float64)\n    dest_dist = np.array([distance_matrix[i, destination_node] for i in cand],\n                         dtype=np.float64)\n\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    centrality = np.sum(sub_mat, axis=1) / (sub_mat.shape[1] + 1e-12)\n\n    # Manual ranking (count how many values are less than or equal)\n    r_step = np.empty_like(step_dist, dtype=np.float64)\n    r_dest = np.empty_like(dest_dist, dtype=np.float64)\n    r_cent = np.empty_like(centrality, dtype=np.float64)\n    for idx in range(cand.size):\n        r_step[idx] = np.sum(step_dist <= step_dist[idx]) - 1\n        r_dest[idx] = np.sum(dest_dist <= dest_dist[idx]) - 1\n        r_cent[idx] = np.sum(centrality <= centrality[idx]) - 1\n\n    # Deterministic noise for tie breaking\n    noise = (np.arange(cand.size) + 1) * 1e-7\n    score = r_step + 0.8 * r_dest + 0.5 * r_cent + noise\n    score = np.clip(score, 0, None)  # avoid negative values\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_l1_rank_mix_aug_177": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n\n    # Clip distances to avoid extreme values\n    step_dist = np.clip(distance_matrix[current_node, cand], 0, 1e6)\n    dest_dist = np.clip(distance_matrix[cand, destination_node], 0, 1e6)\n\n    sub_mat = distance_matrix[np.ix_(cand, cand)]\n    centrality = np.median(sub_mat, axis=1)\n\n    # Ranking\n    r_step = np.argsort(np.argsort(step_dist)).astype(np.float64)\n    r_dest = np.argsort(np.argsort(dest_dist)).astype(np.float64)\n    r_cent = np.argsort(np.argsort(centrality)).astype(np.float64)\n\n    score = r_step + 0.6 * r_dest + 0.7 * r_cent\n\n    # Soft\u2011max with temperature\n    temp = 1.0\n    logits = -score / (temp + 1e-12)\n    probs = np.exp(logits - np.max(logits))  # numerical stability\n    probs /= probs.sum() + 1e-12\n\n    # Deterministic random choice among top\u2011k\n    rng = np.random.default_rng(seed=int((current_node + destination_node) * 1e6))\n    top_k = 7\n    top_indices = np.argpartition(-probs, top_k - 1)[:top_k]\n    chosen = rng.choice(top_indices,\n                        p=probs[top_indices] / probs[top_indices].sum())\n    return int(cand[chosen])\n\n",
  "max_margin_to_nearest_aug_178": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    # Distance from the current node to each candidate\n    step = dist[current_node, candidates]\n\n    # Pairwise distances among candidates\n    pair_dist = dist[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    # Find the nearest and third\u2011nearest neighbors\n    part = np.partition(pair_dist, 2, axis=1)\n    d1, d3 = part[:, 0], part[:, 2]\n\n    # Structural margin\n    margin = d3 - d1\n\n    # Normalization with safeguards\n    s_norm = step / (np.mean(step) + 1e-12)\n    m_norm = margin / (np.mean(margin) + 1e-12)\n\n    # Scoring: larger margin favoured\n    score = s_norm - 0.80 * m_norm\n    return int(candidates[np.argmin(score)])\n\n",
  "max_margin_to_nearest_aug_179": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    step = dist[current_node, candidates]\n    pair_dist = dist[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    part = np.partition(pair_dist, 2, axis=1)\n    d1, d3 = part[:, 0], part[:, 2]\n    margin = d3 - d1\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    m_norm = margin / (np.mean(margin) + 1e-12)\n\n    # Tuned weights\n    score = 0.6 * s_norm - 0.4 * m_norm\n\n    # Small deterministic noise to break ties\n    noise = 1e-6 * np.random.rand(len(candidates))\n    score += noise\n\n    # Choose among the best top\u2011k candidates\n    top_k = 7\n    if len(candidates) > top_k:\n        idx_top = np.argpartition(score, top_k - 1)[:top_k]\n        chosen_idx = idx_top[np.argmin(score[idx_top])]\n    else:\n        chosen_idx = np.argmin(score)\n\n    return int(candidates[chosen_idx])\n\n",
  "max_margin_to_nearest_aug_180": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    step = dist[current_node, candidates]\n    pair_dist = dist[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    # Use the maximum distance as the third\u2011nearest neighbour\n    d1 = np.min(pair_dist, axis=1)\n    d3 = np.max(pair_dist, axis=1)\n    margin = d3 - d1\n\n    s_norm = step / (np.median(step) + 1e-12)\n    m_norm = margin / (np.median(margin) + 1e-12)\n\n    score = s_norm - 0.8 * m_norm\n\n    # Deterministic noise for stable tie\u2011breaking\n    noise = 1e-9 * np.arange(len(candidates))\n    score += noise\n\n    # Random choice among the top\u2011k best candidates\n    top_k = 5\n    if len(candidates) > top_k:\n        idx_top = np.argpartition(score, top_k - 1)[:top_k]\n        chosen_idx = np.random.choice(idx_top)\n    else:\n        chosen_idx = np.argmin(score)\n\n    return int(candidates[chosen_idx])\n\n",
  "min_destination_curvature_aug_181": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # If no candidates left, return the destination\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Pre\u2011compute distances\n    cur_to_dest = float(dist_mat[current_node, destination_node])\n    cur_to_cand = dist_mat[current_node, candidates]\n    cand_to_dest = dist_mat[candidates, destination_node]\n\n    # Curvature proxy\n    curvature = (cur_to_cand + cand_to_dest) / (cur_to_dest + 1e-12)\n\n    # Use median instead of mean and add a weighted step term\n    step_median = np.median(cur_to_cand)\n    score = curvature + 0.4 * (cur_to_cand / (step_median + 1e-12))\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(candidates.size) * 1e-9\n    score += noise\n\n    # Clip to avoid extreme values\n    score = np.clip(score, 0, np.inf)\n\n    # Choose the candidate with the smallest score\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "min_destination_curvature_aug_182": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    cur_to_dest = float(dist_mat[current_node, destination_node])\n    cur_to_cand = dist_mat[current_node, candidates]\n    cand_to_dest = dist_mat[candidates, destination_node]\n\n    curvature = (cur_to_cand + cand_to_dest) / (cur_to_dest + 1e-12)\n\n    # Median as a robust central tendency\n    step_median = np.median(cur_to_cand)\n    score = curvature + 0.3 * (cur_to_cand / (step_median + 1e-12))\n\n    # Select a small subset of promising candidates\n    top_k = 7\n    if candidates.size <= top_k:\n        top_idx = np.argsort(score)\n    else:\n        top_idx = np.argpartition(score, top_k)[:top_k]\n        top_idx = top_idx[np.argsort(score[top_idx])]\n\n    # Random choice among the top candidates\n    chosen_idx = int(np.random.choice(top_idx))\n    return int(candidates[chosen_idx])\n\n",
  "min_destination_curvature_aug_183": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    if cand.size == 0:\n        return int(destination_node)\n\n    cur_to_dest = float(dm[current_node, destination_node])\n    step = dm[current_node, cand]\n    rem = dm[cand, destination_node]\n\n    curvature = (step + rem) / (cur_to_dest + 1e-12)\n\n    # Sum aggregation instead of mean\n    step_sum = np.sum(step) + 1e-12\n    weight = 0.5\n    score = curvature + weight * (step / step_sum)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.linspace(0, 1e-8, cand.size)\n    score += noise\n\n    # Clip to avoid negative or infinite values\n    score = np.clip(score, 0, np.inf)\n\n    # Softmin selection using exponential weights\n    exp_scores = np.exp(-score - np.max(-score))  # numerical stability\n    probs = exp_scores / exp_scores.sum()\n    chosen_index = int(np.random.choice(cand.size, p=probs))\n    return int(cand[chosen_index])\n\n",
  "min_destination_curvature_aug_184": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    nodes = unvisited_nodes.astype(int)\n    mat = distance_matrix\n\n    if nodes.size == 0:\n        return int(destination_node)\n\n    cur_dest = float(mat[current_node, destination_node])\n    cur_to_nodes = mat[current_node, nodes]\n    nodes_to_dest = mat[nodes, destination_node]\n\n    curvature = (cur_to_nodes + nodes_to_dest) / (cur_dest + 1e-12)\n\n    # Sum aggregation for step distances\n    step_sum = np.sum(cur_to_nodes) + 1e-12\n    score = curvature + 0.7 * (cur_to_nodes / step_sum)\n\n    # Clip to a reasonable range\n    score = np.clip(score, 0, 1e6)\n\n    # Randomly pick among the top\u2011k lowest scores\n    k = 5\n    if nodes.size <= k:\n        top = np.argsort(score)\n    else:\n        top = np.argpartition(score, k)[:k]\n        top = top[np.argsort(score[top])]\n\n    idx = int(np.random.choice(top))\n    return int(nodes[idx])\n\n",
  "min_quantile_attach_cost_aug_185": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    # Invert the original conditional\n    if candidates.size:\n        # Ensure indices are integers\n        idx = candidates.astype(int)\n\n        # Distance from the current node to each candidate\n        step_dist = dist_mat[current_node, idx]\n\n        # Sub\u2011matrix of distances between candidates\n        sub_mat = dist_mat[np.ix_(idx, idx)].copy()\n        np.fill_diagonal(sub_mat, np.inf)\n\n        # 75th percentile of distances for each candidate\n        q75_vals = np.percentile(sub_mat, 75, axis=1)\n\n        # Normalized scores\n        step_norm = step_dist / (np.mean(step_dist) + 1e-12)\n        q75_norm = q75_vals / (np.mean(q75_vals) + 1e-12)\n\n        # Combine the two components\n        combined = step_norm + 0.70 * q75_norm\n\n        # Return the candidate with the minimal combined score\n        return int(idx[int(np.argmin(combined))])\n    else:\n        return int(destination_node)\n\n",
  "min_quantile_attach_cost_aug_186": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename and cast\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    # Sub\u2011matrix of candidate distances\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    # 75th percentile per candidate\n    q75 = np.percentile(sub, 75, axis=1)\n\n    # Normalization using the median to dampen outliers\n    step_norm = step / (np.median(step) + 1e-12)\n    q75_norm = q75 / (np.median(q75) + 1e-12)\n\n    # Tuned weighting\n    score = 0.6 * step_norm + 0.4 * q75_norm\n\n    # Clip to keep values sane\n    score = np.clip(score, 0, np.inf)\n\n    # Pick among the best top_k candidates\n    top_k = 7\n    if score.size > top_k:\n        threshold = np.partition(score, top_k - 1)[top_k - 1]\n        mask = score <= threshold\n        chosen_idx = np.argmin(score[mask])\n        return int(cand[mask][chosen_idx])\n    else:\n        return int(cand[int(np.argmin(score))])\n\n",
  "min_quantile_attach_cost_aug_187": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n\n    q75 = np.percentile(sub, 75, axis=1)\n\n    step_norm = step / (np.mean(step) + 1e-12)\n    q75_norm = q75 / (np.mean(q75) + 1e-12)\n\n    score = step_norm + 0.70 * q75_norm\n\n    # Deterministic tiny noise for tie\u2011breaking\n    rng = np.random.default_rng(seed=int((current_node + destination_node) * 1_000_000))\n    noise = rng.normal(scale=1e-4, size=score.shape)\n    score_noisy = score + noise\n\n    # Soft\u2011min selection with temperature\n    temp = 0.5\n    weights = np.exp(-score_noisy / temp)\n    weights /= np.sum(weights)\n\n    # Random choice weighted by the soft\u2011min probabilities\n    chosen = rng.choice(cand, p=weights)\n    return int(chosen)\n\n",
  "min_quantile_attach_cost_aug_188": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Use squared distances for extra robustness\n    step_sq = np.square(dist_mat[current_node, candidates])\n\n    # Sub\u2011matrix among candidates\n    sub_mat = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    # 75th percentile per candidate\n    q75_vals = np.percentile(sub_mat, 75, axis=1)\n\n    # Normalization with mean and clipping\n    step_norm = step_sq / (np.mean(step_sq) + 1e-12)\n    q75_norm = q75_vals / (np.mean(q75_vals) + 1e-12)\n    q75_norm = np.clip(q75_norm, 0, 10)\n\n    # Weighted combination\n    combined = 0.55 * step_norm + 0.45 * q75_norm\n    combined = np.clip(combined, 0, np.inf)\n\n    # Keep only the best top_k candidates\n    top_k = 5\n    if combined.size > top_k:\n        kth_val = np.partition(combined, top_k - 1)[top_k - 1]\n        mask = combined <= kth_val\n        candidates_top = candidates[mask]\n        scores_top = combined[mask]\n    else:\n        candidates_top = candidates\n        scores_top = combined\n\n    # Softmax selection for diversity\n    temp = 1.0\n    probs = np.exp(-scores_top / temp)\n    probs /= np.sum(probs)\n\n    # Deterministic RNG seeded by node indices\n    rng = np.random.default_rng(seed=int((current_node << 16) + destination_node))\n    chosen = rng.choice(candidates_top, p=probs)\n    return int(chosen)\n\n",
  "destination_monotone_filter_aug_189": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    target_dist = float(dist_mat[current_node, destination_node])\n    to_target   = dist_mat[candidates, destination_node]\n    step_dist   = dist_mat[current_node, candidates]\n\n    # Candidates that do not increase the distance to the destination\n    ok_idx = np.where(to_target <= target_dist + 1e-12)[0]\n    if ok_idx.size > 0:\n        # Weighted score with altered coefficients\n        scores = step_dist[ok_idx] * 0.6 + to_target[ok_idx] * 0.4\n        # Small deterministic noise for tie\u2011breaking\n        noise = np.random.uniform(0, 1e-8, size=scores.shape)\n        scores += noise\n        chosen = candidates[ok_idx[np.argmin(scores)]]\n        return int(chosen)\n\n    # Fallback: minimal triangle slack\n    slack  = (step_dist + to_target) - target_dist\n    scores = slack + 0.2 * step_dist\n    chosen = candidates[np.argmin(scores)]\n    return int(chosen)\n\n",
  "destination_monotone_filter_aug_190": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n    target_dist = float(dist_mat[current_node, destination_node])\n\n    # Iterate until a candidate keeps the distance non\u2011increasing\n    idx = 0\n    chosen_candidate = None\n    while idx < len(candidates):\n        cand = candidates[idx]\n        if dist_mat[current_node, cand] + dist_mat[cand, destination_node] <= target_dist + 1e-12:\n            chosen_candidate = cand\n            break\n        idx += 1\n\n    if chosen_candidate is not None:\n        return int(chosen_candidate)\n\n    # Fallback: pick randomly among the top\u2011k smallest slack values\n    step  = dist_mat[current_node, candidates]\n    to_tgt = dist_mat[candidates, destination_node]\n    slack = (step + to_tgt) - target_dist\n    top_k = 5\n    top_indices = np.argsort(slack)[:top_k]\n    chosen = np.random.choice(candidates[top_indices])\n    return int(chosen)\n\n",
  "destination_monotone_filter_aug_191": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand   = unvisited_nodes.astype(int)\n    dist   = distance_matrix\n    tgt    = float(dist[current_node, destination_node])\n\n    step   = dist[current_node, cand]\n    to_tgt = dist[cand, destination_node]\n\n    mask = to_tgt <= tgt + 1e-12\n    if np.any(mask):\n        scores = step[mask] + 0.5 * to_tgt[mask]\n        temp = 1e-1\n        probs = np.exp(-scores / (temp + 1e-12))\n        probs /= np.sum(probs + 1e-12)  # epsilon on denominator\n        chosen = cand[mask][np.argmax(probs)]\n        return int(chosen)\n\n    # Fallback: mean of slack and step with slight weighting\n    slack = (step + to_tgt) - tgt\n    slack = np.clip(slack, 0, None)  # ensure non\u2011negative\n    scores = np.mean([slack, step], axis=0) + 0.15 * step\n    chosen = cand[np.argmin(scores)]\n    return int(chosen)\n\n",
  "destination_monotone_filter_aug_192": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n    tgt  = float(dist[current_node, destination_node])\n\n    # Square\u2011root distances with clipping to avoid negative values\n    step   = np.sqrt(np.clip(dist[current_node, cand], 0, None))\n    to_tgt = np.sqrt(np.clip(dist[cand, destination_node], 0, None))\n\n    mask = to_tgt <= tgt + 1e-12\n    if np.any(mask):\n        # np.max aggregation with weighted contribution\n        scores = np.max([step[mask], to_tgt[mask]], axis=0) * 0.7 + 0.3 * step[mask]\n        chosen = cand[mask][np.argmin(scores)]\n        return int(chosen)\n\n    # Fallback: random among top\u2011k minimal triangle slack\n    slack = (step + to_tgt) - tgt\n    top_k = 7\n    idx = np.argsort(slack)[:top_k]\n    chosen = np.random.choice(cand[idx])\n    return int(chosen)\n\n",
  "centrality_then_isolation_switch_aug_193": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    step = dist_mat[current_node, candidates]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    central = D.mean(axis=1)\n    isolation = np.median(D, axis=1)          # use median instead of mean\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    c_norm = central / (np.mean(central) + 1e-12)\n    i_norm = isolation / (np.mean(isolation) + 1e-12)\n\n    noise = 1e-6 * np.arange(candidates.size)  # deterministic tie\u2011breaker\n\n    if progress < 0.55:\n        score = s_norm + 0.85 * c_norm\n    else:\n        score = s_norm - 0.85 * i_norm\n\n    score += noise\n    return int(candidates[np.argmin(score)])\n\n",
  "centrality_then_isolation_switch_aug_194": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    step = dist_mat[current_node, candidates]\n\n    size = candidates.size\n    D = np.full((size, size), np.inf)\n    for i in range(size):\n        for j in range(size):\n            if i != j:\n                D[i, j] = dist_mat[candidates[i], candidates[j]]\n\n    central = np.sum(D, axis=1) / (size - 1)    # mean via sum\n    isolation = np.max(D, axis=1)              # use max as isolation proxy\n\n    s_norm = step / (np.mean(step) + 1e-12)\n    c_norm = central / (np.mean(central) + 1e-12)\n    i_norm = isolation / (np.mean(isolation) + 1e-12)\n\n    noise = 1e-7 * np.arange(size)             # deterministic tie\u2011breaker\n\n    if progress < 0.5:\n        score = s_norm + 0.6 * c_norm\n    else:\n        score = s_norm - 0.6 * i_norm\n\n    score += noise\n    return int(candidates[np.argmin(score)])\n\n",
  "destination_rank_smoothing_aug_195": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[current_node, cand]\n    dist_to_dest = distance_matrix[cand, destination_node]\n\n    # Rank candidates by distance to destination\n    idx_sorted = np.argsort(dist_to_dest)\n    rank = np.empty_like(idx_sorted, dtype=np.float64)\n    rank[idx_sorted] = np.arange(idx_sorted.size, dtype=np.float64)\n\n    total_nodes = int(distance_matrix.shape[0])\n    remaining = int(cand.size)\n    progress = 1.0 - remaining / max(1, total_nodes)\n\n    x = rank / max(1.0, float(remaining))\n    center = 0.70 - 0.40 * progress\n    steep = 8.0\n    sigmoid = 1.0 / (1.0 + np.exp(-steep * (x - center)))\n    sigmoid = np.clip(sigmoid, 0.0, 1.0)\n\n    # Use median instead of mean for scaling\n    score = (dist_to_cand / (np.median(dist_to_cand) + 1e-12)) + 0.9 * sigmoid\n\n    # Add tiny deterministic noise for tie-breaking\n    noise = np.arange(cand.size, dtype=np.float64) * 1e-9\n    score += noise\n\n    # Softmin selection: lower score gets higher probability\n    exp_neg = np.exp(-score)\n    probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n    chosen_idx = int(np.argmax(probs))\n    return int(cand[chosen_idx])\n\n",
  "destination_rank_smoothing_aug_196": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    d_step = distance_matrix[current_node, cand]\n    d_to_dest = distance_matrix[cand, destination_node]\n\n    # Rank by distance to destination\n    order = np.argsort(d_to_dest)\n    rank = np.empty_like(order, dtype=np.float64)\n    rank[order] = np.arange(order.size, dtype=np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - n_rem / max(1, n_total)\n\n    x = rank / max(1.0, float(n_rem))\n    center = 0.60 - 0.30 * progress\n    steep = 12.0\n    penalty = 1.0 / (1.0 + np.exp(-steep * (x - center)))\n    penalty = np.clip(penalty, 0.0, 1.0)\n\n    # Use sum instead of mean for scaling\n    score = (d_step / (np.sum(d_step) + 1e-12)) + 0.8 * penalty\n\n    # Determine top_k candidates\n    top_k = min(7, cand.size)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    rng = np.random.default_rng()\n    chosen = rng.choice(top_indices)\n    return int(cand[chosen])\n\n",
  "destination_rank_smoothing_aug_197": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step_dist = distance_matrix[current_node, cand]\n    dest_dist = distance_matrix[cand, destination_node]\n\n    # Compute rank of candidates by distance to destination\n    order = np.argsort(dest_dist)\n    rank = np.empty_like(order, dtype=np.float64)\n    rank[order] = np.arange(order.size, dtype=np.float64)\n\n    total_nodes = int(distance_matrix.shape[0])\n    rem_nodes = int(cand.size)\n    progress = 1.0 - rem_nodes / max(1, total_nodes)\n\n    x = rank / max(1.0, float(rem_nodes))\n    center = 0.55 - 0.35 * progress\n    steep = 9.0\n    sigmoid = 1.0 / (1.0 + np.exp(-steep * (x - center)))\n    sigmoid = np.clip(sigmoid, 0.0, 1.0)\n\n    # Use max instead of mean for scaling\n    score = (step_dist / (np.max(step_dist) + 1e-12)) + 1.2 * sigmoid\n\n    # Add small deterministic noise to break ties\n    noise = np.linspace(0, 1e-8, cand.size)\n    score += noise\n\n    # Softmin probability\n    exp_neg = np.exp(-score)\n    probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n    chosen_idx = int(np.argmax(probs))\n    return int(cand[chosen_idx])\n\n",
  "destination_rank_smoothing_aug_198": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_current = distance_matrix[current_node, candidates]\n    dist_to_dst = distance_matrix[candidates, destination_node]\n\n    # Rank candidates by proximity to destination\n    sorted_idx = np.argsort(dist_to_dst)\n    rank = np.empty_like(sorted_idx, dtype=np.float64)\n    rank[sorted_idx] = np.arange(sorted_idx.size, dtype=np.float64)\n\n    total = int(distance_matrix.shape[0])\n    remaining = int(candidates.size)\n    progress = 1.0 - remaining / max(1, total)\n\n    x = rank / max(1.0, float(remaining))\n    center = 0.68 - 0.42 * progress\n    steep = 11.0\n    penalty = 1.0 / (1.0 + np.exp(-steep * (x - center)))\n    penalty = np.clip(penalty, 0.0, 1.0)\n\n    # Use median for scaling and a higher penalty weight\n    score = (dist_current / (np.median(dist_current) + 1e-12)) + 1.5 * penalty\n\n    # Randomly pick among the best 5 candidates\n    top_k = min(5, candidates.size)\n    best_idx = np.argpartition(score, top_k - 1)[:top_k]\n    rng = np.random.default_rng(42)\n    chosen = rng.choice(best_idx)\n    return int(candidates[chosen])\n\n",
  "min_destination_hinge_loss_aug_199": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n\n    # Margin based on median distance\n    margin = 0.05 * (np.median(r) + 1e-12)\n    hinge = np.maximum(0.0, r - (r0 + margin))\n\n    # Normalise with median / mean\n    step_norm = step / (np.median(step) + 1e-12)\n    step_norm = np.clip(step_norm, 0, 1)\n    hinge_norm = hinge / (np.mean(hinge) + 1e-12)\n\n    # Weighted score\n    score = 0.7 * step_norm + 0.3 * hinge_norm\n\n    # Soft\u2011min with temperature\n    temp = 0.5\n    probs = np.exp(-temp * score)\n    probs /= np.sum(probs) + 1e-12\n    chosen_idx = np.argmax(probs)\n\n    return int(cand[chosen_idx])\n\n",
  "min_destination_hinge_loss_aug_200": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n\n    margin = 0.10 * (np.mean(r) + 1e-12)\n    hinge = np.maximum(0.0, r - (r0 + margin))\n\n    step_norm = step / (np.mean(step) + 1e-12)\n    hinge_norm = hinge / (np.mean(hinge) + 1e-12)\n\n    # Weighted score\n    score = 0.6 * step_norm + 0.4 * hinge_norm\n\n    # Top\u2011k selection\n    top_k = 7\n    if cand.size <= top_k:\n        idxs = np.arange(cand.size)\n    else:\n        idxs = np.argpartition(score, top_k)[:top_k]\n\n    scores_top = score[idxs]\n\n    # Deterministic noise for tie\u2011breaking\n    rng = np.random.default_rng(42)\n    noise = rng.uniform(-1e-6, 1e-6, size=scores_top.shape)\n    scores_top += noise\n\n    chosen_idx = idxs[np.argmin(scores_top)]\n    return int(cand[chosen_idx])\n\n",
  "min_destination_hinge_loss_aug_201": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n\n    margin = 0.07 * (np.mean(r) + 1e-12)\n    hinge = np.maximum(0.0, r - (r0 + margin))\n\n    # Normalise with maxima\n    step_norm = step / (np.max(step) + 1e-12)\n    hinge_norm = hinge / (np.max(hinge) + 1e-12)\n\n    score = step_norm + hinge_norm\n\n    top_k = 5\n    if cand.size <= top_k:\n        idxs = np.arange(cand.size)\n    else:\n        idxs = np.argpartition(score, top_k)[:top_k]\n\n    rng = np.random.default_rng(123)\n    chosen_idx = rng.choice(idxs)\n    return int(cand[chosen_idx])\n\n",
  "min_destination_hinge_loss_aug_202": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n\n    margin = 0.06 * (np.median(r) + 1e-12)\n    hinge = np.maximum(0.0, r - (r0 + margin))\n\n    # Square step distances for heavier weighting\n    step_sq = np.square(step)\n    step_norm = np.clip(step_sq / (np.mean(step_sq) + 1e-12), 0, 1)\n    hinge_norm = np.clip(hinge / (np.mean(hinge) + 1e-12), 0, 1)\n\n    # Balanced weighting\n    score = 0.5 * step_norm + 0.5 * hinge_norm\n\n    # Soft\u2011min with temperature\n    temp = 1.0\n    probs = np.exp(-temp * score)\n    probs /= np.sum(probs) + 1e-12\n    chosen_idx = np.argmax(probs)\n\n    return int(cand[chosen_idx])\n\n",
  "trimmed_mean_centrality_aug_203": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    n = candidates.size\n    central = np.empty(n)\n\n    for idx, cand in enumerate(candidates):\n        sub = dist_mat[cand, candidates]\n        if n <= 6:\n            central[idx] = np.median(sub)\n        else:\n            lo = int(np.floor(0.15 * n))\n            hi = int(np.ceil(0.85 * n))\n            sorted_row = np.sort(sub)\n            central[idx] = np.median(sorted_row[lo:hi])\n\n    eps = 1e-12\n    score = 0.6 * (step / (np.mean(step) + eps)) + \\\n            0.4 * (central / (np.mean(central) + eps))\n    score = np.clip(score, 0, None)          # safety clipping\n\n    chosen = int(candidates[np.argmin(score)])\n    return chosen\n\n",
  "trimmed_mean_centrality_aug_204": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    n = candidates.size\n    central = np.empty(n)\n    idx = 0\n    while idx < n:\n        cand = candidates[idx]\n        sub = dist_mat[cand, candidates]\n        if n <= 6:\n            central[idx] = np.mean(sub)\n        else:\n            lo = int(np.floor(0.15 * n))\n            hi = int(np.ceil(0.85 * n))\n            sorted_row = np.sort(sub)\n            central[idx] = np.mean(sorted_row[lo:hi])\n        idx += 1\n\n    eps = 1e-12\n    score = (step / (np.mean(step) + eps)) + \\\n            0.85 * (central / (np.mean(central) + eps))\n\n    # deterministic tie\u2011breaking noise\n    score += 1e-8 * np.arange(n)\n\n    # soft\u2011min weights\n    weights = np.exp(-score)\n    weights /= np.sum(weights)\n\n    # pick a candidate according to the soft\u2011min distribution\n    chosen_idx = np.random.choice(n, p=weights)\n    return int(candidates[chosen_idx])\n\n",
  "trimmed_mean_centrality_aug_205": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    n = candidates.size\n\n    D = dist_mat[np.ix_(candidates, candidates)]\n\n    if n <= 6:\n        central = D.max(axis=1)\n    else:\n        lo = int(np.floor(0.15 * n))\n        hi = int(np.ceil(0.85 * n))\n        sorted_D = np.sort(D, axis=1)\n        central = sorted_D[:, lo:hi].max(axis=1)\n\n    eps = 1e-12\n    score = 0.8 * (step / (np.mean(step) + eps)) + \\\n            0.2 * (central / (np.mean(central) + eps))\n    score = np.clip(score, 0, None)          # ensure non\u2011negative\n\n    chosen = int(candidates[np.argmin(score)])\n    return chosen\n\n",
  "trimmed_mean_centrality_aug_206": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    n = candidates.size\n    central = np.empty(n)\n\n    for i, cand in enumerate(candidates):\n        sub = dist_mat[cand, candidates]\n        if n <= 6:\n            central[i] = np.mean(sub)\n        else:\n            lo = int(np.floor(0.15 * n))\n            hi = int(np.ceil(0.85 * n))\n            # partition to get the middle segment without full sort\n            middle = np.partition(sub, [lo, hi-1])[lo:hi]\n            central[i] = np.mean(middle)\n\n    eps = 1e-12\n    score = (step / (np.mean(step) + eps)) + \\\n            0.85 * (central / (np.mean(central) + eps))\n\n    # deterministic noise for tie\u2011breaking\n    score += 1e-9 * np.arange(n)\n\n    # select top\u20115 candidates\n    top_k = min(5, n)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    return int(candidates[chosen_idx])\n\n",
  "kcore_proxy_degree_aug_207": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    # Build pairwise distance matrix for candidates\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Radius as median of all finite distances\n    radius = float(np.median(D[np.isfinite(D)]))\n\n    # Degree: number of neighbors within radius\n    deg = np.sum(D <= radius, axis=1).astype(np.float64)\n\n    # Target degree (median of degrees)\n    target = float(np.median(deg))\n\n    # Score calculation with safe denominators\n    denom = np.mean(np.abs(deg - target)) + 1e-12\n    score = np.abs(deg - target) / denom + 0.35 * (\n        step / (np.mean(step) + 1e-12)\n    )\n    # Clip to avoid overflow\n    score = np.clip(score, 0, 1e6)\n\n    # Invert logic: pick index of maximum negative score\n    idx = int(np.argmax(-score))\n    return int(candidates[idx])\n\n",
  "kcore_proxy_degree_aug_208": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    radius = float(np.median(D[np.isfinite(D)]))\n    deg = np.sum(D <= radius, axis=1).astype(np.float64)\n\n    target = float(np.median(deg))\n    denom = np.mean(np.abs(deg - target)) + 1e-12\n    score = np.abs(deg - target) / denom + 0.5 * (\n        step / (np.mean(step) + 1e-12)\n    )\n    # Clip to keep values bounded\n    score = np.clip(score, 0, 1e6)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(len(candidates)) * 1e-6\n    score += noise\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "kcore_proxy_degree_aug_209": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    radius = float(np.median(D[np.isfinite(D)]))\n    deg = np.sum(D <= radius, axis=1).astype(np.float64)\n\n    target = float(np.median(deg))\n    denom = np.mean(np.abs(deg - target)) + 1e-12\n    score = np.abs(deg - target) / denom + 0.35 * (\n        step / (np.max(step) + 1e-12)\n    )\n    score = np.clip(score, 0, 1e6)\n\n    # Randomly choose among the k best (lowest) scores\n    k = 5\n    if len(score) <= k:\n        idx = int(np.argmin(score))\n    else:\n        topk_idx = np.argpartition(score, k)[:k]\n        idx = int(np.random.choice(topk_idx))\n    return int(candidates[idx])\n\n",
  "kcore_proxy_degree_aug_210": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    # Use squared distances for the step component\n    step = np.square(distance_matrix[current_node, candidates])\n\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Radius approximated by mean of finite distances\n    finite_vals = D[np.isfinite(D)]\n    radius = float(np.mean(finite_vals))\n\n    deg = np.sum(D <= radius, axis=1).astype(np.float64)\n\n    target = float(np.median(deg))\n    denom = np.mean(np.abs(deg - target)) + 1e-12\n    mean_step = np.clip(np.mean(step), 1e-12, np.inf)\n    score = np.abs(deg - target) / denom + 0.35 * (step / mean_step)\n    score = np.clip(score, 0, 1e6)\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "destination_aligned_pair_min_aug_211": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming for clarity\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    # Step cost from current node to each candidate\n    step = dist[cur, cand]\n\n    # Distance from each candidate to the destination\n    d_dest = dist[cand, dest]\n\n    # Matrix of distances between candidates\n    D = dist[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Allow transitions only towards the destination\n    allow = (d_dest[None, :] <= d_dest[:, None])\n    masked = np.where(allow, D, np.inf)\n\n    # Future cost \u2013 minimal onward step\n    future = np.min(masked, axis=1)\n\n    # Score combining step and future with a strong future weight\n    score = step + 0.9 * future\n\n    # Deterministic tie\u2011breaker: tiny increasing noise\n    noise = np.arange(cand.size, dtype=float) * 1e-6\n    score += noise\n\n    # Soft\u2011min selection via exponential weighting\n    exp_vals = np.exp(-score)\n    exp_vals = np.clip(exp_vals, 0, 1e10)                # safety clip\n    weights = exp_vals / (np.sum(exp_vals) + 1e-12)     # epsilon in denominator\n    idx = int(np.argmax(weights))\n    return int(cand[idx])\n\n",
  "destination_aligned_pair_min_aug_212": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    scores = []\n    for i in cand:\n        step = dist[cur, i]\n        d_dest_i = dist[i, dest]\n\n        # Gather allowed future costs (towards destination)\n        allowed = dist[i, cand]\n        mask = dist[cand, dest] <= d_dest_i\n        future_vals = allowed[mask]\n        future = np.min(future_vals) if future_vals.size > 0 else np.inf\n        future = np.clip(future, 0, np.inf)\n\n        scores.append(step + 0.85 * future)\n\n    scores = np.array(scores, dtype=float)\n\n    # Deterministic noise to break ties\n    noise = np.arange(cand.size, dtype=float) * 1e-6\n    scores += noise\n\n    # Select top_k lowest scores and pick one at random\n    top_k = 7\n    top_indices = np.argsort(scores)[:top_k]\n    chosen = np.random.choice(top_indices)\n    return int(cand[chosen])\n\n",
  "destination_aligned_pair_min_aug_213": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    step = dist[cur, cand]\n    d_dest = dist[cand, dest]\n\n    # Future cost: median of allowed onward distances\n    D = dist[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    allow = (d_dest[None, :] <= d_dest[:, None])\n    masked = np.where(allow, D, np.inf)\n    future = np.median(masked, axis=1)\n\n    # Additional cost: small weight on distance to destination\n    extra = 0.05 * d_dest\n\n    # Weighted score\n    score = 0.7 * step + 0.25 * future + extra\n    score = np.clip(score, 0, np.inf)          # prevent negative values\n\n    # Deterministic tie\u2011breaker\n    noise = np.arange(cand.size, dtype=float) * 1e-6\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "destination_aligned_pair_min_aug_214": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    scores = []\n    idx = 0\n    while idx < cand.size:\n        i = cand[idx]\n        step = dist[cur, i]\n        d_dest_i = dist[i, dest]\n\n        # Future cost: maximum allowed onward distance\n        allowed = dist[i, cand]\n        mask = dist[cand, dest] <= d_dest_i\n        future_vals = allowed[mask]\n        future = np.max(future_vals) if future_vals.size > 0 else 0.0\n        future = np.clip(future, 0, np.inf)\n\n        scores.append(step + 0.6 * future)\n        idx += 1\n\n    scores = np.array(scores, dtype=float)\n\n    # Softmax selection\n    exp_vals = np.exp(-scores)\n    exp_vals = np.clip(exp_vals, 0, 1e10)                # clip for numerical safety\n    weights = exp_vals / (np.sum(exp_vals) + 1e-12)     # epsilon in denominator\n    chosen = int(np.argmax(weights))\n    return int(cand[chosen])\n\n",
  "local_spread_minimizer_aug_215": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    # Determine k (at least 3, at most n\u20111, 12% of n)\n    n = candidates.size\n    k = int(max(3, min(n - 1, int(np.ceil(0.12 * n)))))\n\n    # Build distance matrix among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # k\u2011nearest neighbors\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    spread = np.median(knn, axis=1)          # use median instead of std\n    spread = np.clip(spread, 0, None)        # keep values non\u2011negative\n\n    # Normalised scores\n    step_norm = step / (np.median(step) + 1e-12)\n    spread_norm = spread / (np.median(spread) + 1e-12)\n\n    # Weighted sum of the two terms\n    score = step_norm + 0.4 * spread_norm\n\n    # Deterministic tie\u2011breaking: add a tiny index\u2011based offset\n    noise = np.arange(candidates.size) * 1e-6\n    score += noise\n\n    return int(candidates[np.argmin(score)])\n\n",
  "local_spread_minimizer_aug_216": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    n = cand.size\n    k = int(max(4, min(n - 1, int(np.ceil(0.15 * n)))))\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    spread = np.sum(knn, axis=1)          # use sum instead of std\n\n    # Normalise\n    step_norm = step / (np.mean(step) + 1e-12)\n    spread_norm = spread / (np.mean(spread) + 1e-12)\n\n    # Soft\u2011min with temperature\n    temp = 0.5\n    logits = - (0.6 * step_norm + 0.4 * spread_norm)\n    probs = np.exp(logits / temp)\n    probs /= np.clip(probs.sum(), 1e-12, None)\n\n    # Random choice according to the probabilities\n    idx = np.random.choice(cand.size, p=probs)\n    return int(cand[idx])\n\n",
  "local_spread_minimizer_aug_217": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    n = cand.size\n    k = int(max(3, min(n - 1, int(np.ceil(0.10 * n)))))\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    spread = np.max(knn, axis=1)          # use max instead of std\n\n    # Squared distances\n    step_sq = np.square(step)\n\n    # Normalise\n    step_norm = step_sq / (np.max(step_sq) + 1e-12)\n    spread_norm = spread / (np.max(spread) + 1e-12)\n\n    # Weighted score\n    score = step_norm + 0.3 * spread_norm\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(cand.size) * 1e-7\n    score += noise\n\n    # Invert logic: choose the maximum score instead of minimum\n    return int(cand[np.argmax(score)])\n\n",
  "local_spread_minimizer_aug_218": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    n = cand.size\n    k = 5\n    if k >= n:\n        k = n - 1\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # Approximate spread as max\u2011min difference among k\u2011nearest neighbors\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    spread = np.max(knn, axis=1) - np.min(knn, axis=1)\n\n    # Normalise using medians\n    step_norm = step / (np.median(step) + 1e-12)\n    spread_norm = spread / (np.median(spread) + 1e-12)\n\n    # Weighted score\n    score = 0.5 * step_norm + 0.5 * spread_norm\n\n    # Deterministic noise to break ties\n    noise = np.arange(cand.size) * 1e-6\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "destination_ring_quantized_aug_219": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    cand_int = candidates.astype(int)\n    r0 = float(dist_mat[current_node, destination_node])\n    r = dist_mat[cand_int, destination_node]\n    step = dist_mat[current_node, cand_int]\n\n    # Ring width based on IQR of remaining destination distances\n    iqr = float(np.subtract(*np.percentile(r, [75, 25]))) + 1e-12\n    w = 0.35 * iqr\n    w = max(w, 1e-12)                     # prevent zero width\n\n    ring0 = np.floor(r0 / w)\n    ring = np.floor(r / w)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(cand_int.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Invert conditional logic: early prefer smaller ring index\n    if progress >= 0.55:\n        penalty = np.abs(ring - ring0)\n    else:\n        penalty = ring\n    penalty = np.clip(penalty, 0.0, None)\n\n    # Normalization using median instead of mean\n    norm_step = step / (np.median(step) + 1e-12)\n    norm_penalty = penalty / (np.median(penalty) + 1e-12)\n\n    # Deterministic noise for tie\u2011breaking\n    rng = np.random.default_rng(0)\n    noise = rng.uniform(-1e-6, 1e-6, size=norm_step.shape)\n\n    score = 0.6 * norm_step + 0.4 * norm_penalty + noise\n    chosen = int(cand_int[np.argmin(score)])\n    return chosen\n\n",
  "destination_ring_quantized_aug_220": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    cand_int = candidates.astype(int)\n    r0 = float(dist_mat[current_node, destination_node])\n    r = dist_mat[cand_int, destination_node]\n    step = dist_mat[current_node, cand_int]\n\n    iqr = float(np.subtract(*np.percentile(r, [75, 25]))) + 1e-12\n    w = 0.4 * iqr\n    w = max(w, 1e-12)\n\n    ring0 = np.floor(r0 / w)\n    ring = np.floor(r / w)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(cand_int.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress < 0.6:\n        penalty = ring\n    else:\n        penalty = np.abs(ring - ring0)\n    penalty = np.clip(penalty, 0.0, None)\n\n    norm_step = step / (np.sum(step) + 1e-12)\n    norm_penalty = penalty / (np.sum(penalty) + 1e-12)\n\n    score = 0.55 * norm_step + 0.45 * norm_penalty\n\n    # Softmin probabilities\n    temp = 0.1\n    temp = max(temp, 1e-12)\n    exp_vals = np.exp(-score / temp)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Random choice among top\u2011k candidates\n    top_k = 5\n    top_indices = np.argpartition(probs, -top_k)[-top_k:]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (np.sum(top_probs) + 1e-12)\n\n    rng = np.random.default_rng(0)\n    chosen_idx = rng.choice(top_indices, p=top_probs)\n    return int(cand_int[chosen_idx])\n\n",
  "destination_ring_quantized_aug_221": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    cand_int = candidates.astype(int)\n    r0 = float(dist_mat[current_node, destination_node])\n    r = dist_mat[cand_int, destination_node]\n    step = dist_mat[current_node, cand_int]\n\n    iqr = float(np.subtract(*np.percentile(r, [75, 25]))) + 1e-12\n    w = 0.45 * iqr\n    w = max(w, 1e-12)\n\n    ring0 = np.floor(r0 / w)\n    ring = np.floor(r / w)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(cand_int.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # Early: prefer smaller ring index, late: stay in same ring\n    if progress < 0.6:\n        penalty = ring\n    else:\n        penalty = np.abs(ring - ring0)\n    penalty = np.clip(penalty, 0.0, None)\n\n    norm_step = step / (np.max(step) + 1e-12)\n    norm_penalty = penalty / (np.max(penalty) + 1e-12)\n\n    score = 0.5 * norm_step + 0.5 * norm_penalty\n\n    rng = np.random.default_rng(0)\n    noise = rng.uniform(-1e-6, 1e-6, size=score.shape)\n    score += noise\n\n    chosen = int(cand_int[np.argmin(score)])\n    return chosen\n\n",
  "destination_ring_quantized_aug_222": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    cand_int = candidates.astype(int)\n    r0 = float(dist_mat[current_node, destination_node])\n    r = dist_mat[cand_int, destination_node]\n    step = dist_mat[current_node, cand_int]\n\n    iqr = float(np.subtract(*np.percentile(r, [75, 25]))) + 1e-12\n    w = 0.3 * iqr\n    w = max(w, 1e-12)\n\n    ring0 = np.floor(r0 / w)\n    ring = np.floor(r / w)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(cand_int.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress < 0.5:\n        penalty = np.abs(ring - ring0)\n    else:\n        penalty = ring\n    penalty = np.clip(penalty, 0.0, None)\n\n    # Proxy: use squared step distances\n    step_sq = np.square(step)\n    norm_step = step_sq / (np.median(step_sq) + 1e-12)\n\n    norm_penalty = penalty / (np.median(penalty) + 1e-12)\n\n    score = 0.7 * norm_step + 0.3 * norm_penalty\n\n    # Softmin with temperature\n    temp = 0.05\n    temp = max(temp, 1e-12)\n    exp_vals = np.exp(-score / temp)\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Random choice among top\u20113 candidates\n    top_k = 3\n    top_indices = np.argpartition(probs, -top_k)[-top_k:]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (np.sum(top_probs) + 1e-12)\n\n    rng = np.random.default_rng(0)\n    chosen_idx = rng.choice(top_indices, p=top_probs)\n    return int(cand_int[chosen_idx])\n\n",
  "min_destination_pareto_front_aug_223": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # step and destination distances\n    step = dist_mat[current_node, candidates]\n    dest = dist_mat[candidates, destination_node]\n\n    # find non\u2011dominated points using a while loop\n    idx = np.argsort(step)\n    nd_idx = []\n    best_dest = np.inf\n    i = 0\n    while i < len(idx):\n        j = idx[i]\n        if dest[j] < best_dest - 1e-12:\n            nd_idx.append(j)\n            best_dest = dest[j]\n        i += 1\n    nd = np.array(nd_idx, dtype=int)\n\n    if nd.size == 1:\n        return int(candidates[nd[0]])\n\n    # centrality (mean distance to remaining nodes)\n    sub = dist_mat[np.ix_(candidates, candidates)]\n    central = sub.mean(axis=1)\n\n    # normalise and score\n    s = step[nd] / (np.mean(step[nd]) + 1e-12)\n    d = dest[nd] / (np.mean(dest[nd]) + 1e-12)\n    c = central[nd] / (np.mean(central[nd]) + 1e-12)\n    noise = 1e-9 * np.random.rand(nd.size)\n    score = 0.6 * s + 0.4 * d + 0.3 * c + noise\n    score = np.clip(score, 0, None)\n\n    return int(candidates[nd[np.argmin(score)]])\n\n",
  "min_destination_pareto_front_aug_224": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    # distances\n    step = dm[current_node, cand]\n    dest = dm[cand, destination_node]\n\n    # non\u2011dominated points via list comprehension\n    sorted_idx = sorted(range(len(step)), key=lambda i: step[i])\n    nd = []\n    best_dest = np.inf\n    for i in sorted_idx:\n        if dest[i] < best_dest - 1e-12:\n            nd.append(i)\n            best_dest = dest[i]\n    nd = np.array(nd, dtype=int)\n\n    if nd.size == 1:\n        return int(cand[nd[0]])\n\n    # centrality using median\n    sub = dm[np.ix_(cand, cand)]\n    central = np.median(sub, axis=1)\n\n    # normalise and score\n    s = step[nd] / (np.median(step[nd]) + 1e-12)\n    d = dest[nd] / (np.median(dest[nd]) + 1e-12)\n    c = central[nd] / (np.median(central[nd]) + 1e-12)\n    score = 0.5 * s + 0.5 * d + 0.4 * c\n    score = np.clip(score, 0, None)\n\n    # soft\u2011min probabilities\n    temp = 0.5\n    probs = np.exp(-score / temp)\n    probs /= probs.sum()\n\n    # random choice among the top\u2011k\n    top_k = min(5, len(nd))\n    top_idx = np.argpartition(probs, -top_k)[-top_k:]\n    chosen = np.random.choice(top_idx, p=probs[top_idx] / probs[top_idx].sum())\n\n    return int(cand[nd[chosen]])\n\n",
  "min_destination_pareto_front_aug_225": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    nodes = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    # distances\n    step = dm[current_node, nodes]\n    dest = dm[nodes, destination_node]\n\n    # non\u2011dominated points using a while loop\n    idx = np.argsort(step)\n    nd_list = []\n    best_dest = np.inf\n    i = 0\n    while i < len(idx):\n        j = idx[i]\n        if dest[j] < best_dest - 1e-12:\n            nd_list.append(j)\n            best_dest = dest[j]\n        i += 1\n    nd = np.array(nd_list, dtype=int)\n\n    if nd.size == 1:\n        return int(nodes[nd[0]])\n\n    # centrality using sum\n    sub = dm[np.ix_(nodes, nodes)]\n    central = sub.sum(axis=1)\n\n    # normalise and score\n    s = step[nd] / (np.mean(step[nd]) + 1e-12)\n    d = dest[nd] / (np.mean(dest[nd]) + 1e-12)\n    c = central[nd] / (np.mean(central[nd]) + 1e-12)\n    noise = 1e-8 * np.arange(nd.size)\n    score = 0.7 * s + 0.3 * d + 0.2 * c + noise\n    score = np.clip(score, 0, None)\n\n    return int(nodes[nd[np.argmin(score)]])\n\n",
  "min_destination_pareto_front_aug_226": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename variables\n    cand = unvisited_nodes.astype(int)\n    dm = distance_matrix\n\n    # distances\n    step = dm[current_node, cand]\n    dest = dm[cand, destination_node]\n\n    # non\u2011dominated points via sorted list comprehension\n    sorted_idx = sorted(range(len(step)), key=lambda i: step[i])\n    nd = []\n    best_dest = np.inf\n    for i in sorted_idx:\n        if dest[i] < best_dest - 1e-12:\n            nd.append(i)\n            best_dest = dest[i]\n    nd = np.array(nd, dtype=int)\n\n    if nd.size == 1:\n        return int(cand[nd[0]])\n\n    # centrality using median\n    sub = dm[np.ix_(cand, cand)]\n    central = np.median(sub, axis=1)\n\n    # normalise and score\n    s = step[nd] / (np.median(step[nd]) + 1e-12)\n    d = dest[nd] / (np.median(dest[nd]) + 1e-12)\n    c = central[nd] / (np.median(central[nd]) + 1e-12)\n    score = 0.4 * s + 0.4 * d + 0.3 * c\n    score = np.clip(score, 0, None)\n\n    # soft\u2011min probabilities and top\u2011k sampling\n    temp = 0.3\n    probs = np.exp(-score / temp)\n    probs /= probs.sum()\n\n    top_k = min(7, len(nd))\n    top_idx = np.argpartition(probs, -top_k)[-top_k:]\n    chosen = np.random.choice(top_idx, p=probs[top_idx] / probs[top_idx].sum())\n\n    return int(cand[nd[chosen]])\n\n",
  "closest_to_median_pairwise_aug_227": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    step = np.clip(step, 0, None)                     # keep values non\u2011negative\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    med = np.median(D, axis=1)\n    mad = np.median(np.abs(D - med[:, None]), axis=1)\n\n    mean_step = np.mean(step) + 1e-12\n    mean_mad  = np.mean(mad)  + 1e-12\n\n    # deterministic tie\u2011breaking noise\n    noise = np.arange(len(step)) * 1e-8\n\n    score = (step / mean_step) + 0.7 * (mad / mean_mad) + noise\n\n    # find minimal score with a while\u2011loop\n    idx, min_val = 0, score[0]\n    for i in range(1, len(score)):\n        if score[i] < min_val:\n            min_val = score[i]\n            idx = i\n    return int(cand[idx])\n\n",
  "closest_to_median_pairwise_aug_228": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    step = np.clip(step, 0, None)\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    # proxy for MAD: sum of absolute deviations from the mean\n    mad = np.sum(np.abs(D - np.mean(D, axis=1)[:, None]), axis=1)\n\n    mean_step = np.mean(step) + 1e-12\n    max_mad   = np.max(mad) + 1e-12\n\n    score = 0.4 * (step / mean_step) + 0.6 * (mad / max_mad)\n\n    # choose among the top\u2011k smallest scores\n    top_k = 7\n    if top_k > len(score):\n        top_k = len(score)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    best_idx = top_indices[np.argmin(score[top_indices])]\n    return int(cand[best_idx])\n\n",
  "closest_to_median_pairwise_aug_229": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    step = np.clip(step, 0, None)\n\n    D = distance_matrix[np.ix_(cand, cand)]\n    # proxy MAD: half the range of distances\n    mad = 0.5 * (np.max(D, axis=1) - np.min(D, axis=1))\n\n    median_step = np.median(step) + 1e-12\n    max_mad     = np.max(mad) + 1e-12\n\n    score = 0.5 * (step / median_step) + 0.5 * (mad / max_mad)\n\n    # deterministic noise for reproducibility\n    noise = np.arange(len(score)) * 1e-9\n    score = score + noise\n\n    # softmin selection\n    beta = 10.0\n    weights = np.exp(-beta * score)\n    weights = weights / (np.sum(weights) + 1e-12)\n    best_idx = int(np.argmax(weights))\n    return int(cand[best_idx])\n\n",
  "closest_to_median_pairwise_aug_230": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size != 0:\n        cand = unvisited_nodes.astype(int)\n        # transform distances with a square to change scale\n        step = np.square(distance_matrix[current_node, cand])\n        step = np.clip(step, 0, None)\n\n        D = distance_matrix[np.ix_(cand, cand)]\n        # use maximum absolute deviation as a proxy for MAD\n        mad = np.max(np.abs(D - np.mean(D, axis=1)[:, None]), axis=1)\n\n        mean_step = np.sum(step) + 1e-12\n        max_mad   = np.max(mad) + 1e-12\n\n        score = 0.8 * (step / mean_step) + 0.2 * (mad / max_mad)\n\n        # deterministic tie\u2011breaking with a list comprehension\n        noise = np.array([i * 1e-7 for i in range(len(score))])\n        score = score + noise\n\n        best_idx = int(np.argmin(score))\n        return int(cand[best_idx])\n    else:\n        return int(destination_node)\n\n",
  "anti_hub_preference_aug_231": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[current_node, candidates]\n    dist_to_cand = np.clip(dist_to_cand, 1e-12, None)\n\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    finite_vals = sub_mat[np.isfinite(sub_mat)]\n    radius = float(np.percentile(finite_vals, 25)) + 1e-12\n\n    degree = np.sum(sub_mat <= radius, axis=1).astype(np.float64)\n    degree = np.clip(degree, 0, None)\n\n    norm_dist = dist_to_cand / (np.median(dist_to_cand) + 1e-12)\n    norm_deg  = degree  / (np.median(degree)  + 1e-12)\n\n    score = 0.6 * norm_dist + 0.4 * norm_deg\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.arange(len(candidates)) * 1e-9\n    score += noise\n\n    # softmin weighting (argmax of exp(-score))\n    weights = np.exp(-score)\n    idx = int(np.argmax(weights))\n    return int(candidates[idx])\n\n",
  "anti_hub_preference_aug_232": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[current_node, candidates]\n    dist_to_cand = np.clip(dist_to_cand, 1e-12, None)\n\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    finite_vals = sub_mat[np.isfinite(sub_mat)]\n    radius = float(np.percentile(finite_vals, 30)) + 1e-12\n\n    degree = np.sum(sub_mat <= radius, axis=1).astype(np.float64)\n    degree = np.clip(degree, 0, None)\n\n    norm_dist = dist_to_cand / (np.max(dist_to_cand) + 1e-12)\n    norm_deg  = degree  / (np.max(degree)  + 1e-12)\n\n    score = 0.7 * norm_dist + 0.3 * norm_deg\n\n    # deterministic noise for tie\u2011breaking\n    noise = (np.arange(len(candidates)) + 1) * 1e-10\n    score += noise\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "anti_hub_preference_aug_233": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[current_node, candidates]\n    dist_to_cand = np.clip(dist_to_cand, 1e-12, None)\n\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    finite_vals = sub_mat[np.isfinite(sub_mat)]\n    radius = float(np.percentile(finite_vals, 35)) + 1e-12\n    radius = np.clip(radius, 1e-12, None)\n\n    degree = np.sum(sub_mat <= radius, axis=1).astype(np.float64)\n\n    top_k = 5\n    if len(candidates) > top_k:\n        idx_top = np.argpartition(dist_to_cand, top_k)[:top_k]\n    else:\n        idx_top = np.arange(len(candidates))\n\n    top_candidates = candidates[idx_top]\n    top_dist      = dist_to_cand[idx_top]\n    top_degree    = degree[idx_top]\n\n    norm_dist = top_dist / (np.mean(top_dist) + 1e-12)\n    norm_deg  = top_degree / (np.mean(top_degree) + 1e-12)\n\n    score = 0.5 * norm_dist + 0.5 * norm_deg\n\n    # deterministic random choice among ties\n    rng = np.random.default_rng(0)\n    min_score = np.min(score)\n    tie_indices = np.where(score == min_score)[0]\n    chosen_idx = int(rng.choice(tie_indices))\n\n    return int(top_candidates[chosen_idx])\n\n",
  "anti_hub_preference_aug_234": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[current_node, candidates]\n    dist_to_cand = np.clip(dist_to_cand, 1e-12, None)\n\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(sub_mat, np.inf)\n\n    finite_vals = sub_mat[np.isfinite(sub_mat)]\n    radius = float(np.percentile(finite_vals, 20)) + 1e-12\n\n    degree = np.sum(sub_mat <= radius, axis=1).astype(np.float64)\n    degree = np.sqrt(degree)                 # proxy approximation\n    degree = np.clip(degree, 0, 10)           # bound extreme values\n\n    norm_dist = dist_to_cand / (np.max(dist_to_cand) + 1e-12)\n    norm_deg  = degree  / (np.max(degree)  + 1e-12)\n\n    score = 0.4 * norm_dist + 0.6 * norm_deg\n\n    # deterministic noise for tie\u2011breaking\n    noise = np.linspace(0, 1e-8, len(candidates))\n    score += noise\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "max_gap_in_destination_ranks_aug_235": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    d_dest = dist_mat[candidates, destination_node]\n    step = dist_mat[current_node, candidates]\n\n    # sort destination distances\n    order = np.argsort(d_dest)\n    sd = d_dest[order]\n    gaps = np.diff(sd)\n\n    if gaps.size == 0:\n        # fallback: choose nearest step\n        return int(candidates[np.argmin(step)])\n\n    cut = np.argmax(gaps)\n    lo = max(0, cut - 1)\n    hi = min(order.size - 1, cut + 2)\n    band_idx = order[lo:hi + 1]\n\n    # scoring with median normalisation\n    mean_step = np.median(step[band_idx]) + 1e-12\n    mean_dest = np.median(d_dest[band_idx]) + 1e-12\n    score = 0.7 * (step[band_idx] / mean_step) + 0.3 * (d_dest[band_idx] / mean_dest)\n\n    # deterministic noise for tie\u2011breaking\n    noise = 1e-9 * np.arange(len(band_idx))\n    score += noise\n\n    return int(candidates[band_idx[np.argmin(score)]])\n\n",
  "max_gap_in_destination_ranks_aug_236": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    d_dest = dist_mat[candidates, destination_node]\n    step = dist_mat[current_node, candidates]\n\n    # select nodes within a threshold of mean + 0.5*std\n    mean_dest = np.mean(d_dest) + 1e-12\n    std_dest = np.std(d_dest) + 1e-12\n    mask = d_dest <= mean_dest + 0.5 * std_dest\n    if not np.any(mask):\n        mask = np.ones_like(d_dest, dtype=bool)\n\n    band_idx = np.where(mask)[0]\n\n    # score with mean normalisation and clipping\n    mean_step = np.mean(step[band_idx]) + 1e-12\n    mean_dest_band = np.mean(d_dest[band_idx]) + 1e-12\n    score = 0.5 * (step[band_idx] / mean_step) + 0.5 * (d_dest[band_idx] / mean_dest_band)\n    score = np.clip(score, 0, 10)\n\n    return int(candidates[band_idx[np.argmin(score)]])\n\n",
  "min_expected_next_step_aug_237": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step_dist = distance_matrix[current_node, candidates]\n    sub_dist = distance_matrix[np.ix_(candidates, candidates)]\n\n    # manual mean with epsilon to avoid division by zero\n    denom = sub_dist.shape[1] + 1e-12\n    exp_next = sub_dist.sum(axis=1) / denom\n\n    score = step_dist + 0.4 * exp_next\n    # deterministic noise for stable tie\u2011breaking\n    noise = 1e-9 * np.arange(score.size)\n    score = score + noise\n\n    # clip to prevent overflow\n    score = np.clip(score, -1e12, 1e12)\n\n    # find the index of the minimum score using a while loop\n    min_idx = 0\n    i = 1\n    while i < score.size:\n        if score[i] < score[min_idx]:\n            min_idx = i\n        i += 1\n\n    return int(candidates[min_idx])\n\n",
  "min_expected_next_step_aug_238": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size > 0:\n        pass\n    else:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step_dist = np.array([distance_matrix[current_node, n] for n in candidates])\n    sub_dist = distance_matrix[np.ix_(candidates, candidates)]\n\n    # median as the expectation of the next step\n    exp_next = np.median(sub_dist, axis=1)\n\n    score = step_dist + 0.5 * exp_next\n\n    # select top\u2011k candidates\n    top_k = 5\n    if score.size <= top_k:\n        top_indices = np.argsort(score)[:top_k]\n    else:\n        top_indices = np.argpartition(score, top_k)[:top_k]\n\n    # softmin probabilities with temperature tau\n    tau = 0.5\n    exp_vals = np.exp(-score[top_indices] / (tau + 1e-12))\n    probs = exp_vals / np.clip(exp_vals.sum(), 1e-12, None)\n\n    chosen = np.random.choice(top_indices, p=probs)\n    return int(candidates[chosen])\n\n",
  "min_expected_next_step_aug_239": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step_dist = distance_matrix[current_node, candidates]\n    sub_dist = distance_matrix[np.ix_(candidates, candidates)]\n\n    # sum\u2011based expectation with epsilon\n    denom = sub_dist.shape[1] + 1e-12\n    exp_next = sub_dist.sum(axis=1) / denom\n\n    score = 0.7 * step_dist + 0.3 * exp_next\n    score = np.clip(score, -1e9, 1e9)\n\n    # choose among the best three candidates\n    top_k = 3\n    if score.size <= top_k:\n        top_indices = np.argsort(score)[:top_k]\n    else:\n        top_indices = np.argpartition(score, top_k)[:top_k]\n\n    noise = 1e-8 * np.arange(score.size)\n    noisy_top = score[top_indices] + noise[top_indices]\n    best = top_indices[np.argmin(noisy_top)]\n\n    return int(candidates[best])\n\n",
  "min_expected_next_step_aug_240": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    # clip distances to avoid extreme values\n    step_dist = np.clip(distance_matrix[current_node, candidates], 0, 1e6)\n    sub_dist = np.clip(distance_matrix[np.ix_(candidates, candidates)], 0, 1e6)\n\n    denom = sub_dist.shape[1] + 1e-12\n    exp_next = sub_dist.sum(axis=1) / denom\n\n    score = 0.8 * step_dist + 0.2 * exp_next\n\n    rng = np.random.default_rng(42)\n    noise = rng.standard_normal(score.size) * 1e-9\n    score = score + noise\n    score = np.clip(score, -1e12, 1e12)\n\n    # find minimum using a while loop\n    min_idx = 0\n    i = 1\n    while i < score.size:\n        if score[i] < score[min_idx]:\n            min_idx = i\n        i += 1\n\n    return int(candidates[min_idx])\n\n",
  "min_worst_kNN_aug_241": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    # If there are no remaining nodes, finish at the destination\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Distance from the current node to each candidate\n    step = dist_mat[current_node, candidates]\n    step = np.clip(step, a_min=1e-12, a_max=None)          # avoid division by zero\n\n    # Build the pairwise distance matrix among candidates\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)                            # ignore self\u2011distance\n\n    # Determine k for k\u2011nearest\u2011neighbor radius\n    n = candidates.size\n    k = int(max(2, min(n - 1, int(np.ceil(0.10 * n)))))\n\n    # Extract k\u2011nearest distances and compute radius\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    radius = np.max(knn, axis=1)\n\n    # Normalise distances and radii\n    step_norm = step / (np.mean(step) + 1e-12)\n    rad_norm  = radius / (np.mean(radius) + 1e-12)\n\n    # Combine with a heavier weight on the step distance\n    score = 0.85 * step_norm + 0.15 * rad_norm\n\n    # Choose the candidate with the minimum score\n    idx = np.argmin(score)\n    return int(candidates[idx])\n\n",
  "min_worst_kNN_aug_242": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    step = np.clip(step, a_min=1e-12, a_max=None)\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = candidates.size\n    top_k = 7\n    k = int(max(2, min(n - 1, min(top_k, int(np.ceil(0.10 * n))))))\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    radius = np.median(knn, axis=1)\n\n    step_norm = step / (np.median(step) + 1e-12)\n    rad_norm  = radius / (np.median(radius) + 1e-12)\n\n    # Add deterministic noise for tie\u2011breaking\n    noise = np.arange(candidates.size) * 1e-6\n    score = 0.6 * step_norm + 0.4 * rad_norm + noise\n\n    idx = np.argmin(score)\n    return int(candidates[idx])\n\n",
  "min_worst_kNN_aug_243": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    step = np.clip(step, a_min=1e-12, a_max=None)\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = candidates.size\n    k = int(max(2, min(n - 1, 5)))          # fixed top_k = 5\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    radius = np.median(knn, axis=1)\n\n    step_med = np.median(step)\n    rad_med  = np.median(radius)\n\n    step_norm = step / (step_med + 1e-12)\n    rad_norm  = radius / (rad_med + 1e-12)\n\n    # Deterministic noise for reproducible tie\u2011breaking\n    noise = np.sin(np.arange(candidates.size) + 0.123) * 1e-6\n    score = 0.4 * step_norm + 0.6 * rad_norm + noise\n\n    # Softmax selection with random choice weighted by the scores\n    exp_scores = np.exp(-score)                 # negative for minimisation\n    probs      = exp_scores / (np.sum(exp_scores) + 1e-12)\n    idx = int(np.random.choice(candidates.size, p=probs))\n    return int(candidates[idx])\n\n",
  "destination_hysteresis_aug_244": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename variables for clarity\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Distance to the final destination\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    # Threshold based on the 35th percentile of remaining distances\n    thr = float(np.percentile(d_dest, 35))\n    thr = np.clip(thr, 0, np.max(d_dest))\n\n    if r0 <= thr + 1e-12:\n        # Pull strongly toward the destination\n        score = step + 1.10 * d_dest\n    else:\n        # Explore by centrality of the remaining graph\n        D = distance_matrix[np.ix_(cand, cand)]\n        central = D.mean(axis=1)\n        score = (step / (np.mean(step) + 1e-12)) + 0.95 * (central / (np.mean(central) + 1e-12))\n\n    # Deterministic tie\u2011breaking noise\n    noise = 1e-8 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "destination_hysteresis_aug_245": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    # Use a slightly lower percentile for the threshold\n    thr = float(np.percentile(d_dest, 30))\n    thr = np.clip(thr, 0, np.max(d_dest))\n\n    if r0 <= thr + 1e-12:\n        score = 0.80 * step + 0.70 * d_dest\n    else:\n        D = distance_matrix[np.ix_(cand, cand)]\n        central = np.median(D, axis=1)\n        score = (step / (np.mean(step) + 1e-12)) + 0.85 * (central / (np.median(central) + 1e-12))\n\n    # Soft\u2011min probabilities\n    soft = np.exp(-score / (np.std(score) + 1e-12))\n\n    # Randomly pick among the top\u2011k highest probabilities\n    top_k = 5\n    top_indices = np.argpartition(-soft, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices)\n\n    return int(cand[chosen])\n\n",
  "destination_hysteresis_aug_246": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = np.array([distance_matrix[current_node, i] for i in cand], dtype=float)\n    d_dest = np.array([distance_matrix[i, destination_node] for i in cand], dtype=float)\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    thr = float(np.percentile(d_dest, 40))\n    thr = np.clip(thr, 0, np.max(d_dest))\n\n    if r0 <= thr + 1e-12:\n        score = 0.90 * step + 1.05 * d_dest\n    else:\n        D = distance_matrix[np.ix_(cand, cand)]\n        central = np.max(D, axis=1)\n        score = (step / (np.mean(step) + 1e-12)) + 0.80 * (central / (np.max(central) + 1e-12))\n\n    # Deterministic tie\u2011breaking\n    noise = 1e-9 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "destination_hysteresis_aug_247": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    thr = float(np.percentile(d_dest, 25))\n    thr = np.clip(thr, 0, np.max(d_dest))\n\n    if r0 <= thr + 1e-12:\n        score = 1.20 * step + 0.95 * d_dest\n    else:\n        D = distance_matrix[np.ix_(cand, cand)]\n        central = np.sum(D, axis=1)\n        score = (step / (np.mean(step) + 1e-12)) + 0.70 * (central / (np.sum(central) + 1e-12))\n\n    # Additive noise for deterministic tie\u2011breaking\n    noise = 1e-7 * np.arange(score.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_span_proxy_aug_248": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # distance from current node to each candidate\n    step = dist_mat[current_node, candidates]\n\n    # pairwise distances among candidates\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    mx = D.max(axis=1)\n    mn = np.where(D == 0.0, np.inf, D).min(axis=1)\n    span = mx - mn\n\n    # normalize using median and clip to avoid extreme values\n    step_norm = step / (np.median(step) + 1e-12)\n    span_norm = span / (np.median(span) + 1e-12)\n    step_norm = np.clip(step_norm, None, 1e6)\n    span_norm = np.clip(span_norm, None, 1e6)\n\n    # deterministic tie\u2011breaking noise\n    noise = np.arange(len(candidates)) * 1e-6\n\n    # weighted score\n    score = 0.7 * step_norm + 0.3 * span_norm + noise\n    return int(candidates[int(np.argmin(score))])\n\n",
  "min_span_proxy_aug_249": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    mx = D.max(axis=1)\n    mn = np.where(D == 0.0, np.inf, D).min(axis=1)\n    span = mx - mn\n\n    # use sum aggregation and clip\n    step_norm = step / (np.sum(step) + 1e-12)\n    span_norm = span / (np.sum(span) + 1e-12)\n    step_norm = np.clip(step_norm, None, 1e6)\n    span_norm = np.clip(span_norm, None, 1e6)\n\n    # weighted score\n    score = 0.6 * step_norm + 0.4 * span_norm\n\n    # softmin probabilities\n    exp_scores = np.exp(-score)\n    probs = exp_scores / (np.sum(exp_scores) + 1e-12)\n\n    # choose among the top\u2011k candidates\n    top_k = min(7, len(candidates))\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices,\n                              p=probs[top_indices] / (np.sum(probs[top_indices]) + 1e-12))\n    return int(candidates[int(chosen)])\n\n",
  "min_span_proxy_aug_250": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n    # additional feature: distance to the final destination\n    dist_to_dest = dist_mat[candidates, destination_node]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    mx = D.max(axis=1)\n    mn = np.where(D == 0.0, np.inf, D).min(axis=1)\n    span = mx - mn\n\n    # median normalization and clipping\n    step_norm = step / (np.median(step) + 1e-12)\n    span_norm = span / (np.median(span) + 1e-12)\n    dest_norm = dist_to_dest / (np.median(dist_to_dest) + 1e-12)\n    step_norm = np.clip(step_norm, None, 1e6)\n    span_norm = np.clip(span_norm, None, 1e6)\n    dest_norm = np.clip(dest_norm, None, 1e6)\n\n    # weighted score\n    score = 0.5 * step_norm + 0.3 * span_norm + 0.2 * dest_norm\n\n    # random choice among the best few candidates\n    top_k = min(5, len(candidates))\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices)\n    return int(candidates[int(chosen)])\n\n",
  "min_span_proxy_aug_251": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    mx = D.max(axis=1)\n    mn = np.where(D == 0.0, np.inf, D).min(axis=1)\n    span = mx - mn\n\n    # harmonic mean of step and span (avoiding division by zero)\n    step_safe = step + 1e-12\n    span_safe = span + 1e-12\n    harmonic = 2.0 / (1.0 / step_safe + 1.0 / span_safe)\n\n    # max aggregation and clipping\n    step_norm = step / (np.max(step) + 1e-12)\n    span_norm = span / (np.max(span) + 1e-12)\n    harmonic_norm = harmonic / (np.max(harmonic) + 1e-12)\n    step_norm = np.clip(step_norm, None, 1e6)\n    span_norm = np.clip(span_norm, None, 1e6)\n    harmonic_norm = np.clip(harmonic_norm, None, 1e6)\n\n    # weighted score\n    score = 0.5 * step_norm + 0.5 * harmonic_norm\n\n    # deterministic tie\u2011breaking noise\n    noise = np.linspace(0, 1e-6, len(candidates))\n    score += noise\n\n    return int(candidates[int(np.argmin(score))])\n\n",
  "quantile_balanced_step_aug_252": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # rename for readability\n    dist_mat = distance_matrix\n    cand_nodes = unvisited_nodes\n\n    if cand_nodes.size == 0:\n        return int(destination_node)\n\n    # distances from current node to each candidate\n    step = dist_mat[current_node, cand_nodes.astype(int)]\n\n    # pairwise distances among candidates\n    pair_mat = dist_mat[np.ix_(cand_nodes.astype(int), cand_nodes.astype(int))]\n    finite_vals = pair_mat[np.isfinite(pair_mat)]\n\n    if finite_vals.size == 0:\n        # fallback to nearest candidate\n        return int(cand_nodes[np.argmin(step)])\n\n    n_total = dist_mat.shape[0]\n    n_rem   = cand_nodes.size\n\n    # progress \u2208 [0,1] \u2013 clip to avoid rounding artefacts\n    progress = np.clip(1.0 - (n_rem / float(n_total + 1e-12)), 0.0, 1.0)\n\n    # quantile target \u2013 early steps favour higher distances\n    q = 0.35 + 0.40 * (1.0 - progress)\n    target = float(np.quantile(finite_vals, q))\n\n    # score is absolute deviation from target\n    score = np.abs(step - target)\n\n    # choose the candidate with minimal score\n    return int(cand_nodes[np.argmin(score)])\n\n",
  "quantile_balanced_step_aug_253": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    pair_mat = dist_mat[np.ix_(candidates.astype(int), candidates.astype(int))]\n    finite_vals = pair_mat[np.isfinite(pair_mat)]\n\n    if finite_vals.size == 0:\n        return int(candidates[np.argmin(step)])\n\n    n_total = dist_mat.shape[0]\n    n_rem   = candidates.size\n\n    progress = np.clip(1.0 - (n_rem / float(n_total + 1e-12)), 0.0, 1.0)\n\n    # more aggressive early bias\n    q = 0.25 + 0.50 * (1.0 - progress)\n    target = float(np.quantile(finite_vals, q))\n\n    # weighted score: 70% distance deviation, 30% distance to destination\n    dist_to_dest = dist_mat[current_node, destination_node]\n    score = 0.7 * np.abs(step - target) + 0.3 * np.abs(step - dist_to_dest)\n\n    # soft\u2011min with temperature\n    alpha = 10.0\n    soft_weights = np.exp(-alpha * score)\n    soft_weights /= np.sum(soft_weights + 1e-12)\n\n    # top\u2011k filtering before final selection\n    top_k = 7\n    top_indices = np.argsort(score)[:top_k]\n    chosen_idx = np.argmax(soft_weights[top_indices])\n\n    return int(candidates[top_indices[chosen_idx]])\n\n",
  "quantile_balanced_step_aug_254": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    cand = unvisited_nodes\n\n    if cand.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, cand.astype(int)]\n\n    pair_mat = dist_mat[np.ix_(cand.astype(int), cand.astype(int))]\n    finite_vals = pair_mat[np.isfinite(pair_mat)]\n\n    if finite_vals.size == 0:\n        return int(cand[np.argmin(step)])\n\n    n_total = dist_mat.shape[0]\n    n_rem   = cand.size\n\n    # use median to estimate progress\n    progress = np.clip(1.0 - (n_rem / float(n_total + 1e-12)), 0.0, 1.0)\n\n    q = 0.35 + 0.40 * (1.0 - progress)\n    target = float(np.quantile(finite_vals, q))\n\n    score = np.abs(step - target)\n\n    # deterministic noise: small offset based on node indices\n    noise = 1e-6 * np.arange(score.size)\n    score += noise\n\n    # choose among the best 5 candidates\n    top_k = 5\n    best_idx = np.argsort(score)[:top_k]\n\n    # deterministic RNG seeded by current node and destination\n    rng = np.random.default_rng(seed=hash((current_node, destination_node)))\n    chosen = rng.choice(best_idx)\n\n    return int(cand[chosen])\n\n",
  "quantile_balanced_step_aug_255": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    nodes = unvisited_nodes\n\n    if nodes.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, nodes.astype(int)]\n\n    pair_mat = dist_mat[np.ix_(nodes.astype(int), nodes.astype(int))]\n    finite_vals = pair_mat[np.isfinite(pair_mat)]\n\n    if finite_vals.size == 0:\n        return int(nodes[np.argmin(step)])\n\n    n_total = dist_mat.shape[0]\n    n_rem   = nodes.size\n\n    progress = np.clip(1.0 - (n_rem / float(n_total + 1e-12)), 0.0, 1.0)\n\n    # approximate quantile using percentile\n    q = 0.35 + 0.40 * (1.0 - progress)\n    target = float(np.percentile(finite_vals, 100 * q))\n\n    score = np.abs(step - target)\n\n    # soft\u2011min weighting\n    beta = 8.0\n    w = np.exp(-beta * score)\n    w /= np.sum(w + 1e-12)\n\n    # final selection via weighted random choice\n    rng = np.random.default_rng(seed=current_node + destination_node)\n    chosen = rng.choice(nodes, p=w)\n\n    return int(chosen)\n\n",
  "min_logsumexp_future_aug_256": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    sub_dist = distance_matrix[np.ix_(candidates, candidates)]\n\n    n = int(candidates.size)\n    tau = np.clip(0.35 + 0.25 * (n / max(1, distance_matrix.shape[0])),\n                  1e-6, None)\n\n    inv_tau = 1.0 / (tau + 1e-12)\n    x = -sub_dist * inv_tau\n    m = np.max(x, axis=1)\n    lse = m + np.log(np.sum(np.exp(x - m[:, None]), axis=1) + 1e-12)\n    softmin = -tau * lse\n\n    score = step + 0.6 * softmin\n\n    noise = np.arange(candidates.size) * 1e-9\n    idx = int(np.argmin(score + noise))\n    return int(candidates[idx])\n\n",
  "min_logsumexp_future_aug_257": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    sub = distance_matrix[np.ix_(cand, cand)]\n\n    n = int(cand.size)\n    tau = np.clip(0.5 + 0.3 * np.sqrt(n / max(1, distance_matrix.shape[0])),\n                  1e-6, None)\n\n    inv_tau = 1.0 / (tau + 1e-12)\n    x = -sub * inv_tau\n    m = np.max(x, axis=1)\n    lse = m + np.log(np.sum(np.exp(x - m[:, None]), axis=1) + 1e-12)\n    softmin = -tau * lse\n\n    score = step + 0.4 * softmin\n\n    top_k = min(7, cand.size)\n    top_idx = np.argpartition(score, top_k)[:top_k]\n    chosen = np.random.choice(top_idx)\n    return int(cand[chosen])\n\n",
  "min_logsumexp_future_aug_258": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, nodes]\n\n    sub = distance_matrix[np.ix_(nodes, nodes)]\n\n    n = int(nodes.size)\n    tau = np.clip(0.4 + 0.2 * (n / max(1, distance_matrix.shape[0])),\n                  1e-6, None)\n\n    inv_tau = 1.0 / (tau + 1e-12)\n    x = -sub * inv_tau\n    m = np.max(x, axis=1)\n    lse = m + np.log(np.mean(np.exp(x - m[:, None]), axis=1) + 1e-12)\n    softmin = -tau * lse\n\n    score = step + 0.5 * softmin\n\n    probs = np.exp(-score / (tau + 1e-12))\n    probs /= np.sum(probs + 1e-12)\n    chosen = int(np.random.choice(nodes, p=probs))\n    return chosen\n\n",
  "min_logsumexp_future_aug_259": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, nodes]\n\n    sub = distance_matrix[np.ix_(nodes, nodes)]\n\n    n = int(nodes.size)\n    tau = np.clip(0.6 + 0.1 * (n / max(1, distance_matrix.shape[0])),\n                  1e-6, None)\n\n    inv_tau = 1.0 / (tau + 1e-12)\n    x = -sub * inv_tau\n    m = np.max(x, axis=1)\n    lse = m + np.log(1 + np.exp(m[:, None] - x).sum(axis=1) + 1e-12)\n    softmin = -tau * lse\n\n    score = step + 0.7 * softmin\n\n    best_idx = 0\n    best_score = score[0]\n    i = 1\n    while i < len(score):\n        if score[i] < best_score:\n            best_score = score[i]\n            best_idx = i\n        i += 1\n    return int(nodes[best_idx])\n\n",
  "min_destination_betweenness_proxy_aug_260": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # Distance from current node to each candidate\n    step = dist_mat[current_node, candidates]\n    step_norm = step / (np.mean(step) + 1e-12)\n    step_norm = np.clip(step_norm, 0, 1)\n\n    # Count how many other nodes consider this candidate a near\u2011shortest path\n    d_to_dest = dist_mat[candidates, destination_node]\n    d_from_other = dist_mat[np.ix_(candidates, candidates)]\n    eps = 0.08\n    on_path = (d_from_other + d_to_dest[None, :]) <= \\\n              (1.0 + eps) * d_to_dest[:, None] + 1e-12\n    count = on_path.sum(axis=0).astype(np.float64)\n    count_norm = count / (np.mean(count) + 1e-12)\n\n    # Deterministic tie breaker\n    noise = 1e-9 * np.arange(candidates.size)\n\n    score = step_norm - 0.75 * count_norm + noise\n    chosen_idx = int(candidates[np.argmin(score)])\n    return chosen_idx\n\n",
  "min_destination_betweenness_proxy_aug_261": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    dist = distance_matrix\n\n    step = dist[current_node, cand]\n    step_norm = step / (np.median(step) + 1e-12)\n    step_norm = np.clip(step_norm, 0, 1)\n\n    d_to_dest = dist[cand, destination_node]\n    d_from_other = dist[np.ix_(cand, cand)]\n    eps = 0.05\n    on_path = (d_from_other + d_to_dest[None, :]) <= \\\n              (1.0 + eps) * d_to_dest[:, None] + 1e-12\n    count = on_path.sum(axis=0).astype(np.float64)\n    count_norm = count / (np.median(count) + 1e-12)\n\n    score = 0.6 * step_norm - 0.4 * count_norm\n    noise = 1e-10 * np.arange(cand.size)\n    score += noise\n\n    top_k = 5\n    k = min(top_k, cand.size)\n    idxs = np.argsort(score)[:k]\n    chosen_idx = int(cand[np.random.choice(idxs)])\n    return chosen_idx\n\n",
  "min_destination_betweenness_proxy_aug_262": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    mat = distance_matrix\n\n    step = mat[current_node, nodes]\n    step_norm = step / (np.mean(step) + 1e-12)\n    step_norm = np.clip(step_norm, 0, 1)\n\n    d_to_dest = mat[nodes, destination_node]\n    d_from_other = mat[np.ix_(nodes, nodes)]\n    eps = 0.08\n    on_path = (d_from_other + d_to_dest[None, :]) <= \\\n              (1.0 + eps) * d_to_dest[:, None] + 1e-12\n    count = on_path.sum(axis=0).astype(np.float64)\n    count_norm = count / (np.max(count) + 1e-12)\n\n    noise = 1e-9 * np.arange(nodes.size)\n    score = step_norm - 0.75 * count_norm + noise\n\n    alpha = 15.0\n    probs = np.exp(-alpha * score)\n    probs /= probs.sum() + 1e-12\n    chosen_idx = int(nodes[np.random.choice(nodes.size, p=probs)])\n    return chosen_idx\n\n",
  "min_detour_ratio_aug_263": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n    eps = 1e-12\n\n    # Invert conditional\n    if not candidates.size:\n        return int(destination_node)\n\n    # Compute distances\n    cur_to_dest = float(dist_mat[current_node, destination_node])\n    cur_to_cand = dist_mat[current_node, candidates]\n    cand_to_dest = dist_mat[candidates, destination_node]\n\n    # Clip to avoid overflow\n    cur_to_cand = np.clip(cur_to_cand, a_min=0, a_max=None)\n    cand_to_dest = np.clip(cand_to_dest, a_min=0, a_max=None)\n\n    # Ratio and score\n    ratio = (cur_to_cand + cand_to_dest) / (cur_to_dest + eps)\n    score = ratio + 0.05 * (cur_to_cand / (np.mean(cur_to_cand) + eps))\n\n    # Deterministic tie\u2011breaking noise\n    noise = np.arange(candidates.size) * 1e-6\n    score += noise\n\n    # Select candidate\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "min_detour_ratio_aug_264": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n    eps = 1e-12\n\n    if not candidates.size:\n        return int(destination_node)\n\n    cur_to_dest = float(dist_mat[current_node, destination_node])\n    cur_to_cand = dist_mat[current_node, candidates]\n    cand_to_dest = dist_mat[candidates, destination_node]\n\n    # Use median for robustness\n    ratio = (cur_to_cand + cand_to_dest) / (cur_to_dest + eps)\n    score = ratio + 0.1 * (cur_to_cand / (np.median(cur_to_cand) + eps))\n\n    # Softmin with temperature\n    temp = 5.0\n    weights = np.exp(-score * temp)\n    weights /= np.sum(weights)\n\n    # Random choice among top_k\n    top_k = 7\n    top_indices = np.argsort(score)[:top_k]\n    probs = weights[top_indices]\n    probs /= np.sum(probs)\n    chosen = np.random.choice(top_indices, p=probs)\n\n    return int(candidates[chosen])\n\n",
  "min_detour_ratio_aug_265": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    dmat = distance_matrix\n    eps = 1e-12\n\n    if not cand.size:\n        return int(destination_node)\n\n    cur_to_dest = float(dmat[current_node, destination_node])\n    cur_to_cand = dmat[current_node, cand]\n    cand_to_dest = dmat[cand, destination_node]\n\n    # Emphasize worst\u2011case with max in ratio\n    ratio = (cur_to_cand + cand_to_dest) / (cur_to_dest + eps)\n    score = ratio + 0.07 * (cur_to_cand / (np.max(cur_to_cand) + eps))\n\n    # Softmin with lower temperature\n    temp = 2.0\n    probs = np.exp(-score * temp)\n    probs /= np.sum(probs)\n\n    # Random choice among top_k=5\n    top_k = 5\n    top_idx = np.argsort(score)[:top_k]\n    probs_top = probs[top_idx]\n    probs_top /= np.sum(probs_top)\n    chosen = np.random.choice(top_idx, p=probs_top)\n\n    return int(cand[chosen])\n\n",
  "min_detour_ratio_aug_266": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    nodes = unvisited_nodes.astype(int)\n    mat = distance_matrix\n    eps = 1e-12\n\n    # Invert conditional\n    if nodes.size == 0:\n        return int(destination_node)\n\n    # Pre\u2011compute distances\n    cur_dest = float(mat[current_node, destination_node])\n    cur_to = mat[current_node, nodes]\n    to_dest = mat[nodes, destination_node]\n\n    # Use np.square for step distances\n    cur_to_sq = np.square(cur_to)\n\n    # Compute ratio\n    ratio = (cur_to_sq + to_dest) / (cur_dest + eps)\n\n    # Use np.median for aggregation\n    score = ratio + 0.06 * (cur_to_sq / (np.median(cur_to_sq) + eps))\n\n    # Clip scores to avoid extreme values\n    score = np.clip(score, a_min=0, a_max=None)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(nodes.size) * 1e-7\n    score += noise\n\n    # Find best candidate via while loop\n    best_idx = 0\n    best_val = score[0]\n    i = 1\n    while i < nodes.size:\n        if score[i] < best_val:\n            best_val = score[i]\n            best_idx = i\n        i += 1\n\n    return int(nodes[best_idx])\n\n",
  "max_interiority_score_aug_267": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename for clarity\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    # direct distance to each candidate\n    step = dist_mat[current_node, cand]\n\n    # pairwise distances among candidates\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # interiority: how many neighbours are closer than the median distance\n    med = np.median(D, axis=1)\n    interior = np.sum(D <= med[:, None], axis=1).astype(np.float64)\n\n    # normalise\n    i_norm = interior / (np.mean(interior) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n\n    # clip to avoid extreme values\n    s_norm = np.clip(s_norm, 0, 10)\n\n    # weighted score\n    score = 0.6 * s_norm - 0.4 * i_norm\n\n    # small deterministic noise to break ties\n    noise = np.random.randn(score.size) * 1e-6\n    idx = np.argmin(score + noise)\n\n    return int(cand[idx])\n\n",
  "max_interiority_score_aug_268": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    step = dist_mat[current_node, cand]\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    # use farthest neighbour as a simple interiority proxy\n    interior = np.max(D, axis=1).astype(np.float64)\n\n    i_norm = interior / (np.mean(interior) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n    s_norm = np.clip(s_norm, 0, 10)\n\n    score = 0.7 * s_norm - 0.3 * i_norm\n\n    # soft\u2011min with beta\n    beta = 10.0\n    weights = np.exp(-beta * score)\n    weights = weights / (np.sum(weights) + 1e-12)\n\n    # random choice weighted by soft\u2011min probabilities\n    idx = np.random.choice(len(weights), p=weights)\n    return int(cand[idx])\n\n",
  "max_interiority_score_aug_269": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    step = dist_mat[current_node, cand]\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    med = np.median(D, axis=1)\n    interior = np.sum(D <= med[:, None], axis=1).astype(np.float64)\n\n    i_norm = interior / (np.mean(interior) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n    s_norm = np.clip(s_norm, 0, 10)\n\n    score = 0.6 * s_norm - 0.4 * i_norm\n\n    top_k = min(5, len(cand))\n    # get indices of the top_k smallest scores\n    idxs = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = np.random.choice(idxs)\n    return int(cand[chosen])\n\n",
  "max_interiority_score_aug_270": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    step = dist_mat[current_node, cand]\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    med = np.median(D, axis=1)\n    # interiority as the median of boolean comparisons\n    interior = np.median(D <= med[:, None], axis=1).astype(np.float64)\n\n    i_norm = interior / (np.mean(interior) + 1e-12)\n    s_norm = step / (np.mean(step) + 1e-12)\n    s_norm = np.clip(s_norm, 0, 10)\n\n    score = 0.5 * s_norm - 0.5 * i_norm\n\n    # deterministic noise for stable tie breaking\n    noise = np.random.uniform(-1e-6, 1e-6, size=score.shape)\n    idx = np.argmin(score + noise)\n\n    return int(cand[idx])\n\n",
  "min_border_crossing_aug_271": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # renamed variables\n    candidates = unvisited_nodes.astype(int)\n\n    # current profile vs remaining\n    cur_prof = distance_matrix[current_node, candidates]\n    qcur = float(np.quantile(cur_prof, 0.4))\n\n    # pairwise distances among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    q = np.quantile(D, 0.4, axis=1)\n\n    # distance step\n    step = distance_matrix[current_node, candidates]\n    denom = np.median(step) + 1e-12          # median instead of mean\n    ratio = step / denom\n    ratio = np.clip(ratio, 0, 1)             # bound ratio to avoid extreme values\n\n    # scoring: absolute quantile difference + weighted ratio\n    score = np.abs(q - qcur) + 0.15 * ratio\n\n    # add deterministic noise to break ties\n    noise = 1e-8 * np.arange(len(candidates))\n    score += noise\n\n    # soft\u2011min selection\n    lam = 10.0\n    probs = np.exp(-lam * score)\n    probs = probs / (np.sum(probs) + 1e-12)\n\n    idx = int(np.argmax(probs))\n    return int(candidates[idx])\n\n",
  "min_border_crossing_aug_272": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n\n    cur_prof = distance_matrix[current_node, candidates]\n    qcur = float(np.quantile(cur_prof, 0.35))\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    q = np.quantile(D, 0.35, axis=1)\n\n    step = distance_matrix[current_node, candidates]\n    denom = np.max(step) + 1e-12\n    ratio = step / denom\n    ratio = np.clip(ratio, 0, 1)\n\n    score = np.abs(q - qcur) + 0.25 * ratio\n    score += 1e-9 * np.arange(len(candidates))  # deterministic noise\n\n    # manual argmin with tie\u2011breaking (lower index wins)\n    min_val = np.inf\n    min_idx = -1\n    for idx, val in enumerate(score):\n        if val < min_val:\n            min_val = val\n            min_idx = idx\n    return int(candidates[min_idx])\n\n",
  "min_border_crossing_aug_273": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # list comprehension for candidates\n    candidates = [int(x) for x in unvisited_nodes]\n\n    cur_prof = [distance_matrix[current_node, c] for c in candidates]\n    qcur = float(np.quantile(cur_prof, 0.35))\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    q = [float(np.quantile(D[i], 0.35)) for i in range(len(candidates))]\n\n    step = [distance_matrix[current_node, c] for c in candidates]\n    denom = np.sum(step) + 1e-12\n    ratio = [np.clip(s / denom, 0, 1) for s in step]\n\n    score = [abs(q[i] - qcur) + 0.30 * ratio[i] for i in range(len(candidates))]\n\n    # top\u2011k deterministic selection\n    top_k = 5\n    top_indices = sorted(range(len(score)), key=lambda i: score[i])[:top_k]\n\n    rng = np.random.default_rng(seed=12345)\n    chosen = rng.choice(top_indices)\n    return int(candidates[chosen])\n\n",
  "destination_late_commitment_aug_274": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    # isolation = minimum distance to any other candidate\n    pairwise = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pairwise, np.inf)\n    isolation = np.min(pairwise, axis=1)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    # logistic pivot\n    pivot = 1.0 / (1.0 + np.exp(-12.0 * (progress - 0.65)))\n    pivot = np.clip(pivot, 0.0, 1.0)\n\n    # scoring with tweaked weights\n    score = (1.0 - pivot) * (step - 0.80 * isolation) + \\\n            pivot * (step + 1.10 * d_dest)\n\n    # deterministic tie\u2011breaking noise\n    noise = 1e-6 * np.arange(score.size, dtype=np.float64)\n    score += noise\n\n    return int(candidates[np.argmin(score)])\n\n",
  "destination_late_commitment_aug_275": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step   = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    pairwise = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pairwise, np.inf)\n    isolation = np.min(pairwise, axis=1)\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    pivot = 1.0 / (1.0 + np.exp(-10.0 * (progress - 0.70)))\n    pivot = np.clip(pivot, 0.0, 1.0)\n\n    # modified weights\n    score = (1.0 - pivot) * (0.4 * step + 0.6 * isolation) + \\\n            pivot * (0.3 * step + 1.20 * d_dest)\n\n    # deterministic noise for tie\u2011breaking\n    score += 1e-7 * np.arange(score.size, dtype=np.float64)\n\n    # top\u2011k selection\n    k = 5\n    if k > score.size:\n        k = score.size\n    top_k_idx = np.argpartition(score, k - 1)[:k]\n    best_idx  = top_k_idx[np.argmin(score[top_k_idx])]\n\n    return int(candidates[best_idx])\n\n",
  "destination_late_commitment_aug_276": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size > 0:\n        step   = dist_mat[current_node, candidates]\n        d_dest = dist_mat[candidates, destination_node]\n\n        pairwise = dist_mat[np.ix_(candidates, candidates)].copy()\n        np.fill_diagonal(pairwise, np.inf)\n        isolation = np.mean(pairwise, axis=1)   # proxy: mean instead of min\n\n        n_total = int(dist_mat.shape[0])\n        n_rem   = int(candidates.size)\n        progress = 1.0 - (n_rem / max(1, n_total))\n        progress = np.clip(progress, 0.0, 1.0)\n\n        pivot = 1.0 / (1.0 + np.exp(-8.0 * (progress - 0.60)))\n        pivot = np.clip(pivot, 0.0, 1.0)\n\n        score = (1.0 - pivot) * (0.5 * step + 0.5 * isolation) + \\\n                pivot * (0.6 * step + 0.9 * d_dest)\n\n        # deterministic noise\n        score += 1e-8 * np.arange(score.size, dtype=np.float64)\n\n        # softmin with temperature\n        temp = 0.5\n        probs = np.exp(-score / (temp + 1e-12))\n        probs /= np.sum(probs)\n        best_idx = int(np.argmax(probs))\n        return int(candidates[best_idx])\n    else:\n        return int(destination_node)\n\n",
  "destination_late_commitment_aug_277": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step   = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n\n    pairwise = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pairwise, np.inf)\n    isolation = np.max(pairwise, axis=1)   # farthest from others\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    pivot = 1.0 / (1.0 + np.exp(-14.0 * (progress - 0.70)))\n    pivot = np.clip(pivot, 0.0, 1.0)\n\n    score = (1.0 - pivot) * (step + 0.7 * isolation) + \\\n            pivot * (step - 0.8 * d_dest)\n\n    # deterministic noise\n    score += 1e-9 * np.arange(score.size, dtype=np.float64)\n\n    best_idx = int(np.argmin(score))\n    return int(candidates[best_idx])\n\n",
  "max_spacing_then_fill_aug_278": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(np.int64)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    step = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress >= 0.55:\n        k = int(max(1, np.ceil(0.15 * n_rem)))\n        far_idx = np.argsort(-step)[:k]\n        submat = dist_mat[np.ix_(candidates, candidates)]\n        centrality = submat.mean(axis=1)\n        cand = far_idx\n        scores = centrality[cand] + 0.12 * step[cand]\n        scores += np.arange(scores.size) * 1e-8          # deterministic noise\n        chosen = np.argmin(scores)\n        return int(candidates[int(far_idx[chosen])])\n    else:\n        chosen = np.argmin(step)\n        return int(candidates[int(chosen)])\n\n",
  "max_spacing_then_fill_aug_279": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(np.int64)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    step = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress < 0.4:\n        k = int(max(1, np.ceil(0.20 * n_rem)))\n        far_idx = np.argsort(-step)[:k]\n        submat = dist_mat[np.ix_(candidates, candidates)]\n        centrality = submat.median(axis=1)\n        cand = far_idx\n        scores = 0.6 * centrality[cand] + 0.4 * step[cand]\n        scores += np.arange(scores.size) * 1e-9          # deterministic noise\n        beta = 10.0\n        probs = np.exp(-beta * scores)\n        probs /= probs.sum() + 1e-12\n        chosen = np.random.choice(cand, p=probs)\n        return int(candidates[int(chosen)])\n    else:\n        chosen = np.argmin(step)\n        return int(candidates[int(chosen)])\n\n",
  "max_spacing_then_fill_aug_280": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(np.int64)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    step = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress < 0.5:\n        k = int(max(1, np.ceil(0.18 * n_rem)))\n        far_idx = np.argsort(-step)[:k]\n        submat = dist_mat[np.ix_(candidates, candidates)]\n        centrality = submat.median(axis=1)\n        cand = far_idx\n        scores = 0.5 * centrality[cand] + 0.5 * step[cand]\n        scores += np.random.uniform(-1e-8, 1e-8, size=scores.shape)   # random tie\u2011noise\n        chosen = np.random.choice(cand, p=np.ones_like(cand, dtype=float) / len(cand))\n        return int(candidates[int(chosen)])\n    else:\n        chosen = np.argmin(step)\n        return int(candidates[int(chosen)])\n\n",
  "max_spacing_then_fill_aug_281": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(np.int64)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    step = np.square(dist_mat[current_node, candidates])   # proxy: squared distance\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    progress = np.clip(progress, 0.0, 1.0)\n\n    if progress < 0.6:\n        k = int(max(1, np.ceil(0.22 * n_rem)))\n        far_idx = np.argsort(-step)[:k]\n        submat = dist_mat[np.ix_(candidates, candidates)]\n        centrality = submat.max(axis=1)\n        cand = far_idx\n        scores = 0.7 * centrality[cand] + 0.3 * step[cand]\n        scores += np.arange(scores.size) * 1e-7                 # deterministic noise\n        beta = 5.0\n        logits = -beta * scores\n        exp_logits = np.exp(logits - np.max(logits))\n        probs = exp_logits / (exp_logits.sum() + 1e-12)\n        chosen = np.random.choice(cand, p=probs)\n        return int(candidates[int(chosen)])\n    else:\n        chosen = np.argmin(step)\n        return int(candidates[int(chosen)])\n\n",
  "min_two_hop_diameter_aug_282": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename variables for clarity\n    candidates = unvisited_nodes.astype(int)\n    dist_to_next = distance_matrix[current_node, candidates]\n    dist_to_end   = distance_matrix[candidates, destination_node]\n\n    # Pairwise distances among candidates\n    pairwise = distance_matrix[np.ix_(candidates, candidates)]\n    cap = np.max(np.minimum(pairwise, dist_to_end[None, :]), axis=1)\n\n    # Median\u2011based normalization\n    denom_step = np.median(dist_to_next) + 1e-12\n    denom_cap  = np.median(cap) + 1e-12\n\n    score = (dist_to_next / denom_step) + 0.8 * (cap / denom_cap)\n\n    # Small deterministic noise to break ties\n    noise = 1e-6 * np.arange(len(candidates))\n    chosen = int(candidates[np.argmin(score + noise)])\n    return chosen\n\n",
  "min_two_hop_diameter_aug_283": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n    d_dest = distance_matrix[candidates, destination_node]\n\n    pairwise = distance_matrix[np.ix_(candidates, candidates)]\n    cap = np.max(np.minimum(pairwise, d_dest[None, :]), axis=1)\n\n    # Normalization with mean\n    step_norm = step / (np.mean(step) + 1e-12)\n    cap_norm  = cap / (np.mean(cap) + 1e-12)\n\n    # Weighted score\n    score = 0.6 * step_norm + 0.4 * cap_norm\n\n    # Random choice among the best 7 candidates\n    top_k = min(7, len(candidates))\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen_idx = np.random.choice(top_indices)\n    return int(candidates[chosen_idx])\n\n",
  "min_two_hop_diameter_aug_284": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Use destination distance as a proxy for future cost\n    cap = d_dest\n\n    # Mean\u2011based normalization\n    step_norm = step / (np.mean(step) + 1e-12)\n    cap_norm  = cap / (np.mean(cap) + 1e-12)\n\n    score = 0.7 * step_norm + 0.3 * cap_norm\n\n    # Soft\u2011min selection with probability weighting\n    probs = np.exp(-score)\n    probs = probs / (np.sum(probs) + 1e-12)\n\n    chosen_idx = np.random.choice(len(cand), p=probs)\n    return int(cand[chosen_idx])\n\n",
  "entropy_of_ranks_aug_285": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    steps = distance_matrix[current_node, candidates]\n    D = distance_matrix[np.ix_(candidates, candidates)]\n\n    # rank matrix (lower distance -> lower rank)\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n\n    # entropy of ranks\n    row_sum = ranks.sum(axis=1) + 1e-12\n    P = ranks / row_sum[:, None]\n    ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    # scoring: distance term minus weighted entropy term\n    score = (steps / (np.mean(steps) + 1e-12)) \\\n            - 0.8 * (ent / (np.mean(ent) + 1e-12))\n\n    # small noise to break ties deterministically\n    noise = np.random.uniform(0, 1e-6, size=steps.shape)\n    score += noise\n\n    return int(candidates[np.argmin(score)])\n\n",
  "entropy_of_ranks_aug_286": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    steps = distance_matrix[current_node, candidates]\n    mean_step = steps.mean() + 1e-12\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n\n    row_sum = ranks.sum(axis=1) + 1e-12\n    P = ranks / row_sum[:, None]\n    ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    # compute scores one by one using a while loop\n    scores = np.empty(candidates.size, dtype=np.float64)\n    idx = 0\n    while idx < candidates.size:\n        step = steps[idx]\n        score = (step / mean_step) \\\n                - 0.6 * (ent[idx] / (ent.mean() + 1e-12))\n        scores[idx] = score\n        idx += 1\n\n    # softmin sampling to avoid deterministic greedy choice\n    probs = np.exp(-scores)\n    probs = probs / (probs.sum() + 1e-12)\n\n    chosen = np.random.choice(candidates, p=probs)\n    return int(chosen)\n\n",
  "entropy_of_ranks_aug_287": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    steps = distance_matrix[current_node, candidates]\n    D = distance_matrix[np.ix_(candidates, candidates)]\n\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n\n    # use max instead of sum for rank normalisation\n    row_sum = ranks.max(axis=1) + 1e-12\n    P = ranks / row_sum[:, None]\n    ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    # median instead of mean\n    score = (steps / (np.median(steps) + 1e-12)) \\\n            - 0.7 * (ent / (np.median(ent) + 1e-12))\n\n    noise = np.random.uniform(0, 1e-6, size=steps.shape)\n    score += noise\n\n    top_k = 5\n    if candidates.size <= top_k:\n        return int(candidates[np.argmin(score)])\n\n    top_idx = np.argpartition(score, top_k)[:top_k]\n    chosen = np.random.choice(candidates[top_idx])\n    return int(chosen)\n\n",
  "entropy_of_ranks_aug_288": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    steps = distance_matrix[current_node, candidates]\n    D = distance_matrix[np.ix_(candidates, candidates)]\n\n    ranks = np.argsort(np.argsort(D, axis=1), axis=1).astype(np.float64)\n\n    row_sum = ranks.sum(axis=1) + 1e-12\n    P = ranks / row_sum[:, None]\n    ent = -(P * np.log(P + 1e-12)).sum(axis=1)\n\n    score = (steps / (np.mean(steps) + 1e-12)) \\\n            - 0.5 * (ent / (np.mean(ent) + 1e-12))\n\n    # softmin with clipping to keep probabilities sane\n    probs = np.exp(-score)\n    probs = np.clip(probs, 0, 1e6)\n    probs = probs / (probs.sum() + 1e-12)\n\n    chosen = np.random.choice(candidates, p=probs)\n    return int(chosen)\n\n",
  "destination_anchor_then_wander_aug_289": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Renamed variables for clarity\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    # Distances from current node and to destination\n    step_dist = dist_mat[current_node, candidates]\n    dest_dist = dist_mat[candidates, destination_node]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    if progress < 0.40:\n        # Early phase \u2013 choose among the closest to destination\n        k = int(max(2, min(n_rem, int(np.ceil(0.20 * n_rem)))))\n        idx = np.argsort(dest_dist)[:k]\n        score = 0.7 * step_dist[idx] + 0.3 * dest_dist[idx]\n        noise = np.arange(k) * 1e-6          # deterministic tie\u2011breaker\n        score += noise\n        chosen = int(candidates[idx[np.argmin(score)]])\n        return chosen\n\n    # Later phase \u2013 structural best\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, np.inf)\n    bottleneck = np.median(D, axis=1)\n    mean_step = np.mean(step_dist) + 1e-12\n    mean_bot = np.mean(bottleneck) + 1e-12\n    score = (step_dist / mean_step) + 0.3 * (bottleneck / mean_bot)\n    chosen = int(candidates[np.argmin(score)])\n    return chosen\n\n",
  "destination_anchor_then_wander_aug_290": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n    step = dist_mat[current_node, cand]\n    dest = dist_mat[cand, destination_node]\n\n    n_tot = int(dist_mat.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_tot))\n\n    if progress < 0.40:\n        # Early phase \u2013 softmin over weighted sum\n        score = 0.6 * step + 0.4 * dest\n        exp_neg = np.exp(-score)\n        probs = exp_neg / (np.sum(exp_neg) + 1e-12)\n        probs = np.clip(probs, 0, 1)\n        chosen_idx = int(np.argmax(probs))\n        return int(cand[chosen_idx])\n\n    # Later phase \u2013 structural\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    bottleneck = np.percentile(D, 30, axis=1)\n    mean_step = np.mean(step) + 1e-12\n    mean_bot = np.mean(bottleneck) + 1e-12\n    score = (step / mean_step) + 0.4 * (bottleneck / mean_bot)\n\n    # Deterministic random choice among top\u20113\n    top_k = 3\n    idx_top = np.argsort(score)[:top_k]\n    rng = np.random.default_rng(42)\n    chosen_idx = rng.choice(idx_top)\n    return int(cand[chosen_idx])\n\n",
  "destination_anchor_then_wander_aug_291": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n    step = dist_mat[current_node, cand]\n    dest = dist_mat[cand, destination_node]\n\n    n_tot = int(dist_mat.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_tot))\n\n    if progress < 0.40:\n        # Early phase \u2013 weighted sum with dest\n        score = 0.5 * step + 0.5 * dest\n        exp_pos = np.exp(score)\n        probs = exp_pos / (np.sum(exp_pos) + 1e-12)\n        probs = np.clip(probs, 0, 1)\n        chosen_idx = int(np.argmax(probs))\n        return int(cand[chosen_idx])\n\n    # Later phase \u2013 structural\n    D = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n    bottleneck = np.max(D, axis=1)\n    mean_step = np.sum(step) + 1e-12\n    mean_bot = np.sum(bottleneck) + 1e-12\n    score = (step / mean_step) + 0.5 * (bottleneck / mean_bot)\n\n    top_k = 5\n    idx_top = np.argsort(score)[:top_k]\n    rng = np.random.default_rng(12345)\n    chosen_idx = rng.choice(idx_top)\n    return int(cand[chosen_idx])\n\n",
  "destination_anchor_then_wander_aug_292": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = [int(x) for x in unvisited_nodes]\n    step = np.array([dist_mat[current_node, c] for c in candidates], dtype=float)\n    dest = np.array([dist_mat[c, destination_node] for c in candidates], dtype=float)\n\n    n_tot = int(dist_mat.shape[0])\n    n_rem = int(len(candidates))\n    progress = 1.0 - (n_rem / max(1, n_tot))\n\n    # Inverted logic: early phase when progress >= 0.4\n    if progress >= 0.40:\n        score = 0.8 * step + 0.2 * dest\n        noise = np.arange(len(candidates)) * 1e-7\n        score += noise\n        chosen = candidates[int(np.argmin(score))]\n        return chosen\n\n    # Later phase \u2013 structural\n    D = np.array([[dist_mat[i, j] for j in candidates] for i in candidates], dtype=float)\n    np.fill_diagonal(D, np.inf)\n    bottleneck = np.percentile(D, 15, axis=1)\n    step = np.clip(step, 0, None)\n    bottleneck = np.clip(bottleneck, 0, None)\n    mean_step = np.mean(step) + 1e-12\n    mean_bot = np.mean(bottleneck) + 1e-12\n    score = (step / mean_step) + 0.2 * (bottleneck / mean_bot)\n    chosen = candidates[int(np.argmin(score))]\n    return chosen\n\n",
  "min_variance_of_knn_aug_293": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    n = cand.size\n    k = int(np.clip(np.ceil(0.12 * n), 3, n - 1))\n    knn = np.partition(D, k - 1, axis=1)[:, :k]\n    var = knn.var(axis=1)\n\n    dist_score = step / (step.mean() + eps)\n    var_score = var / (var.mean() + eps)\n\n    score = dist_score + 0.75 * var_score\n    return int(cand[np.argmin(score)])\n\n",
  "min_variance_of_knn_aug_294": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    rng = np.random.default_rng()\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    n = cand.size\n    k = int(np.clip(np.ceil(0.15 * n), 3, n - 1))\n\n    scores = []\n    for idx in cand:\n        d = distance_matrix[current_node, idx]\n        neigh = np.delete(cand, np.where(cand == idx))\n        if neigh.size == 0:\n            var = 0.0\n        else:\n            D_neigh = distance_matrix[np.ix_(neigh, neigh)].copy()\n            np.fill_diagonal(D_neigh, np.inf)\n            knn = np.partition(D_neigh, k - 1, axis=1)[:, :k]\n            var = knn.var(axis=1).mean()\n        dist_agg = d\n        score = (dist_agg / (dist_agg + eps)) + 0.4 * (var / (var + eps))\n        score += rng.random() * 1e-6\n        scores.append(score)\n\n    scores = np.array(scores)\n    alpha = 10.0\n    probs = np.exp(-alpha * scores)\n    probs /= probs.sum()\n    chosen = rng.choice(cand, p=probs)\n    return int(chosen)\n\n",
  "min_variance_of_knn_aug_295": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    rng = np.random.default_rng()\n    cand = unvisited_nodes.astype(int)\n    n = cand.size\n    k = int(np.clip(5, 3, n - 1))\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    var = D.var(axis=1)\n\n    step = distance_matrix[current_node, cand]\n    step_med = np.median(step)\n    dist_score = step / (step_med + eps)\n\n    var_sum = np.sum(var)\n    var_score = var / (var_sum + eps)\n\n    score = dist_score + 0.5 * var_score\n\n    top_indices = np.argpartition(score, k - 1)[:k]\n    chosen = rng.choice(cand[top_indices])\n    return int(chosen)\n\n",
  "min_variance_of_knn_aug_296": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    eps = 1e-12\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    n = cand.size\n    k = int(np.clip(np.ceil(0.2 * n), 3, n - 1))\n\n    step = distance_matrix[current_node, cand]\n    max_step = step.max() + eps\n\n    D = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(D, np.inf)\n\n    best_score = np.inf\n    best_idx = None\n\n    for i, idx in enumerate(cand):\n        d = step[i]\n        neigh = np.delete(cand, np.where(cand == idx))\n        if neigh.size == 0:\n            var = 0.0\n        else:\n            D_neigh = distance_matrix[np.ix_(neigh, neigh)].copy()\n            np.fill_diagonal(D_neigh, np.inf)\n            knn = np.partition(D_neigh, k - 1, axis=1)[:, :k]\n            var = knn.var(axis=1).mean()\n\n        dist_score = d / max_step\n        var_score = var / (var + eps)\n        score = 0.6 * dist_score + 0.4 * var_score\n\n        score += 1e-6 * np.random.rand()\n\n        if score < best_score:\n            best_score = score\n            best_idx = idx\n\n    return int(best_idx)\n\n",
  "min_regret_over_two_hops_aug_297": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    if cand.size == 0:\n        return int(destination_node)\n    if cand.size == 1:\n        return int(cand[0])\n\n    # Step distances from current node to each candidate\n    step = dist_mat[current_node, cand]\n    # Distance from each candidate to the destination\n    d_dest = dist_mat[cand, destination_node]\n\n    # Two\u2011hop matrix (candidate \u2192 intermediate \u2192 destination)\n    twohop = dist_mat[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(twohop, np.inf)\n    twohop += d_dest[None, :]\n\n    # Best and second best two\u2011hop costs per candidate\n    best = np.partition(twohop, 1, axis=1)[:, 0]\n    second = np.partition(twohop, 1, axis=1)[:, 1]\n    regret = second - best\n\n    # Median\u2011based normalization\n    step_norm = step / (np.median(step) + 1e-12)\n    regret_norm = regret / (np.median(regret) + 1e-12)\n\n    # Scoring and deterministic noise for tie\u2011breaking\n    score = step_norm - 0.85 * regret_norm\n    noise = 1e-8 * np.arange(cand.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_regret_over_two_hops_aug_298": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    if cand.size == 0:\n        return int(destination_node)\n    if cand.size == 1:\n        return int(cand[0])\n\n    step = dist[current_node, cand]\n    d_dest = dist[cand, destination_node]\n\n    twohop = dist[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(twohop, np.inf)\n    twohop += d_dest[None, :]\n\n    best = np.partition(twohop, 1, axis=1)[:, 0]\n    second = np.partition(twohop, 1, axis=1)[:, 1]\n    regret = second - best\n\n    step_norm = step / (np.mean(step) + 1e-12)\n    regret_norm = regret / (np.mean(regret) + 1e-12)\n\n    score = step_norm - 0.85 * regret_norm\n\n    # Soft\u2011min probabilities\n    eps = 1e-12\n    probs = np.exp(-score / (np.std(score) + eps))\n    probs = probs / (np.sum(probs) + eps)\n\n    # Random choice among top\u2011k candidates\n    top_k = min(7, cand.size)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    top_probs = probs[top_indices]\n    top_probs = top_probs / (np.sum(top_probs) + eps)\n\n    chosen_idx = np.random.choice(top_indices, p=top_probs)\n    return int(cand[chosen_idx])\n\n",
  "min_regret_over_two_hops_aug_299": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    if cand.size == 0:\n        return int(destination_node)\n    if cand.size == 1:\n        return int(cand[0])\n\n    step = dist[current_node, cand]\n    d_dest = dist[cand, destination_node]\n\n    # Proxy two\u2011hop: sum of step and destination distances\n    proxy = np.add.outer(step, d_dest)\n    best_two = np.min(proxy, axis=1)\n    second_two = np.partition(proxy, 1, axis=1)[:, 1]\n    regret = second_two - best_two\n\n    step_norm = step / (np.max(step) + 1e-12)\n    regret_norm = regret / (np.sum(regret) + 1e-12)\n\n    score = 0.6 * step_norm + 0.4 * regret_norm\n    score = np.clip(score, 0, 1)\n\n    # Small deterministic noise\n    noise = 1e-9 * np.arange(cand.size)\n    score += noise\n\n    return int(cand[np.argmin(score)])\n\n",
  "min_regret_over_two_hops_aug_300": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist = distance_matrix\n    cand = unvisited_nodes.astype(int)\n\n    if cand.size == 0:\n        return int(destination_node)\n    if cand.size == 1:\n        return int(cand[0])\n\n    step = dist[current_node, cand]\n    d_dest = dist[cand, destination_node]\n\n    twohop = dist[np.ix_(cand, cand)] + d_dest[None, :]\n    np.fill_diagonal(twohop, np.inf)\n\n    best = np.array([np.min(row) for row in twohop])\n    second = np.array([np.partition(row, 1)[1] for row in twohop])\n    regret = second - best\n\n    step_norm = step / (np.sum(step) + 1e-12)\n    step_norm = np.clip(step_norm, 0, 1)\n\n    regret_norm = regret / (np.max(regret) + 1e-12)\n\n    # Invert logic: larger score is better\n    score = -(step_norm - 0.75 * regret_norm)\n\n    # Deterministic noise for tie\u2011breaking\n    noise = 1e-7 * np.arange(cand.size)\n    score += noise\n\n    return int(cand[np.argmax(score)])\n\n",
  "destination_time_window_aug_301": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    d_dest = dist_mat[candidates, destination_node]\n    step   = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    hi = float(np.percentile(d_dest, 80))\n    lo = float(np.percentile(d_dest, 20))\n    target = (1.0 - progress) * hi + progress * lo\n\n    width   = (0.60 - 0.40 * progress) * (hi - lo + 1e-12)\n    penalty = np.maximum(0.0, np.abs(d_dest - target) - width)\n    penalty = np.clip(penalty, 0.0, None)\n\n    score = 0.70 * (step / (np.median(step) + 1e-12)) + \\\n            0.30 * (penalty / (np.median(penalty) + 1e-12))\n\n    noise = 1e-6 * np.arange(len(candidates))\n    final_score = score + noise\n\n    return int(candidates[np.argmin(final_score)])\n\n",
  "destination_time_window_aug_302": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_dest = dist_mat[candidates, destination_node]\n    step   = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    idx_hi = int(0.80 * n_rem)\n    idx_lo = int(0.20 * n_rem)\n\n    hi = float(np.partition(d_dest, idx_hi)[idx_hi])\n    lo = float(np.partition(d_dest, idx_lo)[idx_lo])\n    target = (1.0 - progress) * hi + progress * lo\n\n    width   = np.clip(0.55 - 0.40 * progress, 0.0, None) * (hi - lo + 1e-12)\n    penalty = np.maximum(0.0, np.abs(d_dest - target) - width)\n\n    score = 0.50 * (step / (np.max(step) + 1e-12)) + \\\n            0.50 * (penalty / (np.max(penalty) + 1e-12))\n\n    noise = 1e-6 * np.arange(len(candidates))\n    final_score = score + noise\n\n    probs = np.exp(-final_score)\n    probs /= np.sum(probs) + 1e-12\n\n    chosen_idx = np.random.choice(len(candidates), p=probs)\n\n    return int(candidates[chosen_idx])\n\n",
  "destination_time_window_aug_303": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat   = distance_matrix\n\n    d_dest = dist_mat[candidates, destination_node]\n    step   = dist_mat[current_node, candidates]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem   = int(candidates.size)\n    progress = 1.0 - (n_rem / max(1, n_total))\n\n    hi = float(np.quantile(d_dest, 0.80))\n    lo = float(np.quantile(d_dest, 0.20))\n    target = (1.0 - progress) * hi + progress * lo\n\n    width   = np.clip(0.55 - 0.40 * progress, 0.0, None) * (hi - lo + 1e-12)\n    penalty = np.maximum(0.0, np.abs(d_dest - target) - width)\n\n    scores = np.empty_like(step, dtype=np.float64)\n    idx = 0\n    while idx < len(step):\n        denom_step = np.mean(step) + 1e-12\n        denom_pen  = np.mean(penalty) + 1e-12\n        scores[idx] = 0.65 * (step[idx] / denom_step) + \\\n                      0.35 * (penalty[idx] / denom_pen)\n        idx += 1\n\n    noise = 1e-6 * np.arange(len(step))\n    scores += noise\n\n    top_k = 5\n    top_indices = np.argpartition(scores, top_k)[:top_k]\n    probs = scores[top_indices] - np.min(scores[top_indices])\n    probs = np.clip(probs, 0.0, None)\n    probs /= np.sum(probs) + 1e-12\n\n    chosen = np.random.choice(top_indices, p=probs)\n\n    return int(candidates[chosen])\n\n",
  "nearest_neighbor_with_blacklist_radius_aug_304": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[cur, cand]\n\n    # pairwise distances among remaining candidates\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    micro_radius = float(np.percentile(finite_vals, 15)) + 1e-12\n    crowding = np.sum(pair_dist <= micro_radius, axis=1).astype(np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    lower = np.percentile(crowding, 40)\n    upper = np.percentile(crowding, 80)\n    limit = (1.0 - progress) * upper + progress * lower\n    limit = np.clip(limit, 0, np.inf)\n\n    # Invert conditional logic: if no candidates satisfy crowding, use all\n    mask_list = [c <= limit for c in crowding]\n    if not any(mask_list):\n        idx = int(np.argmin(step))\n        return int(cand[idx])\n\n    mask = np.array(mask_list, dtype=bool)\n    eligible = np.where(mask)[0]\n    idx = int(np.argmin(step[eligible]))\n    return int(cand[eligible[idx]])\n\n",
  "nearest_neighbor_with_blacklist_radius_aug_305": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[cur, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    micro_radius = float(np.percentile(finite_vals, 70)) + 1e-12   # higher percentile\n    crowd = np.sum(pair_dist <= micro_radius, axis=1).astype(np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    lower = np.percentile(crowd, 30)\n    upper = np.percentile(crowd, 90)\n    limit = (1.0 - progress) * upper + progress * lower\n    limit = np.clip(limit, 0, np.inf)\n\n    # Composite score: distance penalised by crowding\n    score = dist_to_cand / (crowd + 1e-12)\n    mask = crowd <= limit\n    if np.any(mask):\n        eligible = cand[mask]\n        eligible_score = score[mask]\n        idx = int(np.argmin(eligible_score))\n        return int(eligible[idx])\n    else:\n        idx = int(np.argmin(dist_to_cand))\n        return int(cand[idx])\n\n",
  "nearest_neighbor_with_blacklist_radius_aug_306": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[cur, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    micro_radius = float(np.percentile(finite_vals, 15)) + 1e-12\n    crowd = np.sum(pair_dist <= micro_radius, axis=1).astype(np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    lower = np.percentile(crowd, 40)\n    upper = np.percentile(crowd, 80)\n    limit = (1.0 - progress) * upper + progress * lower\n    limit = np.clip(limit, 0, np.inf)\n\n    mask = crowd <= limit\n    if not np.any(mask):\n        return int(cand[int(np.argmin(dist_to_cand))])\n\n    # Soft\u2011min selection among eligible nodes\n    eligible_idx = np.where(mask)[0]\n    eligible_dist = dist_to_cand[eligible_idx]\n\n    # Deterministic noise for tie breaking\n    noise = np.arange(len(eligible_dist)) * 1e-9\n    noisy_dist = eligible_dist + noise\n\n    beta = 10.0\n    weights = np.exp(-beta * noisy_dist)\n    weights = weights / (np.sum(weights) + 1e-12)\n\n    rng = np.random.default_rng(seed=42)   # deterministic seed\n    chosen = rng.choice(eligible_idx, p=weights)\n    return int(cand[chosen])\n\n",
  "nearest_neighbor_with_blacklist_radius_aug_307": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cur = int(current_node)\n    dest = int(destination_node)\n    cand = unvisited_nodes.astype(int)\n    dist_to_cand = distance_matrix[cur, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    sorted_vals = np.sort(finite_vals)\n    idx_15 = max(0, int(len(sorted_vals) * 0.15))\n    micro_radius = float(sorted_vals[idx_15]) + 1e-12\n\n    # Use maximum instead of sum for crowding\n    crowd = np.max((pair_dist <= micro_radius).astype(int), axis=1).astype(np.float64)\n\n    n_total = int(distance_matrix.shape[0])\n    n_rem = int(cand.size)\n    progress = 1.0 - (n_rem / max(1, n_total + 1e-12))\n    lower = np.percentile(crowd, 20)\n    upper = np.percentile(crowd, 70)\n    limit = (1.0 - progress) * upper + progress * lower\n    limit = np.clip(limit, 0, np.inf)\n\n    mask = crowd <= limit\n    if not np.any(mask):\n        return int(cand[int(np.argmin(dist_to_cand))])\n\n    eligible_idx = np.where(mask)[0]\n    eligible_dist = dist_to_cand[eligible_idx]\n\n    # Random choice among the top\u2011k closest eligible nodes\n    top_k = min(5, len(eligible_idx))\n    sorted_top = np.argsort(eligible_dist)[:top_k]\n    chosen = eligible_idx[sorted_top[np.random.randint(top_k)]]\n    return int(cand[chosen])\n\n",
  "destination_funnel_kbest_aug_308": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n    dest_cost = dist_mat[candidates, destination_node]\n\n    n_total = int(dist_mat.shape[0])\n    n_rem = int(candidates.size)\n    # Avoid division by zero\n    progress = 1.0 - (n_rem / (max(1, n_total) + 1e-12))\n\n    k = int(np.ceil((0.30 - 0.22 * progress) * n_rem))\n    k = int(np.clip(k, 2, n_rem))\n\n    # Build top\u2011k list using while loop\n    sorted_idx = np.argsort(step)\n    topk_idx = []\n    i = 0\n    while len(topk_idx) < k and i < len(sorted_idx):\n        topk_idx.append(sorted_idx[i])\n        i += 1\n\n    # Add tiny deterministic noise for tie\u2011breaking\n    noise = np.arange(len(topk_idx)) * 1e-9\n    best_idx = topk_idx[int(np.argmin(dest_cost[topk_idx] + noise))]\n\n    return int(candidates[best_idx])\n\n",
  "destination_funnel_kbest_aug_309": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    # Compute step and destination cost using list comprehension\n    step = np.array([dist_mat[current_node, c] for c in candidates])\n    dest_cost = np.array([dist_mat[c, destination_node] for c in candidates])\n\n    n_rem = int(candidates.size)\n    top_k = int(np.clip(min(7, n_rem), 2, n_rem))\n\n    # Weighted combined score\n    score = 0.6 * step + 0.4 * dest_cost\n\n    # Get indices of top_k smallest scores\n    sorted_idx = np.argsort(score)\n    topk_idx = sorted_idx[:top_k]\n\n    # Deterministic random choice among tied minima\n    rng = np.random.default_rng(0)\n    best = rng.choice(topk_idx)\n\n    return int(candidates[best])\n\n",
  "destination_funnel_kbest_aug_310": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n    dest_cost = dist_mat[candidates, destination_node]\n\n    # Median\u2011based filtering\n    median_step = np.median(step)\n    mask = step <= (median_step + 1e-12)\n    filtered = candidates[mask]\n    if filtered.size == 0:\n        filtered = candidates\n\n    # Recompute step and dest_cost for filtered set\n    step_f = dist_mat[current_node, filtered]\n    dest_f = dist_mat[filtered, destination_node]\n\n    # Deterministic noise for tie\u2011breaking\n    noise = np.arange(filtered.size) * 1e-9\n    best_idx = int(np.argmin(dest_f + noise))\n\n    return int(filtered[best_idx])\n\n",
  "destination_funnel_kbest_aug_311": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    dist_mat = distance_matrix\n\n    step = dist_mat[current_node, candidates]\n    dest_cost = dist_mat[candidates, destination_node]\n\n    n_rem = int(candidates.size)\n    k = int(np.clip(min(7, n_rem), 2, n_rem))\n    rng = np.random.default_rng(0)\n\n    while k >= 2:\n        sorted_idx = np.argsort(step)\n        topk_idx = sorted_idx[:k]\n        # Weighted score\n        score = 0.4 * step[topk_idx] + 0.6 * dest_cost[topk_idx]\n        min_score = np.min(score)\n        # Find all indices with minimal score\n        candidates_min = topk_idx[np.isclose(score, min_score, atol=1e-12)]\n        if candidates_min.size > 0:\n            chosen = rng.choice(candidates_min)\n            return int(candidates[chosen])\n        k -= 1\n\n    # Fallback: pick minimal score among all\n    score = 0.4 * step + 0.6 * dest_cost\n    chosen = int(np.argmin(score))\n    return int(candidates[chosen])\n\n",
  "destination_divergence_penalty_aug_312": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    # Pre\u2011compute global values\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n    min_r = np.min(r)\n    best_gain = r0 - min_r\n\n    best_score = np.inf\n    best_idx = None\n    idx = 0\n    while idx < cand.size:\n        gain = r0 - r[idx]\n        divergence = best_gain - gain\n        mean_step = np.sum(step) / (cand.size + 1e-12)\n        mean_div = np.sum(divergence) / (cand.size + 1e-12)\n        score = (0.6 * (step[idx] / (mean_step + 1e-12)) +\n                 0.4 * (divergence / (mean_div + 1e-12)))\n\n        # deterministic noise for tie\u2011breaking\n        score += 1e-6 * idx\n\n        if score < best_score:\n            best_score = score\n            best_idx = idx\n        idx += 1\n\n    return int(cand[best_idx])\n\n",
  "destination_divergence_penalty_aug_313": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n    min_r = np.min(r)\n    best_gain = r0 - min_r\n\n    scores = [\n        0.5 * (step[i] / (np.max(step) + 1e-12)) +\n        0.5 * ((best_gain - (r0 - r[i])) / (np.max(step) + 1e-12))\n        for i in range(cand.size)\n    ]\n\n    # Clip to avoid extreme values\n    scores = np.clip(scores, 0, np.max(scores) * 1.1)\n\n    # Select top\u2011k indices (k=3)\n    k = min(3, cand.size)\n    top_k_idx = np.argsort(scores)[:k]\n    chosen_idx = np.random.choice(top_k_idx)\n    return int(cand[chosen_idx])\n\n",
  "destination_divergence_penalty_aug_314": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    r0 = float(distance_matrix[current_node, destination_node])\n\n    r = distance_matrix[cand, destination_node]\n    step = distance_matrix[current_node, cand]\n    min_r = np.min(r)\n    best_gain = r0 - min_r\n\n    best_score = np.inf\n    best_idx = None\n\n    for i in range(cand.size):\n        gain = r0 - r[i]\n        divergence = best_gain - gain\n        mean_step = np.sum(step) / (cand.size + 1e-12)\n        mean_div = np.sum(divergence) / (cand.size + 1e-12)\n\n        score = (0.8 * (step[i] / (mean_step + 1e-12)) +\n                 0.2 * (divergence / (mean_div + 1e-12)))\n\n        # Random noise for tie\u2011breaking\n        score += np.random.uniform(0, 1e-7)\n\n        # Clip to prevent overflow\n        score = np.clip(score, 0, np.inf)\n\n        if score < best_score:\n            best_score = score\n            best_idx = i\n\n    return int(cand[best_idx])\n\n",
  "min_congestion_cost_aug_315": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # rename for clarity\n    candidates = unvisited_nodes.astype(int)\n    # distance from current node to each candidate\n    step = distance_matrix[current_node, candidates]\n\n    # pairwise distances among candidates\n    pair_dists = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pair_dists, np.inf)\n\n    # scale based on median distance\n    scale = float(np.median(pair_dists[np.isfinite(pair_dists)])) + 1e-12\n    density = np.exp(-pair_dists / scale).sum(axis=1)\n\n    # weighted score: 60\u202f% step, 40\u202f% density\n    score = (0.6 * step) / (np.mean(step) + 1e-12) + \\\n            (0.4 * density) / (np.mean(density) + 1e-12)\n\n    # choose candidate with minimal score\n    idx = np.argmin(score)\n    return int(candidates[idx])\n\n",
  "min_congestion_cost_aug_316": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, cand]\n\n    # pairwise distances\n    pd = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pd, np.inf)\n\n    # density using median scale\n    scale = float(np.median(pd[np.isfinite(pd)])) + 1e-12\n    density = np.exp(-pd / scale).sum(axis=1)\n\n    # weight: 70\u202f% step, 30\u202f% density; use median for density denominator\n    score = 0.7 * step / (np.mean(step) + 1e-12) + \\\n            0.3 * density / (np.median(density) + 1e-12)\n\n    # deterministic tie\u2011breaker\n    noise = np.arange(len(cand)) * 1e-6\n    score += noise\n\n    # select among top\u2011k candidates\n    top_k = 7\n    top_idx = np.argpartition(score, top_k - 1)[:top_k]\n    best = top_idx[np.argmin(score[top_idx])]\n    return int(cand[best])\n\n",
  "min_congestion_cost_aug_317": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    # use squared distances to emphasize longer hops\n    step = np.square(distance_matrix[current_node, cand])\n\n    # pairwise distances\n    pd = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pd, np.inf)\n\n    # density via maximum proximity\n    scale = float(np.median(pd[np.isfinite(pd)])) + 1e-12\n    density = np.exp(-pd / scale).max(axis=1)\n\n    # balanced score\n    score = 0.5 * step / (np.mean(step) + 1e-12) + \\\n            0.5 * density / (np.mean(density) + 1e-12)\n\n    # soft\u2011min selection with temperature\n    temp = 0.5\n    probs = np.exp(-score / temp)\n    probs /= probs.sum() + 1e-12\n    chosen = np.random.choice(cand, p=probs)\n    return int(chosen)\n\n",
  "min_congestion_cost_aug_318": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    # pairwise distances\n    pd = distance_matrix[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(pd, np.inf)\n\n    scale = float(np.median(pd[np.isfinite(pd)])) + 1e-12\n    density = np.exp(-pd / scale).sum(axis=1)\n\n    # weighted score with clipping\n    score = 0.55 * step / (np.mean(step) + 1e-12) + \\\n            0.45 * density / (np.mean(density) + 1e-12)\n    score = np.clip(score, 0, np.inf)\n\n    # top\u2011k candidates and soft\u2011min over them\n    top_k = 5\n    top_idx = np.argpartition(score, top_k - 1)[:top_k]\n    sub_score = score[top_idx]\n\n    temp = 0.3\n    probs = np.exp(-sub_score / temp)\n    probs /= probs.sum() + 1e-12\n\n    chosen_idx = top_idx[np.random.choice(len(top_idx), p=probs)]\n    return int(candidates[chosen_idx])\n\n",
  "max_coverage_jump_aug_319": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    hop = distance_matrix[current_node, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    rad = float(np.percentile(finite_vals, 30)) + 1e-12\n    cover = np.sum(pair_dist <= rad, axis=1).astype(np.float64)\n\n    c_norm = cover / (np.median(cover) + 1e-12)\n    s_norm = hop / (np.median(hop) + 1e-12)\n\n    score = 0.6 * s_norm + 0.4 * c_norm\n    noise = np.arange(len(score)) * 1e-12   # deterministic tie\u2011breaker\n    return int(cand[int(np.argmin(score + noise))])\n\n",
  "max_coverage_jump_aug_320": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    hop = distance_matrix[current_node, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    rad = float(np.percentile(finite_vals, 40)) + 1e-12\n    cover = np.sum(pair_dist <= rad, axis=1).astype(np.float64)\n\n    s_norm = hop / (np.mean(hop) + 1e-12)\n    c_norm = cover / (np.sum(cover) + 1e-12)\n\n    score = 0.5 * s_norm - 0.5 * c_norm\n\n    top_k = 7\n    if top_k > len(score):\n        top_k = len(score)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = np.random.choice(top_indices)\n    return int(cand[chosen])\n\n",
  "max_coverage_jump_aug_321": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    hop = distance_matrix[current_node, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    rad = float(np.percentile(finite_vals, 25)) + 1e-12\n    cover = np.max(pair_dist <= rad, axis=1).astype(np.float64)  # 0 or 1\n\n    s_norm = hop / (np.median(hop) + 1e-12)\n    c_norm = cover / (np.mean(cover) + 1e-12)\n\n    score = 0.8 * s_norm + 0.2 * c_norm\n\n    # Soft\u2011min probability distribution\n    exp_vals = np.exp(-score - np.min(score))\n    probs = exp_vals / (np.sum(exp_vals) + 1e-12)\n    probs = np.clip(probs, 1e-12, None)\n\n    chosen = np.random.choice(len(cand), p=probs)\n    return int(cand[chosen])\n\n",
  "max_coverage_jump_aug_322": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    hop = distance_matrix[current_node, cand]\n\n    pair_dist = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(pair_dist, np.inf)\n\n    finite_vals = pair_dist[np.isfinite(pair_dist)]\n    rad = float(np.percentile(finite_vals, 35)) + 1e-12\n    cover = np.sum(pair_dist <= rad, axis=1).astype(np.float64)\n\n    s_norm = hop / (np.mean(hop) + 1e-12)\n    c_norm = cover / (np.mean(cover) + 1e-12)\n\n    score = s_norm - 0.5 * c_norm\n\n    top_k = 5\n    if top_k > len(score):\n        top_k = len(score)\n    top_indices = np.argpartition(score, top_k - 1)[:top_k]\n    chosen = top_indices[np.argmin(score[top_indices])]\n    return int(cand[chosen])\n\n",
  "robust_minimax_two_quantiles_aug_323": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    # Rename for clarity\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    # Fast exit if nothing left to visit\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Vectorised distance to remaining nodes\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    # Build distance matrix among candidates\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    # 80th percentile and max per row\n    q80 = np.percentile(D, 80, axis=1)\n    mx  = D.max(axis=1)\n\n    # Tail score \u2013 weighted blend\n    tail = 0.65 * q80 + 0.35 * mx\n\n    # Normalised scores\n    step_norm = step / (np.mean(step) + 1e-12)\n    tail_norm = tail / (np.mean(tail) + 1e-12)\n\n    # Combined score with different weights\n    score = 0.6 * step_norm + 0.4 * tail_norm\n\n    # Deterministic noise for tie breaking\n    noise = ((current_node + destination_node) % 1000) * 1e-6\n    score += noise\n\n    # Select node with minimal score\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "robust_minimax_two_quantiles_aug_324": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    q80 = np.percentile(D, 80, axis=1)\n    mx  = D.max(axis=1)\n    tail = 0.7 * q80 + 0.3 * mx\n\n    # Normalise using median to reduce influence of outliers\n    step_norm = step / (np.median(step) + 1e-12)\n    tail_norm = tail / (np.median(tail) + 1e-12)\n\n    # Weighted blend\n    raw = 0.4 * step_norm + 0.6 * tail_norm\n\n    # Softmin with temperature\n    beta = 10.0\n    exp_vals = np.exp(-raw * beta)\n    softmin = exp_vals / (exp_vals.sum() + 1e-12)\n\n    # Deterministic noise for tie breaking\n    noise = ((current_node * 31 + destination_node) % 1000) * 1e-6\n    softmin += noise\n\n    # Pick the index with minimal softmin value\n    idx = int(np.argmin(softmin))\n    return int(candidates[idx])\n\n",
  "robust_minimax_two_quantiles_aug_325": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates, candidates)].copy()\n    np.fill_diagonal(D, 0.0)\n\n    # Use 90th percentile as proxy for tail\n    q90 = np.percentile(D, 90, axis=1)\n    mx  = D.max(axis=1)\n    tail = 0.6 * q90 + 0.4 * mx\n\n    # Sum aggregation\n    step_sum = step / (np.sum(step) + 1e-12)\n    tail_sum = tail / (np.sum(tail) + 1e-12)\n\n    score = 0.5 * step_sum + 0.5 * tail_sum\n\n    # Deterministic random choice among top 7\n    top_k = 7\n    idx_sorted = np.argsort(score)\n    top_idx = idx_sorted[:top_k]\n    rng = np.random.default_rng(seed=current_node + destination_node)\n    chosen = rng.choice(top_idx)\n\n    return int(candidates[chosen])\n\n",
  "robust_minimax_two_quantiles_aug_326": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat   = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    # Build step array\n    step = np.array([dist_mat[current_node, int(c)] for c in candidates])\n\n    # Construct D via list comprehension\n    D = np.array([[dist_mat[int(a), int(b)] for b in candidates] for a in candidates])\n    np.fill_diagonal(D, 0.0)\n\n    q80 = np.percentile(D, 80, axis=1)\n    mx  = D.max(axis=1)\n    tail = 0.5 * q80 + 0.5 * mx\n\n    # Normalise with max to avoid division by zero\n    step_norm = step / (np.max(step) + 1e-12)\n    tail_norm = tail / (np.max(tail) + 1e-12)\n\n    # Weighted blend\n    raw = 0.7 * step_norm + 0.3 * tail_norm\n\n    # Softmax selection\n    exp_vals = np.exp(raw)\n    softmax = exp_vals / (np.sum(exp_vals) + 1e-12)\n\n    # Clip to avoid extreme values\n    softmax = np.clip(softmax, 0.0, 1.0)\n\n    # Deterministic noise for stability\n    noise = ((current_node * 17 + destination_node) % 1000) * 1e-6\n    softmax += noise\n\n    # Choose index with minimal softmax value\n    idx = int(np.argmin(softmax))\n    return int(candidates[idx])\n\n",
  "min_cross_cluster_pull_aug_327": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    if cand.size == 0:\n        return int(destination_node)\n\n    # step distances from current node to each candidate\n    step = distance_matrix[current_node, cand]\n\n    # nearest\u2011neighbour distances among candidates\n    sub = distance_matrix[np.ix_(cand, cand)].copy()\n    np.fill_diagonal(sub, np.inf)\n    nn = np.min(sub, axis=1)\n\n    # normalise with mean (add epsilon)\n    mean_nn = np.mean(nn) + 1e-12\n    mean_step = np.mean(step) + 1e-12\n    n_norm = nn / mean_nn\n    s_norm = step / mean_step\n\n    # clip to avoid extreme values\n    n_norm = np.clip(n_norm, 0, 1)\n    s_norm = np.clip(s_norm, 0, 1)\n\n    # scoring function with a different weight\n    score = s_norm - 0.9 * n_norm\n\n    # find minimal score using a while loop\n    best_idx = 0\n    best_val = score[0]\n    i = 1\n    while i < score.size:\n        if score[i] < best_val:\n            best_val = score[i]\n            best_idx = i\n        i += 1\n\n    return int(cand[best_idx])\n\n",
  "min_cross_cluster_pull_aug_328": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    if cand.size == 0:\n        return int(destination_node)\n\n    # step distances via list comprehension\n    step = np.array([distance_matrix[current_node, i] for i in cand])\n\n    # nearest\u2011neighbour distances using a for\u2011loop\n    nn = []\n    for i in cand:\n        dists = distance_matrix[i, cand]\n        dists = dists[dists != 0]          # ignore self\n        nn.append(np.min(dists) if dists.size > 0 else np.inf)\n    nn = np.array(nn)\n\n    # normalise with median\n    n_norm = nn / (np.median(nn) + 1e-12)\n    s_norm = step / (np.median(step) + 1e-12)\n\n    n_norm = np.clip(n_norm, 0, 1)\n    s_norm = np.clip(s_norm, 0, 1)\n\n    # deterministic noise for tie\u2011breaking\n    noise = 1e-5 * np.arange(cand.size)\n    score = s_norm - 0.8 * n_norm + noise\n\n    best_idx = int(np.argmin(score))\n    return int(cand[best_idx])\n\n",
  "destination_biased_kmedian_aug_329": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    step    = dist_mat[current_node, candidates]\n    d_dest  = dist_mat[candidates, destination_node]\n    D       = dist_mat[np.ix_(candidates, candidates)]\n    med     = np.median(D, axis=1)\n\n    # Weighted components\n    w_step = 0.6\n    w_med  = 0.25\n    w_dest = 0.15\n\n    denom_step = np.mean(step) + 1e-12\n    denom_med  = np.mean(med)  + 1e-12\n    denom_dest = np.mean(d_dest)+ 1e-12\n\n    score = (step / denom_step) \\\n          + w_med  * (med / denom_med) \\\n          + w_dest * (d_dest / denom_dest)\n\n    # Add deterministic noise to break ties\n    noise = np.arange(len(candidates)) * 1e-6\n    score = score + noise\n\n    # Clip to avoid any negative or NaN values\n    score = np.clip(score, 0, np.inf)\n\n    chosen_idx = int(np.argmin(score))\n    return int(candidates[chosen_idx])\n\n",
  "destination_biased_kmedian_aug_330": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    step   = dist_mat[current_node, candidates]\n    d_dest = dist_mat[candidates, destination_node]\n    D      = dist_mat[np.ix_(candidates, candidates)]\n    med    = np.median(D, axis=1)\n\n    # Weighted components\n    w_step = 0.5\n    w_med  = 0.3\n    w_dest = 0.2\n\n    denom_step = np.mean(step) + 1e-12\n    denom_med  = np.mean(med)  + 1e-12\n    denom_dest = np.sum(d_dest) + 1e-12\n\n    score = (step / denom_step) \\\n          + w_med  * (med / denom_med) \\\n          + w_dest * (d_dest / denom_dest)\n\n    # Clip to avoid extreme values\n    score = np.clip(score, 0, np.inf)\n\n    # Randomly pick among the top\u2011k lowest scores\n    top_k = min(5, len(score))\n    idxs = np.argpartition(score, top_k - 1)[:top_k]\n    rng = np.random.default_rng(123)\n    chosen = rng.choice(idxs)\n\n    return int(candidates[chosen])\n\n",
  "destination_biased_kmedian_aug_331": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes.astype(int)\n\n    best_score = -np.inf\n    best_idx   = -1\n\n    # Weighted components (inverted priorities)\n    w_step = 0.7\n    w_med  = 0.2\n    w_dest = 0.1\n\n    for idx, cand in enumerate(candidates):\n        step   = dist_mat[current_node, cand]\n        d_dest = dist_mat[cand, destination_node]\n        D      = dist_mat[np.ix_(candidates, candidates)]\n        med    = np.median(D, axis=1)[idx]\n\n        denom_step = np.mean(dist_mat[current_node, candidates]) + 1e-12\n        denom_med  = np.mean(med) + 1e-12\n        denom_dest = np.mean(d_dest) + 1e-12\n\n        score = (step / denom_step) \\\n              + w_med  * (med / denom_med) \\\n              + w_dest * (d_dest / denom_dest)\n\n        # Clip to keep scores sane\n        score = np.clip(score, -np.inf, np.inf)\n\n        if score > best_score:\n            best_score = score\n            best_idx   = idx\n\n    return int(candidates[best_idx])\n\n",
  "max_distance_dispersion_aug_332": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates.astype(int), candidates.astype(int))]\n\n    mu = D.mean(axis=1) + 1e-12\n    sigma = D.std(axis=1)\n    dispersion = sigma / mu\n\n    # larger dispersion is preferable\n    score = (step / (np.mean(step) + 1e-12)) - 0.75 * (dispersion / (np.mean(dispersion) + 1e-12))\n    score = np.clip(score, -1e6, 1e6)\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "max_distance_dispersion_aug_333": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates.astype(int), candidates.astype(int))]\n\n    mu = D.mean(axis=1) + 1e-12\n    sigma = D.std(axis=1)\n    dispersion = sigma / mu\n\n    # tuned weights\n    w_dist = 0.6\n    w_disp = 0.4\n\n    mean_step = np.median(step) + 1e-12\n    mean_disp = np.median(dispersion) + 1e-12\n\n    score = w_dist * (step / mean_step) - w_disp * (dispersion / mean_disp)\n\n    idx = int(np.argmin(score))\n    return int(candidates[idx])\n\n",
  "max_distance_dispersion_aug_334": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates.astype(int), candidates.astype(int))]\n\n    mu = D.mean(axis=1) + 1e-12\n    sigma = D.std(axis=1)\n    dispersion = sigma / mu\n\n    noise = 1e-6 * np.arange(candidates.size)  # deterministic tie\u2011breaker\n    mean_step = np.mean(step) + 1e-12\n    mean_disp = np.mean(dispersion) + 1e-12\n\n    score = (step / mean_step) - 0.75 * (dispersion / mean_disp) + noise\n\n    # soft\u2011min with temperature\n    temp = 0.5\n    exp_vals = np.exp(-score / temp)\n    probs = exp_vals / np.clip(exp_vals.sum(), 1e-12, None)\n\n    chosen = int(np.random.choice(candidates.astype(int), p=probs))\n    return chosen\n\n",
  "max_distance_dispersion_aug_335": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    dist_mat = distance_matrix\n    candidates = unvisited_nodes\n\n    if candidates.size == 0:\n        return int(destination_node)\n\n    step = dist_mat[current_node, candidates.astype(int)]\n\n    D = dist_mat[np.ix_(candidates.astype(int), candidates.astype(int))]\n\n    mu = D.mean(axis=1) + 1e-12\n    sigma = D.std(axis=1)\n    dispersion = sigma / mu\n\n    mean_step = np.mean(step) + 1e-12\n    mean_disp = np.mean(dispersion) + 1e-12\n\n    score = (step / mean_step) - 0.75 * (dispersion / mean_disp)\n    score = np.clip(score, -1e3, 1e3)\n\n    top_k = 5\n    if top_k > len(score):\n        top_k = len(score)\n\n    top_indices = np.argpartition(score, top_k)[:top_k]\n    top_candidates = candidates[top_indices]\n    chosen = int(np.random.choice(top_candidates.astype(int), p=None))\n    return chosen\n\n",
  "min_geodesic_deviation_aug_336": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n = int(candidates.size)\n\n    # Distances from the current node to all candidates\n    step = distance_matrix[current_node, candidates]\n    if n < 3:\n        return int(candidates[int(np.argmin(step))])\n\n    # Profile of distances from the current node to the candidates\n    pc = step - np.median(step)\n    pc_norm = np.linalg.norm(pc) + 1e-12\n\n    # Pairwise distance matrix among candidates\n    D = distance_matrix[np.ix_(candidates, candidates)]\n\n    # Vectorised correlation computation\n    pi = D - np.median(D, axis=1, keepdims=True)\n    pi_norms = np.linalg.norm(pi, axis=1) + 1e-12\n    corr = np.dot(pi, pc) / (pi_norms * pc_norm)\n\n    # Scale step and correlation using median, add small deterministic noise\n    step_scaled = step / (np.median(step) + 1e-12)\n    corr_scaled = (1.0 - corr) / (np.median(1.0 - corr) + 1e-12)\n    noise = 1e-8 * np.arange(n)\n\n    score = step_scaled + 0.35 * corr_scaled + noise\n    return int(candidates[int(np.argmin(score))])\n\n",
  "min_geodesic_deviation_aug_337": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n = int(candidates.size)\n\n    step = distance_matrix[current_node, candidates]\n    if n < 3:\n        return int(candidates[int(np.argmin(step))])\n\n    pc = step - np.mean(step)\n    pc_norm = np.linalg.norm(pc) + 1e-12\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    corr = np.empty(n, dtype=np.float64)\n\n    i = 0\n    while i < n:\n        pi = D[i] - np.mean(D[i])\n        denom = np.linalg.norm(pi) * pc_norm + 1e-12\n        corr[i] = np.dot(pi, pc) / denom\n        i += 1\n\n    # Softmin with lambda = 5.0\n    scores = (step / (np.mean(step) + 1e-12)) + 0.35 * ((1.0 - corr) / (np.mean(1.0 - corr) + 1e-12))\n    probs = np.exp(-5.0 * scores)\n    probs /= np.clip(probs.sum(), 1e-12, None)\n\n    # Randomly choose among the top 5 lowest scores\n    top_k = min(5, n)\n    top_indices = np.argsort(scores)[:top_k]\n    chosen = np.random.choice(top_indices, p=probs[top_indices] / np.clip(probs[top_indices].sum(), 1e-12, None))\n    return int(candidates[int(chosen)])\n\n",
  "min_geodesic_deviation_aug_338": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    candidates = unvisited_nodes.astype(int)\n    n = int(candidates.size)\n\n    step = distance_matrix[current_node, candidates]\n    if n < 3:\n        return int(candidates[int(np.argmin(step))])\n\n    pc = step - np.mean(step)\n    pc_norm = np.linalg.norm(pc) + 1e-12\n\n    D = distance_matrix[np.ix_(candidates, candidates)]\n    pi = D - np.mean(D, axis=1, keepdims=True)\n    pi_norms = np.linalg.norm(pi, axis=1) + 1e-12\n    corr = np.dot(pi, pc) / (pi_norms * pc_norm)\n\n    # Ensure correlation stays within [-1, 1]\n    corr = np.clip(corr, -1.0, 1.0)\n\n    step_scaled = step / (np.mean(step) + 1e-12)\n    corr_scaled = (1.0 - corr) / (np.mean(1.0 - corr) + 1e-12)\n\n    score = step_scaled + 0.35 * corr_scaled\n\n    # Randomly pick one of the best 7 candidates\n    top_k = min(7, n)\n    top_indices = np.argsort(score)[:top_k]\n    chosen = np.random.choice(top_indices)\n    return int(candidates[int(chosen)])\n\n",
  "destination_intercept_ratio_aug_339": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, candidates]\n    r = distance_matrix[candidates, destination_node]\n\n    gain = np.maximum(1e-12, r0 - r)\n    ratio = step / np.clip(gain, 1e-12, None)\n\n    # If no positive gain, fallback to the shortest step.\n    if np.all(r0 - r <= 1e-12):\n        return int(candidates[np.argmin(step)])\n\n    # Add small deterministic noise for tie\u2011breaking.\n    noise = np.linspace(0, 1e-9, step.size)\n    ratio = ratio + noise\n\n    # Clip ratio to avoid extreme values.\n    ratio = np.clip(ratio, 0, 1e6)\n\n    return int(candidates[np.argmin(ratio)])\n\n",
  "destination_intercept_ratio_aug_340": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    candidates = unvisited_nodes.astype(int)\n    if candidates.size == 0:\n        return int(destination_node)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    ratios = []\n    steps = []\n\n    for idx in candidates:\n        step = distance_matrix[current_node, idx]\n        r = distance_matrix[idx, destination_node]\n        gain = np.maximum(1e-12, r0 - r)\n        ratio = step / np.clip(gain, 1e-12, None)\n        ratios.append(ratio)\n        steps.append(step)\n\n    ratios = np.array(ratios)\n    steps = np.array(steps)\n\n    if np.all(r0 - distance_matrix[candidates, destination_node] <= 1e-12):\n        return int(candidates[np.argmin(steps)])\n\n    # Randomly choose among the top\u2011k smallest ratios.\n    top_k = 5\n    idx_sorted = np.argsort(ratios)\n    top_indices = idx_sorted[:top_k]\n    chosen = np.random.choice(top_indices)\n    return int(candidates[chosen])\n\n",
  "destination_intercept_ratio_aug_341": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    if cand.size == 0:\n        return int(destination_node)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, cand]\n    r = distance_matrix[cand, destination_node]\n    gain = np.maximum(1e-12, r0 - r)\n    ratio = step / np.clip(gain, 1e-12, None)\n\n    if np.all(r0 - r <= 1e-12):\n        return int(cand[np.argmin(step)])\n\n    # Use median ratio as a threshold.\n    median_ratio = np.median(ratio)\n    mask = ratio <= median_ratio\n\n    if np.any(mask):\n        sub_steps = step[mask]\n        sub_cand = cand[mask]\n        return int(sub_cand[np.argmin(sub_steps)])\n    else:\n        return int(cand[np.argmin(ratio)])\n\n",
  "destination_intercept_ratio_aug_342": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    cand = unvisited_nodes.astype(int)\n    if cand.size == 0:\n        return int(destination_node)\n\n    r0 = float(distance_matrix[current_node, destination_node])\n    step = distance_matrix[current_node, cand]\n    r = distance_matrix[cand, destination_node]\n    gain = np.maximum(1e-12, r0 - r)\n\n    # Weighted combination of distance and gain.\n    w_dist = 0.6\n    w_gain = 0.4\n    score = w_dist * step + w_gain * (r0 - r)\n\n    # Add deterministic noise for tie\u2011breaking.\n    noise = np.linspace(0, 1e-9, step.size)\n    score = score + noise\n\n    # Clip score to avoid extreme values.\n    score = np.clip(score, 0, 1e6)\n\n    return int(cand[np.argmin(score)])\n\n",
  "late_stage_endgame_lock_aug_343": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Rename variables for clarity\n    cand = unvisited_nodes.astype(int)\n    n = cand.size\n\n    # Current step distance and distance to the final destination\n    step   = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Small epsilon to avoid division by zero\n    eps = 1e-12\n\n    if n <= 6:\n        D = distance_matrix[np.ix_(cand, cand)].copy()\n        np.fill_diagonal(D, np.inf)\n        future = np.min(D + d_dest[None, :], axis=1)\n        score = step + future\n    else:\n        # Moderate pull towards the destination\n        score = step + 0.85 * d_dest\n\n    # Clip to safe bounds and add a tiny deterministic noise for tie\u2011breaking\n    score = np.clip(score, 0, 1e9)\n    rng   = np.random.default_rng(42)\n    noise = rng.uniform(-1e-6, 1e-6, size=score.shape)\n    score += noise\n\n    # Soft\u2011min weighting (used only for stability, final choice is still argmin)\n    tau = 1.0\n    exp_neg = np.exp(-score / (tau + eps))\n    softmin = exp_neg / (np.sum(exp_neg) + eps)\n\n    # Return the index of the best candidate\n    idx = int(np.argmin(score))\n    return int(cand[idx])\n\n",
  "late_stage_endgame_lock_aug_344": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    n    = cand.size\n\n    step   = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    # Adjusted threshold and weight\n    if n <= 8:\n        D = distance_matrix[np.ix_(cand, cand)].copy()\n        np.fill_diagonal(D, np.inf)\n        future = np.min(D + d_dest[None, :], axis=1)\n        score  = step + future\n    else:\n        score = step + 0.75 * d_dest   # new weight\n\n    # Clip to avoid extreme values\n    score = np.clip(score, 0, 1e9)\n\n    # Deterministic noise for stable tie\u2011breaking\n    rng   = np.random.default_rng(123)\n    noise = rng.uniform(-5e-7, 5e-7, size=score.shape)\n    score += noise\n\n    # Randomly pick one of the top\u2011k smallest scores\n    top_k = 5\n    k     = min(top_k, score.size)\n    top_indices = np.argpartition(score, k - 1)[:k]\n    chosen = rng.choice(top_indices)\n\n    return int(cand[chosen])\n\n",
  "late_stage_endgame_lock_aug_345": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    cand = unvisited_nodes.astype(int)\n    n    = cand.size\n\n    step   = distance_matrix[current_node, cand]\n    d_dest = distance_matrix[cand, destination_node]\n\n    if n <= 6:\n        D = distance_matrix[np.ix_(cand, cand)].copy()\n        np.fill_diagonal(D, np.inf)\n        future = np.median(D + d_dest[None, :], axis=1)   # median instead of min\n        score  = step + future\n    else:\n        median_dest = np.median(d_dest)\n        score = step + 0.8 * median_dest   # use median as proxy\n\n    # Clip to keep values within a reasonable range\n    score = np.clip(score, 0, 1e9)\n\n    # Deterministic noise for reproducible tie\u2011breaking\n    rng   = np.random.default_rng(7)\n    noise = rng.uniform(-2e-6, 2e-6, size=score.shape)\n    score += noise\n\n    idx = int(np.argmin(score))\n    return int(cand[idx])\n\n",
  "late_stage_endgame_lock_aug_346": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    nodes = unvisited_nodes.astype(int)\n    m     = nodes.size\n\n    step      = distance_matrix[current_node, nodes]\n    d_to_dest = distance_matrix[nodes, destination_node]\n\n    eps = 1e-12\n    # Exhaustive search with a different aggregator\n    if m <= 7:\n        D = distance_matrix[np.ix_(nodes, nodes)].copy()\n        np.fill_diagonal(D, np.inf)\n        future = np.max(D + d_to_dest[None, :], axis=1)   # use max instead of min\n        score  = step + future\n    else:\n        # Division by (1 + destination distance) with epsilon\n        score = step / (1.0 + d_to_dest + eps)\n        score = score * 1.5   # scaling factor\n\n    # Clip to avoid overflow\n    score = np.clip(score, 0, 1e9)\n\n    # Deterministic small noise\n    rng   = np.random.default_rng(99)\n    noise = rng.uniform(-1e-6, 1e-6, size=score.shape)\n    score += noise\n\n    # Randomly choose among the top\u2011k smallest scores\n    top_k = 4\n    k     = min(top_k, score.size)\n    smallest = np.argpartition(score, k - 1)[:k]\n    chosen   = rng.choice(smallest)\n\n    return int(nodes[chosen])\n\n",
  "edge_contrast_balancer_aug_347": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Syntactic rewrite: renamed variables\n    candidates = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, candidates]\n\n    # Compute the median distance matrix among the candidates\n    sub_mat = distance_matrix[np.ix_(candidates, candidates)]\n    med = np.median(sub_mat, axis=1)\n\n    # Scoring: absolute difference normalised by its mean\n    diff = np.abs(step - med)\n    denom = np.mean(diff) + 1e-12          # epsilon to avoid division by zero\n\n    # Deterministic tie\u2011breaker: small increasing noise\n    noise = 1e-6 * np.arange(diff.size)\n    score = diff / denom + noise\n\n    # Greedy choice\n    return int(candidates[np.argmin(score)])\n\n",
  "edge_contrast_balancer_aug_348": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Variable renaming and vectorised operations\n    nodes = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, nodes]\n    sub = distance_matrix[np.ix_(nodes, nodes)]\n    med = np.median(sub, axis=1)\n\n    # Parameter tuning: weighted scoring\n    diff = np.abs(step - med)\n    score = 0.6 * diff + 0.4 * step          # 0.6*diff + 0.4*step\n\n    # Top\u2011k selection with softmin probability\n    top_k = 7\n    if score.size > top_k:\n        top_idx = np.argpartition(score, top_k)[:top_k]\n        top_scores = score[top_idx]\n        tau = 0.5\n        probs = np.exp(-top_scores / tau)\n        probs /= np.clip(np.sum(probs), 1e-12, None)   # epsilon in denominator\n        chosen = np.random.choice(top_idx, p=probs)\n        return int(nodes[chosen])\n    else:\n        return int(nodes[np.argmin(score)])\n\n",
  "edge_contrast_balancer_aug_349": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    if unvisited_nodes.size == 0:\n        return int(destination_node)\n\n    # Clean variable names\n    nodes = unvisited_nodes.astype(int)\n    step = distance_matrix[current_node, nodes]\n    sub = distance_matrix[np.ix_(nodes, nodes)]\n    med = np.median(sub, axis=1)\n\n    # Median\u2011based normalisation\n    diff = np.abs(step - med)\n    denom = np.median(diff) + 1e-12\n    score = diff / denom\n\n    # Deterministic noise to break ties\n    noise = 1e-7 * np.arange(score.size)\n    score += noise\n\n    # Softmin selection with tau=1.0\n    tau = 1.0\n    weights = np.exp(-score / tau)\n    weights /= np.clip(np.sum(weights), 1e-12, None)   # epsilon in denominator\n    idx = np.random.choice(score.size, p=weights)\n    return int(nodes[idx])\n\n",
  "edge_contrast_balancer_aug_350": "import numpy as np\n\ndef select_next_node(current_node: int, destination_node: int, unvisited_nodes: np.ndarray, distance_matrix: np.ndarray) -> int:\n    def _inner():\n        if unvisited_nodes.size == 0:\n            return destination_node\n        # List\u2011comprehension style variable creation\n        cand = [int(v) for v in unvisited_nodes]\n        step = [distance_matrix[current_node, v] for v in cand]\n        sub = distance_matrix[np.ix_(cand, cand)]\n        med = [np.median(sub[i]) for i in range(len(cand))]\n        diff = [abs(s - m) for s, m in zip(step, med)]\n\n        # Use np.max for normalisation\n        denom = np.max(diff) + 1e-12\n        score = [d / denom for d in diff]\n\n        # Deterministic noise for tie\u2011breaking\n        noise = [1e-6 * i for i in range(len(score))]\n        score = [s + n for s, n in zip(score, noise)]\n\n        return cand[np.argmin(score)]\n\n    return int(_inner())\n\n"
}
