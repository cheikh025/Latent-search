{
 "EoH": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n  \"\"\"Returns priority with which we want to add item to each bin.\n  Args:\n    item: Size of item to be added to the bin.\n    bins: Array of capacities for each bin.\n  Return:\n    Array of same size as bins with priority score of each bin.\n  \"\"\"\n  return 1 / (bins + 1e-8) / (bins / (bins + item))\n\n",
 "funsearch": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n  \"\"\"Returns priority with which we want to add item to each bin.\n  Args:\n    item: Size of item to be added to the bin.\n    bins: Array of capacities for each bin.\n  Return:\n    Array of same size as bins with priority score of each bin.\n  \"\"\"\n  return item - bins\n\n",
 "mctsahd": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n  \"\"\"Returns priority with which we want to add item to each bin.\n  Args:\n    item: Size of item to be added to the bin.\n    bins: Array of capacities for each bin.\n  Return:\n    Array of same size as bins with priority score of each bin.\n  \"\"\"\n  if item <= 0:\n    return np.ones_like(bins) * 1e-8\n  \n  scaled_bins = bins / item\n  \n  # Dynamic sharpness of Lorentzian peak using sigmoid based on item size\n  max_ratio = 1.4\n  min_ratio = 0.7\n  base_width = 0.4\n  sensitivity_factor = 1.0 + 0.5 * np.log1p(1.0 / (1.0 + np.exp(-2 * (item - 1.0))))\n  width = base_width * sensitivity_factor\n  \n  # Lorentzian kernel with adaptive width\n  lorentzian_kernel = 1.0 / (1.0 + ((scaled_bins - 1.0) / width) ** 2)\n  \n  # Fixed threshold to suppress extreme deviations\n  threshold_factor = 0.8\n  lorentzian_kernel = lorentzian_kernel * threshold_factor\n  \n  # Cosine modulation to break symmetry and add oscillation\n  phase_shift = np.pi * (scaled_bins - 0.5)\n  cosine_modulation = np.cos(phase_shift + np.pi / 6) * 0.15\n  modulated = lorentzian_kernel + cosine_modulation\n  \n  # Symmetric entropy regularization based on distance from median ratio\n  median_ratio = np.median(scaled_bins)\n  entropy_term = np.clip(1.0 / (1.0 + 0.4 * (np.abs(scaled_bins - median_ratio) / 0.4) ** 2), 0.4, 1.0)\n  final = modulated * entropy_term\n  \n  # Clamp to ensure positive values and minimal baseline\n  return np.clip(final + 1e-8, 1e-8, 1.0)\n\n",
 "reevo": "\nimport numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n  \"\"\"Returns priority with which we want to add item to each bin.\n  Args:\n    item: Size of item to be added to the bin.\n    bins: Array of capacities for each bin.\n  Return:\n    Array of same size as bins with priority score of each bin.\n  \"\"\"\n  residual_capacity = bins - item\n  feasible_residues = np.clip(residual_capacity, 0, None)\n  \n  if np.any(feasible_residues > 0):\n    # Use inverse of residual capacity to prioritize bins with smaller remaining space\n    # This ensures bins with more space get lower priority (less preferred) and vice versa\n    # Normalize to balance priorities and avoid bias from large gaps\n    inverse_residues = 1.0 / (feasible_residues + 1e-8)\n    normalized_priority = inverse_residues / inverse_residues.sum()\n    priority = normalized_priority\n  else:\n    priority = np.zeros_like(bins)\n  \n  return priority\n\n",
 "LHS": "import numpy as np\n\ndef priority(item: float, bins: np.ndarray) -> np.ndarray:\n  a = bins.copy().astype(float)\n  a[a < item] = -np.inf\n  return -np.clip(a, 0, None)\n\n"
 
}